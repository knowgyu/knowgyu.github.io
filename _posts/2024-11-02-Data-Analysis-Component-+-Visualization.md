---
title: "Data Analysis Component + Visualization"
author: knowgyu
description: " "
date: 2023-12-09 09:43:01 +0900
math: true
categories: [MLOps, 4-Kubeflow-Pipeline-YOLOv8]
tags: [MLOps, Kubeflow]
---

ë³¸ ë¬¸ì„œì—ì„œëŠ” í•™ìŠµ ì „ ë°ì´í„°ì…‹ ë¶„ì„ì„ ìœ„í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ íŒŒì¼ ìˆ˜ì™€ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ jsoní˜•íƒœë¡œ ì €ì¥í•˜ê³ , Kubeflow UIë¥¼ í†µí•´ ì‹œê°í™”í•˜ëŠ” ê²ƒì„ ë‹¤ë£¹ë‹ˆë‹¤.

# Data Analysis

---

MLëª¨ë¸ì„ í•™ìŠµí•  ë•Œ, ë°ì´í„°ì…‹ì€ ë§¤ìš° ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ë°ì´í„°ì— ì˜í•´ MLëª¨ë¸ì˜ ì„±ëŠ¥ ì €í•˜ê°€ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” ë¬¸ì œì ë“¤ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

- ì‘ì€ í¬ê¸°ì˜ ë°ì´í„°ì…‹
- ì…ë ¥ ì´ë¯¸ì§€ì˜ í¬ê¸°
- (ìƒëŒ€ì ìœ¼ë¡œ) ì‘ì€ ì¸ìŠ¤í„´ìŠ¤ : ì…ë ¥ ì´ë¯¸ì§€ ë‚´ì— ë¼ë²¨ë§ë˜ëŠ” ê°ì²´ê°€ ì‘ì€ ê²½ìš°
- ê²¹ì³ìˆëŠ” ì¸ìŠ¤í„´ìŠ¤
- ë¶€ì •í™•í•œ ë°”ìš´ë”© ë°•ìŠ¤
- í´ë˜ìŠ¤ ë¶ˆê· í˜•

ìœ„ ë¬¸ì œë“¤ ì™¸ì—ë„ ë°ì´í„°ì— ì˜í•œ MLëª¨ë¸ ì„±ëŠ¥ ì €í•˜ëŠ” ë‹¤ì–‘í•œ ì›ì¸ìœ¼ë¡œ ë°œìƒí•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ë°ì´í„°ì…‹ì˜ ë¬¸ì œë¥¼ í•´ê²° í˜¹ì€ ë°ì´í„°ì…‹ì„ ë”ìš± ì˜ ì´í•´í•˜ê¸° ìœ„í•´ CDA, EDAì™€ ê°™ì€ ë°ì´í„° ë¶„ì„ ê¸°ë²•ì´ ì¡´ì¬í•©ë‹ˆë‹¤.

ë¬´ìˆ˜íˆ ë§ì€ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  ì´í•´í•˜ê¸° ìœ„í•´ì„œ ì‹œê°í™”ëŠ” ë§¤ìš° ì¤‘ìš”í•œ ì‚¬í•­ì…ë‹ˆë‹¤.

ì´ë¥¼ ìœ„í•´ ë³¸ í˜ì´ì§€ì—ì„œëŠ” íŒŒì´í”„ë¼ì¸ Configë¡œ ì…ë ¥ë°›ì€ `data-custom.yaml` ì—ì„œ ë°ì´í„°ì…‹ì˜ ìœ„ì¹˜ì™€ í´ë˜ìŠ¤ ì´ë¦„ì„ í™•ì¸í•˜ê³ , í•´ë‹¹ ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ë³„ ì´ë¯¸ì§€ íŒŒì¼ì˜ ìˆ˜ì™€ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ Kubeflow Dashboard UIë¥¼ ì´ìš©í•´ ì‹œê°í™”í•˜ê² ìŠµë‹ˆë‹¤.

## Pipeline Visualization

---

Kubeflow ëŒ€ì‹œë³´ë“œì˜ Runsì—ì„œ ì‹¤í–‰ëœ íŒŒì´í”„ë¼ì¸ì˜ ì§„í–‰ì‚¬í•­ê³¼ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê·¸ë˜í”„ì—ì„œ ì‹¤í–‰ëœ ì»´í¬ë„ŒíŠ¸ë¥¼ ëˆ„ë¥´ë©´ ì»´í¬ë„ŒíŠ¸ì˜ ì…ì¶œë ¥, Logs, Visualizationê³¼ ê°™ì€ ì‹¤í–‰ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ ì¤‘, Visualization ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ ì»´í¬ë„ŒíŠ¸ì—ì„œ ìƒì„±ëœ Plotì„ í™•ì¸í•˜ê² ìŠµë‹ˆë‹¤.

> [https://mlops-for-all.github.io/docs/kubeflow/advanced-run](https://mlops-for-all.github.io/docs/kubeflow/advanced-run)
> 

### ì‹œê°í™” ì˜ˆì‹œ

`mlpipeline_ui_metadata: OutputPath("UI_Metadata")` argumentì— html í¬ë§·ìœ¼ë¡œ ì €ì¥í•´ plotì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
@partial(
    create_component_from_func,
    packages_to_install=["matplotlib"],
)
def plot_linear(
    mlpipeline_ui_metadata: OutputPath("UI_Metadata")
):
    import base64
    import json
    from io import BytesIO

    import matplotlib.pyplot as plt

    plt.plot(x=[1, 2, 3], y=[1, 2,3])

    tmpfile = BytesIO()
    plt.savefig(tmpfile, format="png")
    encoded = base64.b64encode(tmpfile.getvalue()).decode("utf-8")

    html = f"<img src='data:image/png;base64,{encoded}'>"
    metadata = {
        "outputs": [
            {
                "type": "web-app",
                "storage": "inline",
                "source": html,
            },
        ],
    }
    with open(mlpipeline_ui_metadata, "w") as html_writer:
        json.dump(metadata, html_writer)
```

ğŸ’¡ Kubeflow Pipeline UIì—ì„œ ì‹œê°í™”ë¥¼ í•˜ê¸° ìœ„í•´ ì•„í‹°íŒ©íŠ¸ì˜ ì´ë¦„ì€ ë°˜ë“œì‹œ `mlpipeline-ui-metadata` ë¡œ ì§€ì •í•´ì•¼í•©ë‹ˆë‹¤.


> For KFP v1, the pipeline component must write a JSON file specifying metadata for the output viewer(s) that you want to use for visualizing the results. The component must also export a file output artifact with an artifact name ofÂ `mlpipeline-ui-metadata`, or else the Kubeflow Pipelines UI will not render the visualization. In other words, theÂ `.outputs.artifacts`Â setting for the generated pipeline component should show:Â `- {name: mlpipeline-ui-metadata, path: /mlpipeline-ui-metadata.json}`. The JSON filepath does not matter, althoughÂ `/mlpipeline-ui-metadata.json`Â is used for consistency in the examples below.

- ì‹¤í–‰ ê²°ê³¼

![ëª¨ë‘ë¥¼ ìœ„í•œ MLOps https://mlops-for-all.github.io/docs/kubeflow/advanced-run](/assets/img/kubeflow/kubeyolo301.png)


## Data distribution

---

ìœ„ ê¸°ëŠ¥ì„ ì´ìš©í•´ Plotí•˜ê¸° ì „, `data-custom.yaml`ì„ ì½ê³ , í´ë˜ìŠ¤ ì´ë¦„ê³¼ ë°ì´í„°ì…‹ì˜ í´ë˜ìŠ¤ë³„ ë¶„í¬ë¥¼ ë¶„ì„í•˜ê² ìŠµë‹ˆë‹¤.


- `data-custom.yaml`

```python
# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
# Default path is '/data/datasets'
# To edit default path check this link "https://docs.ultralytics.com/quickstart/#inspecting-settings"
train: custom_train.txt
val: custom_test.txt

# number of classes
nc: 5

# class names
names: [ 'cat', 'dog', 'orange', 'person', 'glasses' ]
```

### ë°ì´í„° ë¶„í¬ ë¶„ì„ ì»´í¬ë„ŒíŠ¸

- `get_data_distribution_op`(1/2)

```python
def get_data_distribution_op(
    data_yaml: str,
    mlpipeline_metrics_path: OutputPath("Metrics"), # Unused
    result_json_path: OutputPath("json"),
    cls_names_json_path: OutputPath("json"),
    ):
    import os
    import yaml
    import json
    from collections import defaultdict
    from tqdm import tqdm
    from ultralytics import settings
    
    yolo_default_dir = settings['datasets_dir']
    
    # Read yaml and Get train.txt path
    with open(data_yaml, 'r', encoding='utf-8') as file:
        data = yaml.safe_load(file)
        train_txt_rel_path = data['train']
        train_txt_abs_path = yolo_default_dir + '/' + train_txt_rel_path
        
        # Get Class names from yaml file
        cls_names = data['names']
        print('cls_names:',cls_names)
        
        cls_dict = {i: cls_names[i] for i in range(len(cls_names))}

        
    # Read train.txt and Get dataset path
    with open(train_txt_abs_path, 'r', encoding='utf-8') as file:
        line = file.readline().strip()
        dir = os.path.dirname(line)
        
        # if folders are nested, dirname func may not work as desired
        folders = dir.split(os.path.sep)
        print(folders)
        
        dataset_dir = os.path.join(yolo_default_dir, folders[1])
```

ìœ„ í•¨ìˆ˜ì˜ ArgsëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

- `data_yaml` : íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œ ì…ë ¥ë°›ì€ ë°ì´í„°ì…‹ êµ¬ì„± ì •ë³´ë¥¼ ë‹´ì€ yamlíŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤.
- `mlpipeline_metrics_path` : ì•„ì§ êµ¬í˜„í•˜ì§€ ì•Šì€ ê¸°ëŠ¥ì…ë‹ˆë‹¤.(metricsê¸°ëŠ¥ì„ ì´ìš© í‘œë¡œ ë‚˜íƒ€ë‚¼ ì˜ˆì •)
- `result_json_path` : jsoní˜•íƒœì˜ íŒŒì¼ì„ plot ì»´í¬ë„ŒíŠ¸ë¡œ ë³´ë‚´ê¸° ìœ„í•œ ì¸ìì…ë‹ˆë‹¤.
- `cls_names_json_path` : jsoní˜•íƒœì˜ íŒŒì¼ì„ plot ì»´í¬ë„ŒíŠ¸ë¡œ ë³´ë‚´ê¸° ìœ„í•œ ì¸ìì…ë‹ˆë‹¤.

ìœ„ ì½”ë“œ ìŠ¤ë‹ˆí«ì€ ì…ë ¥ë°›ì€ yamlíŒŒì¼ì„ ì½ì–´ í•™ìŠµí•˜ë ¤ëŠ” íŒŒì¼ë“¤ì˜ ê²½ë¡œê°€ ë‹´ê¸´ `train.txt` íŒŒì¼ì˜ ìœ„ì¹˜ë¥¼ ì°¾ê³ , `train.txt` ì˜ ì²«ë²ˆì§¸ ì¤„ì„ ì½ì–´ ë°ì´í„°ì…‹ì˜ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤. ë˜í•œ, yamlíŒŒì¼ë¡œë¶€í„° í´ë˜ìŠ¤ ì´ë¦„ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤.

> `train.txt` ëŠ” `./coco128/025324.jpg` ì™€ ê°™ì´ `./` ë¥¼ í¬í•¨í•´ì•¼í•©ë‹ˆë‹¤.<br>
> `./animal/cat/siamesecat/029384.jpg` ì™€ ê°™ì´ ì¤‘ì²©ëœ í´ë”ì¼ ê²½ìš° `dir.split(os.path.sep)` ì„ ì´ìš©í•´ `./animal` ì˜ í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤.
{: .prompt-tip }

- `get_data_distribution_op`(2/2)

```python
# Search txt files and count imgs and instances per class
    cls_files = defaultdict(set)
    class_instances = defaultdict(int)
    
    for root, _, files in tqdm(os.walk(dataset_dir)):
        for filename in files:
            if filename.endswith('.txt'):
                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:
                    for line in f.readlines():
                        try:
                            cls_id = int(line.split()[0])
                        
                        except ValueError:
                            continue
                        
                        cls_files[cls_id].add(filename)
                        class_instances[cls_id] += 1
                        
    class_imgs = {k:len(cls_files[k]) for k in sorted(cls_files.keys())}
    class_instances = {k:v for k,v in sorted(class_instances.items())}
    
    result_dict = {key: {'img': class_imgs[key], 'instances': class_instances[key]} for key in class_instances}
    
    print('Result dict\n',result_dict)
    print('Class name dict\n',cls_dict)

    with open(result_json_path, 'w', encoding='utf-8') as f:
        json.dump(result_dict, f)
        
    with open(cls_names_json_path, 'w', encoding='utf-8') as f:
        json.dump(cls_dict, f)
    
    # Unused
    with open(mlpipeline_metrics_path, 'w', encoding='utf-8') as f:
        json.dump(result_dict, f)
```

ë°ì´í„°ì…‹ì˜ ê²½ë¡œë¥¼ ì°¾ì•˜ë‹¤ë©´, í•´ë‹¹ ë°ì´í„°ì…‹ì„ ìˆœíšŒí•˜ë©° í´ë˜ìŠ¤ ë³„ íŒŒì¼ ìˆ˜ì™€ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

`result_dict` ì™€ `cls_dict` ì˜ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ ì €ì¥ë©ë‹ˆë‹¤.

```python
# result_dict
{"0": {"img": 62, "instances": 261}, "1": {"img": 3, "instances": 6}, "2": {"img": 13, "instances": 48}, "3": {"img": 5, "instances": 6}, ...

# cls_dict
{"0": "person", "1": "bicycle", "2": "car", "3": "motorcycle", "4": "airplane", "5": "bus", "6": "train", "7": "truck",
```

ìœ„ì™€ ê°™ì´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥í–ˆë‹¤ë©´, Jsoní˜•íƒœë¡œ ì €ì¥í•´ ë‹¤ìŒ ì»´í¬ë„ŒíŠ¸ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.

- ì‹¤í–‰ ê²°ê³¼

![Untitled](/assets/img/kubeflow/kubeyolo302.png)

### ë°ì´í„° Plot ì»´í¬ë„ŒíŠ¸

- `plot_data_distribution_op` (1/2)

```python
def plot_data_distribution_op(
    result_json_path: InputPath("json"),
    cls_names_json_path: InputPath("json"),
    mlpipeline_ui_metadata: OutputPath("UI_Metadata"),
    ) -> bool:
    import os
    from collections import defaultdict
    from tqdm import tqdm
    import json
    
    import base64
    from io import BytesIO
    import matplotlib.pyplot as plt
    
    import pandas as pd
    import seaborn as sns
    from matplotlib.ticker import MultipleLocator

    # Load data from JSON
    with open(result_json_path, 'r', encoding='utf-8') as f:
        result_dict = json.load(f)
    
    with open(cls_names_json_path, 'r', encoding='utf-8') as f:
        cls_dict = json.load(f)
        
    result_dict = {int(key): value for key, value in result_dict.items()}
    cls_dict = {int(key): value for key, value in cls_dict.items()}
    print('result dict\n',result_dict)
    print('cls_dict\n',cls_dict)

    # Convert data to DataFrame
    df = pd.DataFrame(list(result_dict.items()), columns=['Classes', 'Values'], index=result_dict.keys())
    df_values = pd.json_normalize(df['Values'])
    df = pd.concat([df.drop('Values', axis=1), df_values], axis=1)
    df_melted = pd.melt(df, id_vars=['Classes'], value_vars=['img', 'instances'], var_name='Category', value_name='Values')
    df_melted['Classes'] = df_melted['Classes'].map(cls_dict)
```

ìœ„ í•¨ìˆ˜ì˜ Argsë“¤ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

- `result_json_path` : ë°ì´í„° ë¶„ì„ ì»´í¬ë„ŒíŠ¸ì—ì„œ ìƒì„±í•œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë³„ ì´ë¯¸ì§€ìˆ˜ì™€ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ ë‹´ì€ Jsonì„ ë°›ì•„ì˜µë‹ˆë‹¤.
- `cls_names_json_path` : ë°ì´í„° ë¶„ì„ ì»´í¬ë„ŒíŠ¸ì—ì„œ ìƒì„±í•œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë³„ í´ë˜ìŠ¤ ì´ë¦„ì„ ë‹´ì€ Jsonì„ ë°›ì•„ì˜µë‹ˆë‹¤.
- `mlpipeline_ui_metadata` : Kubeflow Pipeline UIì— ì‹œê°í™”í•˜ê¸°ìœ„í•œ HTMLì„ ë°˜í™˜í•©ë‹ˆë‹¤.

ìœ„ ì½”ë“œ ìŠ¤ë‹ˆí«ì€ ë°ì´í„° ë¶„í¬ ë¶„ì„ ì»´í¬ë„ŒíŠ¸ì—ì„œ ë°›ì€ JsoníŒŒì¼ì„ í†µí•´ ë°›ì•„ì˜¨ í›„, `result_dict`ì™€ `cls_dict`í˜•íƒœë¡œ ì €ì¥í•©ë‹ˆë‹¤.

ê·¸ í›„, matplotlibë¡œ Plotí•˜ê¸° ì „, `pandas` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì´ìš©í•´ `DataFrame` í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

<aside>
ğŸ’¡ `result_dict = {int(key): value for key, value in result_dict.items()}` 
ìœ„ ì½”ë“œì˜ ê²½ìš° ì´ì „ ì»´í¬ë„ŒíŠ¸ì—ì„œ Jsoní˜•íƒœë¡œ ë”•ì…”ë„ˆë¦¬ë¥¼ ê°€ì ¸ì˜¬ ë•Œ, keyê°’ì´ Stringìœ¼ë¡œ ë°”ë€Œì–´ ì €ì¥ë˜ì—ˆëŠ”ë°, Plotí•˜ëŠ” ì½”ë“œì—ì„œ keyê°’ì„ intë¡œ ì²˜ë¦¬í•˜ê¸°ì— í˜•ë³€í™˜í•˜ì˜€ìŠµë‹ˆë‹¤.

</aside>

```python
# Plotting
...
    # Save plot as image and encode to base64
    tmpfile = BytesIO()
    plt.savefig(tmpfile, format='png')
    encoded = base64.b64encode(tmpfile.getvalue()).decode("utf-8")

    # Create HTML string
    html = f"<img src='data:image/png;base64,{encoded}'>"

    # Define metadata for the web app
    metadata = {
        "outputs": [
            {
                "type": "web-app",
                "storage": "inline",
                "source": html,
            },
        ],
    }

    # Save metadata to file
    with open(mlpipeline_ui_metadata, "w") as html_writer:
        json.dump(metadata, html_writer)
        
    return True
```

Plotí•˜ëŠ” ê³¼ì •ì€ ìƒëµí•˜ì˜€ìŠµë‹ˆë‹¤.

Plot í›„ â€˜pngâ€™í˜•íƒœë¡œ ì €ì¥ â†’ HTMLë¡œ ë³€í™˜í•´ `mlpipeline_ui_metadata`ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

- ì‹¤í–‰ ê²°ê³¼

![Untitled](/assets/img/kubeflow/kubeyolo303.png)

## Conclusion

---

ì „ì²´ ì½”ë“œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

- `pipeline_compiler.py`
    
    ```python
    from functools import partial
    from typing import NamedTuple
    
    import kfp
    from kfp.components import create_component_from_func, InputPath, OutputPath
    from kfp import dsl
    
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.2",
    )
    def verify_pipeline_op(
        model_path: str,
        cfg_input: str,
        data_input: str,
        ) -> NamedTuple("Yamlfiles",[("cfg_yaml", str), ("data_yaml", str)]):
        import os
        import torch
        from collections import namedtuple
    
        if not cfg_input.endswith('.yaml'):
            cfg_input += '.yaml'
        if not data_input.endswith('.yaml'):
            data_input += '.yaml'    
        
        if not os.path.isfile(model_path):
            raise FileNotFoundError(f"FileNotFound : {model_path}")    
        if not os.path.isfile(cfg_input):
            raise FileNotFoundError(f"FileNotFound : {cfg_input}")
        if not os.path.isfile(data_input):
            raise FileNotFoundError(f"FileNotFound : {data_input}")
        
        verify_outputs = namedtuple(
            'Yamlfiles',
            ['cfg_yaml', 'data_yaml'],
        )
        
        return verify_outputs(cfg_input,data_input)
    
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.2",
    )    
    def get_data_distribution_op(
        data_yaml: str,
        mlpipeline_metrics_path: OutputPath("Metrics"), # Unused
        result_json_path: OutputPath("json"),
        cls_names_json_path: OutputPath("json"),
        ):
        import os
        import yaml
        import json
        from collections import defaultdict
        from tqdm import tqdm
        from ultralytics import settings
        
        yolo_default_dir = settings['datasets_dir']
        
        # Read yaml and Get train.txt path
        with open(data_yaml, 'r', encoding='utf-8') as file:
            data = yaml.safe_load(file)
            train_txt_rel_path = data['train']
            train_txt_abs_path = yolo_default_dir + '/' + train_txt_rel_path
            
            # Get Class names from yaml file
            cls_names = data['names']
            print('cls_names:',cls_names)
            
            cls_dict = {i: cls_names[i] for i in range(len(cls_names))}
    
            
        # Read train.txt and Get dataset path
        with open(train_txt_abs_path, 'r', encoding='utf-8') as file:
            line = file.readline().strip()
            dir = os.path.dirname(line)
            
            # if folders are nested, dirname func may not work as desired
            folders = dir.split(os.path.sep)
            print(folders)
            
            dataset_dir = os.path.join(yolo_default_dir, folders[1])
            
        # Search txt files and count imgs and instances per class
        cls_files = defaultdict(set)
        class_instances = defaultdict(int)
        
        for root, _, files in tqdm(os.walk(dataset_dir)):
            for filename in files:
                if filename.endswith('.txt'):
                    with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:
                        for line in f.readlines():
                            try:
                                cls_id = int(line.split()[0])
                            
                            except ValueError:
                                continue
                            
                            cls_files[cls_id].add(filename)
                            class_instances[cls_id] += 1
                            
        class_imgs = {k:len(cls_files[k]) for k in sorted(cls_files.keys())}
        class_instances = {k:v for k,v in sorted(class_instances.items())}
        
        result_dict = {key: {'img': class_imgs[key], 'instances': class_instances[key]} for key in class_instances}
        
        print('Result dict\n',result_dict)
        print('Class name dict\n',cls_dict)
    
        with open(result_json_path, 'w', encoding='utf-8') as f:
            json.dump(result_dict, f)
            
        with open(cls_names_json_path, 'w', encoding='utf-8') as f:
            json.dump(cls_dict, f)
        
        # Unused
        with open(mlpipeline_metrics_path, 'w', encoding='utf-8') as f:
            json.dump(result_dict, f)
    
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.2",
        packages_to_install=["seaborn","pandas"]
    )    
    def plot_data_distribution_op(
        result_json_path: InputPath("json"),
        cls_names_json_path: InputPath("json"),
        mlpipeline_ui_metadata: OutputPath("UI_Metadata"),
        ) -> bool:
        import os
        from collections import defaultdict
        from tqdm import tqdm
        import json
        
        import base64
        from io import BytesIO
        import matplotlib.pyplot as plt
        
        import pandas as pd
        import seaborn as sns
        from matplotlib.ticker import MultipleLocator
    
        # Load data from JSON
        with open(result_json_path, 'r', encoding='utf-8') as f:
            result_dict = json.load(f)
        
        with open(cls_names_json_path, 'r', encoding='utf-8') as f:
            cls_dict = json.load(f)
            
        result_dict = {int(key): value for key, value in result_dict.items()}
        cls_dict = {int(key): value for key, value in cls_dict.items()}
        print('result dict\n',result_dict)
        print('cls_dict\n',cls_dict)
    
        # Convert data to DataFrame
        df = pd.DataFrame(list(result_dict.items()), columns=['Classes', 'Values'], index=result_dict.keys())
        df_values = pd.json_normalize(df['Values'])
        df = pd.concat([df.drop('Values', axis=1), df_values], axis=1)
        df_melted = pd.melt(df, id_vars=['Classes'], value_vars=['img', 'instances'], var_name='Category', value_name='Values')
        df_melted['Classes'] = df_melted['Classes'].map(cls_dict)
    
        # Plotting
        sns.set(style='whitegrid')
        plt.figure(figsize=(14, 8))
    
        # Define display variable
        display = 'both'
    
        # Plot based on display value
        palette = 'Set2'
        title = '< Distribution of Img & GT per Class >'
    
        # Create bar plot
        ax = sns.barplot(data=df_melted,
                        x='Values',
                        y='Classes',
                        hue='Category',
                        palette=palette,
                        order=df_melted['Classes'].unique(),
                        orient='h')
    
        # Customize plot
        plt.xlabel('Count', rotation=0, fontsize=12)
        plt.ylabel('Classes', rotation=90, fontsize=12)
        plt.title(title)
        plt.gca().yaxis.set_major_locator(MultipleLocator(base=1))
    
        # Display values on the plot
        for p in ax.patches:
            ax.text(p.get_width() + 200,
                    p.get_y() + p.get_height() / 1.7,
                    f"{p.get_width():.0f}",
                    ha='left', va='center', fontsize=10)
    
            if display == 'img':
                ax.text(p.get_width() + 2500,
                        p.get_y() + p.get_height() / 1.7,
                        f"({round((int(p.get_width()) / sum(df_melted[df_melted['Category'] == 'img']['Values']) * 100), 1)}%)",
                        ha='left', va='center', fontsize=9, color='purple', alpha=1.0)
            elif display == 'instances':
                ax.text(p.get_width() + 5200,
                        p.get_y() + p.get_height() / 1.7,
                        f"({round((int(p.get_width()) / sum(df_melted[df_melted['Category'] == 'instances']['Values']) * 100), 1)}%)",
                        ha='left', va='center', fontsize=9, color='#004d97', alpha=1.0)
    
        # Save plot as image and encode to base64
        tmpfile = BytesIO()
        plt.savefig(tmpfile, format='png')
        encoded = base64.b64encode(tmpfile.getvalue()).decode("utf-8")
    
        # Create HTML string
        html = f"<img src='data:image/png;base64,{encoded}'>"
    
        # Define metadata for the web app
        metadata = {
            "outputs": [
                {
                    "type": "web-app",
                    "storage": "inline",
                    "source": html,
                },
            ],
        }
    
        # Save metadata to file
        with open(mlpipeline_ui_metadata, "w") as html_writer:
            json.dump(metadata, html_writer)
            
        return True
    
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.2",
    )
    def train_op(
        model_path: str,
        cfg: str,
        data: str,
        ) -> NamedTuple("trainOutputs",[("last_pt",str), ("best_pt",str), ("data_yaml",str), ("project",str), ("exp_name", str)]):
        import os
        from ultralytics import YOLO
        import mlflow
        import yaml
        from collections import namedtuple
    
        # MLflow Setup
        os.environ["MLFLOW_TRACKING_URI"] = "http://mlflow-server-service.mlflow-system.svc:5000"
        os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"
        os.environ["AWS_ACCESS_KEY_ID"] = "minio"
        os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
    
        # Train
        model = YOLO(model_path)    
        
        results = model.train(cfg=cfg,data=data)
    
        with open(cfg,'r',encoding='utf-8') as file:
            config = yaml.safe_load(file)
            
        train_outputs = namedtuple(
            'trainOutputs',
            ['last_pt','best_pt','data_yaml','project','exp_name'],
        )
    
        data_yaml = data
        project = config.get('project')
        exp_name = config.get('name')
        last_pt = os.path.join(project,exp_name,'weights','last.pt')
        best_pt = os.path.join(project,exp_name,'weights','best.pt')
    
        return train_outputs(last_pt, best_pt, data_yaml, project, exp_name)
    
        
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.2",
    )
    def tune_op(
        last_pt: str,
        best_pt: str,
        data_yaml: str,
        project: str,
        exp_name: str,
        ):
        from ultralytics import YOLO
        from ray import tune
        import os
        import yaml
    
        os.environ["MLFLOW_TRACKING_URI"] = "http://mlflow-server-service.mlflow-system.svc:5000"
        os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"
        os.environ["AWS_ACCESS_KEY_ID"] = "minio"
        os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
    
        model = YOLO(last_pt)
        
        result = model.tune(
                    data=data_yaml,
                    space={"lr0": tune.uniform(1e-5, 1e-1)},
                    epochs=2,
                    grace_period=2,
                    gpu_per_trial=1,
                    iterations=1,
                    project=project,
                    name="tune",
                    batch=4,
                    use_ray=True
                    )
                
    @dsl.pipeline(name="pipelinename",
              description="MLpipline Description",
              )
    def train_pipeline(
        model_name: str = 'yolov8n.pt',
        cfg: str = 'cfg-custom',
        data: str = 'data-custom',
        bool_train: bool=True,
        bool_tune: bool=True,
        ):
        import os
        
        vop = dsl.VolumeOp(
            name="volume mount",
            resource_name="pvc-local-cocodata",
            storage_class='train',
            modes=dsl.VOLUME_MODE_RWO,
            size="3Gi",
            generate_unique_name=False,
            action='apply',)
        
        verifier = verify_pipeline_op(model_name, cfg, data)
        
        get_distribution = get_data_distribution_op(verifier.outputs['data_yaml'])
        
        plotting = plot_data_distribution_op(get_distribution.outputs["result_json"], get_distribution.outputs["cls_names_json"])
        
        with dsl.Condition(plotting.outputs!= None and bool_train == True , "train"):
            trainer = train_op(model_name, verifier.outputs['cfg_yaml'], verifier.outputs['data_yaml'])
            
            with dsl.Condition(bool_tune == True , 'tune'):
                raytuner = tune_op(trainer.outputs['last_pt'],trainer.outputs['best_pt'],trainer.outputs['data_yaml'],trainer.outputs['project'],trainer.outputs['exp_name'])
        
        # Volume Mount
        verifier.add_pvolumes({"/data":vop.volume})
        get_distribution.add_pvolumes({"/data":vop.volume})
        plotting.add_pvolumes({"/data":vop.volume})
        trainer.add_pvolumes({"/data":vop.volume})
        raytuner.add_pvolumes({"/data":vop.volume})
        
        # Disable caching. Two Options 
        '''
        This Option doesn't work well
        Use `.execution_options.caching_strategy.max_cache_staleness = "P0D"` instead.
        
        # verifier.set_caching_options(False)
        # get_distribution.set_caching_options(False)
        # plotting.set_caching_options(False)
        # trainer.set_caching_options(False)
        # raytuner.set_caching_options(False)
        '''
        verifier.execution_options.caching_strategy.max_cache_staleness = "P0D"
        get_distribution.execution_options.caching_strategy.max_cache_staleness = "P0D"
        plotting.execution_options.caching_strategy.max_cache_staleness = "P0D"
        trainer.execution_options.caching_strategy.max_cache_staleness = "P0D"
        raytuner.execution_options.caching_strategy.max_cache_staleness = "P0D"
        
        # UI Component name settings (Default is Op name)
        '''
        vop.set_display_name("UI Component name settings")
        verifier.set_display_name("UI Component name settings")
        get_distribution.set_display_name("UI Component name settings")
        plotting.set_display_name("UI Component name settings")
        trainer.set_display_name("UI Component name settings")
        raytuner.set_display_name("UI Component name settings")
        '''
    
    if __name__ == "__main__":
        kfp.compiler.Compiler().compile(train_pipeline, "knowgyu_optimizeTest.yaml")
    ```
    

### Pipeline Graph

![Untitled](/assets/img/kubeflow/kubeyolo304.png)

### Pipeline Run parameters

| í•­ëª©       | ì˜ˆì‹œ        | ì„¤ëª…                                                                                             |
| ---------- | ----------- | ------------------------------------------------------------------------------------------------ |
| model_name | yolov8n.pt  | ëª¨ë¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.                                                                               |
| cfg        | cfg-custom  | YOLOì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° Configuration íŒŒì¼ì„ ì…ë ¥í•©ë‹ˆë‹¤. .yaml í™•ì¥ìë¥¼ ë¶™ì´ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. |
| data       | data-custom | ë°ì´í„°ì…‹ yamlíŒŒì¼ì„ ì…ë ¥í•©ë‹ˆë‹¤. yaml í™•ì¥ìë¥¼ ë¶™ì´ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.                              |
| bool_train | True        | boolí˜•ìœ¼ë¡œ Trueë¡œ ì…ë ¥í•  ì‹œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.                                                   |
| bool_tune  | False       | boolí˜•ìœ¼ë¡œ Trueë¡œ ì…ë ¥í•  ì‹œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ì„ ì§„í–‰í•©ë‹ˆë‹¤.                                    |

## + Misc

---

### Disable Caching

KubeflowëŠ” ìºì‹± ê¸°ëŠ¥ì„ ì§€ì›í•˜ì—¬ ë™ì¼í•œ Configë¡œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ì‹œ ìºì‹œëœ íŒŒì¼ì„ ì´ìš©í•´ ì‹¤í–‰ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•©ë‹ˆë‹¤.

![ìºì‹œíŒŒì¼ì„ ì´ìš©í•´ ì¶œë ¥í•  ê²½ìš° ìœ„ì™€ ê°™ì´ í‘œì‹œë¨](/assets/img/kubeflow/kubeyolo305.png)

ìºì‹œíŒŒì¼ì„ ì´ìš©í•´ ì¶œë ¥í•  ê²½ìš° ìœ„ì™€ ê°™ì´ í‘œì‹œë¨

í•˜ì§€ë§Œ, `cfg-custom` í˜¹ì€ `data-custom` íŒŒì¼ ë‚´ë¶€ì—ì„œ ë³€ê²½ì´ ë  ê²½ìš° ì…ë ¥ë˜ëŠ” ConfigëŠ” ë™ì¼í•˜ê¸°ì— ì˜¤ì‘ë™í•˜ëŠ” ìƒí™©ì´ ë°œìƒí•©ë‹ˆë‹¤.

ì´ëŸ¬í•œ ë¬¸ì œë¥¼ ë§‰ê¸° ìœ„í•´ ìºì‹œ ê¸°ëŠ¥ì„ ë„ê² ìŠµë‹ˆë‹¤.

```python
# Disable caching. Two Options 
    '''
    This Option doesn't work well
    Use `.execution_options.caching_strategy.max_cache_staleness = "P0D"` instead.
    
    # verifier.set_caching_options(False)
    # get_distribution.set_caching_options(False)
    # plotting.set_caching_options(False)
    # trainer.set_caching_options(False)
    # raytuner.set_caching_options(False)
    '''
    verifier.execution_options.caching_strategy.max_cache_staleness = "P0D"
    get_distribution.execution_options.caching_strategy.max_cache_staleness = "P0D"
    plotting.execution_options.caching_strategy.max_cache_staleness = "P0D"
    trainer.execution_options.caching_strategy.max_cache_staleness = "P0D"
    raytuner.execution_options.caching_strategy.max_cache_staleness = "P0D"
```

`set_caching_options(False)` ì˜ ê²½ìš° ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë°œìƒí•´ ë‹¤ë¥¸ ë°©ë²•ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

`.execution_options.caching_strategy.max_cache_staleness = "P0D"` ë¥¼ í†µí•´ ìºì‹œ ê¸°ëŠ¥ì„ ì¢…ë£Œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ë§Œì•½, ì‹¤ì œ í•™ìŠµì„ ìœ„í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì´ ì•„ë‹Œ, ê° ì»´í¬ë„ŒíŠ¸ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•¨ì´ë¼ë©´, ëª‡ëª‡ ì»´í¬ë„ŒíŠ¸ëŠ” ìºì‹œê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br>
ex) í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ ì»´í¬ë„ŒíŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì„ ë•Œ(`raytuner`) ì´ì „ ì»´í¬ë„ŒíŠ¸ë“¤ì—ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê±°ë‚˜ ëª¨ë¸ì„ í•™ìŠµí•˜ì§€ ì•Šì•„ë„ ìƒê´€ì—†ìŠµë‹ˆë‹¤. <br>
ì´ëŸ° ìƒí™©ì—ì„œ `raytuner`ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì»´í¬ë„ŒíŠ¸ë“¤ì€ ì£¼ì„ì²˜ë¦¬í•´ ìºì‹œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•œë‹¤ë©´, `raytuner` ì»´í¬ë„ŒíŠ¸ë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì»´í¬ë„ŒíŠ¸ë“¤ì˜ ê²°ê³¼ëŠ” ìºì‹œì—ì„œ ê°€ì ¸ì˜¤ê¸°ì— ë¹ ë¥´ê²Œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
{: .prompt-tip }


### Set UI display name

Kubeflow Pipeline Graphì— í‘œì‹œë˜ëŠ” ì»´í¬ë„ŒíŠ¸ ì´ë¦„ì€ ê° í•¨ìˆ˜ì˜ ì´ë¦„ì…ë‹ˆë‹¤.

ë³¸ ì˜ˆì‹œì—ì„œëŠ” ë™ì¼í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê¸°ì—, ì„œë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆì§€ë§Œ, ë§Œì•½ ë™ì¼í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—¬ëŸ¬ë²ˆ ì‚¬ìš©í•˜ê²Œ ë  ê²½ìš° UIë¡œ í‘œì‹œë˜ëŠ” ì´ë¦„ì´ ë™ì¼í•´ êµ¬ë³„ì´ í˜ë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

 `.set_display_name`ì„ ì´ìš©í•´ íŒŒì´í”„ë¼ì¸ ê·¸ë˜í”„ì— í‘œì‹œë˜ëŠ” ì´ë¦„ì„ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
# UI Component name settings (Default is Op name)
    vop.set_display_name("UI Component name settings")
    verifier.set_display_name("UI Component name settings")
    get_distribution.set_display_name("UI Component name settings")
    plotting.set_display_name("UI Component name settings")
    trainer.set_display_name("UI Component name settings")
    raytuner.set_display_name("UI Component name settings")
```
