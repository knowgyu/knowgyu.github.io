---
title: "Pipeline for Train YOLOv8 on a Custom Dataset"
author: knowgyu
description: " "
date: 2023-12-09 09:42:45 +0900
math: true
categories: [AI & CV, Kubeflow]
tags: [MLOps, Kubeflow]
---

ë³¸ ë¬¸ì„œì—ì„œëŠ” YOLOv8 ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í•™ìŠµê³¼ cfgíŒŒì¼ì„ í†µí•´ í•™ìŠµ ì„¤ì •ì„ ë³€ê²½í•˜ëŠ” ê²ƒì— ëŒ€í•´ ë‹¤ë£¨ê² ìŠµë‹ˆë‹¤.

# Customize Ultralytics

---

Ultralytics ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì‹¤í—˜ì— ëŒ€í•œ ë¯¸ì„¸í•œ ì œì–´ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ì„¤ì • ê´€ë¦¬ ì‹œìŠ¤í…œ(Settings Management system)ì„ ì œê³µí•©ë‹ˆë‹¤. `ultralytics.utils` ëª¨ë“ˆ ë‚´ì— ìˆëŠ” `SettingsManager`ë¥¼ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ì‚¬ìš©ìëŠ” ì‰½ê²Œ ì„¤ì •ì„ ì ‘ê·¼í•˜ê³  ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

CLIì—ì„œ ê°„ë‹¨í•œ ëª…ë ¹ì–´ í•˜ë‚˜ë¡œ í™•ì¸í•˜ê³ , ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# Check Settings
yolo settings

# Update a setting
yolo settings mlflow=False

# Reset settings to Default
yolo settings reset
```

https://docs.ultralytics.com/quickstart/#inspecting-settings

ë˜í•œ, YOLOv8 ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©° ìµœì ì˜ ì„±ëŠ¥ì„ ì°¾ê¸° ìœ„í•œ ë‹¤ì–‘í•œ configurationë„ ì œê³µí•©ë‹ˆë‹¤.

## Configuration

---

https://docs.ultralytics.com/usage/cfg/?h=configuration#modes

> YOLO ì„¤ì •ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥, ì†ë„, ì •í™•ë„ì— í° ì˜í–¥ì„ ë¼ì¹©ë‹ˆë‹¤.

- Docs example

```python
from ultralytics import YOLO

# Load a YOLOv8 model from a pre-trained weights file
model = YOLO('yolov8n.pt')

# Run MODE mode using the custom arguments ARGS (guess TASK)
model.MODE(ARGS)
```

> Where:
> 
> - `TASK`Â (optional) is one of ([detect](https://docs.ultralytics.com/tasks/detect/),Â [segment](https://docs.ultralytics.com/tasks/segment/),Â [classify](https://docs.ultralytics.com/tasks/classify/),Â [pose](https://docs.ultralytics.com/tasks/pose/))
> - `MODE`Â (required) is one of ([train](https://docs.ultralytics.com/modes/train/),Â [val](https://docs.ultralytics.com/modes/val/),Â [predict](https://docs.ultralytics.com/modes/predict/),Â [export](https://docs.ultralytics.com/modes/export/),Â [track](https://docs.ultralytics.com/modes/track/))
> - `ARGS`Â (optional) areÂ `arg=value`Â pairs likeÂ `imgsz=640`Â that override defaults.

YOLOv8 ëª¨ë¸ì„ í•™ìŠµ ì‹œí‚¬ ë•Œ, ë‹¤ì–‘í•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì™€ ì„¤ì •ë“¤ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì„¤ì •ê³¼ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì€ `cfg/defaults.yaml`ì— ì •ì˜ë˜ì–´ìˆì–´ ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•˜ì§€ ì•Šë”ë¼ë„, ê¸°ë³¸ê°’ì„ ì´ìš©í•´ í•™ìŠµí•˜ê²Œë˜ë©°, ë§Œì•½ ì›í•˜ëŠ” Argsë¥¼ ì…ë ¥í•œë‹¤ë©´ ê¸°ë³¸ê°’ì— ë®ì–´ì“°ì—¬ í•´ë‹¹ Argsë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ëŸ¬í•œ Custom ArgsëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê±°ë‚˜, Epochs, Batch size, Resume ë“± í•„ìš”ì— ë”°ë¼ ë‹¤ì–‘í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### YOLOv8 ëª¨ë¸ í•™ìŠµ ì˜ˆì‹œ

YOLOv8ì˜ CLI ëª…ë ¹ì–´ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤

```bash
# YOLOv8 with DDP
yolo detect train model=yolov8m.pt data=/data1/dataset/custom_dataset/custom_data.yaml \
batch=48 workers=8 device=0,1 imgsz=640 \ 
project=custom_yolov8 name=Test1 \
save=True save_period=30
```

ì´ë¥¼ Kubeflow Component í˜•ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

```python
@partial(
    create_component_from_func,
    base_image="nohgyu/test:v1.1",
    packages_to_install=["ultralytics","ray[tune]","opencv-python==4.8.0.74","mlflow", "boto3"],
)
def train(
    checker: bool,
    model_path: str,
    data: str,
    batch: int,
    workers: int,
    device: int,
    imgsz: int,
    project: str,
    name: str,
    save: bool,
    save_period: int,
        ) -> str:
    import os
    from ultralytics import YOLO
    import mlflow
    
    if not checker:
        print("CUDA is not available.\nPlease Check GPU Device")
        return None

    model = YOLO(model_path)    

    results = model.train(data=data, batch=batch, workers=workers,
                          device=device, imgsz=imgsz, project=project,
                          name=name, save=save, save_period=save_period)

    return os.path.join(project,name,'weights','last.pt')
```

ìœ„ ì˜ˆì‹œì²˜ëŸ¼ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œ ìµœì ì˜ ì„±ëŠ¥ì„ ì°¾ê¸° ìœ„í•´ ë‹¤ì–‘í•œ Argsë¡œ ì‹¤í—˜í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

í•˜ì§€ë§Œ, í•™ìŠµì„ ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ë§ì€ Argsë“¤ì„ ì§ì ‘ ì…ë ¥í•´ì¤˜ì•¼í•©ë‹ˆë‹¤.

íŠ¹íˆ, Kubeflow íŒŒì´í”„ë¼ì¸ì„ **ì‹¤í–‰í•  ë•Œë§ˆë‹¤** ë§ì€ Configê°’ë“¤ì„ **ì§ì ‘ ì…ë ¥**í•´ì•¼í•˜ë©°, ì´ëŠ” **íœ´ë¨¼ì—ëŸ¬**ë¥¼ ì¼ìœ¼í‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì´ëŸ¬í•œ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ê¸° ìœ„í•´ `cfg`íŒŒì¼ì„ ì´ìš©í•˜ê² ìŠµë‹ˆë‹¤.

### YOLOv8 `cfg-custom.yaml`

- `cfg/defaults.yaml`
    
    ```python
    # Ultralytics YOLO ğŸš€, AGPL-3.0 license
    # Default training settings and hyperparameters for medium-augmentation COCO training
    
    task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose
    mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark
    
    # Train settings -------------------------------------------------------------------------------------------------------
    model:  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
    data:  # (str, optional) path to data file, i.e. coco128.yaml
    epochs: 300  # (int) number of epochs to train for
    patience: 50  # (int) epochs to wait for no observable improvement for early stopping of training
    batch: 16  # (int) number of images per batch (-1 for AutoBatch)
    imgsz: 640  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
    save: True  # (bool) save train checkpoints and predict results
    save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)
    cache: False  # (bool) True/ram, disk or False. Use cache for data loading
    device:  # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
    workers: 8  # (int) number of worker threads for data loading (per RANK if DDP)
    project:  # (str, optional) project name
    name:  # (str, optional) experiment name, results saved to 'project/name' directory
    exist_ok: False  # (bool) whether to overwrite existing experiment
    pretrained: True  # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)
    optimizer: auto  # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
    verbose: True  # (bool) whether to print verbose output
    seed: 0  # (int) random seed for reproducibility
    deterministic: True  # (bool) whether to enable deterministic mode
    single_cls: False  # (bool) train multi-class data as single-class
    rect: False  # (bool) rectangular training if mode='train' or rectangular validation if mode='val'
    cos_lr: False  # (bool) use cosine learning rate scheduler
    close_mosaic: 10  # (int) disable mosaic augmentation for final epochs (0 to disable)
    resume: False  # (bool) resume training from last checkpoint
    amp: True  # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check
    fraction: 1.0  # (float) dataset fraction to train on (default is 1.0, all images in train set)
    profile: False  # (bool) profile ONNX and TensorRT speeds during training for loggers
    freeze: None  # (int | list, optional) freeze first n layers, or freeze list of layer indices during training
    # Segmentation
    overlap_mask: True  # (bool) masks should overlap during training (segment train only)
    mask_ratio: 4  # (int) mask downsample ratio (segment train only)
    # Classification
    dropout: 0.0  # (float) use dropout regularization (classify train only)
    
    # Val/Test settings ----------------------------------------------------------------------------------------------------
    val: True  # (bool) validate/test during training
    split: val  # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'
    save_json: False  # (bool) save results to JSON file
    save_hybrid: False  # (bool) save hybrid version of labels (labels + additional predictions)
    conf:  # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)
    iou: 0.7  # (float) intersection over union (IoU) threshold for NMS
    max_det: 300  # (int) maximum number of detections per image
    half: False  # (bool) use half precision (FP16)
    dnn: False  # (bool) use OpenCV DNN for ONNX inference
    plots: True  # (bool) save plots during train/val
    
    # Prediction settings --------------------------------------------------------------------------------------------------
    source:  # (str, optional) source directory for images or videos
    show: False  # (bool) show results if possible
    save_txt: False  # (bool) save results as .txt file
    save_conf: False  # (bool) save results with confidence scores
    save_crop: False  # (bool) save cropped images with results
    show_labels: True  # (bool) show object labels in plots
    show_conf: True  # (bool) show object confidence scores in plots
    vid_stride: 1  # (int) video frame-rate stride
    stream_buffer: False  # (bool) buffer all streaming frames (True) or return the most recent frame (False)
    line_width:   # (int, optional) line width of the bounding boxes, auto if missing
    visualize: False  # (bool) visualize model features
    augment: False  # (bool) apply image augmentation to prediction sources
    agnostic_nms: False  # (bool) class-agnostic NMS
    classes:  # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]
    retina_masks: False  # (bool) use high-resolution segmentation masks
    boxes: True  # (bool) Show boxes in segmentation predictions
    
    # Export settings ------------------------------------------------------------------------------------------------------
    format: torchscript  # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats
    keras: False  # (bool) use Kera=s
    optimize: False  # (bool) TorchScript: optimize for mobile
    int8: False  # (bool) CoreML/TF INT8 quantization
    dynamic: False  # (bool) ONNX/TF/TensorRT: dynamic axes
    simplify: False  # (bool) ONNX: simplify model
    opset:  # (int, optional) ONNX: opset version
    workspace: 4  # (int) TensorRT: workspace size (GB)
    nms: False  # (bool) CoreML: add NMS
    
    # Hyperparameters ------------------------------------------------------------------------------------------------------
    lr0: 0.01  # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)
    lrf: 0.01  # (float) final learning rate (lr0 * lrf)
    momentum: 0.937  # (float) SGD momentum/Adam beta1
    weight_decay: 0.0005  # (float) optimizer weight decay 5e-4
    warmup_epochs: 3.0  # (float) warmup epochs (fractions ok)
    warmup_momentum: 0.8  # (float) warmup initial momentum
    warmup_bias_lr: 0.1  # (float) warmup initial bias lr
    box: 7.5  # (float) box loss gain
    cls: 0.5  # (float) cls loss gain (scale with pixels)
    dfl: 1.5  # (float) dfl loss gain
    pose: 12.0  # (float) pose loss gain
    kobj: 1.0  # (float) keypoint obj loss gain
    label_smoothing: 0.0  # (float) label smoothing (fraction)
    nbs: 64  # (int) nominal batch size
    hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)
    hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)
    hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)
    degrees: 0.0  # (float) image rotation (+/- deg)
    translate: 0.1  # (float) image translation (+/- fraction)
    scale: 0.5  # (float) image scale (+/- gain)
    shear: 0.0  # (float) image shear (+/- deg)
    perspective: 0.0  # (float) image perspective (+/- fraction), range 0-0.001
    flipud: 0.0  # (float) image flip up-down (probability)
    fliplr: 0.5  # (float) image flip left-right (probability)
    mosaic: 1.0  # (float) image mosaic (probability)
    mixup: 0.0  # (float) image mixup (probability)
    copy_paste: 0.0  # (float) segment copy-paste (probability)
    
    # Custom config.yaml ---------------------------------------------------------------------------------------------------
    cfg:  # (str, optional) for overriding defaults.yaml
    
    # Tracker settings ------------------------------------------------------------------------------------------------------
    tracker: botsort.yaml  # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]
    ```
    

ìœ„ íŒŒì¼ì€ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” `ARG`ê°’ë“¤ì´ ì •ì˜ë˜ì–´ìˆëŠ” íŒŒì¼ì…ë‹ˆë‹¤.  ì´ íŒŒì¼ì„ ì´ìš©í•´ `cfg-custom.yaml` ì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤.

- `cfg-custom.yaml`

```
# Ultralytics YOLO ğŸš€, AGPL-3.0 license
# Default training settings and hyperparameters for medium-augmentation COCO training

task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose
mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark

# Train settings -------------------------------------------------------------------------------------------------------
model: **yolov8m.pt**  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
data: **/data1/dataset/custom_dataset/custom_data.yaml** # (str, optional) path to data file, i.e. coco128.yaml
epochs: **300**  # (int) number of epochs to train for
patience: 50  # (int) epochs to wait for no observable improvement for early stopping of training
batch: **48**  # (int) number of images per batch (-1 for AutoBatch)
imgsz: **640**  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
...
...ìƒëµ
...

```

ì´ë ‡ê²Œ `cfg-custom.yaml` íŒŒì¼ì„ ìƒì„±í–ˆë‹¤ë©´, ì•„ë˜ì™€ ê°™ì´ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```bash
# ìˆ˜ì • ì „ ì½”ë“œ
yolo detect train model=yolov8m.pt data=/data1/dataset/custom_dataset/custom_data.yaml \
batch=48 workers=8 device=0,1 imgsz=640 \ 
project=custom_yolov8 name=Test \
save=True save_period=30

# ìˆ˜ì • í›„ ì½”ë“œ
yolo detect train cfg=cfg-custom.yaml
```

ì´ì²˜ëŸ¼ `cfg-custom.yaml` íŒŒì¼ì„ ì´ìš©í•˜ë©´ ë”ìš± í¸ë¦¬í•˜ê²Œ YOLO ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ì´ë¥¼ í™œìš©í•´ Kubeflow Pipelineì— ì ìš©í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

## Custom Dataset Training Pipeline

---

ë…¸ë“œ **ë¡œì»¬** ë³¼ë¥¨ì— ìˆëŠ” COCO128 ë°ì´í„°ì…‹ì„ í•™ìŠµí•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.

ìš°ì„ , í´ë” êµ¬ì¡°ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤

```bash
kfcocotest/
â”œâ”€â”€ cfg-custom.yaml
â”œâ”€â”€ data-custom.yaml
â”œâ”€â”€ datasets
â”‚Â Â  â”œâ”€â”€ coco128  [256 entries exceeds filelimit, not opening dir]
â”‚Â Â  â”œâ”€â”€ coco128test.txt
â”‚Â Â  â””â”€â”€ coco128train.txt
â””â”€â”€ KFP_compiler.py
```

### ë³¼ë¥¨ ë§ˆìš´íŠ¸

ì´ì „ PV Mount ë¬¸ì„œì—ì„œ ë‹¤ë£¬ ë°©ë²•ëŒ€ë¡œ PV/PVCë¥¼ ìƒì„±í•œ í›„ Pipelineì— ì—°ê²°í•˜ê² ìŠµë‹ˆë‹¤.

- `cocopv.yaml`

```bash
apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-cocodata
spec:
  capacity:
    storage: 3Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: "train"
  hostPath:
    path: "/data/kfcocotest"
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - knowgyu
```

- `cocopvc.yaml`

```bash
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-local-cocodata
  namespace: knowgyu
spec:
  accessModes:
  - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 3Gi
  storageClassName: "train"
```

- ìƒì„± ë° í™•ì¸

```bash
kubectl apply -f cocopv.yaml 
kubectl apply -f cocopvc.yaml 

# ê°ê° ì•„ë˜ì™€ ê°™ì€ ë©”ì„¸ì§€ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.
persistentvolume/local-cocodata created
persistentvolumeclaim/pvc-local-cocodata created
```

![Kubeflow Dashboardì—ì„œ í™•ì¸. pvc-local-cocodata ìƒì„± í™•ì¸ ì™„ë£Œ](/assets/img/kubeflow/kubeyolo201.png)

Kubeflow Dashboardì—ì„œ í™•ì¸. pvc-local-cocodata ìƒì„± í™•ì¸ ì™„ë£Œ

![í•´ë‹¹ PVCì— ì—°ê²°í•œ Jupyter Notebook í™•ì¸](/assets/img/kubeflow/kubeyolo202.png)

í•´ë‹¹ PVCì— ì—°ê²°í•œ Jupyter Notebook í™•ì¸

### í•™ìŠµ ì„¤ì •

ì •ìƒì ìœ¼ë¡œ ë§ˆìš´íŠ¸ëœ ê²ƒì„ í™•ì¸í–ˆë‹¤ë©´, Notebookì—ì„œ yamlíŒŒì¼ë“¤ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.

![Untitled](/assets/img/kubeflow/kubeyolo203.png)

- `cfg-custom.yaml`
    
    ```yaml
    # Ultralytics YOLO ğŸš€, AGPL-3.0 license
    # Default training settings and hyperparameters for medium-augmentation COCO training
    
    task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose
    mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark
    
    # Train settings -------------------------------------------------------------------------------------------------------
    model:  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml
    data:  # (str, optional) path to data file, i.e. coco128.yaml
    epochs: 2  # (int) number of epochs to train for
    patience: 50  # (int) epochs to wait for no observable improvement for early stopping of training
    batch: 4  # (int) number of images per batch (-1 for AutoBatch)
    imgsz: 320  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes
    save: True  # (bool) save train checkpoints and predict results
    save_period: 30 # (int) Save checkpoint every x epochs (disabled if < 1)
    cache: False  # (bool) True/ram, disk or False. Use cache for data loading
    device:  # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu
    workers: 8  # (int) number of worker threads for data loading (per RANK if DDP)
    project: testprj  # (str, optional) project name
    name: testexp  # (str, optional) experiment name, results saved to 'project/name' directory
    exist_ok: False  # (bool) whether to overwrite existing experiment
    pretrained: True  # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)
    optimizer: auto  # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
    verbose: True  # (bool) whether to print verbose output
    seed: 404  # (int) random seed for reproducibility
    deterministic: True  # (bool) whether to enable deterministic mode
    single_cls: False  # (bool) train multi-class data as single-class
...
...
ìƒëµ
...
...
    mixup: 0.0  # (float) image mixup (probability)
    copy_paste: 0.0  # (float) segment copy-paste (probability)
    
    # Custom config.yaml ---------------------------------------------------------------------------------------------------
    cfg:  # (str, optional) for overriding defaults.yaml
    
    # Tracker settings ------------------------------------------------------------------------------------------------------
    tracker: botsort.yaml  # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]
    ```
    
- `data-custom.yaml`
    
    ```bash
    # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]
    train: ./coco128train.txt # 6,331
    val: ./coco128test.txt # 1,118
    
    # number of classes
    nc: 80
    
    # class names
    names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
             'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
             'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
             'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
             'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
             'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
             'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
             'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
             'hair drier', 'toothbrush' ]
    ```
    

>`yolo settings` ëª…ë ¹ì–´ë¡œ `datasets_dir` ê²½ë¡œë¥¼ ì˜ í™•ì¸í•´ì•¼í•©ë‹ˆë‹¤.
>
>`coco128train.txt` ëŠ” ì•„ë˜ì™€ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì…ë ¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
>`./coco128/000000000357.jpg` 
>`./coco128/000000000450.jpg`
{: .prompt-tip }

### íŒŒì´í”„ë¼ì¸ ì‘ì„± ë° ì—…ë¡œë“œ

- `KFP_compiler.py`
    
    ```python
    from functools import partial
    
    import kfp
    from kfp.components import create_component_from_func, InputPath, OutputPath
    from kfp import dsl
    
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.1",
    )
    def verify_training(
        model_name: str,
        cfg: str,
        data: str,
        ) -> bool:
        import torch
    
        assert isinstance(model_name, str), "model_name must be a string"
        assert isinstance(cfg, str), "model_name must be a string"
        assert isinstance(data, str), "model_name must be a string"
        
        return torch.cuda.is_available()
        
        
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.1",
        packages_to_install=["ultralytics","opencv-python==4.8.0.74","mlflow", "boto3"],
    )
    def train(
        checker: bool,
        model_name: str,
        cfg: str,
        data: str,
            ) -> str:
        import os
        from ultralytics import YOLO
        import mlflow
        import yaml
        
        if not checker:
            print("CUDA is not available.\nPlease Check GPU Device")
            return None
    
        os.environ["MLFLOW_TRACKING_URI"] = "http://mlflow-server-service.mlflow-system.svc:5000"
        os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"
        os.environ["AWS_ACCESS_KEY_ID"] = "minio"
        os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
    
        model = YOLO(model_name)    
    
        if not cfg.endswith('.yaml'):
            cfg += '.yaml'
        if not data.endswith('.yaml'):
            data += '.yaml'    
        
        if not os.path.isfile(cfg):
            raise FileNotFoundError(f"FileNotFound : {cfg}")
        if not os.path.isfile(data):
            raise FileNotFoundError(f"FileNotFound : {data}")
        
        results = model.train(cfg=cfg,data=data)
    
        with open(cfg,'r',encoding='utf-8') as file:
            tmp = yaml.safe_load(file)
            
        project = tmp.get('project')
        name = tmp.get('name')
            
        return os.path.join(project,name,'weights','last.pt')
        
    @partial(
        create_component_from_func,
        base_image="nohgyu/test:v1.1",
        packages_to_install=["ultralytics","ray[tune]","opencv-python==4.8.0.74","mlflow", "boto3"],
    )
    def tune(
        model_path: str,
        cfg: str,
        data: str,
        ):
        from ultralytics import YOLO
        from ray import tune
        import os
        import yaml
    
        os.environ["MLFLOW_TRACKING_URI"] = "http://mlflow-server-service.mlflow-system.svc:5000"
        os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://minio-service.kubeflow.svc:9000"
        os.environ["AWS_ACCESS_KEY_ID"] = "minio"
        os.environ["AWS_SECRET_ACCESS_KEY"] = "minio123"
        
        model = YOLO(model_path)
    
        if not cfg.endswith('.yaml'):
            cfg += '.yaml'
        if not data.endswith('.yaml'):
            data += '.yaml'    
        
        with open(cfg,'r',encoding='utf-8') as file:
            tmp = yaml.safe_load(file)
            
        project = tmp.get('project')
        name = tmp.get('name')
        print(f"project : {project}, name : {name}")
        print(os.listdir())
        
        result = model.tune(
                    data=data,
                    space={"lr0": tune.uniform(1e-5, 1e-1)},
                    epochs=2,
                    grace_period=2,
                    gpu_per_trial=1,
                    iterations=1,
                    project=project,
                    batch=4,
                    use_ray=True
                    )
        
        print(os.listdir())
            
    @dsl.pipeline(name="pipelinename",
              description="MLpipline Description",
              )
    def train_pipeline(
        model_name: str,
        cfg: str,
        data: str,
        ):
        import os
        
        vop = dsl.VolumeOp(
            name="volume mount",
            resource_name="pvc-local-cocodata",
            storage_class='train',
            modes=dsl.VOLUME_MODE_RWO,
            size="3Gi",
            generate_unique_name=False,
            action='apply',
        )
        
        check = verify_training(model_name, cfg, data).add_pvolumes({"/data":vop.volume})
        trained = train(check.output, model_name, cfg, data).add_pvolumes({"/data":vop.volume})
        tune(trained.output, cfg, data).add_pvolumes({"/data":vop.volume})
    
    if __name__ == "__main__":
        kfp.compiler.Compiler().compile(train_pipeline, "knowgyu_MountTest.yaml")
    ```
    

>íŒŒì´í”„ë¼ì¸ Configë¡œ `model_name`, `cfg`, `data` ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤. `cfg`ì™€ `data`ì˜ ê²½ìš° `.yaml`ì„ ë¶™ì´ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
>
>Pipeline ì»´íŒŒì¼ í›„ yamlíŒŒì¼ ì—…ë¡œë“œëŠ” Notebookì´ ì•„ë‹Œ **ë¡œì»¬**ì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤. (`kfp` ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)
{: .prompt-info }

- ì…ë ¥ ì˜ˆì‹œ

![cfgì™€ dataì˜ ê²½ìš° .yamlì„ ë¶™ì´ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.](/assets/img/kubeflow/kubeyolo204.png)

cfgì™€ dataì˜ ê²½ìš° .yamlì„ ë¶™ì´ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.

- íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼

![Untitled](/assets/img/kubeflow/kubeyolo205.png)

- `train.log`
    
    ```bash
    /tmp/tmp.8YNyaqswau:44: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives
      from distutils.util import strtobool
    /usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:127: UserWarning: Field "model_server_url" has conflict with protected namespace "model_".
    
    You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.
      warnings.warn(
    /usr/local/lib/python3.10/dist-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:
    * 'schema_extra' has been renamed to 'json_schema_extra'
      warnings.warn(message, UserWarning)
    
      0%|          | 0.00/755k [00:00<?, ?B/s]
     32%|Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Â      | 240k/755k [00:00<00:00, 2.37MB/s]
    100%|Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†| 755k/755k [00:00<00:00, 4.90MB/s]
    
    [34m[1mtrain: [0mScanning /data/datasets/coco128...:   0%|          | 0/115 [00:00<?, ?it/s]
    [34m[1mtrain: [0mScanning /data/datasets/coco128... 8 images, 0 backgrounds, 0 corrupt:   7%|Ã¢â€“â€¹         | 8/115 [00:00<00:01, 79.12it/s]
    [34m[1mtrain: [0mScanning /data/datasets/coco128... 48 images, 1 backgrounds, 0 corrupt:  43%|Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Å½     | 49/115 [00:00<00:00, 261.80it/s]
...
...
...ìƒëµ
...
...
              dining table         13          1      0.348          1      0.497      0.497
                    laptop         13          2          1          0      0.995      0.646
                cell phone         13          1          1          0          0          0
                     clock         13          2      0.678          1      0.995      0.504
                teddy bear         13         10       0.68        0.6      0.647      0.279
    Speed: 0.1ms preprocess, 0.9ms inference, 0.0ms loss, 0.5ms postprocess per image
    Results saved to [1mtestprj/testexp[0m
    [34m[1mMLflow: [0mresults logged to http://mlflow-server-service.mlflow-system.svc:5000
    [34m[1mMLflow: [0mdisable with 'yolo settings mlflow=False'
    ```
    

```yaml
engine/trainer: [0mtask=detect, mode=train, model=None, data=data-custom.yaml, epochs=2, patience=50, batch=4, imgsz=320, save=True, save_period=30, cache=False, device=None, workers=8, project=testprj, name=testexp, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=404, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=cfg-custom.yaml, tracker=botsort.yaml, save_dir=testprj/testexp
```

ìœ„ëŠ” ë¡œê·¸ì˜ ì¼ë¶€ë¶„ì…ë‹ˆë‹¤. ìœ„ ì¶œë ¥ì„ ë³´ë©´ `cfg-custom`ì—ì„œ ì§€ì •í•´ì¤€ `ARG`ë“¤ì´ ì •ìƒì ìœ¼ë¡œ ì ìš©ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## Conclusion

---

ìœ„ì™€ ê°™ì€ ë°©ë²•ì„ í†µí•´ YOLO Settingê³¼ Hyper paramsì„ ì¡°ì •í•˜ê³  Custom Datasetì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.


> í˜„ì¬ ì»´í¬ë„ŒíŠ¸ë“¤ì´ ì„œë¡œ ì£¼ê³ ë°›ëŠ” Configë“¤ì´ ìœ ê¸°ì ìœ¼ë¡œ ì—°ê²°ë˜ì–´ìˆì§€ì•Šì•„ ì¶”ê°€ë¡œ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
>
>ë˜í•œ, í˜„ì¬ `Tune` ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰ ì‹œ ì²« ì´í„°ë ˆì´ì…˜ ì´í›„ì— `data-custom.yaml` ì„ ì°¾ì§€ ëª»í•˜ëŠ” ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.
>
>`os.listdir()` ë¡œ í„°ë¯¸ë„ ë¡œê·¸ë¥¼ í™•ì¸í•œ ê²°ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ ë‚´ì— ìˆìŒì—ë„ ë¶ˆêµ¬í•˜ê³  ë°œìƒí•˜ëŠ” ì—ëŸ¬ì¸ë°, ë‹¤ë¥¸ í”„ë¡œì„¸ì„œì—ì„œ ì‚¬ìš©í•˜ê³  ìˆì–´ ë°œìƒí•˜ëŠ” ë¬¸ì œì¸ì§€ í™•ì¸ì„ í•´ë´ì•¼í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤.
{:. prompt-warning }
