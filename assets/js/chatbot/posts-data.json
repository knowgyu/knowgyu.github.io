[
  {
    "id": "2025-03-05-ROS1-Hybrid-A",
    "title": "ROS1 Hybrid A* Global Planner 사용하기",
    "path": "/2025/03/05/ROS1-Hybrid-A*-적용하기/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 개요\n\nROS1 네비게이션 스택에서는 Global Planner로 다양한 알고리즘(A\\*, Dijkstra 등)을 제공합니다.  \n하지만, 이들 대부분은 그리드 기반의 경로 탐색에 초점을 맞추고 있어 실제 차량의 동역학 제약을 충분히 반영하지 못합니다.  \n  \nHybrid A\\* 알고리즘을 활용하면, 기존의 A\\*와 달리 차량의 회전 반경 및 비홀로노믹 제약을 고려한 경로 생성이 가능해집니다.  \n이번 포스트에서는 ROS1 환경에서 Hybrid A\\* 플러그인을 적용하여 글로벌 플래너로 사용하는 방법에 대해 다룹니다.  \n\n> ROS1 move_base의 기본 Global Planner는 [https://wiki.ros.org/global_planner?distro=noetic](https://wiki.ros.org/global_planner?distro=noetic)를 참고바랍니다.\n{: .prompt-tip}\n\n---\n\n## 1. Hybrid A* vs. A* 비교\n\n\n- **A\\*:** 단순한 경로 탐색, 차량의 동역학 무시  \n- **Hybrid A\\*:** 차량 제약을 반영한 경로 생성으로, 애커만 차량에 적합  \n\nROS2의 Nav2에서는 Hybrid A*를 기본 제공하지만, ROS1에서는 별도로 직접 구현하거나 외부 플러그인을 활용해야 합니다.  \n이번 예제에서는 [https://github.com/dengpw/hybrid_astar_planner](https://github.com/dengpw/hybrid_astar_planner) 레포를 기반으로 플러그인을 설치하고 활용하는 방법을 다룹니다.\n\n---\n\n## 2. 플러그인 설치\n\n### 2.1. 레포 클론 및 빌드\n\n터미널에서 아래 명령어를 실행하여 레포를 클론하고 빌드 환경을 구성합니다.\n\n```bash\nsudo apt install libompl-dev \\\n&& cd ~/catkin_ws/src \\\n&& git clone https://github.com/dengpw/hybrid_astar_planner.git  \\\n&& cd .. \\\n&& catkin_make \\\n&& source devel/setup.bash \\\n&& rospack profile\n```\n\n \n> OMPL 관련 문제 발생 시, OMPL의 설치 경로(예: `/usr/lib` 또는 `/usr/local/lib`)를 확인하고 환경변수 `OMPL_DIR`를 올바르게 설정해야 합니다.    \n> 예를 들어, OMPL이 `/usr/local/lib`에 설치된 경우 아래와 같이 환경변수를 추가할 수 있습니다.\n> \n> ```bash\n> export OMPL_DIR=/usr/local/lib\n> ```\n{: .prompt-warning}\n\n### 2.2. 플러그인 테스트\n\n아래 명령어를 실행하여 플러그인이 정상적으로 설치되었는지 확인합니다.\n\n```bash\nroslaunch hybrid_astar_planner test.launch\n```\n\n테스트가 성공적으로 실행되면, Hybrid A* 알고리즘을 사용하여 경로를 생성하는 것을 확인할 수 있습니다.\n\n---\n\n## 3. 기존 패키지에 플러그인 설정\n\n### 3.1 런치 파일 내 글로벌 플래너 변경\n\n기존의 글로벌 플래너 설정을 Hybrid A* 플러그인으로 변경합니다.  \n런치 파일에서 다음과 같이 수정합니다.\n\n```xml\n<!-- 기존 설정 -->\n<!-- <param name=\"base_global_planner\" value=\"navfn/NavfnROS\"/> -->\n\n<!-- Hybrid A* 플러그인 설정 -->\n<param name=\"base_global_planner\" value=\"hybrid_astar_planner/HybridAStarPlanner\"/>\n```\n\n### 3.2 package.xml 수정\n\n패키지 의존성에도 해당 플러그인을 추가해줘야 합니다.  \n아래와 같이 `package.xml` 파일에 의존성을 추가합니다.\n\n```xml\n...\n  <exec_depend>std_msgs</exec_depend>\n  <exec_depend>tf</exec_depend>\n  <depend>backoff_recovery</depend>\n  <depend>hybrid_astar_planner</depend>\n...\n```\n\n> 모든 의존성이 올바르게 설정되어 있지 않으면, 빌드 시 오류가 발생할 수 있습니다.\n{: .prompt-warning}\n\n![alt text](/assets/img/ros/astar.gif)\n---\n\n\n## 마무리\n\n이번 글에서는 ROS1 환경에서 Hybrid A\\*를 사용하기 위한 방법에 대해 다뤘습니다.  \n\n이제, 기본적인 기능은 모두 추가했으니 다음부터는 파라미터 튜닝에 대해 알아보겠습니다.  \n",
    "date": "2025-03-05",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-03-05-ROS1-Hybrid-A_chunk_0",
        "text": "ROS1 Hybrid A* Global Planner 사용하기\n\n## 개요\n\nROS1 네비게이션 스택에서는 Global Planner로 다양한 알고리즘(A\\*, Dijkstra 등)을 제공합니다.  \n하지만, 이들 대부분은 그리드 기반의 경로 탐색에 초점을 맞추고 있어 실제 차량의 동역학 제약을 충분히 반영하지 못합니다.  \n  \nHybrid A\\* 알고리즘을 활용하면, 기존의 A\\*와 달리 차량의 회전 반경 및 비홀로노믹 제약을 고려한 경로 생성이 가능해집니다.  \n이번 포스트에서는 ROS1 환경에서 Hybrid A\\* 플러그인을 적용하여 글로벌 플래너로 사용하는 방법에 대해 다룹니다.  \n\n> ROS1 move_base의 기본 Global Planner는 [https://wiki.ros.org/global_planner?distro=noetic](https://wiki.ros.org/global_planner?distro=noetic)를 참고바랍니다.\n{: .prompt-tip}\n\n---\n\n## 1. Hybrid A* vs. A* 비교\n\n\n- **A\\*:** 단순한 경로 탐색, 차량의 동역학 무시  \n- **Hybrid A\\*:** 차량 제약을 반영한 경로 생성으로, 애커만 차량에 적합  \n\nROS2의 Nav2에서는 Hybrid A*를 기본 제공하지만, ROS1에서는 별도로 직접 구현하거나 외부 플러그인을 활용해야 합니다.",
        "index": 0
      },
      {
        "id": "2025-03-05-ROS1-Hybrid-A_chunk_1",
        "text": "한 경로 생성으로, 애커만 차량에 적합  \n\nROS2의 Nav2에서는 Hybrid A*를 기본 제공하지만, ROS1에서는 별도로 직접 구현하거나 외부 플러그인을 활용해야 합니다.  \n이번 예제에서는 [https://github.com/dengpw/hybrid_astar_planner](https://github.com/dengpw/hybrid_astar_planner) 레포를 기반으로 플러그인을 설치하고 활용하는 방법을 다룹니다.\n\n---\n\n## 2. 플러그인 설치\n\n### 2.1. 레포 클론 및 빌드\n\n터미널에서 아래 명령어를 실행하여 레포를 클론하고 빌드 환경을 구성합니다.\n\n```bash\nsudo apt install libompl-dev \\\n&& cd ~/catkin_ws/src \\\n&& git clone https://github.com/dengpw/hybrid_astar_planner.git  \\\n&& cd .. \\\n&& catkin_make \\\n&& source devel/setup.bash \\\n&& rospack profile\n```\n\n \n> OMPL 관련 문제 발생 시, OMPL의 설치 경로(예: `/usr/lib` 또는 `/usr/local/lib`)를 확인하고 환경변수 `OMPL_DIR`를 올바르게 설정해야 합니다.    \n> 예를 들어, OMPL이 `/usr/local/lib`에 설치된 경우 아래와 같이 환경변수를 추가할 수 있습니다.\n> \n> ```bash\n> export OMPL_DIR=/usr/local/lib\n> ```\n{: .prompt-warning}\n\n### 2.2.",
        "index": 1
      },
      {
        "id": "2025-03-05-ROS1-Hybrid-A_chunk_2",
        "text": "환경변수를 추가할 수 있습니다.\n> \n> ```bash\n> export OMPL_DIR=/usr/local/lib\n> ```\n{: .prompt-warning}\n\n### 2.2. 플러그인 테스트\n\n아래 명령어를 실행하여 플러그인이 정상적으로 설치되었는지 확인합니다.\n\n```bash\nroslaunch hybrid_astar_planner test.launch\n```\n\n테스트가 성공적으로 실행되면, Hybrid A* 알고리즘을 사용하여 경로를 생성하는 것을 확인할 수 있습니다.\n\n---\n\n## 3. 기존 패키지에 플러그인 설정\n\n### 3.1 런치 파일 내 글로벌 플래너 변경\n\n기존의 글로벌 플래너 설정을 Hybrid A* 플러그인으로 변경합니다.  \n런치 파일에서 다음과 같이 수정합니다.\n\n```xml\n<!-- 기존 설정 -->\n<!-- <param name=\"base_global_planner\" value=\"navfn/NavfnROS\"/> -->\n\n<!-- Hybrid A* 플러그인 설정 -->\n<param name=\"base_global_planner\" value=\"hybrid_astar_planner/HybridAStarPlanner\"/>\n```\n\n### 3.2 package.xml 수정\n\n패키지 의존성에도 해당 플러그인을 추가해줘야 합니다.",
        "index": 2
      },
      {
        "id": "2025-03-05-ROS1-Hybrid-A_chunk_3",
        "text": "brid_astar_planner/HybridAStarPlanner\"/>\n```\n\n### 3.2 package.xml 수정\n\n패키지 의존성에도 해당 플러그인을 추가해줘야 합니다.  \n아래와 같이 `package.xml` 파일에 의존성을 추가합니다.\n\n```xml\n...\n  <exec_depend>std_msgs</exec_depend>\n  <exec_depend>tf</exec_depend>\n  <depend>backoff_recovery</depend>\n  <depend>hybrid_astar_planner</depend>\n...\n```\n\n> 모든 의존성이 올바르게 설정되어 있지 않으면, 빌드 시 오류가 발생할 수 있습니다.\n{: .prompt-warning}\n\n![alt text](/assets/img/ros/astar.gif)\n---\n\n\n## 마무리\n\n이번 글에서는 ROS1 환경에서 Hybrid A\\*를 사용하기 위한 방법에 대해 다뤘습니다.  \n\n이제, 기본적인 기능은 모두 추가했으니 다음부터는 파라미터 튜닝에 대해 알아보겠습니다.",
        "index": 3
      },
      {
        "id": "2025-03-05-ROS1-Hybrid-A_chunk_4",
        "text": "는 ROS1 환경에서 Hybrid A\\*를 사용하기 위한 방법에 대해 다뤘습니다.  \n\n이제, 기본적인 기능은 모두 추가했으니 다음부터는 파라미터 튜닝에 대해 알아보겠습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-03-05-ROS-Recovery-Behavior----Backoff",
    "title": "ROS Recovery Behavior 설정(Backoff 추가)",
    "path": "/2025/03/05/ROS-Recovery-Behavior-설정(Backoff-추가)/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 개요\n\nROS1 네비게이션 스택은 기본적으로 제자리 회전과 코스트맵 초기화를 recovery behavior로 제공합니다.  \n하지만 애커만 조향 차량은 제자리 회전이 불가능하므로, 후진과 같은 다른 방안이 필요합니다.  \n  \n    \n이번 글에서는 [https://github.com/maker-ATOM/backoff_recovery](https://github.com/maker-ATOM/backoff_recovery/) 레포를 활용하여 후진 리커버리 동작을 추가하는 방법을 다룹니다.  \n이를 통해 ROS1 환경에서도 애커만 차량에 적합한 리커버리 동작을 구현할 수 있습니다.\n\n---\n\n## 1. Repo Clone\n\n먼저, ROS 워크스페이스 내에 backoff_recovery 레포를 클론합니다.\n\n```bash\ncd ~/catkin_ws/src\ngit clone https://github.com/maker-ATOM/backoff_recovery/\n```\n\n---\n\n## 2. 네임스페이스 설정\n\nbackoff_recovery 패키지의 클래스 초기화 시, recovery 파라미터가 올바르게 반영되도록 네임스페이스를 설정해주어야 합니다.  \n아래와 같이 코드를 수정합니다.\n\n```cpp\nnamespace backoff_recovery\n{\n    BackoffRecovery::BackoffRecovery() : initialized_(false)\n    {\n    }\n\n    void BackoffRecovery::initialize(std::string name, tf2_ros::Buffer *,\n                                     costmap_2d::Costmap2DROS *, costmap_2d::Costmap2DROS *local_costmap)\n    {\n        if (!initialized_)\n        {\n            ros::NodeHandle private_nh(\"~/\" + name);  // 여기 수정\n\n            private_nh.param(\"backoff_distance\", backoff_distance_, 0.2);\n            private_nh.param(\"frequency\", frequency_, 20.0);\n            private_nh.param(\"vel\", vel_, 0.1);\n```\n\n> 저 부분을 수정하지 않으면, recovery 파라미터 파일(recovery_params.yaml)에서 후진 속도나 후진 거리를 조정해도 반영되지 않습니다.\n{: .prompt-tip}\n\n---\n\n## 3. 설치 확인\n\n아래 명령어를 실행하여 backoff_recovery 플러그인이 정상적으로 설치되었는지 확인합니다.\n\n```bash\nrospack plugins --attrib=plugin nav_core\n```\n\n출력에 아래와 같이 backoff_recovery 관련 항목이 표시되면 성공입니다.\n\n```yaml\nbackoff_recovery /<path_to_ws>/src/backoff_recovery/backoff_plugin.xml\n```\n\n---\n\n## 4. 리커버리 파라미터 설정\n\n네비게이션 리커버리 동작에 사용할 파라미터 파일(recovery_params.yaml)을 작성합니다.  \n여기서는 기본 코스트맵 초기화와 두 단계의 후진 동작을 정의합니다.\n\n```yaml\nrecovery_behaviors:\n  - name: 'conservative_reset'    \n    type: 'clear_costmap_recovery/ClearCostmapRecovery'\n  \n  - name: 'backoff_slow'           # 첫 번째 후진 시도 (천천히)\n    type: 'backoff_recovery/BackoffRecovery'\n  \n  - name: 'aggressive_reset'      \n    type: 'clear_costmap_recovery/ClearCostmapRecovery'\n\n  - name: 'backoff_fast'           # 두 번째 후진 시도 (빠르게)\n    type: 'backoff_recovery/BackoffRecovery'\n\n# recovery 세부 설정\nconservative_reset:\n  reset_distance: 3.0\n  layer_names: [\"laser_scan\"]\n\nbackoff_slow:                      # 첫 번째 후진 파라미터\n  backoff_distance: 0.2    \n  vel: 0.3\n\nbackoff_fast:                      # 두 번째 후진 파라미터\n  backoff_distance: 0.5    \n  vel: 0.3\n\naggressive_reset:\n  reset_distance: 0.0            \n  layer_names: [\"laser_scan\"]\n```\n\n> 위 파라미터들 또한 추후 튜닝할 예정입니다.\n{: .prompt-tip}\n\n---\n\n## 마무리\n\n이번 글에서는 ROS1 네비게이션 스택에 기본적으로 제공되는 recovery behavior에 추가로 후진 리커버리 동작을 추가했습니다.  \n\n이와 같이 ROS1에서 기본 제공되지 않지만, 필요한 기능들을 Github에서 찾아보거나 직접 플러그인을 만들어 사용할 수 있습니다.\n",
    "date": "2025-03-05",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-03-05-ROS-Recovery-Behavior----Backoff_chunk_0",
        "text": "ROS Recovery Behavior 설정(Backoff 추가)\n\n## 개요\n\nROS1 네비게이션 스택은 기본적으로 제자리 회전과 코스트맵 초기화를 recovery behavior로 제공합니다.  \n하지만 애커만 조향 차량은 제자리 회전이 불가능하므로, 후진과 같은 다른 방안이 필요합니다.  \n  \n    \n이번 글에서는 [https://github.com/maker-ATOM/backoff_recovery](https://github.com/maker-ATOM/backoff_recovery/) 레포를 활용하여 후진 리커버리 동작을 추가하는 방법을 다룹니다.  \n이를 통해 ROS1 환경에서도 애커만 차량에 적합한 리커버리 동작을 구현할 수 있습니다.\n\n---\n\n## 1. Repo Clone\n\n먼저, ROS 워크스페이스 내에 backoff_recovery 레포를 클론합니다.\n\n```bash\ncd ~/catkin_ws/src\ngit clone https://github.com/maker-ATOM/backoff_recovery/\n```\n\n---\n\n## 2. 네임스페이스 설정\n\nbackoff_recovery 패키지의 클래스 초기화 시, recovery 파라미터가 올바르게 반영되도록 네임스페이스를 설정해주어야 합니다.",
        "index": 0
      },
      {
        "id": "2025-03-05-ROS-Recovery-Behavior----Backoff_chunk_1",
        "text": "--\n\n## 2. 네임스페이스 설정\n\nbackoff_recovery 패키지의 클래스 초기화 시, recovery 파라미터가 올바르게 반영되도록 네임스페이스를 설정해주어야 합니다.",
        "index": 1
      },
      {
        "id": "2025-03-05-ROS-Recovery-Behavior----Backoff_chunk_2",
        "text": "--\n\n## 2. 네임스페이스 설정\n\nbackoff_recovery 패키지의 클래스 초기화 시, recovery 파라미터가 올바르게 반영되도록 네임스페이스를 설정해주어야 합니다.",
        "index": 2
      },
      {
        "id": "2025-03-05-ROS-Recovery-Behavior----Backoff_chunk_3",
        "text": "--\n\n## 2. 네임스페이스 설정\n\nbackoff_recovery 패키지의 클래스 초기화 시, recovery 파라미터가 올바르게 반영되도록 네임스페이스를 설정해주어야 합니다.",
        "index": 3
      },
      {
        "id": "2025-03-05-ROS-Recovery-Behavior----Backoff_chunk_4",
        "text": "--\n\n## 2. 네임스페이스 설정\n\nbackoff_recovery 패키지의 클래스 초기화 시, recovery 파라미터가 올바르게 반영되도록 네임스페이스를 설정해주어야 합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-03-03-ROS-Navigation-Stack",
    "title": "ROS Navigation Stack 설정하기",
    "path": "/2025/03/03/ROS-Navigation-Stack-설정하기/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 개요\n\n이전 글에서 모터 드라이버를 ROS 패키지화 했습니다.  \n이번 글에서는 **my_slam** 패키지에 네비게이션 스택 설정을 추가하여, SLAM으로 생성된 지도 위에서 경로를 계획하고 이동할 수 있도록 합니다.  \n\n---\n\n## 1. 현재 디렉터리 구조\n\n먼저, **my_slam** 패키지의 디렉터리 구조입니다.  \n여기에는 SLAM 관련 파일과 네비게이션 설정 파일이 추가될 예정입니다.\n\n```bash\nmy_slam\n├── CMakeLists.txt\n├── include\n│   └── my_slam\n├── launch\n│   ├── my_slam.launch\n│   └── teleop_test.launch\n├── package.xml\n├── rviz\n│   └── slam.rviz\n└── src\n```\n\n---\n\n## 2. 패키지 설치\n\n네비게이션 스택을 사용하기 위해 필요한 ROS 패키지를 설치합니다.  \n\n```bash\nsudo apt-get install ros-noetic-move-base ros-noetic-navigation\n```\n\n---\n\n## 3. 파라미터 파일 생성\n\n네비게이션 스택의 동작을 제어하는 여러 파라미터 파일들을 생성합니다.  \n아래 명령어를 통해 파라미터 파일을 저장할 디렉터리와 필요한 파일들을 생성합니다.\n\n```bash\ncd ~/catkin_ws/src/my_slam\nmkdir -p config/move_base\n\n# 파라미터 파일 생성\ntouch config/move_base/costmap_common_params.yaml\ntouch config/move_base/local_costmap_params.yaml\ntouch config/move_base/global_costmap_params.yaml\ntouch config/move_base/base_local_planner_params.yaml\n```\n\n---\n\n## 4. 파라미터 파일 내용\n\n### 4.1 costmap_common_params.yaml\n\n모든 costmap이 공통으로 사용하는 기본 파라미터를 정의합니다.  \n로봇의 물리적 크기, 센서 설정, 장애물 감지 및 안전 거리 등을 포함합니다.\n\n```yaml\n# 로봇의 물리적 특성\nfootprint: [[-0.15, -0.06], [-0.15, 0.06], [0.15, 0.06], [0.15, -0.06]]\nrobot_radius: 0.20\n\n# 장애물 감지 및 회피 설정\nobstacle_layer:\n  observation_sources: laser_scan_sensor\n  laser_scan_sensor:\n    sensor_frame: laser_frame\n    data_type: LaserScan\n    topic: scan\n    marking: true\n    clearing: true\n    inf_is_valid: true\n\n# 장애물 팽창 설정\ninflation_layer:\n  inflation_radius: 0.50\n  cost_scaling_factor: 2.0\n\n# 속도 제한 설정\nmax_vel_x: 0.3\nmax_vel_theta: 0.8\nmin_vel_x: -0.3\nmin_vel_theta: -0.8\nmin_in_place_vel_theta: 0.4\n```\n\n### 4.2 local_costmap_params.yaml\n\n로봇 주변의 단기 경로 계획을 위한 지역(costmap) 설정 파일입니다.  \n실시간으로 업데이트되는 작은 영역을 대상으로 하며, 장애물 회피에 주로 활용됩니다.\n\n```yaml\nlocal_costmap:\n  global_frame: odom\n  robot_base_frame: base_footprint\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: false\n  rolling_window: true\n  width: 3.0\n  height: 3.0\n  resolution: 0.05\n  transform_tolerance: 0.5\n\n  obstacle_layer:\n    observation_persistence: 0.2\n    mark_threshold: 0.3\n    clearing_threshold: 0.7\n\n  plugins:\n    - {name: obstacle_layer, type: \"costmap_2d::ObstacleLayer\"}\n    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n```\n\n### 4.3 global_costmap_params.yaml\n\n전체 환경에 대한 경로 계획을 위한 글로벌 costmap 설정 파일입니다.  \nSLAM으로 생성된 전체 지도를 활용하여 출발지부터 목적지까지의 전반적인 경로를 계획합니다.\n\n```yaml\nglobal_costmap:\n  global_frame: map\n  robot_base_frame: base_footprint\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: true\n  transform_tolerance: 0.5\n  plugins:\n    - {name: static_layer, type: \"costmap_2d::StaticLayer\"}\n    - {name: obstacle_layer, type: \"costmap_2d::ObstacleLayer\"}\n    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n```\n\n### 4.4 base_local_planner_params.yaml\n\n로봇의 실제 움직임을 제어하는 파라미터들을 설정합니다.  \n최대 속도, 가속도, 목표 도달 허용 오차 등 로봇이 계획된 경로를 어떻게 따라갈지 결정합니다.\n\n```yaml\nTrajectoryPlannerROS:\n  max_vel_x: 0.5\n  min_vel_x: 0.2\n  max_vel_theta: 0.8\n  min_vel_theta: -0.8\n  min_in_place_vel_theta: 0.4\n\n  acc_lim_theta: 0.6\n  acc_lim_x: 0.2\n  acc_lim_y: 0.0\n\n  holonomic_robot: false\n  \n  # 목표 도달 허용 오차\n  xy_goal_tolerance: 0.10\n  yaw_goal_tolerance: 0.05\n\n  # Forward Simulation Parameters\n  sim_time: 2.0\n  vx_samples: 10\n  vtheta_samples: 20\n\n  # Trajectory Scoring Parameters\n  meter_scoring: true\n  path_distance_bias: 0.8\n  goal_distance_bias: 0.6\n  occdist_scale: 0.02\n  heading_lookahead: 0.325\n```\n\n> 추후 성능 고도화를 위해 파라미터 튜닝을 진행할 예정이기에, 우선 이렇게 설정하고 넘어갑니다.\n{: .prompt-tip }\n\n---\n\n## 5. 런치 파일 작성\n\n네비게이션 스택과 SLAM, 그리고 모터 컨트롤러 노드를 동시에 실행하기 위한 런치 파일을 작성합니다.\n\n### 5.1 navigation.launch\n\n`launch/navigation.launch` 파일은 SLAM, 모터 컨트롤러, Move Base, RViz를 모두 포함하여 전체 시스템을 실행합니다.\n\n```xml\n<?xml version=\"1.0\"?>\n<launch>\n    <!-- SLAM 실행 -->\n    <include file=\"$(find my_slam)/launch/my_slam.launch\" />\n    \n    <!-- 모터 컨트롤러 실행 -->\n    <include file=\"$(find robot_motor_controller)/launch/motor_controller.launch\" />\n\n    <!-- Move Base 노드 실행 -->\n    <node pkg=\"move_base\" type=\"move_base\" respawn=\"false\" name=\"move_base\" output=\"screen\">\n        <rosparam file=\"$(find my_slam)/config/move_base/costmap_common_params.yaml\" command=\"load\" ns=\"global_costmap\" />\n        <rosparam file=\"$(find my_slam)/config/move_base/costmap_common_params.yaml\" command=\"load\" ns=\"local_costmap\" />\n        <rosparam file=\"$(find my_slam)/config/move_base/local_costmap_params.yaml\" command=\"load\" />\n        <rosparam file=\"$(find my_slam)/config/move_base/global_costmap_params.yaml\" command=\"load\" />\n        <rosparam file=\"$(find my_slam)/config/move_base/base_local_planner_params.yaml\" command=\"load\" />\n    </node>\n\n    <!-- RViz 실행 -->\n    <node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" args=\"-d $(find my_slam)/rviz/navigation.rviz\"/>\n</launch>\n```\n\n> RViz 파일은 코드 길이가 길어 생략하겠습니다.  \n> 실행 후, 직접 Add로 토픽들을 추가한 후 저장하여 사용할 수 있습니다.\n{: .prompt-tip }\n\n### 5.2 my_slam.launch 수정\n\n**my_slam.launch** 파일에서는 네비게이션과 SLAM 둘 다 RViz를 사용하기 때문에, SLAM 테스트를 위한 RViz 실행 부분은 주석 처리합니다.\n\n```xml\n...\n\t<node pkg=\"tf\" type=\"static_transform_publisher\" name=\"map_to_odom\" args=\"0 0 0 0 0 0 map nav 100\"/>\n    <!-- RViz -->\n    <!--<node pkg=\"rviz\" type=\"rviz\" name=\"rviz\" \n          args=\"-d $(find my_slam)/rviz/slam.rviz\" respawn=\"true\"/>-->\n...\n```\n\n---\n\n## 6. 실행 결과\n\n모든 설정이 완료되면, 다음 명령어로 전체 시스템을 실행합니다.\n\n```bash\nroslaunch my_slam navigation.launch\n```\n\n실행 결과로는 SLAM을 통한 지도 생성, 네비게이션 스택에 의한 경로 계획, 그리고 RViz를 통한 시각화가 동시에 이루어지며, 아래와 같은 결과 화면을 확인할 수 있습니다.\n\n- **지도 생성 및 네비게이션 경로:**  \n  SLAM으로 생성된 지도 위에 로봇의 경로 및 장애물 정보가 표시됩니다.  \n![rviz](/assets/img/ros/rvizresult.png)\n\n\n- **TF 프레임 및 rosgraph:**  \n  로봇의 좌표계 정보와 노드 간의 연결 관계를 확인할 수 있습니다.  \n![TF Tree](/assets/img/ros/TFtree.png)\n![ros graph](/assets/img/ros/rosgraph.png)  \n\n> 현재 TF Tree에 바퀴와 관련된 Frame들이 보이는데, 이는 URDF에 의한 것으로, 추후 제거 예정입니다.  \n> TF tree가 다른 점은 추후 수정할 예정이며, 정상적으로 경로가 생성된다면 괜찮습니다.  \n{: .prompt-warning }\n\n---\n\n## 마무리\n\n이번 글에서는 기존의 모터 드라이버 기반 ROS 패키지와 SLAM 시스템에 네비게이션 스택을 통합하는 과정을 다뤘습니다.  \n\n이후 글로벌 플래너와 로컬 플래너를 변경할 예정이며, 각종 파라미터 튜닝을 진행할 계획입니다.  \n\n현재는 정상적으로 경로가 생성되는 지, 그리고 `rostopic echo cmd_vel`을 통해 정상적으로 명령이 출력되는 지 확인하면 됩니다.  \n",
    "date": "2025-03-03",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-03-03-ROS-Navigation-Stack_chunk_0",
        "text": "ROS Navigation Stack 설정하기\n\n## 개요\n\n이전 글에서 모터 드라이버를 ROS 패키지화 했습니다.  \n이번 글에서는 **my_slam** 패키지에 네비게이션 스택 설정을 추가하여, SLAM으로 생성된 지도 위에서 경로를 계획하고 이동할 수 있도록 합니다.  \n\n---\n\n## 1. 현재 디렉터리 구조\n\n먼저, **my_slam** 패키지의 디렉터리 구조입니다.  \n여기에는 SLAM 관련 파일과 네비게이션 설정 파일이 추가될 예정입니다.\n\n```bash\nmy_slam\n├── CMakeLists.txt\n├── include\n│   └── my_slam\n├── launch\n│   ├── my_slam.launch\n│   └── teleop_test.launch\n├── package.xml\n├── rviz\n│   └── slam.rviz\n└── src\n```\n\n---\n\n## 2. 패키지 설치\n\n네비게이션 스택을 사용하기 위해 필요한 ROS 패키지를 설치합니다.  \n\n```bash\nsudo apt-get install ros-noetic-move-base ros-noetic-navigation\n```\n\n---\n\n## 3. 파라미터 파일 생성\n\n네비게이션 스택의 동작을 제어하는 여러 파라미터 파일들을 생성합니다.",
        "index": 0
      },
      {
        "id": "2025-03-03-ROS-Navigation-Stack_chunk_1",
        "text": "-move-base ros-noetic-navigation\n```\n\n---\n\n## 3. 파라미터 파일 생성\n\n네비게이션 스택의 동작을 제어하는 여러 파라미터 파일들을 생성합니다.  \n아래 명령어를 통해 파라미터 파일을 저장할 디렉터리와 필요한 파일들을 생성합니다.\n\n```bash\ncd ~/catkin_ws/src/my_slam\nmkdir -p config/move_base\n\n# 파라미터 파일 생성\ntouch config/move_base/costmap_common_params.yaml\ntouch config/move_base/local_costmap_params.yaml\ntouch config/move_base/global_costmap_params.yaml\ntouch config/move_base/base_local_planner_params.yaml\n```\n\n---\n\n## 4. 파라미터 파일 내용\n\n### 4.1 costmap_common_params.yaml\n\n모든 costmap이 공통으로 사용하는 기본 파라미터를 정의합니다.",
        "index": 1
      },
      {
        "id": "2025-03-03-ROS-Navigation-Stack_chunk_2",
        "text": "`\n\n---\n\n## 4. 파라미터 파일 내용\n\n### 4.1 costmap_common_params.yaml\n\n모든 costmap이 공통으로 사용하는 기본 파라미터를 정의합니다.  \n로봇의 물리적 크기, 센서 설정, 장애물 감지 및 안전 거리 등을 포함합니다.\n\n```yaml\n# 로봇의 물리적 특성\nfootprint: [[-0.15, -0.06], [-0.15, 0.06], [0.15, 0.06], [0.15, -0.06]]\nrobot_radius: 0.20\n\n# 장애물 감지 및 회피 설정\nobstacle_layer:\n  observation_sources: laser_scan_sensor\n  laser_scan_sensor:\n    sensor_frame: laser_frame\n    data_type: LaserScan\n    topic: scan\n    marking: true\n    clearing: true\n    inf_is_valid: true\n\n# 장애물 팽창 설정\ninflation_layer:\n  inflation_radius: 0.50\n  cost_scaling_factor: 2.0\n\n# 속도 제한 설정\nmax_vel_x: 0.3\nmax_vel_theta: 0.8\nmin_vel_x: -0.3\nmin_vel_theta: -0.8\nmin_in_place_vel_theta: 0.4\n```\n\n### 4.2 local_costmap_params.yaml\n\n로봇 주변의 단기 경로 계획을 위한 지역(costmap) 설정 파일입니다.",
        "index": 2
      },
      {
        "id": "2025-03-03-ROS-Navigation-Stack_chunk_3",
        "text": "ce_vel_theta: 0.4\n```\n\n### 4.2 local_costmap_params.yaml\n\n로봇 주변의 단기 경로 계획을 위한 지역(costmap) 설정 파일입니다.  \n실시간으로 업데이트되는 작은 영역을 대상으로 하며, 장애물 회피에 주로 활용됩니다.\n\n```yaml\nlocal_costmap:\n  global_frame: odom\n  robot_base_frame: base_footprint\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: false\n  rolling_window: true\n  width: 3.0\n  height: 3.0\n  resolution: 0.05\n  transform_tolerance: 0.5\n\n  obstacle_layer:\n    observation_persistence: 0.2\n    mark_threshold: 0.3\n    clearing_threshold: 0.7\n\n  plugins:\n    - {name: obstacle_layer, type: \"costmap_2d::ObstacleLayer\"}\n    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n```\n\n### 4.3 global_costmap_params.yaml\n\n전체 환경에 대한 경로 계획을 위한 글로벌 costmap 설정 파일입니다.",
        "index": 3
      },
      {
        "id": "2025-03-03-ROS-Navigation-Stack_chunk_4",
        "text": "InflationLayer\"}\n```\n\n### 4.3 global_costmap_params.yaml\n\n전체 환경에 대한 경로 계획을 위한 글로벌 costmap 설정 파일입니다.  \nSLAM으로 생성된 전체 지도를 활용하여 출발지부터 목적지까지의 전반적인 경로를 계획합니다.\n\n```yaml\nglobal_costmap:\n  global_frame: map\n  robot_base_frame: base_footprint\n  update_frequency: 5.0\n  publish_frequency: 2.0\n  static_map: true\n  transform_tolerance: 0.5\n  plugins:\n    - {name: static_layer, type: \"costmap_2d::StaticLayer\"}\n    - {name: obstacle_layer, type: \"costmap_2d::ObstacleLayer\"}\n    - {name: inflation_layer, type: \"costmap_2d::InflationLayer\"}\n```\n\n### 4.4 base_local_planner_params.yaml\n\n로봇의 실제 움직임을 제어하는 파라미터들을 설정합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-03-02-ROS-Motor-Controller",
    "title": "ROS Motor Controller 패키지 생성",
    "path": "/2025/03/02/ROS-Motor-Controller-만들기/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 개요\n\n이번 글에서는 기존에 제작한 모터 드라이버를 활용하여, ROS 환경에서 모터와 서보를 제어할 수 있는 **`robot_motor_controller`** 패키지를 만드는 과정을 다룹니다.\n\n---\n\n## 1. 패키지 생성 및 디렉터리 구조\n\n먼저, 새로운 ROS 패키지를 생성합니다. 아래 명령어를 통해 **`robot_motor_controller`** 패키지를 생성하고, 기본 디렉터리 구조를 구성합니다.\n\n```bash\ncd ~/catkin_ws/src\ncatkin_create_pkg robot_motor_controller roscpp geometry_msgs\n\ncd robot_motor_controller\nmkdir -p include/robot_motor_controller config\n```\n\n패키지 생성 후 디렉터리 구조는 아래와 같이 구성됩니다.\n\n> 모터 드라이버에 대한 내용은 추후 작성 후, 링크 첨부 예정입니다.\n{: .prompt-info }\n\n```bash\n$ tree .\n.\n├── CMakeLists.txt\n├── README.md\n├── config\n├── include\n│   └── robot_motor_controller\n│       ├── DC_motor.hpp\n│       ├── PCA9685.hpp\n│       ├── Servo_motor.hpp\n│       ├── i2c.hpp\n│       └── motor_controller.h\n├── launch\n├── package.xml\n└── src\n    ├── DC_motor.cpp\n    ├── PCA9685.cpp\n    ├── Servo_motor.cpp\n    ├── i2c.cpp\n    ├── motor_controller.cpp\n    └── motor_controller_node.cpp\n```\n\n---\n\n## 2. 헤더 파일 작성\n\n`include/robot_motor_controller/motor_controller.h` 파일에서는 모터 제어에 필요한 각종 드라이버 헤더와 ROS 인터페이스를 포함합니다.  \n여기서 **ROS Subscriber**를 이용해 `cmd_vel` 토픽을 구독하고, 이를 통해 모터의 throttle과 서보의 각도를 제어하는 인터페이스를 정의합니다.\n\n```cpp\n#ifndef MOTOR_CONTROLLER_H\n#define MOTOR_CONTROLLER_H\n\n#include <ros/ros.h>\n#include <geometry_msgs/Twist.h>\n#include \"DC_motor.hpp\"\n#include \"Servo_motor.hpp\"\n#include \"PCA9685.hpp\"\n#include \"i2c.hpp\"\n\nclass MotorController {\nprivate:\n    ros::NodeHandle nh_;\n    ros::Subscriber cmd_vel_sub_;\n    \n    // I2C 디바이스 (모터와 서보를 위한 각각의 I2C 인터페이스)\n    I2CDevice i2c_dc_;\n    I2CDevice i2c_servo_;\n    \n    // PCA9685 컨트롤러 (각 I2C 디바이스에 연결)\n    PCA9685 pca_dc_;\n    PCA9685 pca_servo_;\n    \n    // 모터 및 서보 제어 객체\n    PWMThrottleHat motor_;\n    Servo servo_;\n    \n    // ROS 파라미터 (예: 서보 채널 번호)\n    int servo_channel_;\n\npublic:\n    MotorController(ros::NodeHandle& nh);\n    void cmdVelCallback(const geometry_msgs::Twist::ConstPtr& msg);\n};\n\n#endif // MOTOR_CONTROLLER_H\n```\n\n---\n\n## 3. 소스 코드 작성\n\n### 모터 컨트롤러 클래스 구현\n\n`src/motor_controller.cpp` 파일에서는 생성자 내 초기화 작업과 `cmdVelCallback` 함수에서 받은 속도 명령을 모터 제어 명령으로 변환하는 과정을 다룹니다.  \n여기서는 `geometry_msgs/Twist` 메시지의 `linear.x` 값을 throttle로, `angular.z` 값을 서보 각도로 변환합니다.\n\n> 제작하는 차량의 경우 애커만 조향인 점을 고려해 `linear.x`와 `angular.z`만 사용합니다.\n{: .prompt-info }\n\n```cpp\n#include \"robot_motor_controller/motor_controller.h\"\n#include <algorithm>\n\nMotorController::MotorController(ros::NodeHandle& nh) : \n    nh_(nh),\n    i2c_dc_(\"/dev/i2c-7\", 0x40),\n    i2c_servo_(\"/dev/i2c-7\", 0x60),\n    pca_dc_(i2c_dc_),\n    pca_servo_(i2c_servo_),\n    motor_(pca_dc_, 0),\n    servo_(pca_servo_)\n{\n    // ROS 파라미터 초기화 (필요 시 rosparam을 이용하여 동적 설정 가능)\n    servo_channel_ = 0;  // 기본값 설정\n    \n    // cmd_vel 토픽 구독: 로봇의 이동 명령을 수신\n    cmd_vel_sub_ = nh_.subscribe(\"cmd_vel\", 1, &MotorController::cmdVelCallback, this);\n    \n    ROS_INFO(\"Motor Controller initialized\");\n}\n\nvoid MotorController::cmdVelCallback(const geometry_msgs::Twist::ConstPtr& msg)\n{\n    // linear.x를 throttle로 변환 (-1.0 ~ 1.0 범위)\n    float throttle = msg->linear.x;  // 필요한 경우 추가 스케일링 적용 가능\n    \n    // angular.z를 서보의 회전각으로 변환 (-45° ~ 45°)\n    float angle = msg->angular.z * (45.0 / M_PI);  // rad/s -> degree 변환\n    \n    // 값의 범위를 제한\n    throttle = std::max(-1.0f, std::min(1.0f, throttle));\n    angle = std::max(-45.0f, std::min(45.0f, angle));\n    \n    // 모터 및 서보 제어 호출\n    motor_.setThrottle(throttle);\n    servo_.setAngle(servo_channel_, angle);\n}\n```\n\n### 노드 파일 작성\n\n`src/motor_controller_node.cpp` 파일에서는 ROS 노드를 초기화하고, 모터 컨트롤러 객체를 생성한 후 `ros::spin()`을 호출하여 콜백 함수가 계속 실행되도록 합니다.  \n\n> ROS **노드(Node)**란 하나의 실행 단위로, 서로 독립적으로 동작하며 메시지를 주고받는 기본 단위입니다.  \n> 비유하자면 개별 프로세스 느낌?\n{: .prompt-tip }\n\n```cpp\n#include <ros/ros.h>\n#include \"robot_motor_controller/motor_controller.h\"\n\nint main(int argc, char** argv)\n{\n    ros::init(argc, argv, \"motor_controller_node\");\n    ros::NodeHandle nh;\n    \n    MotorController controller(nh);\n    \n    ros::spin();\n    \n    return 0;\n}\n```\n\n---\n\n## 4. 런치 파일 작성\n\nROS 패키지를 실행할 때 사용하는 런치(launch) 파일을 작성합니다.  \n이 파일을 통해, 노드 실행 시 필요한 파라미터 설정과 실행 옵션을 쉽게 관리할 수 있습니다.\n\n```xml\n<launch>\n    <node pkg=\"robot_motor_controller\" type=\"motor_controller_node\" name=\"motor_controller\" output=\"screen\">\n    </node>\n</launch>\n```\n\n---\n\n## 5. CMakeLists.txt 수정 내용 설명\n\nROS 패키지를 빌드하기 위해 CMakeLists.txt 파일을 수정합니다.  \n여기서 수정 사항은 아래와 같습니다.\n\n### 라이브러리와 실행 파일 분리\n\n- **라이브러리 추가:**  \n  소스 파일들(`DC_motor.cpp`, `PCA9685.cpp`, `Servo_motor.cpp`, `i2c.cpp`)을 하나의 라이브러리로 묶어 다른 소스 파일에서 재사용할 수 있도록 합니다.\n  \n  ```cmake\n  add_library(${PROJECT_NAME}\n    src/DC_motor.cpp\n    src/PCA9685.cpp\n    src/Servo_motor.cpp\n    src/i2c.cpp\n  )\n  ```\n\n- **실행 파일 추가:**  \n  노드 실행을 위한 `motor_controller_node.cpp`와 모터 컨트롤러 구현 파일(`motor_controller.cpp`)을 하나의 실행 파일로 빌드합니다.\n  \n  ```cmake\n  add_executable(motor_controller_node \n    src/motor_controller_node.cpp\n    src/motor_controller.cpp\n  )\n  ```\n\n### 타겟 간 의존성 및 링크 설정\n\n- 라이브러리와 실행 파일이 올바르게 연결될 수 있도록 `add_dependencies`와 `target_link_libraries`를 사용합니다.  \n- 실행 파일은 먼저 라이브러리를 링크한 후, ROS 의존성을 해결하기 위해 `${catkin_LIBRARIES}`를 추가합니다.\n\n  ```cmake\n  add_dependencies(motor_controller_node ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})\n  \n  target_link_libraries(${PROJECT_NAME}\n    ${catkin_LIBRARIES}\n  )\n  \n  target_link_libraries(motor_controller_node\n    ${PROJECT_NAME}\n    ${catkin_LIBRARIES}\n  )\n  ```\n\n---\n\n## 6. 빌드 및 실행\n\n모든 파일 작성이 완료되면, catkin 워크스페이스 최상위 디렉터리에서 빌드를 진행합니다.\n\n```bash\ncd ~/catkin_ws\ncatkin_make\n```\n\n빌드가 완료된 후, 다음 명령어로 노드를 실행하여 모터 및 서보 제어가 정상 동작하는지 확인합니다.\n\n```bash\nroslaunch robot_motor_controller motor_controller.launch\n```\n\n---\n\n## 마무리\n\n이번 글에서는 모터 드라이버를 기반으로 한 ROS 패키지 **`robot_motor_controller`**를 제작하는 과정을 다뤘습니다.  \n\n간단한 테스트 후, 정상 작동하는 것을 확인했다면 ROS Navigation Stack을 연동하여 실제로 주행해보겠습니다.  \n",
    "date": "2025-03-02",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-03-02-ROS-Motor-Controller_chunk_0",
        "text": "ROS Motor Controller 패키지 생성\n\n## 개요\n\n이번 글에서는 기존에 제작한 모터 드라이버를 활용하여, ROS 환경에서 모터와 서보를 제어할 수 있는 **`robot_motor_controller`** 패키지를 만드는 과정을 다룹니다.\n\n---\n\n## 1. 패키지 생성 및 디렉터리 구조\n\n먼저, 새로운 ROS 패키지를 생성합니다.",
        "index": 0
      },
      {
        "id": "2025-03-02-ROS-Motor-Controller_chunk_1",
        "text": "`robot_motor_controller`** 패키지를 만드는 과정을 다룹니다.\n\n---\n\n## 1. 패키지 생성 및 디렉터리 구조\n\n먼저, 새로운 ROS 패키지를 생성합니다.",
        "index": 1
      },
      {
        "id": "2025-03-02-ROS-Motor-Controller_chunk_2",
        "text": "`robot_motor_controller`** 패키지를 만드는 과정을 다룹니다.\n\n---\n\n## 1. 패키지 생성 및 디렉터리 구조\n\n먼저, 새로운 ROS 패키지를 생성합니다.",
        "index": 2
      },
      {
        "id": "2025-03-02-ROS-Motor-Controller_chunk_3",
        "text": "`robot_motor_controller`** 패키지를 만드는 과정을 다룹니다.\n\n---\n\n## 1. 패키지 생성 및 디렉터리 구조\n\n먼저, 새로운 ROS 패키지를 생성합니다.",
        "index": 3
      },
      {
        "id": "2025-03-02-ROS-Motor-Controller_chunk_4",
        "text": "`robot_motor_controller`** 패키지를 만드는 과정을 다룹니다.\n\n---\n\n## 1. 패키지 생성 및 디렉터리 구조\n\n먼저, 새로운 ROS 패키지를 생성합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-02-23-Git------1",
    "title": "Git 튜토리얼 1",
    "path": "/2025/02/23/Git-튜토리얼-1/",
    "categories": [
      "Computer Science",
      "Git",
      "Computer_Science/git"
    ],
    "content": "## 개요\n\n이 글은 [Learn Git Branching](https://learngitbranching.js.org/?locale=ko) 튜토리얼을 참고하여 Git의 주요 개념과 기능들을 정리한 내용입니다.  \n\n---\n\n## Git 커밋\n\nGit에서 **커밋**은 작업 디렉터리의 상태(변경 사항)를 저장소에 기록하는 순간입니다.  \n실제로 Git은 디렉터리 내 모든 파일의 전체 스냅샷을 저장하는 것이 아니라, 파일들의 **변경 내역(Delta)** 만을 저장하여 효율적으로 버전을 관리합니다.  \n커밋을 생성하면, 변경된 내용이 추적 가능하며 나중에 특정 시점으로 되돌리거나 비교할 수 있습니다.\n\n```bash\ngit commit -m \"커밋메시지\"\n```\n\n---\n\n## Git 브랜치\n\n**브랜치**는 저장소 내의 특정 커밋을 가리키는 포인터(참조)입니다.  \n- **핵심:** 브랜치는 실제 작업 내역을 복사하지 않고, 단지 어떤 커밋을 기준으로 작업을 진행할 것인지를 가리키기 때문에, 브랜치를 만드는 데 별도의 메모리나 디스크 공간이 크게 소모되지 않습니다.\n- **권장:** “빨리 그리고 자주 브랜치를 만들어라!”  \n  작업 단위를 작게 나누어 관리하면, 나중에 통합(merge)할 때 발생하는 충돌이나 문제를 줄일 수 있습니다.\n\n기본 사용법:\n- 브랜치 생성:  \n  ```bash\n  git branch [브랜치이름]\n  ```\n- 브랜치 이동:  \n  ```bash\n  git checkout [브랜치이름]\n  ```\n  \n이 때, 브랜치는 하나의 커밋과 그 부모 커밋들을 포함하는 작업 내역의 연속처럼 보이지만, 실제로는 단순히 특정 커밋을 가리키는 레퍼런스입니다.\n\n---\n\n## Git 머지\n\n**머지(Merge)**는 두 개 이상의 브랜치의 작업 내역을 하나로 합치는 과정입니다.  \n머지를 수행하면, 두 부모의 작업 내역을 통합한 새로운 **병합 커밋(Merge Commit)** 이 생성됩니다.  \n예를 들어, `bugFix` 브랜치에서 작업한 내용을 `main` 브랜치에 병합하려면:\n\n```bash\ngit checkout main\ngit merge bugFix\n```\n\n이렇게 하면 `main` 브랜치에 `bugFix`의 작업 내역이 합쳐집니다.\n\n---\n\n## Git 리베이스\n\n**리베이스(Rebase)**는 현재 브랜치의 커밋들을 다른 브랜치의 최신 커밋 뒤에 재적용하는 작업입니다.  \n- 리베이스는 기존 커밋의 복사본을 만들어 새로운 베이스 위에 재적용하기 때문에, 커밋 로그가 한 줄로 깔끔하게 정리되는 효과가 있습니다.\n- 저장소의 커밋 이력이 깨끗해지는 장점이 있으나, 공개된 히스토리에서 리베이스를 사용하면 협업 시 문제가 발생할 수 있으므로 주의해야 합니다.\n\n사용 예:\n```bash\ngit rebase [브랜치명]\n```\n\n예를 들어, `bugFix` 브랜치에서 작업한 커밋들을 `main` 브랜치의 최신 커밋 뒤에 붙이고 싶다면 `git rebase main`을 실행합니다.\n\n---\n\n## Git HEAD\n\n**HEAD**는 현재 체크아웃되어 작업 중인 커밋을 가리킵니다.  \n- 일반적으로는 브랜치(예: `bugFix` 또는 `main`)가 HEAD를 가리키지만, 특정 커밋 해시로 직접 체크아웃할 경우에는 고정된 과거 커밋을 가리키게 됩니다.\n- 커밋을 생성하면 HEAD가 자동으로 최신 커밋을 가리키게 됩니다.\n\n---\n\n## 상대 참조\n\n커밋 해시는 SHA1 알고리즘에 의해 생성되므로 매우 길고 복잡하지만, Git은 **상대 참조**를 통해 간단하게 표현할 수 있도록 지원합니다.\n- `^`: 한 단계 부모 커밋을 가리킵니다.\n- `~<숫자>`: 여러 단계 위의 부모 커밋을 가리킵니다.\n\n예:\n```bash\ngit checkout main^\ngit checkout main~1\n```\n이 둘은 동일하게 `main` 브랜치의 한 단계 이전 커밋으로 이동합니다.\n\n---\n\n## 브랜치 강제 이동\n\n`-f` 옵션과 상대 참조를 사용하면, 브랜치를 특정 커밋으로 재지정할 수 있습니다.\n예를 들어, `main` 브랜치를 현재 HEAD에서 3번 이전 커밋으로 이동시키려면:\n\n```bash\ngit branch -f main HEAD~3\n```\n\n또한, `<브랜치명>`이나 `<커밋 해시>`를 직접 사용할 수도 있습니다.\n\n---\n\n## Git에서 작업 되돌리기\n\n작업 내역을 되돌리는 방법에는 두 가지 주요 방식이 있습니다.\n\n1. **git reset**  \n   - 로컬 히스토리에서 커밋 자체를 제거하여, 커밋하지 않은 상태로 되돌립니다.\n   - 예:  \n     ```bash\n     git reset HEAD~1\n     ```\n   - 주의: 이미 공유된 커밋을 reset하면 협업 시 문제가 발생할 수 있습니다.\n\n2. **git revert**  \n   - 기존 커밋의 변경 내용을 반대로 적용한 새로운 커밋을 생성하여, 변경 사항을 취소합니다.\n   - 예:\n     ```bash\n     git revert HEAD\n     ```\n   - 이렇게 하면, 원래의 커밋은 그대로 유지되면서 반대 내용의 커밋(`C2'` 등)이 생성됩니다.\n\n---\n\n## Git Cherry-pick\n\n**체리픽(Cherry-pick)** 은 특정 커밋 하나 또는 여러 개를 선택하여 현재 브랜치에 복사해오는 기능입니다.\n예를 들어, `C2`와 `C4` 커밋만을 현재 브랜치에 적용하고 싶다면:\n\n```bash\ngit cherry-pick C2 C4\n```\n\n체리픽은 rebase를 사용해서도 가능하지만, 명시적으로 특정 커밋만 선택할 때 유용합니다.\n\n---\n\n## Git Interactive Rebase\n\n**인터랙티브 리베이스**는 `-i` 옵션을 사용하여 커밋 이력을 재구성하는 방법입니다.\n- 커밋 순서를 바꾸거나, 원하지 않는 커밋을 제거하고, 여러 커밋을 하나로 스쿼시할 수 있습니다.\n- 실행 명령어:\n  ```bash\n  git rebase -i [기준 커밋]\n  ```\n- 이 방법을 통해 디버깅용 커밋이나 불필요한 커밋들을 정리할 수 있습니다.\n\n---\n\n## 기존 커밋 내역 수정하기\n\n개발 중 이전 커밋의 내용을 살짝 수정해야 할 경우, 다음과 같은 방법들을 사용할 수 있습니다.\n- **git commit --amend**: 가장 최근 커밋을 수정합니다.\n- **git rebase -i**: 여러 커밋을 대상으로 커밋 메시지 수정, 순서 변경, 스쿼시 등의 작업을 수행합니다.\n\n---\n\n## Git 태그\n\n브랜치는 가변적인 참조인 반면, **태그(Tag)** 는 특정 커밋을 영구적인 마일스톤으로 표시합니다.\n- 태그 생성:\n  ```bash\n  git tag v1 [커밋 해시]\n  ```\n  커밋 해시를 생략하면 현재 HEAD에 태그가 붙습니다.\n- 태그와 커밋 간의 관계를 확인하기 위해:\n  ```bash\n  git describe [브랜치 or 커밋]\n  ```\n  출력 예시: `v1_3_gfed2` — 가장 가까운 태그(`v1`), 그 태그로부터의 커밋 수(`3`), 그리고 커밋 해시의 일부(`fed2`)\n\n---\n\n## 요약\n\n지금까지 Git의 주요 개념에 대해 정리했습니다.\n\n- **커밋**은 변경 사항의 스냅샷을 기록하며, 실제로는 변경된 내역(Delta)만 저장합니다.\n- **브랜치**는 특정 커밋을 가리키는 포인터로, 작업 내역을 효율적으로 분리하고 관리할 수 있게 합니다.\n- **머지**는 두 브랜치의 작업 내역을 통합한 새로운 병합 커밋을 생성합니다.\n- **리베이스**는 커밋들을 복사하여 다른 브랜치 위에 재적용, 커밋 로그를 깔끔하게 정리합니다.\n- **체리픽**은 원하는 특정 커밋만을 선택적으로 적용합니다.\n- **인터랙티브 리베이스**를 통해 커밋 히스토리를 재구성할 수 있습니다.\n- **태그**는 중요한 마일스톤 커밋을 영구적으로 표시하여 관리할 수 있습니다.\n",
    "date": "2025-02-23",
    "tags": [
      "Git",
      "버전관리"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-23-Git------1_chunk_0",
        "text": "Git 튜토리얼 1\n\n## 개요\n\n이 글은 [Learn Git Branching](https://learngitbranching.js.org/?locale=ko) 튜토리얼을 참고하여 Git의 주요 개념과 기능들을 정리한 내용입니다.  \n\n---\n\n## Git 커밋\n\nGit에서 **커밋**은 작업 디렉터리의 상태(변경 사항)를 저장소에 기록하는 순간입니다.  \n실제로 Git은 디렉터리 내 모든 파일의 전체 스냅샷을 저장하는 것이 아니라, 파일들의 **변경 내역(Delta)** 만을 저장하여 효율적으로 버전을 관리합니다.  \n커밋을 생성하면, 변경된 내용이 추적 가능하며 나중에 특정 시점으로 되돌리거나 비교할 수 있습니다.\n\n```bash\ngit commit -m \"커밋메시지\"\n```\n\n---\n\n## Git 브랜치\n\n**브랜치**는 저장소 내의 특정 커밋을 가리키는 포인터(참조)입니다.",
        "index": 0
      },
      {
        "id": "2025-02-23-Git------1_chunk_1",
        "text": "있습니다.\n\n```bash\ngit commit -m \"커밋메시지\"\n```\n\n---\n\n## Git 브랜치\n\n**브랜치**는 저장소 내의 특정 커밋을 가리키는 포인터(참조)입니다.  \n- **핵심:** 브랜치는 실제 작업 내역을 복사하지 않고, 단지 어떤 커밋을 기준으로 작업을 진행할 것인지를 가리키기 때문에, 브랜치를 만드는 데 별도의 메모리나 디스크 공간이 크게 소모되지 않습니다.\n- **권장:** “빨리 그리고 자주 브랜치를 만들어라!”  \n  작업 단위를 작게 나누어 관리하면, 나중에 통합(merge)할 때 발생하는 충돌이나 문제를 줄일 수 있습니다.\n\n기본 사용법:\n- 브랜치 생성:  \n  ```bash\n  git branch [브랜치이름]\n  ```\n- 브랜치 이동:  \n  ```bash\n  git checkout [브랜치이름]\n  ```\n  \n이 때, 브랜치는 하나의 커밋과 그 부모 커밋들을 포함하는 작업 내역의 연속처럼 보이지만, 실제로는 단순히 특정 커밋을 가리키는 레퍼런스입니다.\n\n---\n\n## Git 머지\n\n**머지(Merge)**는 두 개 이상의 브랜치의 작업 내역을 하나로 합치는 과정입니다.  \n머지를 수행하면, 두 부모의 작업 내역을 통합한 새로운 **병합 커밋(Merge Commit)** 이 생성됩니다.",
        "index": 1
      },
      {
        "id": "2025-02-23-Git------1_chunk_2",
        "text": "개 이상의 브랜치의 작업 내역을 하나로 합치는 과정입니다.  \n머지를 수행하면, 두 부모의 작업 내역을 통합한 새로운 **병합 커밋(Merge Commit)** 이 생성됩니다.  \n예를 들어, `bugFix` 브랜치에서 작업한 내용을 `main` 브랜치에 병합하려면:\n\n```bash\ngit checkout main\ngit merge bugFix\n```\n\n이렇게 하면 `main` 브랜치에 `bugFix`의 작업 내역이 합쳐집니다.\n\n---\n\n## Git 리베이스\n\n**리베이스(Rebase)**는 현재 브랜치의 커밋들을 다른 브랜치의 최신 커밋 뒤에 재적용하는 작업입니다.  \n- 리베이스는 기존 커밋의 복사본을 만들어 새로운 베이스 위에 재적용하기 때문에, 커밋 로그가 한 줄로 깔끔하게 정리되는 효과가 있습니다.\n- 저장소의 커밋 이력이 깨끗해지는 장점이 있으나, 공개된 히스토리에서 리베이스를 사용하면 협업 시 문제가 발생할 수 있으므로 주의해야 합니다.\n\n사용 예:\n```bash\ngit rebase [브랜치명]\n```\n\n예를 들어, `bugFix` 브랜치에서 작업한 커밋들을 `main` 브랜치의 최신 커밋 뒤에 붙이고 싶다면 `git rebase main`을 실행합니다.\n\n---\n\n## Git HEAD\n\n**HEAD**는 현재 체크아웃되어 작업 중인 커밋을 가리킵니다.",
        "index": 2
      },
      {
        "id": "2025-02-23-Git------1_chunk_3",
        "text": "최신 커밋 뒤에 붙이고 싶다면 `git rebase main`을 실행합니다.\n\n---\n\n## Git HEAD\n\n**HEAD**는 현재 체크아웃되어 작업 중인 커밋을 가리킵니다.  \n- 일반적으로는 브랜치(예: `bugFix` 또는 `main`)가 HEAD를 가리키지만, 특정 커밋 해시로 직접 체크아웃할 경우에는 고정된 과거 커밋을 가리키게 됩니다.\n- 커밋을 생성하면 HEAD가 자동으로 최신 커밋을 가리키게 됩니다.\n\n---\n\n## 상대 참조\n\n커밋 해시는 SHA1 알고리즘에 의해 생성되므로 매우 길고 복잡하지만, Git은 **상대 참조**를 통해 간단하게 표현할 수 있도록 지원합니다.\n- `^`: 한 단계 부모 커밋을 가리킵니다.\n- `~<숫자>`: 여러 단계 위의 부모 커밋을 가리킵니다.\n\n예:\n```bash\ngit checkout main^\ngit checkout main~1\n```\n이 둘은 동일하게 `main` 브랜치의 한 단계 이전 커밋으로 이동합니다.\n\n---\n\n## 브랜치 강제 이동\n\n`-f` 옵션과 상대 참조를 사용하면, 브랜치를 특정 커밋으로 재지정할 수 있습니다.\n예를 들어, `main` 브랜치를 현재 HEAD에서 3번 이전 커밋으로 이동시키려면:\n\n```bash\ngit branch -f main HEAD~3\n```\n\n또한, `<브랜치명>`이나 `<커밋 해시>`를 직접 사용할 수도 있습니다.\n\n---\n\n## Git에서 작업 되돌리기\n\n작업 내역을 되돌리는 방법에는 두 가지 주요 방식이 있습니다.\n\n1.",
        "index": 3
      },
      {
        "id": "2025-02-23-Git------1_chunk_4",
        "text": "<브랜치명>`이나 `<커밋 해시>`를 직접 사용할 수도 있습니다.\n\n---\n\n## Git에서 작업 되돌리기\n\n작업 내역을 되돌리는 방법에는 두 가지 주요 방식이 있습니다.\n\n1. **git reset**  \n   - 로컬 히스토리에서 커밋 자체를 제거하여, 커밋하지 않은 상태로 되돌립니다.\n   - 예:  \n     ```bash\n     git reset HEAD~1\n     ```\n   - 주의: 이미 공유된 커밋을 reset하면 협업 시 문제가 발생할 수 있습니다.\n\n2.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-02-23-Git------2",
    "title": "Git 튜토리얼 2",
    "path": "/2025/02/23/Git-튜토리얼-2/",
    "categories": [
      "Computer Science",
      "Git",
      "Computer_Science/git"
    ],
    "content": "이 글은 이전 튜토리얼(튜토리얼 1)에 이어, Git의 원격 저장소와 관련된 기능들을 다룹니다.  \n아래 내용을 통해 원격 저장소, clone, fetch, pull, push, 그리고 merge와 rebase의 차이점에 대해 정리합니다.\n\n---\n\n### Git Remote\n\n원격 저장소는 로컬 저장소의 복사본 역할을 하며, GitHub, GitLab 등 다양한 서비스에서 제공됩니다.  \n원격 저장소는 협업이나 백업을 위해 사용되며, 로컬과 별도로 관리됩니다.\n\n---\n\n### Git Clone\n\n`git clone`은 원격 저장소에 있는 내용을 모두 복사해서 내 로컬 디렉터리로 가져오는 작업입니다.  \n클론을 수행하면, 원격 저장소의 브랜치들이 **원격 추적 브랜치**(예: `origin/main`)로 생성됩니다.\n\n---\n\n### Git 원격 브랜치\n\n원격 저장소에서 관리되는 브랜치는 로컬에 클론 시 생성된 `origin/main`과 같은 원격 추적 브랜치입니다.  \n이들은 실제로 원격 저장소의 상태를 반영하는 포인터 역할을 합니다.\n\n- 원격 브랜치에서 작업을 시도해도, 실제 원격 저장소에 바로 반영되지는 않습니다.\n- 예를 들어, `git checkout origin/main`으로 이동하여 커밋을 하더라도, 분리된 HEAD(detached HEAD) 상태가 되어  \n  해당 커밋은 원격 브랜치에 직접 적용되지 않습니다.\n\n---\n\n### Git Fetch\n\n`git fetch`는 원격 저장소의 변경 사항을 로컬 저장소로 다운로드해 옵니다.  \n원격에 있지만 로컬에 없는 커밋 내역을 가져오고, 원격 브랜치의 포인터(예: `origin/main`)를 업데이트하지만,  \n로컬 작업 브랜치에는 자동으로 병합되지 않습니다.\n\n예시:\n```bash\ngit fetch origin main\n```\n또는\n```bash\ngit fetch origin foo^:bar\n```\nfetch 후에는 로컬 상태에 반영하기 위해 추가적으로 `merge`나 `rebase`를 수행해야 합니다.\n\n---\n\n### Git Pull\n\n`git pull`은 `git fetch`와 `merge`(혹은 `rebase`)를 한 번에 수행합니다.  \n예를 들어:\n```bash\ngit pull origin main\n```\n또는\n```bash\ngit pull origin main:foo\n```\n를 사용하면 원격 저장소의 변경 사항을 가져오고 로컬 브랜치에 통합합니다.  \n단, 기본적으로 merge 방식으로 수행되므로 병합 커밋이 생성될 수 있으며, 깔끔한 히스토리를 원한다면 `--rebase` 옵션을 고려할 수 있습니다.\n\n---\n\n### Git Push\n\n`git push`는 로컬 저장소의 변경사항을 원격 저장소에 업로드하는 작업입니다.  \n예를 들어, 로컬의 `main` 브랜치에 있는 모든 커밋들을 원격 저장소의 `main` 브랜치에 반영하려면:\n\n```bash\ngit push\n```\n\n하지만, 원격 저장소에 이미 다른 내용이 추가되어 히스토리가 다를 경우 push가 거부될 수 있습니다.  \nGit은 이를 방지하기 위해, 원격 저장소의 최신 상태를 먼저 반영(merge 또는 rebase)한 후 push하도록 요구합니다.  \n예를 들어:\n```bash\ngit fetch\ngit rebase origin/main\n```\n또는\n```bash\ngit pull --rebase\n```\n를 수행한 후 push하면 정상적으로 진행됩니다.\n\n---\n\n### Git Push `<remote>` `<place>`\n\n`git push <remote> <place>` 형식은 현재 체크아웃된 브랜치와 관계없이 로컬 브랜치와 원격 브랜치 간에 push를 수행할 수 있습니다.  \n예를 들어:\n```bash\ngit push origin main\n```\n은 로컬의 `main` 브랜치에 있는 모든 커밋들을 원격 저장소의 `main` 브랜치에 반영합니다.\n\n만약, 로컬의 `foo` 브랜치에서 원격 저장소의 `bar` 브랜치로 커밋을 보내고 싶다면:\n```bash\ngit push origin foo:bar\n```\n와 같이 사용합니다.\n\n---\n\n### Remote Rejected!\n\n원격 저장소의 `main` 브랜치와 같이 보호되어 있는 브랜치에는 직접 push가 거부되는 경우가 많습니다.  \n이 경우, 기능 개발은 별도의 브랜치(feature 브랜치 등)에서 진행하고, 작업 완료 후 pull request(PR)를 통해 변경사항을 반영합니다.  \n만약 `main`에서 작업을 진행했다면, 이를 해결하기 위해 새로운 브랜치를 만들어 해당 커밋들을 옮긴 후 push하는 방법을 사용할 수 있습니다.\n\n---\n\n### `merge` vs `rebase`\n\n원격 작업 시 대체로 깔끔한 커밋 히스토리를 위해 `rebase`를 선호합니다.\n\n- **merge**  \n  - 장점: 기존 히스토리를 그대로 보존하며, 두 브랜치의 작업 내역을 병합 커밋으로 기록합니다.  \n  - 단점: 여러 병합 커밋이 추가되어 로그가 복잡해질 수 있습니다.\n\n- **rebase**  \n  - 장점: 커밋 로그가 한 줄로 깔끔하게 정리되어 보기 쉽습니다.  \n  - 단점: 기존 커밋의 히스토리를 재작성하기 때문에, 이미 공유된 커밋에 대해 사용 시 주의가 필요합니다.\n  \n즉, 이력이 보존되는 것을 선호한다면 merge, 커밋 트리를 깔끔하게 관리하고 싶다면 rebase를 사용하면 됩니다.\n\n---\n\n## 마무리\n\n이렇게 튜토리얼 1,2가 끝이 났지만, 개인적으로 정말 너무 내용이 많다고 생각합니다.  \nGit에 익숙해지기 위해선, 일단 사용해보는 것이 좋은 방법이라 생각됩니다.  \n\n이를 위해 본인만의 언어를 활용해 간단한 표로 만들어 보는 것을 추천합니다.  \n\n| **개념**           | **명령어/예시**                                      | **설명**                                                |\n| ------------------ | ---------------------------------------------------- | ------------------------------------------------------- |\n| Git Commit         | `git commit -m \"메시지\"`                             | 변경 사항(델타)을 기록하는 스냅샷 생성                  |\n| Git Branch         | `git branch new-branch`<br>`git checkout new-branch` | 새로운 작업 포인터 생성 및 이동                         |\n| Git Merge          | `git merge feature`                                  | 두 브랜치의 작업을 하나로 병합                          |\n| Git Rebase         | `git rebase main`                                    | 현재 브랜치 커밋들을 main 뒤에 재적용                   |\n| 상대 참조          | `git checkout main~1`                                | SHA 대신 간단하게 이전 커밋으로 이동                    |\n| 작업 되돌리기      | `git reset HEAD~1`<br>`git revert HEAD`              | reset: 히스토리에서 제거<br>revert: 반대 내용 커밋 생성 |\n| Git Cherry-pick    | `git cherry-pick <커밋>`                             | 특정 커밋만 현재 브랜치에 복사 적용                     |\n| Interactive Rebase | `git rebase -i HEAD~3`                               | 커밋 순서 변경, 스쿼시, 삭제 등 재구성                  |\n| Git Tag            | `git tag v1.0`                                       | 중요한 커밋에 마일스톤 태그 부여                        |\n| Git Clone          | `git clone <저장소 URL>`                             | 원격 저장소를 로컬로 복제                               |\n| 원격 브랜치        | (예: `origin/main`)                                  | 원격 저장소의 상태를 반영하는 브랜치                    |\n| Git Fetch          | `git fetch origin`                                   | 원격 저장소의 변경 사항 다운로드 (반영X)                |\n| Git Pull           | `git pull origin main`                               | fetch 후 merge/rebase로 로컬 업데이트                   |\n| Git Push           | `git push origin main`<br>`git push origin foo:bar`  | 로컬 변경 사항을 원격 저장소에 업로드                   |\n",
    "date": "2025-02-23",
    "tags": [
      "Git",
      "버전관리"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-23-Git------2_chunk_0",
        "text": "Git 튜토리얼 2\n\n이 글은 이전 튜토리얼(튜토리얼 1)에 이어, Git의 원격 저장소와 관련된 기능들을 다룹니다.  \n아래 내용을 통해 원격 저장소, clone, fetch, pull, push, 그리고 merge와 rebase의 차이점에 대해 정리합니다.\n\n---\n\n### Git Remote\n\n원격 저장소는 로컬 저장소의 복사본 역할을 하며, GitHub, GitLab 등 다양한 서비스에서 제공됩니다.  \n원격 저장소는 협업이나 백업을 위해 사용되며, 로컬과 별도로 관리됩니다.\n\n---\n\n### Git Clone\n\n`git clone`은 원격 저장소에 있는 내용을 모두 복사해서 내 로컬 디렉터리로 가져오는 작업입니다.  \n클론을 수행하면, 원격 저장소의 브랜치들이 **원격 추적 브랜치**(예: `origin/main`)로 생성됩니다.\n\n---\n\n### Git 원격 브랜치\n\n원격 저장소에서 관리되는 브랜치는 로컬에 클론 시 생성된 `origin/main`과 같은 원격 추적 브랜치입니다.  \n이들은 실제로 원격 저장소의 상태를 반영하는 포인터 역할을 합니다.\n\n- 원격 브랜치에서 작업을 시도해도, 실제 원격 저장소에 바로 반영되지는 않습니다.\n- 예를 들어, `git checkout origin/main`으로 이동하여 커밋을 하더라도, 분리된 HEAD(detached HEAD) 상태가 되어  \n  해당 커밋은 원격 브랜치에 직접 적용되지 않습니다.\n\n---\n\n### Git Fetch\n\n`git fetch`는 원격 저장소의 변경 사항을 로컬 저장소로 다운로드해 옵니다.",
        "index": 0
      },
      {
        "id": "2025-02-23-Git------2_chunk_1",
        "text": "해당 커밋은 원격 브랜치에 직접 적용되지 않습니다.\n\n---\n\n### Git Fetch\n\n`git fetch`는 원격 저장소의 변경 사항을 로컬 저장소로 다운로드해 옵니다.  \n원격에 있지만 로컬에 없는 커밋 내역을 가져오고, 원격 브랜치의 포인터(예: `origin/main`)를 업데이트하지만,  \n로컬 작업 브랜치에는 자동으로 병합되지 않습니다.\n\n예시:\n```bash\ngit fetch origin main\n```\n또는\n```bash\ngit fetch origin foo^:bar\n```\nfetch 후에는 로컬 상태에 반영하기 위해 추가적으로 `merge`나 `rebase`를 수행해야 합니다.\n\n---\n\n### Git Pull\n\n`git pull`은 `git fetch`와 `merge`(혹은 `rebase`)를 한 번에 수행합니다.  \n예를 들어:\n```bash\ngit pull origin main\n```\n또는\n```bash\ngit pull origin main:foo\n```\n를 사용하면 원격 저장소의 변경 사항을 가져오고 로컬 브랜치에 통합합니다.  \n단, 기본적으로 merge 방식으로 수행되므로 병합 커밋이 생성될 수 있으며, 깔끔한 히스토리를 원한다면 `--rebase` 옵션을 고려할 수 있습니다.\n\n---\n\n### Git Push\n\n`git push`는 로컬 저장소의 변경사항을 원격 저장소에 업로드하는 작업입니다.",
        "index": 1
      },
      {
        "id": "2025-02-23-Git------2_chunk_2",
        "text": "원한다면 `--rebase` 옵션을 고려할 수 있습니다.\n\n---\n\n### Git Push\n\n`git push`는 로컬 저장소의 변경사항을 원격 저장소에 업로드하는 작업입니다.  \n예를 들어, 로컬의 `main` 브랜치에 있는 모든 커밋들을 원격 저장소의 `main` 브랜치에 반영하려면:\n\n```bash\ngit push\n```\n\n하지만, 원격 저장소에 이미 다른 내용이 추가되어 히스토리가 다를 경우 push가 거부될 수 있습니다.  \nGit은 이를 방지하기 위해, 원격 저장소의 최신 상태를 먼저 반영(merge 또는 rebase)한 후 push하도록 요구합니다.  \n예를 들어:\n```bash\ngit fetch\ngit rebase origin/main\n```\n또는\n```bash\ngit pull --rebase\n```\n를 수행한 후 push하면 정상적으로 진행됩니다.\n\n---\n\n### Git Push `<remote>` `<place>`\n\n`git push <remote> <place>` 형식은 현재 체크아웃된 브랜치와 관계없이 로컬 브랜치와 원격 브랜치 간에 push를 수행할 수 있습니다.",
        "index": 2
      },
      {
        "id": "2025-02-23-Git------2_chunk_3",
        "text": "` `<place>`\n\n`git push <remote> <place>` 형식은 현재 체크아웃된 브랜치와 관계없이 로컬 브랜치와 원격 브랜치 간에 push를 수행할 수 있습니다.  \n예를 들어:\n```bash\ngit push origin main\n```\n은 로컬의 `main` 브랜치에 있는 모든 커밋들을 원격 저장소의 `main` 브랜치에 반영합니다.\n\n만약, 로컬의 `foo` 브랜치에서 원격 저장소의 `bar` 브랜치로 커밋을 보내고 싶다면:\n```bash\ngit push origin foo:bar\n```\n와 같이 사용합니다.\n\n---\n\n### Remote Rejected!\n\n원격 저장소의 `main` 브랜치와 같이 보호되어 있는 브랜치에는 직접 push가 거부되는 경우가 많습니다.  \n이 경우, 기능 개발은 별도의 브랜치(feature 브랜치 등)에서 진행하고, 작업 완료 후 pull request(PR)를 통해 변경사항을 반영합니다.  \n만약 `main`에서 작업을 진행했다면, 이를 해결하기 위해 새로운 브랜치를 만들어 해당 커밋들을 옮긴 후 push하는 방법을 사용할 수 있습니다.\n\n---\n\n### `merge` vs `rebase`\n\n원격 작업 시 대체로 깔끔한 커밋 히스토리를 위해 `rebase`를 선호합니다.\n\n- **merge**  \n  - 장점: 기존 히스토리를 그대로 보존하며, 두 브랜치의 작업 내역을 병합 커밋으로 기록합니다.",
        "index": 3
      },
      {
        "id": "2025-02-23-Git------2_chunk_4",
        "text": "커밋 히스토리를 위해 `rebase`를 선호합니다.\n\n- **merge**  \n  - 장점: 기존 히스토리를 그대로 보존하며, 두 브랜치의 작업 내역을 병합 커밋으로 기록합니다.  \n  - 단점: 여러 병합 커밋이 추가되어 로그가 복잡해질 수 있습니다.\n\n- **rebase**  \n  - 장점: 커밋 로그가 한 줄로 깔끔하게 정리되어 보기 쉽습니다.  \n  - 단점: 기존 커밋의 히스토리를 재작성하기 때문에, 이미 공유된 커밋에 대해 사용 시 주의가 필요합니다.\n  \n즉, 이력이 보존되는 것을 선호한다면 merge, 커밋 트리를 깔끔하게 관리하고 싶다면 rebase를 사용하면 됩니다.\n\n---\n\n## 마무리\n\n이렇게 튜토리얼 1,2가 끝이 났지만, 개인적으로 정말 너무 내용이 많다고 생각합니다.  \nGit에 익숙해지기 위해선, 일단 사용해보는 것이 좋은 방법이라 생각됩니다.  \n\n이를 위해 본인만의 언어를 활용해 간단한 표로 만들어 보는 것을 추천합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-02-23-Ubuntu-------------ntp",
    "title": "Ubuntu 표준 시간대 설정하기(ntp)",
    "path": "/2025/02/23/Ubuntu-표준-시간대-설정하기(ntp)/",
    "categories": [
      "Computer Science",
      "Ubuntu",
      "Computer_Science"
    ],
    "content": "## 개요\n\nUbuntu는 기본적으로 인터넷에 연결되어 있으면 타임 서버와 자동 동기화하여 시스템 시간을 설정합니다.  \n하지만 네트워크 보안 정책 등으로 인해 타임 서버 동기화가 제대로 이루어지지 않을 경우, `ntp` 패키지를 사용하여 문제를 해결할 수 있습니다.  \n이번 글에서는 `ntp` 패키지의 설치, 설정 파일 수정, 그리고 동기화 상태 확인 방법을 살펴봅니다.\n\n---\n\n## 1. ntp 패키지 설치\n\n터미널에서 아래 명령어를 입력하여 `ntp` 패키지를 설치합니다.\n\n```bash\nsudo apt install ntp\n```\n\n설치가 완료되면, ntp 서비스가 자동으로 시작됩니다.\n\n---\n\n## 2. ntp 설정 파일 수정\n\n네트워크 보안 등의 이유로 기본 타임 서버와의 동기화에 문제가 발생할 경우, 설정 파일을 수정하여 다른 타임 서버를 지정할 수 있습니다.\n\n1. ntp 설정 파일을 편집합니다.\n\n   ```bash\n   sudo vi /etc/ntp.conf\n   ```\n\n2. 파일 내 약 20번째 줄 부근에 있는 기본 타임 서버 설정 부분은 아래와 같이 주석 처리되어 있습니다.\n\n   ```bash\n   #pool 0.ubuntu.pool.ntp.org iburst\n   #pool 1.ubuntu.pool.ntp.org iburst\n   #pool 2.ubuntu.pool.ntp.org iburst\n   #pool 3.ubuntu.pool.ntp.org iburst\n   ```\n\n3. 위 4줄 대신 아래와 같이 새로운 타임 서버를 추가합니다.\n\n   ```bash\n   server 0.kr.pool.ntp.org iburst\n   server time.bora.net iburst\n   server time.windows.com iburst\n   server time.google.com iburst\n   ```\n\n\n> `iburst` 옵션은 초기 동기화 속도를 높여주는 역할을 합니다.\n{: .prompt-tip }\n\n---\n\n## 3. ntp 서비스 재시작\n\n설정 파일 수정이 완료되면, ntp 서비스를 재시작하여 변경 사항을 적용합니다.\n\n```bash\nservice ntp restart\n```\n\n> 명령어 실행 시 아래와 같이 **`AUTHENTICATING FOR org.freedesktop.systemd1.manage-units`** 메시지가 출력될 수 있습니다.  \n> 이는 리눅스 시스템에서 서비스를 관리할 때 발생하는 정상적인 인증 요청이며, 사용자 비밀번호를 입력하면 정상적으로 동작합니다.\n{: .prompt-warning }\n\n---\n\n## 4. 동기화 상태 확인\n\n설정이 완료된 후, 아래 명령어로 타임 서버와의 동기화 상태를 확인할 수 있습니다.\n\n```bash\nntpq -p\n```\n\n명령어를 실행하면 다음과 같은 출력이 나타납니다:\n\n```bash\nhero@hero-desktop:~$ ntpq -p\n     remote           refid      st t when poll reach   delay   offset  jitter\n==============================================================================\n ntp.ubuntu.com  .POOL.          16 p    -   64    0    0.000    0.000   0.000\n 121.174.142.82  .INIT.          16 u    -   64    0    0.000    0.000   0.000\n*time.bora.net   90.1.14.51       2 u    9   64    1   93.057  -19.483  16.766\n 52.231.114.183  .STEP.          16 u  477   64    0    0.000    0.000   0.000\n time4.google.co .STEP.          16 u    -   64    0    0.000    0.000   0.000\n```\n\n출력 결과에서 특수문자는 다음과 같은 의미를 갖습니다:\n\n| 기호   | 의미                                          |\n| ------ | --------------------------------------------- |\n| `*`    | 현재 동기화 중인 서버                         |\n| `+`    | 접속은 가능하지만 아직 동기화 중이 아님       |\n| `-`    | 접속은 가능하나 동기화 리스트에서 제외된 서버 |\n| (없음) | 접속 실패                                     |\n\n동기화 중인 서버 옆에 `*` 기호가 표시되면, 해당 서버와 정상적으로 시간 동기화가 이루어지고 있음을 의미합니다.\n",
    "date": "2025-02-23",
    "tags": [
      "Ubuntu",
      "ntp"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-23-Ubuntu-------------ntp_chunk_0",
        "text": "Ubuntu 표준 시간대 설정하기(ntp)\n\n## 개요\n\nUbuntu는 기본적으로 인터넷에 연결되어 있으면 타임 서버와 자동 동기화하여 시스템 시간을 설정합니다.  \n하지만 네트워크 보안 정책 등으로 인해 타임 서버 동기화가 제대로 이루어지지 않을 경우, `ntp` 패키지를 사용하여 문제를 해결할 수 있습니다.  \n이번 글에서는 `ntp` 패키지의 설치, 설정 파일 수정, 그리고 동기화 상태 확인 방법을 살펴봅니다.\n\n---\n\n## 1. ntp 패키지 설치\n\n터미널에서 아래 명령어를 입력하여 `ntp` 패키지를 설치합니다.\n\n```bash\nsudo apt install ntp\n```\n\n설치가 완료되면, ntp 서비스가 자동으로 시작됩니다.\n\n---\n\n## 2. ntp 설정 파일 수정\n\n네트워크 보안 등의 이유로 기본 타임 서버와의 동기화에 문제가 발생할 경우, 설정 파일을 수정하여 다른 타임 서버를 지정할 수 있습니다.\n\n1. ntp 설정 파일을 편집합니다.\n\n   ```bash\n   sudo vi /etc/ntp.conf\n   ```\n\n2. 파일 내 약 20번째 줄 부근에 있는 기본 타임 서버 설정 부분은 아래와 같이 주석 처리되어 있습니다.\n\n   ```bash\n   #pool 0.ubuntu.pool.ntp.org iburst\n   #pool 1.ubuntu.pool.ntp.org iburst\n   #pool 2.ubuntu.pool.ntp.org iburst\n   #pool 3.ubuntu.pool.ntp.org iburst\n   ```\n\n3.",
        "index": 0
      },
      {
        "id": "2025-02-23-Ubuntu-------------ntp_chunk_1",
        "text": "p.org iburst\n   #pool 2.ubuntu.pool.ntp.org iburst\n   #pool 3.ubuntu.pool.ntp.org iburst\n   ```\n\n3. 위 4줄 대신 아래와 같이 새로운 타임 서버를 추가합니다.\n\n   ```bash\n   server 0.kr.pool.ntp.org iburst\n   server time.bora.net iburst\n   server time.windows.com iburst\n   server time.google.com iburst\n   ```\n\n\n> `iburst` 옵션은 초기 동기화 속도를 높여주는 역할을 합니다.\n{: .prompt-tip }\n\n---\n\n## 3. ntp 서비스 재시작\n\n설정 파일 수정이 완료되면, ntp 서비스를 재시작하여 변경 사항을 적용합니다.\n\n```bash\nservice ntp restart\n```\n\n> 명령어 실행 시 아래와 같이 **`AUTHENTICATING FOR org.freedesktop.systemd1.manage-units`** 메시지가 출력될 수 있습니다.  \n> 이는 리눅스 시스템에서 서비스를 관리할 때 발생하는 정상적인 인증 요청이며, 사용자 비밀번호를 입력하면 정상적으로 동작합니다.\n{: .prompt-warning }\n\n---\n\n## 4.",
        "index": 1
      },
      {
        "id": "2025-02-23-Ubuntu-------------ntp_chunk_2",
        "text": "눅스 시스템에서 서비스를 관리할 때 발생하는 정상적인 인증 요청이며, 사용자 비밀번호를 입력하면 정상적으로 동작합니다.\n{: .prompt-warning }\n\n---\n\n## 4. 동기화 상태 확인\n\n설정이 완료된 후, 아래 명령어로 타임 서버와의 동기화 상태를 확인할 수 있습니다.\n\n```bash\nntpq -p\n```\n\n명령어를 실행하면 다음과 같은 출력이 나타납니다:\n\n```bash\nhero@hero-desktop:~$ ntpq -p\n     remote           refid      st t when poll reach   delay   offset  jitter\n==============================================================================\n ntp.ubuntu.com  .POOL.          16 p    -   64    0    0.000    0.000   0.000\n 121.174.142.82  .INIT.          16 u    -   64    0    0.000    0.000   0.000\n*time.bora.net   90.1.14.51       2 u    9   64    1   93.057  -19.483  16.766\n 52.231.114.183  .STEP.          16 u  477   64    0    0.000    0.000   0.000\n time4.google.co .STEP.",
        "index": 2
      },
      {
        "id": "2025-02-23-Ubuntu-------------ntp_chunk_3",
        "text": ".231.114.183  .STEP.          16 u  477   64    0    0.000    0.000   0.000\n time4.google.co .STEP.          16 u    -   64    0    0.000    0.000   0.000\n```\n\n출력 결과에서 특수문자는 다음과 같은 의미를 갖습니다:\n\n| 기호   | 의미                                          |\n| ------ | --------------------------------------------- |\n| `*`    | 현재 동기화 중인 서버                         |\n| `+`    | 접속은 가능하지만 아직 동기화 중이 아님       |\n| `-`    | 접속은 가능하나 동기화 리스트에서 제외된 서버 |\n| (없음) | 접속 실패                                     |\n\n동기화 중인 서버 옆에 `*` 기호가 표시되면, 해당 서버와 정상적으로 시간 동기화가 이루어지고 있음을 의미합니다.",
        "index": 3
      },
      {
        "id": "2025-02-23-Ubuntu-------------ntp_chunk_4",
        "text": "|\n\n동기화 중인 서버 옆에 `*` 기호가 표시되면, 해당 서버와 정상적으로 시간 동기화가 이루어지고 있음을 의미합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-02-22-YDLidar-X4------ROS",
    "title": "YDLidar X4 설정 및 ROS 테스트",
    "path": "/2025/02/22/YDLidar-X4-설정-및-ROS-테스트/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 개요\n\n이번 글에서는 라이다 센서를 사용하기 위한 준비를 합니다.  \n\nYDLidar X4의 경우 12cm ~ 10m 까지 감지가 가능하며, 자세한 내용은 아래 링크를 참고하시면 됩니다.  \n[YDlidar X4 디바이스마트](https://www.devicemart.co.kr/goods/view?no=12170775&srsltid=AfmBOoqmNYC1eyAD3EFEgxfDrUDDTENT1vc7EU-PF8s6uXhjf4wEGZMZ)\n\nX4의 경우 단종되었으며 X4 pro는 약 85,000원으로 비슷한 스펙의 RPlidar사 제품보다 저렴하다는 장점이 있습니다.  \n\n> 저는 중고로 구매하여 약 5만원에 구입했습니다.  \n{: .prompt-tip}\n\n## YDLidar SDK 설치\n\nYDLidar X4를 사용하기 위해 먼저 공식 SDK를 설치합니다.  \n\n```bash\nmkdir -p sdk_ws/src\ncd sdk_ws/src\ngit clone https://github.com/YDLIDAR/YDLidar-SDK.git\n```\n\nSDK 디렉터리로 이동한 후, 빌드 디렉터리를 생성하고 컴파일합니다.\n\n```bash\ncd YDLidar-SDK/\nmkdir build\ncd build\ncmake ..\nmake\nsudo make install\n```\n\n---\n\n## YDLidar ROS Driver 설치\n\nROS 환경에서 YDLidar X4를 사용하기 위해 ROS 드라이버를 설치합니다. 기존의 `catkin_ws` 워크스페이스에서 아래의 과정을 진행합니다.\n\n### 드라이버 패키지 클론\n\n먼저, `catkin_ws/src` 디렉터리로 이동한 후 드라이버 패키지를 클론합니다.\n\n```bash\ncd ~/catkin_ws/src\ngit clone https://github.com/YDLIDAR/ydlidar_ros_driver.git\n```\n\n### 종속성 설치\n\n워크스페이스 루트 디렉터리로 이동하여, 필요한 종속성들을 설치합니다.\n\n```bash\ncd ~/catkin_ws\nrosdep install --from-paths src --ignore-src -r -y\n```\n\n### 빌드 및 환경 설정\n\n드라이버 설치 후, `catkin_make`를 이용해 워크스페이스를 빌드하고, 환경 설정 파일을 적용합니다.\n\n```bash\ncatkin_make\nsource devel/setup.bash\n```\n\n---\n\n## 디바이스 및 udev 규칙 설정\n\nLiDAR 장치와의 통신을 위해 `/dev/ttyUSB0` 권한을 설정합니다.\n\n```bash\nsudo chmod 666 /dev/ttyUSB0\n\n# 지속적으로 권한 설정을 유지하려면 아래 설정을 추가합니다.\nsudo usermod -aG dialout $USER\n```\n\n### udev 규칙 설정 (심볼릭 링크)\n\n아래 명령어로 udev 규칙 파일을 생성하여, LiDAR 장치에 심볼릭 링크를 설정합니다.\n\n```bash\nsudo vi /etc/udev/rules.d/ydlidar.rules\n```\n\n파일에 아래 내용을 추가합니다.\n\n```bash\nSUBSYSTEM==\"tty\", ATTRS{idVendor}==\"10c4\", ATTRS{idProduct}==\"ea60\", MODE:=\"0666\", SYMLINK+=\"ydlidar\"\n```\n\n> 이 심볼릭링크 설정을 통해 실제 디바이스는 `/dev/ttyUSB0`과 같은 형태로 표시되지만, 동시에 `/dev/ydlidar`로 사용할 수 있게 됩니다.\n{: .prompt-info }\n\n규칙 적용을 위해 udev 규칙을 새로고침합니다.\n\n```bash\nsudo udevadm control --reload-rules\nsudo udevadm trigger\n```\n\n---\n\n## LiDAR 노드 실행\n\n이제 ROS 환경에서 YDLidar X4 드라이버가 정상적으로 동작하는지 테스트합니다. 아래 명령어로 LiDAR 노드를 실행합니다.\n\n```bash\nroslaunch ydlidar_ros_driver ydlidar.launch\n```\n\nRViz 혹은 `rostopic list`와 `rostopic echo` 명령어를 통해 데이터를 정상적으로 입력받고 있는지 확인하면 됩니다.  \n\n### 트러블 슈팅\n\n만약 라이다센서의 스캔 데이터가 정상적으로 publish되지 않고 있다면 심볼릭 링크 혹은 권한문제, 혹은 케이블의 문제일 수 있습니다.\n\n다시 한번 `ls /dev/ydlidar` 혹은 `ls /dev/ttyUSB*` 명령어를 통해 장치가 제대로 연결되었는지 확인합니다.  \n\n이후, `sudo chmod 666 <장치명>` 을 통해 권한을 부여하고 다시 테스트하면 됩니다.  \n\n\n만약 위 해결 방법을 수행했음에도 USB 어댑터 보드에 LED는 켜져있지만 데이터가 제대로 송수신되지 않는다면, 케이블 문제일 수 있습니다.  \n\n충전용 케이블이 아닌, 데이터 송수신 케이블인지 다시 한번 확인 후 연결하면 정상적으로 작동할 것입니다.\n\n> 저는 데이터 송수신 케이블을 사용하지 않아 제대로 동작하지 않았던 문제가 있었습니다.\n{: .prompt-warning }\n\n---\n\n## 마무리\n\n이렇게해서 LiDAR 센서가 잘 동작하는 것을 확인했다면, 프로젝트의 절반은 했다고 생각합니다.  (시작이 절반?)\n\n다음 글부터는 LiDAR센서만을 이용해 위치추정까지 가능한 Hector SLAM을 설치하고 테스트해보겠습니다.  \n",
    "date": "2025-02-22",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-22-YDLidar-X4------ROS_chunk_0",
        "text": "YDLidar X4 설정 및 ROS 테스트\n\n## 개요\n\n이번 글에서는 라이다 센서를 사용하기 위한 준비를 합니다.  \n\nYDLidar X4의 경우 12cm ~ 10m 까지 감지가 가능하며, 자세한 내용은 아래 링크를 참고하시면 됩니다.  \n[YDlidar X4 디바이스마트](https://www.devicemart.co.kr/goods/view?no=12170775&srsltid=AfmBOoqmNYC1eyAD3EFEgxfDrUDDTENT1vc7EU-PF8s6uXhjf4wEGZMZ)\n\nX4의 경우 단종되었으며 X4 pro는 약 85,000원으로 비슷한 스펙의 RPlidar사 제품보다 저렴하다는 장점이 있습니다.  \n\n> 저는 중고로 구매하여 약 5만원에 구입했습니다.  \n{: .prompt-tip}\n\n## YDLidar SDK 설치\n\nYDLidar X4를 사용하기 위해 먼저 공식 SDK를 설치합니다.  \n\n```bash\nmkdir -p sdk_ws/src\ncd sdk_ws/src\ngit clone https://github.com/YDLIDAR/YDLidar-SDK.git\n```\n\nSDK 디렉터리로 이동한 후, 빌드 디렉터리를 생성하고 컴파일합니다.\n\n```bash\ncd YDLidar-SDK/\nmkdir build\ncd build\ncmake ..\nmake\nsudo make install\n```\n\n---\n\n## YDLidar ROS Driver 설치\n\nROS 환경에서 YDLidar X4를 사용하기 위해 ROS 드라이버를 설치합니다.",
        "index": 0
      },
      {
        "id": "2025-02-22-YDLidar-X4------ROS_chunk_1",
        "text": "sudo make install\n```\n\n---\n\n## YDLidar ROS Driver 설치\n\nROS 환경에서 YDLidar X4를 사용하기 위해 ROS 드라이버를 설치합니다.",
        "index": 1
      },
      {
        "id": "2025-02-22-YDLidar-X4------ROS_chunk_2",
        "text": "sudo make install\n```\n\n---\n\n## YDLidar ROS Driver 설치\n\nROS 환경에서 YDLidar X4를 사용하기 위해 ROS 드라이버를 설치합니다.",
        "index": 2
      },
      {
        "id": "2025-02-22-YDLidar-X4------ROS_chunk_3",
        "text": "sudo make install\n```\n\n---\n\n## YDLidar ROS Driver 설치\n\nROS 환경에서 YDLidar X4를 사용하기 위해 ROS 드라이버를 설치합니다.",
        "index": 3
      },
      {
        "id": "2025-02-22-YDLidar-X4------ROS_chunk_4",
        "text": "sudo make install\n```\n\n---\n\n## YDLidar ROS Driver 설치\n\nROS 환경에서 YDLidar X4를 사용하기 위해 ROS 드라이버를 설치합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-02-22-Hector-SLAM",
    "title": "Hector SLAM 사용하기",
    "path": "/2025/02/22/Hector-SLAM-사용하기/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## Hector SLAM 개요\n\nHector SLAM은 **주로 2D LiDAR 센서**를 기반으로 동작하는 SLAM 기법으로, IMU나 휠 오도메트리 없이도 실시간으로 맵을 생성할 수 있는 장점이 있습니다. <br>\n타 SLAM 기법(예: GMapping, Cartographer 등)은 보통 IMU나 휠 오도메트리 등 다양한 센서 데이터를 활용해 보다 복잡한 환경에서도 정밀한 맵 생성을 지원하지만, 이 프로젝트에서 만드는 차량은 급격한 회전이나 큰 변화가 없으며, IMU와 같이 odom을 생성할 수 있는 센서를 사용하지 않기 때문에 Hector SLAM을 사용합니다.  \n\nHector SLAM은 다음과 같이 동작합니다:\n\n- **스캔 매칭:** 각 LiDAR 스캔을 기존 맵과 비교하여 로봇의 현재 위치를 추정합니다.\n- **실시간 맵 업데이트:** 추정된 위치를 바탕으로 환경 지도를 업데이트하며, 다중 해상도 맵을 활용해 정밀도를 높입니다.\n- **센서 독립성:** 오직 LiDAR 데이터만 사용하기 때문에 센서 간의 동기화나  캘리브레이션 과정이 줄어듭니다.\n\n---\n\n## ROS TF (Transform)\n\nROS의 TF(Transform) 패키지는 서로 다른 좌표계(프레임) 간의 변환 정보를 실시간으로 관리하고 제공하는 역할을 합니다.  \n이를 통해 여러 센서나 모듈이 서로 다른 좌표계에서 데이터를 주고받을 때, 정확한 위치 관계를 유지할 수 있습니다.\n\n### 주요 TF 프레임\n\nHector SLAM에서는 아래와 같은 좌표계가 사용됩니다.  \n\n- **map**  \n  - **설명:** 전역 좌표계로, 생성된 지도 전체를 나타냅니다.  \n  - **용도:** SLAM 알고리즘에서 최종 생성되는 지도의 기준 좌표계로 사용됩니다.\n\n- **odom (또는 nav)**  \n  - **설명:** odom 좌표계로, 로봇의 짧은 시간 내 움직임을 나타냅니다.  \n  - **용도:** 로봇의 이동 정보(예: 휠 odom)가 반영되며, 단기적인 위치 추정에 사용됩니다.  \n  - Hector SLAM에서는 별도의 odom 센서가 없더라도, 기본적인 움직임 추정을 위해 사용될 수 있습니다.\n\n- **base_link**  \n  - **설명:** 로봇 본체의 중심 좌표계입니다.  \n  - **용도:** 로봇의 주요 동작이나 센서가 부착되는 기준 좌표로, `base_link`를 기준으로 주변 센서 데이터가 변환됩니다.\n\n- **base_footprint**  \n  - **설명:** 로봇의 바닥면을 나타내는 좌표계로, 주로 로봇의 실제 접지면과 관련된 데이터를 다룰 때 사용됩니다.  \n  - **용도:** `base_link`와 비슷하지만, 로봇의 2D 평면상의 위치에 초점을 맞춥니다.\n\n- **laser_frame (또는 scan, 또는 lidar_frame)**  \n  - **설명:** LiDAR 센서가 부착된 좌표계입니다.  \n  - **용도:** LiDAR 스캔 데이터가 이 프레임을 기준으로 측정됩니다.\n\n- **scanmatcher_frame**  \n  - **설명:** Hector SLAM에서 스캔 매칭 시 사용하는 추가 프레임으로, 데이터 변환의 보조 역할을 합니다.  \n  - **용도:** 주로 TF를 이용해 스캔 데이터와 지도 사이의 정밀한 변환을 수행할 때 활용됩니다.\n\n### TF의 역할과 중요성\n\nTF는 위에서 언급한 다양한 좌표계를 서로 연결하는 역할을 합니다.  \n예를 들어, LiDAR 센서에서 수집된 데이터(`laser_frame`)를 로봇의 기준 좌표계(`base_link` 또는 `base_footprint`)로 변환하고, 이를 다시 전역 지도 좌표계(`map`)와 연결하는 작업이 필요합니다.  \n이러한 변환이 **정확해야** SLAM이 올바르게 동작하며, RViz 등에서 **올바른 위치**에 로봇과 장애물을 표시할 수 있습니다.\n\n올바른 TF 구성은 Hector SLAM 뿐 아니라, 전체 자율주행 시스템의 성능에 매우 중요한 영향을 미칩니다.\n\n---\n\n## Hector SLAM 설치 및 테스트\n\n1. **Hector SLAM 레포 클론 및 빌드**\n\n   ```bash\n   cd ~/catkin_ws/src\n   git clone https://github.com/tu-darmstadt-ros-pkg/hector_slam.git\n   cd ~/catkin_ws\n   catkin_make\n   ```\n\n2. **기본 테스트 실행**\n\n   ```bash\n   roslaunch hector_slam tutorial.launch\n   ```\n\n### 런치 파일(`mapping_default.launch`) 주요 파라미터\n\n이 Hector SLAM 패키지에서 제일 중요하다고 생각하는 런치 파일입니다.\n\n추후 프로젝트에서도 이 런치파일을 조금씩 수정해 사용하기에, 간단하게 설명을 하겠습니다.  \n\n```xml\n<?xml version=\"1.0\"?>\n\n<launch>\n  <arg name=\"tf_map_scanmatch_transform_frame_name\" default=\"scanmatcher_frame\"/>\n  <arg name=\"base_frame\" default=\"base_footprint\"/>\n  <arg name=\"odom_frame\" default=\"nav\"/>\n  <arg name=\"pub_map_odom_transform\" default=\"true\"/>\n  <arg name=\"scan_subscriber_queue_size\" default=\"5\"/>\n  <arg name=\"scan_topic\" default=\"scan\"/>\n  <arg name=\"map_size\" default=\"2048\"/>\n  \n  <node pkg=\"hector_mapping\" type=\"hector_mapping\" name=\"hector_mapping\" output=\"screen\">\n    \n    <!-- Frame names -->\n    <param name=\"map_frame\" value=\"map\" />\n    <param name=\"base_frame\" value=\"$(arg base_frame)\" />\n    <param name=\"odom_frame\" value=\"$(arg odom_frame)\" />\n    \n    <!-- Tf use -->\n    <param name=\"use_tf_scan_transformation\" value=\"true\"/>\n    <param name=\"use_tf_pose_start_estimate\" value=\"false\"/>\n    <param name=\"pub_map_odom_transform\" value=\"$(arg pub_map_odom_transform)\"/>\n    \n    <!-- Map size / start point -->\n    <param name=\"map_resolution\" value=\"0.050\"/>\n    <param name=\"map_size\" value=\"$(arg map_size)\"/>\n    <param name=\"map_start_x\" value=\"0.5\"/>\n    <param name=\"map_start_y\" value=\"0.5\" />\n    <param name=\"map_multi_res_levels\" value=\"2\" />\n    \n    <!-- Map update parameters -->\n    <param name=\"update_factor_free\" value=\"0.4\"/>\n    <param name=\"update_factor_occupied\" value=\"0.9\" />    \n    <param name=\"map_update_distance_thresh\" value=\"0.4\"/>\n    <param name=\"map_update_angle_thresh\" value=\"0.06\" />\n    <param name=\"laser_z_min_value\" value = \"-1.0\" />\n    <param name=\"laser_z_max_value\" value = \"1.0\" />\n    \n    <!-- Advertising config --> \n    <param name=\"advertise_map_service\" value=\"true\"/>\n    \n    <param name=\"scan_subscriber_queue_size\" value=\"$(arg scan_subscriber_queue_size)\"/>\n    <param name=\"scan_topic\" value=\"$(arg scan_topic)\"/>\n    \n    <!-- Debug parameters -->\n    <!--\n      <param name=\"output_timing\" value=\"false\"/>\n      <param name=\"pub_drawings\" value=\"true\"/>\n      <param name=\"pub_debug_output\" value=\"true\"/>\n    -->\n    <param name=\"tf_map_scanmatch_transform_frame_name\" value=\"$(arg tf_map_scanmatch_transform_frame_name)\" />\n  </node>\n    \n  <!--<node pkg=\"tf\" type=\"static_transform_publisher\" name=\"map_nav_broadcaster\" args=\"0 0 0 0 0 0 map nav 100\"/>-->\n</launch>\n```\n\n### 주요 인자 및 파라미터 설명\n\n- **런치 파일 인자**\n  - `tf_map_scanmatch_transform_frame_name`: 스캔 매칭을 위한 TF 변환 시 사용하는 프레임 이름 (기본값: `scanmatcher_frame`)\n  - `base_frame`: 로봇의 기준 프레임, 일반적으로 로봇의 중심을 의미 (기본값: `base_footprint`)\n  - `odom_frame`: odom 프레임, 로봇의 이동 정보를 나타냄 (기본값: `nav`)\n  - `pub_map_odom_transform`: 맵과 odom 사이의 TF를 퍼블리시할지 여부 (기본값: `true`)\n  - `scan_subscriber_queue_size`: LiDAR 스캔 데이터를 수신할 때의 큐 크기 (기본값: `5`)\n  - `scan_topic`: LiDAR 스캔 데이터가 발행되는 토픽 이름 (기본값: `scan`)\n  - `map_size`: 생성될 지도 크기 (셀 단위, 기본값: `2048`)\n\n- **노드 내부 파라미터**\n  - **Frame 설정**\n    - `map_frame`: 생성된 지도의 기준 프레임 (값: `map`)\n    - `base_frame`와 `odom_frame`: 위 인자에서 정의된 값이 적용됨\n  - **TF 관련 설정**\n    - `use_tf_scan_transformation`: TF를 통해 스캔 데이터를 변환할지 여부 (값: `true`)\n    - `use_tf_pose_start_estimate`: 초기 자세 추정을 TF를 통해 할지 여부 (값: `false`)\n    - `pub_map_odom_transform`: 맵과 odom 사이의 변환을 퍼블리시할지 여부\n  - **맵 관련 설정**\n    - `map_resolution`: 지도의 해상도 (한 셀당 크기, 기본값: `0.050`m)\n    - `map_size`: 전체 지도 크기  \n    - `map_start_x`, `map_start_y`: 지도 생성 시작 위치의 오프셋 (기본값: `0.5`)\n    - `map_multi_res_levels`: 다중 해상도 맵의 레벨 수 (기본값: `2`)\n  - **맵 업데이트 파라미터**\n    - `update_factor_free`: 자유 공간 업데이트 가중치 (값: `0.4`)\n    - `update_factor_occupied`: 장애물로 인식되는 공간 업데이트 가중치 (값: `0.9`)\n    - `map_update_distance_thresh`: 지도 업데이트를 위한 거리 임계값 (값: `0.4`)\n    - `map_update_angle_thresh`: 지도 업데이트를 위한 각도 임계값 (값: `0.06`)\n    - `laser_z_min_value` 및 `laser_z_max_value`: LiDAR 스캔의 Z 축 범위 설정 (값: `-1.0` ~ `1.0`)\n  - **기타**\n    - `advertise_map_service`: 외부에서 지도 서비스를 요청할 수 있도록 퍼블리시 여부 (값: `true`)\n    - `tf_map_scanmatch_transform_frame_name`: 스캔 매칭에 사용되는 TF 프레임 이름\n\n> 이번 페이지에서는 단순히 튜토리얼 런치파일을 실행해 동작했지만, 프로젝트를 수행하며 매우 중요한 부분이기에 각 인자와 파라미터를 알아두는 것이 중요합니다.   \n{: .prompt-tip }\n\n---\n\n## 마무리\n\n![alt text](/assets/img/ros/ros11.png)\n\n이렇게 해서 Hector SLAM을 빌드하고 직접 테스트까지 수행했습니다.  \n\n급격한 환경 변화가 생길 경우, 현재 위치를 정상적으로 추정하지 못하여 이상하게 맵이 그려질 수 있습니다.  \n이를 위해 간단한 플랫폼을 제작하거나, 혹은 로봇을 모두 완성한 후 수동으로 움직이며 테스트하는 것을 권장드립니다.  \n\n",
    "date": "2025-02-22",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-22-Hector-SLAM_chunk_0",
        "text": "Hector SLAM 사용하기\n\n## Hector SLAM 개요\n\nHector SLAM은 **주로 2D LiDAR 센서**를 기반으로 동작하는 SLAM 기법으로, IMU나 휠 오도메트리 없이도 실시간으로 맵을 생성할 수 있는 장점이 있습니다. <br>\n타 SLAM 기법(예: GMapping, Cartographer 등)은 보통 IMU나 휠 오도메트리 등 다양한 센서 데이터를 활용해 보다 복잡한 환경에서도 정밀한 맵 생성을 지원하지만, 이 프로젝트에서 만드는 차량은 급격한 회전이나 큰 변화가 없으며, IMU와 같이 odom을 생성할 수 있는 센서를 사용하지 않기 때문에 Hector SLAM을 사용합니다.  \n\nHector SLAM은 다음과 같이 동작합니다:\n\n- **스캔 매칭:** 각 LiDAR 스캔을 기존 맵과 비교하여 로봇의 현재 위치를 추정합니다.\n- **실시간 맵 업데이트:** 추정된 위치를 바탕으로 환경 지도를 업데이트하며, 다중 해상도 맵을 활용해 정밀도를 높입니다.\n- **센서 독립성:** 오직 LiDAR 데이터만 사용하기 때문에 센서 간의 동기화나  캘리브레이션 과정이 줄어듭니다.\n\n---\n\n## ROS TF (Transform)\n\nROS의 TF(Transform) 패키지는 서로 다른 좌표계(프레임) 간의 변환 정보를 실시간으로 관리하고 제공하는 역할을 합니다.  \n이를 통해 여러 센서나 모듈이 서로 다른 좌표계에서 데이터를 주고받을 때, 정확한 위치 관계를 유지할 수 있습니다.\n\n### 주요 TF 프레임\n\nHector SLAM에서는 아래와 같은 좌표계가 사용됩니다.",
        "index": 0
      },
      {
        "id": "2025-02-22-Hector-SLAM_chunk_1",
        "text": "이 서로 다른 좌표계에서 데이터를 주고받을 때, 정확한 위치 관계를 유지할 수 있습니다.\n\n### 주요 TF 프레임\n\nHector SLAM에서는 아래와 같은 좌표계가 사용됩니다.  \n\n- **map**  \n  - **설명:** 전역 좌표계로, 생성된 지도 전체를 나타냅니다.  \n  - **용도:** SLAM 알고리즘에서 최종 생성되는 지도의 기준 좌표계로 사용됩니다.\n\n- **odom (또는 nav)**  \n  - **설명:** odom 좌표계로, 로봇의 짧은 시간 내 움직임을 나타냅니다.  \n  - **용도:** 로봇의 이동 정보(예: 휠 odom)가 반영되며, 단기적인 위치 추정에 사용됩니다.  \n  - Hector SLAM에서는 별도의 odom 센서가 없더라도, 기본적인 움직임 추정을 위해 사용될 수 있습니다.\n\n- **base_link**  \n  - **설명:** 로봇 본체의 중심 좌표계입니다.  \n  - **용도:** 로봇의 주요 동작이나 센서가 부착되는 기준 좌표로, `base_link`를 기준으로 주변 센서 데이터가 변환됩니다.\n\n- **base_footprint**  \n  - **설명:** 로봇의 바닥면을 나타내는 좌표계로, 주로 로봇의 실제 접지면과 관련된 데이터를 다룰 때 사용됩니다.  \n  - **용도:** `base_link`와 비슷하지만, 로봇의 2D 평면상의 위치에 초점을 맞춥니다.\n\n- **laser_frame (또는 scan, 또는 lidar_frame)**  \n  - **설명:** LiDAR 센서가 부착된 좌표계입니다.",
        "index": 1
      },
      {
        "id": "2025-02-22-Hector-SLAM_chunk_2",
        "text": "평면상의 위치에 초점을 맞춥니다.\n\n- **laser_frame (또는 scan, 또는 lidar_frame)**  \n  - **설명:** LiDAR 센서가 부착된 좌표계입니다.  \n  - **용도:** LiDAR 스캔 데이터가 이 프레임을 기준으로 측정됩니다.\n\n- **scanmatcher_frame**  \n  - **설명:** Hector SLAM에서 스캔 매칭 시 사용하는 추가 프레임으로, 데이터 변환의 보조 역할을 합니다.  \n  - **용도:** 주로 TF를 이용해 스캔 데이터와 지도 사이의 정밀한 변환을 수행할 때 활용됩니다.\n\n### TF의 역할과 중요성\n\nTF는 위에서 언급한 다양한 좌표계를 서로 연결하는 역할을 합니다.  \n예를 들어, LiDAR 센서에서 수집된 데이터(`laser_frame`)를 로봇의 기준 좌표계(`base_link` 또는 `base_footprint`)로 변환하고, 이를 다시 전역 지도 좌표계(`map`)와 연결하는 작업이 필요합니다.  \n이러한 변환이 **정확해야** SLAM이 올바르게 동작하며, RViz 등에서 **올바른 위치**에 로봇과 장애물을 표시할 수 있습니다.\n\n올바른 TF 구성은 Hector SLAM 뿐 아니라, 전체 자율주행 시스템의 성능에 매우 중요한 영향을 미칩니다.\n\n---\n\n## Hector SLAM 설치 및 테스트\n\n1.",
        "index": 2
      },
      {
        "id": "2025-02-22-Hector-SLAM_chunk_3",
        "text": "올바른 TF 구성은 Hector SLAM 뿐 아니라, 전체 자율주행 시스템의 성능에 매우 중요한 영향을 미칩니다.\n\n---\n\n## Hector SLAM 설치 및 테스트\n\n1. **Hector SLAM 레포 클론 및 빌드**\n\n   ```bash\n   cd ~/catkin_ws/src\n   git clone https://github.com/tu-darmstadt-ros-pkg/hector_slam.git\n   cd ~/catkin_ws\n   catkin_make\n   ```\n\n2. **기본 테스트 실행**\n\n   ```bash\n   roslaunch hector_slam tutorial.launch\n   ```\n\n### 런치 파일(`mapping_default.launch`) 주요 파라미터\n\n이 Hector SLAM 패키지에서 제일 중요하다고 생각하는 런치 파일입니다.\n\n추후 프로젝트에서도 이 런치파일을 조금씩 수정해 사용하기에, 간단하게 설명을 하겠습니다.",
        "index": 3
      },
      {
        "id": "2025-02-22-Hector-SLAM_chunk_4",
        "text": "라미터\n\n이 Hector SLAM 패키지에서 제일 중요하다고 생각하는 런치 파일입니다.\n\n추후 프로젝트에서도 이 런치파일을 조금씩 수정해 사용하기에, 간단하게 설명을 하겠습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-02-22-ROS1",
    "title": "ROS1기반 자율주행 프로젝트 시작하기",
    "path": "/2025/02/22/ROS1기반-자율주행-프로젝트-시작하기/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 프로젝트 개요\n\n오로지 LiDAR센서만을 이용한 자율주행 시스템을 구현하는 프로젝트 입니다.  \nROS 설치부터 SLAM과 ROS1 Navigation 스택까지 전반적인 과정에 대해 다룹니다.  \n\n---\n\n## 하드웨어 및 시스템 구성\n\n- **보드:** Jetson Orin Nano (Jetpack 5.1.3)  \n- **ROS 버전:** ROS1 Noetic  \n- **센서:**  \n  - 2D LiDAR: YDLidar X4  \n- **차량 구성:**  \n  - 후륜구동 구조 (후륜에 DC모터 사용)  \n  - 앞바퀴 조향: 서보모터 장착 (애커만 조향 방식과 유사)  \n\n  > 직접 모터 드라이버 제작 후 사용 예정  \n  {: .prompt-tip}\n- **차체 크기:**  \n  - 전후 30cm, 좌우 12cm, 높이 15cm\n\n--- \n\n## 예상 진행 순서\n- 개발 환경 구성\n- ROS 설치\n- LiDAR 드라이버 설치 및 테스트\n- SLAM 테스트\n- Navigation Stack 연동\n- 파라미터 튜닝 및 고도화\n    ",
    "date": "2025-02-22",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-22-ROS1_chunk_0",
        "text": "ROS1기반 자율주행 프로젝트 시작하기\n\n## 프로젝트 개요\n\n오로지 LiDAR센서만을 이용한 자율주행 시스템을 구현하는 프로젝트 입니다.  \nROS 설치부터 SLAM과 ROS1 Navigation 스택까지 전반적인 과정에 대해 다룹니다.  \n\n---\n\n## 하드웨어 및 시스템 구성\n\n- **보드:** Jetson Orin Nano (Jetpack 5.1.3)  \n- **ROS 버전:** ROS1 Noetic  \n- **센서:**  \n  - 2D LiDAR: YDLidar X4  \n- **차량 구성:**  \n  - 후륜구동 구조 (후륜에 DC모터 사용)  \n  - 앞바퀴 조향: 서보모터 장착 (애커만 조향 방식과 유사)  \n\n  > 직접 모터 드라이버 제작 후 사용 예정  \n  {: .prompt-tip}\n- **차체 크기:**  \n  - 전후 30cm, 좌우 12cm, 높이 15cm\n\n--- \n\n## 예상 진행 순서\n- 개발 환경 구성\n- ROS 설치\n- LiDAR 드라이버 설치 및 테스트\n- SLAM 테스트\n- Navigation Stack 연동\n- 파라미터 튜닝 및 고도화\n    ",
        "index": 0
      }
    ]
  },
  {
    "id": "2025-02-22------------ROS",
    "title": "Jetson orin nano 개발 환경 구성 및 ROS 설치",
    "path": "/2025/02/22/개발-환경-구성-및-ROS-설치/",
    "categories": [
      "Embedded System",
      "ROS"
    ],
    "content": "## 개요\n\n이번 글에서는 Jetson Orin Nano 보드에 Ubuntu 20.04를 설치하고, ROS 환경을 구성하는 과정을 다룹니다.  \n\n---\n\n## 1. Jetson 이미지 설치\n\nJetson 보드의 운영체제를 준비해야 합니다.  \n호환성을 고려해 사용할 Jetpack 버전은 **5.1.3**입니다.\n\n> 25년 1월 기준 최신 버전을 사용할 경우 부팅 문제가 있었습니다.  \n> Jetpack 6.x 버전 사용 시 부트로더 버전 불일치로 인해 문제가 발생할 수 있다고 합니다.\n> https://forums.developer.nvidia.com/t/jetpack-6-x-versions-not-working-jetson-orin-nano-dev-kit/308493?utm_source=chatgpt.com\n{: .prompt-info }\n\n\n- [Jetpack 5.1.3 SD 카드 이미지 다운로드](https://developer.nvidia.com/embedded/jetpack-sdk-513)\n- SD 카드 이미지를 다운로드한 후, **SD card formatter** 또는 **balenaEtcher**와 같은 도구를 이용해 SD 카드에 이미지를 설치합니다.\n![download](/assets/img/ros/ros10.png)\n\n---\n\n## 2. Ubuntu 20.04 설치\n\nSD 카드에 이미지 설치가 완료되면, Jetson 보드에 **Ubuntu 20.04**를 설치합니다.  \n우분투 설치 방법은 여러 블로그에 자세히 나와 있으므로, 참고하여 진행하면 됩니다.\n\n설치가 완료되면, 보드를 부팅하고 기본 설정(사용자 계정, 시간대 설정 등)을 마무리합니다.\n\n---\n\n## 3. 인터넷 설정 및 원격 접속 준비\n\n설치 후에는 네트워크 연결과 원격 접속 설정이 필요합니다.\n\n### Wifi 연결 설정 (nmcli 사용)\n\n우선, Wi-Fi 연결을 위해 `nmcli` 명령어를 사용하여 `wlan0` 인터페이스를 설정합니다.\n\n예를 들어, SSID가 `MyWifi`이고 비밀번호가 `password123`인 경우, 아래와 같이 명령어를 실행합니다.\n\n```bash\nsudo nmcli device wifi connect \"MyWifi\" password \"password123\" ifname wlan0\n```\n\n이 명령어는 지정한 Wi-Fi 네트워크에 연결하며, 정상적으로 연결되면 IP 주소를 할당받게 됩니다.\n\n인터넷 연결이 완료되면 원격 접속을 위한 SSH 서버 설정 등 추가 설정을 진행할 수 있습니다.\n\n---\n\n## 4. 시스템 업데이트 및 재시작\n\n인터넷 설정 후, 다음 명령어를 통해 시스템을 최신 상태로 업데이트합니다.\n\n```bash\nsudo apt update && sudo apt upgrade\n```\n\n업데이트가 완료되면, 재시작을 위해 아래 명령어를 실행합니다.\n\n```bash\nreboot\n```\n\n---\n\n## 5. ROS 설치\n\nUbuntu 20.04에서 ROS1 Noetic을 설치할 예정입니다.  \nROS2 Foxy도 사용 가능하지만, 우선 ROS1에 익숙한 경험과 자료가 많다는 점에서 **ROS1 Noetic**을 선택했습니다.  \n추후 기회가 된다면 ROS2 기반 프로젝트도 진행해 볼 생각입니다.\n\n### 필요 라이브러리 설치\n\n먼저, 기본적인 빌드 도구와 라이브러리들을 설치합니다.\n\n```bash\nsudo apt update && sudo apt upgrade\nsudo apt install build-essential cmake git\n```\n\n---\n\n### ROS 저장소 설정\n\nROS 패키지를 설치하기 위해 ROS 저장소를 추가합니다.\n\n```bash\nsudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu focal main\" > /etc/apt/sources.list.d/ros-latest.list'\n```\n\n---\n\n### ROS 키 추가\n\n```bash\nsudo apt install curl # curl이 설치되어 있지 않다면 설치\ncurl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -\n```\n\n---\n\n### ROS Noetic 설치\n\n```bash\nsudo apt update\nsudo apt install ros-noetic-desktop-full\n```\n\n---\n\n### 의존성 설치\n\nROS와 관련된 의존성 패키지들을 설치합니다.\n\n```bash\nsudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential\n```\n\n---\n\n### rosdep 초기화 및 업데이트\n\n`rosdep`은 ROS 패키지 의존성을 자동으로 해결해 주는 도구입니다.\n\n```bash\nsudo rosdep init\nrosdep update\n```\n\n> **rosdep이란?**  \n> ROS는 여러 패키지가 상호 의존성을 가지기 때문에, 하나하나 설치하기 어렵습니다.  \n> `rosdep`은 이러한 의존성 문제를 해결해주기 위해 기본 설정과 데이터베이스를 초기화 및 업데이트합니다.\n{: .prompt-tip }  \n\n---\n\n### 환경 설정\n\nROS 설치 후 매번 환경 변수를 설정하지 않도록 아래 명령어를 통해 자동 설정되게 합니다.\n\n```bash\necho \"source /opt/ros/noetic/setup.bash\" >> ~/.bashrc\nsource ~/.bashrc\n```\n\n---\n\n### ROS Workspace 설정\n\n프로젝트 관리를 위한 ROS Workspace를 생성합니다.\n\n```bash\nmkdir -p ~/catkin_ws/src\ncd ~/catkin_ws/\ncatkin_make\n```\n\nWorkspace 설정 후, 환경 설정 파일을 다시 적용합니다.\n\n```bash\necho \"source ~/catkin_ws/devel/setup.bash\" >> ~/.bashrc\nsource ~/.bashrc\n```\n\n> 이는 home에 `catkin_ws`를 생성했을 경우 유효합니다.  \n> 만약, 다른 경로로 설정했다면 이를 반영해야 합니다.\n> 혹은, `alias` 명령어를 이용해 설정할 수도 있습니다.  \n\n---\n\n## 마무리\n\n이렇게 해서 ROS 개발 환경 구성은 완료되었습니다.  \n이 외에도 VNC 설정이나 VSCode 원격 구성 등 추가적인 구성 요소가 있지만,  \n필요할 경우 다른 글에 작성 후 링크를 첨부하도록 하겠습니다.  \n\n",
    "date": "2025-02-22",
    "tags": [
      "ROS",
      "자율주행",
      "SLAM"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-02-22------------ROS_chunk_0",
        "text": "Jetson orin nano 개발 환경 구성 및 ROS 설치\n\n## 개요\n\n이번 글에서는 Jetson Orin Nano 보드에 Ubuntu 20.04를 설치하고, ROS 환경을 구성하는 과정을 다룹니다.  \n\n---\n\n## 1. Jetson 이미지 설치\n\nJetson 보드의 운영체제를 준비해야 합니다.  \n호환성을 고려해 사용할 Jetpack 버전은 **5.1.3**입니다.\n\n> 25년 1월 기준 최신 버전을 사용할 경우 부팅 문제가 있었습니다.  \n> Jetpack 6.x 버전 사용 시 부트로더 버전 불일치로 인해 문제가 발생할 수 있다고 합니다.\n> https://forums.developer.nvidia.com/t/jetpack-6-x-versions-not-working-jetson-orin-nano-dev-kit/308493?utm_source=chatgpt.com\n{: .prompt-info }\n\n\n- [Jetpack 5.1.3 SD 카드 이미지 다운로드](https://developer.nvidia.com/embedded/jetpack-sdk-513)\n- SD 카드 이미지를 다운로드한 후, **SD card formatter** 또는 **balenaEtcher**와 같은 도구를 이용해 SD 카드에 이미지를 설치합니다.\n![download](/assets/img/ros/ros10.png)\n\n---\n\n## 2. Ubuntu 20.04 설치\n\nSD 카드에 이미지 설치가 완료되면, Jetson 보드에 **Ubuntu 20.04**를 설치합니다.",
        "index": 0
      },
      {
        "id": "2025-02-22------------ROS_chunk_1",
        "text": "os/ros10.png)\n\n---\n\n## 2. Ubuntu 20.04 설치\n\nSD 카드에 이미지 설치가 완료되면, Jetson 보드에 **Ubuntu 20.04**를 설치합니다.  \n우분투 설치 방법은 여러 블로그에 자세히 나와 있으므로, 참고하여 진행하면 됩니다.\n\n설치가 완료되면, 보드를 부팅하고 기본 설정(사용자 계정, 시간대 설정 등)을 마무리합니다.\n\n---\n\n## 3. 인터넷 설정 및 원격 접속 준비\n\n설치 후에는 네트워크 연결과 원격 접속 설정이 필요합니다.\n\n### Wifi 연결 설정 (nmcli 사용)\n\n우선, Wi-Fi 연결을 위해 `nmcli` 명령어를 사용하여 `wlan0` 인터페이스를 설정합니다.\n\n예를 들어, SSID가 `MyWifi`이고 비밀번호가 `password123`인 경우, 아래와 같이 명령어를 실행합니다.\n\n```bash\nsudo nmcli device wifi connect \"MyWifi\" password \"password123\" ifname wlan0\n```\n\n이 명령어는 지정한 Wi-Fi 네트워크에 연결하며, 정상적으로 연결되면 IP 주소를 할당받게 됩니다.\n\n인터넷 연결이 완료되면 원격 접속을 위한 SSH 서버 설정 등 추가 설정을 진행할 수 있습니다.\n\n---\n\n## 4.",
        "index": 1
      },
      {
        "id": "2025-02-22------------ROS_chunk_2",
        "text": "결하며, 정상적으로 연결되면 IP 주소를 할당받게 됩니다.\n\n인터넷 연결이 완료되면 원격 접속을 위한 SSH 서버 설정 등 추가 설정을 진행할 수 있습니다.\n\n---\n\n## 4. 시스템 업데이트 및 재시작\n\n인터넷 설정 후, 다음 명령어를 통해 시스템을 최신 상태로 업데이트합니다.\n\n```bash\nsudo apt update && sudo apt upgrade\n```\n\n업데이트가 완료되면, 재시작을 위해 아래 명령어를 실행합니다.\n\n```bash\nreboot\n```\n\n---\n\n## 5. ROS 설치\n\nUbuntu 20.04에서 ROS1 Noetic을 설치할 예정입니다.  \nROS2 Foxy도 사용 가능하지만, 우선 ROS1에 익숙한 경험과 자료가 많다는 점에서 **ROS1 Noetic**을 선택했습니다.",
        "index": 2
      },
      {
        "id": "2025-02-22------------ROS_chunk_3",
        "text": "OS1 Noetic을 설치할 예정입니다.  \nROS2 Foxy도 사용 가능하지만, 우선 ROS1에 익숙한 경험과 자료가 많다는 점에서 **ROS1 Noetic**을 선택했습니다.",
        "index": 3
      },
      {
        "id": "2025-02-22------------ROS_chunk_4",
        "text": "OS1 Noetic을 설치할 예정입니다.  \nROS2 Foxy도 사용 가능하지만, 우선 ROS1에 익숙한 경험과 자료가 많다는 점에서 **ROS1 Noetic**을 선택했습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-01-09--BOJ--2437",
    "title": "[BOJ] 2437번 저울",
    "path": "/2025/01/09/[BOJ]-2437번-저울/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "---\n\n> **문제 링크**: [백준 2437번](https://www.acmicpc.net/problem/2437)  \n{: .prompt-tip }\n\n## 문제 요약\n\n- **문제**:  \n  주어진 여러 개의 저울추를 사용하여 측정할 수 없는 **가장 작은 무게**를 찾는 문제입니다.  \n  - 예를 들어, 저울추가 `[3, 1, 6, 2, 7, 30, 1]`일 때, 측정할 수 없는 가장 작은 무게는 **21**입니다.\n\n- **제약 조건**:  \n  - 각 추의 무게는 $$ 1 \\leq \\text{무게} \\leq 1,000,000 $$.\n  - 추의 개수 $$ 1 \\leq N \\leq 1,000 $$.\n\n---\n\n## 문제 풀이 아이디어\n\n1. 처음에는 어느정도 탐색을 하며 최적화를 적용하려했지만, $$ 2^N $$의 경우의 수를 고려해야 하고, 딱히 마땅한 방법이 떠오르지 않았습니다.  \n\n2. **규칙 발견**:\n   - 추를 **오름차순 정렬**하고, 현재까지 측정 가능한 범위를 $$ \\text{sum} $$으로 정의합니다.\n   - 새로운 추 $$ x $$가 $$ \\text{sum} + 1 $$보다 작거나 같으면, 측정 가능한 범위가 확장됩니다.\n   - 그렇지 않다면 $$ \\text{sum} + 1 $$이 측정할 수 없는 최소 무게가 됩니다.\n\n3. 이를 통해 $$ O(N \\log N) $$의 시간 복잡도로 문제를 해결할 수 있습니다.\n\n> 예를 들어, N=5이고 `[1,1,1,1,5]`의 상황을 생각해보면, 1은 그대로 무게를 잴 수 있고, 4까지는 1들을 활용해서 만들 수 있습니다. 5는 그 자체로 측정할 수 있고, 4까지는 5를 활용하지 않고도 만들 수 있었기에, 그 방법들에 5를 추가하면 4 + 5까지는 무조건 측정할 수 있게됩니다.  \n\n\n--- \n\n## 정답 코드\n\n```cpp\n#include <bits/stdc++.h>\nusing namespace std;\n\nint main() {\n    int N; \n    cin >> N;\n    vector<int> arr(N);\n    for (int i = 0; i < N; i++) cin >> arr[i];\n\n    sort(arr.begin(), arr.end());\n    \n    int sum = 0; // 현재까지 측정 가능한 범위의 합\n    for (int i = 0; i < N; i++) {\n        int tar = sum + 1; // 다음으로 측정할 수 없는 최소 무게\n        if (arr[i] <= tar) sum += arr[i];\n        else break; // 더 이상 측정 가능한 범위를 확장할 수 없음\n    }\n    cout << sum + 1; // 측정할 수 없는 최소 무게 출력\n\n    return 0;\n}\n```\n",
    "date": "2025-01-09",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-01-09--BOJ--2437_chunk_0",
        "text": "[BOJ] 2437번 저울\n\n---\n\n> **문제 링크**: [백준 2437번](https://www.acmicpc.net/problem/2437)  \n{: .prompt-tip }\n\n## 문제 요약\n\n- **문제**:  \n  주어진 여러 개의 저울추를 사용하여 측정할 수 없는 **가장 작은 무게**를 찾는 문제입니다.  \n  - 예를 들어, 저울추가 `[3, 1, 6, 2, 7, 30, 1]`일 때, 측정할 수 없는 가장 작은 무게는 **21**입니다.\n\n- **제약 조건**:  \n  - 각 추의 무게는 $$ 1 \\leq \\text{무게} \\leq 1,000,000 $$.\n  - 추의 개수 $$ 1 \\leq N \\leq 1,000 $$.\n\n---\n\n## 문제 풀이 아이디어\n\n1. 처음에는 어느정도 탐색을 하며 최적화를 적용하려했지만, $$ 2^N $$의 경우의 수를 고려해야 하고, 딱히 마땅한 방법이 떠오르지 않았습니다.  \n\n2. **규칙 발견**:\n   - 추를 **오름차순 정렬**하고, 현재까지 측정 가능한 범위를 $$ \\text{sum} $$으로 정의합니다.\n   - 새로운 추 $$ x $$가 $$ \\text{sum} + 1 $$보다 작거나 같으면, 측정 가능한 범위가 확장됩니다.\n   - 그렇지 않다면 $$ \\text{sum} + 1 $$이 측정할 수 없는 최소 무게가 됩니다.\n\n3.",
        "index": 0
      },
      {
        "id": "2025-01-09--BOJ--2437_chunk_1",
        "text": "um} + 1 $$보다 작거나 같으면, 측정 가능한 범위가 확장됩니다.\n   - 그렇지 않다면 $$ \\text{sum} + 1 $$이 측정할 수 없는 최소 무게가 됩니다.\n\n3. 이를 통해 $$ O(N \\log N) $$의 시간 복잡도로 문제를 해결할 수 있습니다.\n\n> 예를 들어, N=5이고 `[1,1,1,1,5]`의 상황을 생각해보면, 1은 그대로 무게를 잴 수 있고, 4까지는 1들을 활용해서 만들 수 있습니다. 5는 그 자체로 측정할 수 있고, 4까지는 5를 활용하지 않고도 만들 수 있었기에, 그 방법들에 5를 추가하면 4 + 5까지는 무조건 측정할 수 있게됩니다.",
        "index": 1
      },
      {
        "id": "2025-01-09--BOJ--2437_chunk_2",
        "text": "만들 수 있습니다. 5는 그 자체로 측정할 수 있고, 4까지는 5를 활용하지 않고도 만들 수 있었기에, 그 방법들에 5를 추가하면 4 + 5까지는 무조건 측정할 수 있게됩니다.  \n\n\n--- \n\n## 정답 코드\n\n```cpp\n#include <bits/stdc++.h>\nusing namespace std;\n\nint main() {\n    int N; \n    cin >> N;\n    vector<int> arr(N);\n    for (int i = 0; i < N; i++) cin >> arr[i];\n\n    sort(arr.begin(), arr.end());\n    \n    int sum = 0; // 현재까지 측정 가능한 범위의 합\n    for (int i = 0; i < N; i++) {\n        int tar = sum + 1; // 다음으로 측정할 수 없는 최소 무게\n        if (arr[i] <= tar) sum += arr[i];\n        else break; // 더 이상 측정 가능한 범위를 확장할 수 없음\n    }\n    cout << sum + 1; // 측정할 수 없는 최소 무게 출력\n\n    return 0;\n}\n```",
        "index": 2
      },
      {
        "id": "2025-01-09--BOJ--2437_chunk_3",
        "text": "k; // 더 이상 측정 가능한 범위를 확장할 수 없음\n    }\n    cout << sum + 1; // 측정할 수 없는 최소 무게 출력\n\n    return 0;\n}\n```",
        "index": 3
      },
      {
        "id": "2025-01-09--BOJ--2437_chunk_4",
        "text": "k; // 더 이상 측정 가능한 범위를 확장할 수 없음\n    }\n    cout << sum + 1; // 측정할 수 없는 최소 무게 출력\n\n    return 0;\n}\n```",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-01-09--BOJ--1700",
    "title": "[BOJ] 1700번 멀티탭 스케줄링",
    "path": "/2025/01/09/[BOJ]-1700번-멀티탭-스케줄링/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 1700번](https://www.acmicpc.net/problem/1700)  \n{: .prompt-tip }\n\n## 문제 요약\n\n- $$ N $$: 멀티탭 구멍의 개수  \n- $$ K $$: 전기용품의 총 사용 횟수  \n- $$ K $$개의 전기용품 사용 순서가 주어질 때, 플러그를 **최소 횟수로 뽑아야** 한다.  \n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 CPU 스케줄링과 유사한 **멀티탭 관리 문제**입니다.  \n멀티탭이 모두 차 있을 때, **어떤 플러그를 뽑는 것이 가장 최적인가**를 결정해야 합니다.\n\n1. **기본 규칙**:\n   - **빈 멀티탭이 있다면** 해당 기기를 바로 꽂는다.\n   - 멀티탭에 이미 현재 기기가 꽂혀 있다면 아무 작업도 하지 않는다.\n\n2. **멀티탭이 모두 찬 경우**:\n   - **가장 늦게 사용되거나 사용되지 않는 기기**를 뽑는 것이 최적이다.  \n   - 이를 구현하기 위해 각 기기별로 **사용 시점의 큐(wait 배열)**를 만들어 사용한다.\n\n3. **구현 흐름**:\n   - **`wait` 큐 배열**: 각 기기의 사용 시점을 저장하는 큐로, 예를 들어 `wait[4] = {1, 3, 8}`는 4번 기기가 1, 3, 8번째에 사용됨을 나타냄. \n   - 현재 멀티탭 상태에서 각 기기가 언제 다시 사용되는지를 기준으로 우선순위 큐(`distpq`)를 사용해 **가장 나중에 사용되거나 사용되지 않는 기기**를 선택.\n\n---\n\n## 정답 코드\n\n```cpp\n#include <bits/stdc++.h>\nusing namespace std;\n\nqueue<int> wait[101]; // 각 기기의 사용 시점\nqueue<int> q;         // 사용 순서를 저장하는 큐\nvector<int> tab;      // 멀티탭 상태\n\nint main() {\n    int N, K;\n    cin >> N >> K;\n\n    tab.resize(N, 0); // 멀티탭 초기화\n\n    for (int i = 0; i < K; i++) {\n        int num; \n        cin >> num;\n        q.push(num);\n        wait[num].push(i); // 각 기기의 사용 시점을 기록\n    }\n\n    int time = 0, ans = 0;\n\n    while (!q.empty()) {\n        int cur = q.front(); q.pop(); // 현재 사용할 기기\n        priority_queue<pair<int, int>> distpq;\n\n        bool isConnect = false;\n\n        for (int i = 0; i < N; i++) {\n            int deviceNum = tab[i]; // 멀티탭의 i번째 칸에 꽂힌 기기 번호\n            if (deviceNum == 0 || deviceNum == cur) { // 비어 있거나 이미 연결된 경우\n                tab[i] = cur;\n                isConnect = true;\n                wait[cur].pop(); // 현재 기기 사용 시점 제거\n                break;\n            } else { // 다른 기기가 꽂혀 있는 경우\n                int dist = wait[deviceNum].empty() ? 999 : wait[deviceNum].front() - time; // 재사용 거리 계산\n                distpq.push({dist, i}); // (재사용 거리, 멀티탭 위치) 저장\n            }\n        }\n\n        if (isConnect) continue; // 연결 완료된 경우 넘어감\n\n        // 가장 나중에 사용되거나 사용되지 않는 기기를 뽑음\n        pair<int,int> tmp = distpq.top();\n        int tabNum = tmp.second;\n        tab[tabNum] = cur; // 현재 기기로 교체\n        wait[cur].pop();\n        ++ans; // 플러그를 뽑은 횟수 증가\n        ++time;\n    }\n\n    cout << ans; // 결과 출력\n    return 0;\n}\n```\n\n## 시간 복잡도\n\n1. **멀티탭 관리**:\n   - $$ N $$: 멀티탭 구멍의 개수, $$ K $$: 기기 사용 횟수.\n   - 각 기기에서 $$ O(N) $$만큼 탐색하며 우선순위 큐 연산은 $$ O(\\log N) $$.\n\n2. **총 시간 복잡도**:  \n   - $$ O(K \\times N \\log N) $$.  \n   - 최대 $$ N = 100 $$, $$ K = 100 $$이므로 충분히 간으함\n",
    "date": "2025-01-09",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-01-09--BOJ--1700_chunk_0",
        "text": "[BOJ] 1700번 멀티탭 스케줄링\n\n> **문제 링크**: [백준 1700번](https://www.acmicpc.net/problem/1700)  \n{: .prompt-tip }\n\n## 문제 요약\n\n- $$ N $$: 멀티탭 구멍의 개수  \n- $$ K $$: 전기용품의 총 사용 횟수  \n- $$ K $$개의 전기용품 사용 순서가 주어질 때, 플러그를 **최소 횟수로 뽑아야** 한다.  \n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 CPU 스케줄링과 유사한 **멀티탭 관리 문제**입니다.  \n멀티탭이 모두 차 있을 때, **어떤 플러그를 뽑는 것이 가장 최적인가**를 결정해야 합니다.\n\n1. **기본 규칙**:\n   - **빈 멀티탭이 있다면** 해당 기기를 바로 꽂는다.\n   - 멀티탭에 이미 현재 기기가 꽂혀 있다면 아무 작업도 하지 않는다.\n\n2. **멀티탭이 모두 찬 경우**:\n   - **가장 늦게 사용되거나 사용되지 않는 기기**를 뽑는 것이 최적이다.  \n   - 이를 구현하기 위해 각 기기별로 **사용 시점의 큐(wait 배열)**를 만들어 사용한다.\n\n3. **구현 흐름**:\n   - **`wait` 큐 배열**: 각 기기의 사용 시점을 저장하는 큐로, 예를 들어 `wait[4] = {1, 3, 8}`는 4번 기기가 1, 3, 8번째에 사용됨을 나타냄.",
        "index": 0
      },
      {
        "id": "2025-01-09--BOJ--1700_chunk_1",
        "text": "- **`wait` 큐 배열**: 각 기기의 사용 시점을 저장하는 큐로, 예를 들어 `wait[4] = {1, 3, 8}`는 4번 기기가 1, 3, 8번째에 사용됨을 나타냄.",
        "index": 1
      },
      {
        "id": "2025-01-09--BOJ--1700_chunk_2",
        "text": "- **`wait` 큐 배열**: 각 기기의 사용 시점을 저장하는 큐로, 예를 들어 `wait[4] = {1, 3, 8}`는 4번 기기가 1, 3, 8번째에 사용됨을 나타냄.",
        "index": 2
      },
      {
        "id": "2025-01-09--BOJ--1700_chunk_3",
        "text": "- **`wait` 큐 배열**: 각 기기의 사용 시점을 저장하는 큐로, 예를 들어 `wait[4] = {1, 3, 8}`는 4번 기기가 1, 3, 8번째에 사용됨을 나타냄.",
        "index": 3
      },
      {
        "id": "2025-01-09--BOJ--1700_chunk_4",
        "text": "- **`wait` 큐 배열**: 각 기기의 사용 시점을 저장하는 큐로, 예를 들어 `wait[4] = {1, 3, 8}`는 4번 기기가 1, 3, 8번째에 사용됨을 나타냄.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-01-05-------4-2",
    "title": "[임베교과서] 4장 임베디드 시스템을 사용한 C언어 프로그래밍 (2)",
    "path": "/2025/01/05/임베교과서-4장2/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "## Blink 프로그램 이해하기\n\n이전 페이지에서 간단히 **Blink 프로그램**을 작성해 보았습니다.  \n이번에는 그 코드를 **어셈블리 레벨**에서 살펴보면서, **레지스터 제어**가 어떻게 이루어지는지 간단히 확인해 보겠습니다.\n\n---\n\n### CPU의 관점에서 바라본 레지스터 제어\n\n**ATmega328P**(아두이노 우노에 탑재된 MCU)의 경우, **I/O Mapped I/O** 방식을 사용합니다.  \n- C 같은 고급 언어에서는 `DDRB`, `PORTB` 등의 **매크로**만 보면 되지만,  \n- 어셈블리어 관점에서는 **특정 명령어**(예: `ld`, `st`)를 통해 **I/O 공간**에 접근하는 형태로 보이게 됩니다.\n\n---\n\n### 어셈블러에서 확인\n\n직접 **어셈블리**를 확인하기 위해, 이전에 빌드한 **ELF 파일**(예: `blink.elf`)을 `avr-objdump`로 디스어셈블해 보겠습니다.\n\n```bash\navr-objdump -S blink.elf > blink.s\n```\n\n이제 `blink.s` 파일을 열어 보면, `DDRB`나 `PORTB`에 값을 쓰는 부분이 어셈블리 코드로 어떻게 표현되는지 볼 수 있습니다.\n\n> 전체 코드는 아래 레포 ch4 디렉터리에 있습니다.\n> [https://github.com/knowgyu/embedded-textbook](https://github.com/knowgyu/embedded-textbook)\n\n#### 예시 코드 (DDRB 제어 부분)\n\n```plaintext\nDDRB |= (1<<PB1);\n  8a:   84 e2         ldi     r24, 0x24   ; 36\n  8c:   90 e0         ldi     r25, 0x00   ; 0\n  8e:   24 e2         ldi     r18, 0x24   ; 36\n  90:   30 e0         ldi     r19, 0x00   ; 0\n  92:   f9 01         movw    r30, r18\n  94:   20 81         ld      r18, Z\n  96:   22 60         ori     r18, 0x02   ; 2\n  98:   fc 01         movw    r30, r24\n  9a:   20 83         st      Z, r18\n```\n\n위 코드를 보면 r25, r24와 같은 것들이 있는데 이는 CPU 내장 레지스터입니다.  \n\n**r00~r31**: CPU 내부의 범용 레지스터  \n- **r26~r31**: 특히 X, Y, Z **인덱스 레지스터**로 사용 가능 (간접 주소 지정 지원)\n\n![alt text](/assets/img/ebtb/eb49.png)\n\n위 이미지처럼 **r26~r31**은 간접 주소 지정에 특화되어 있으며, 실제로 **Z 레지스터**(r30, r31 쌍)가 **외부 I/O 공간**에 접근할 때 사용됩니다.\n\n\n### 명령어 설명\n\n1. **`ldi` 명령**  \n   `ldi r24, 0x24`처럼, **실제 값(immediate value)**자체를 직접 레지스터(r24)에 적재하는 방식입니다.  \n   아래 예시의 첫 4행에서는 `r24, r25`와 `r18, r19` 각각에 **0x0024** 값을 담아, DDRB를 제어하기 위한 준비를 합니다.\n\n   ```\n   8a:\t84 e2       \tldi\tr24, 0x24\t; 36\n   8c:\t90 e0       \tldi\tr25, 0x00\t; 0\n   8e:\t24 e2       \tldi\tr18, 0x24\t; 36\n   90:\t30 e0       \tldi\tr19, 0x00\t; 0\n   ```\n\n   > 레지스터에 16비트 주소 0x0024를 담아야합니다. 하지만, ATmega328P는 8비트 CPU이며, r00~r31은 각각 8비트 레지스터이기에 r25에 0x00, r24에 0x24를 나눠 담는 방식입니다.\n   {: .prompt-tip }\n\n1. **`movw` 명령**  \n   **16비트(word) 단위**로 레지스터 간 데이터를 복사합니다.  \n   예: `movw r30, r18`라고 쓰면, 실제론 `r30, r31 ← r18, r19`가 되어 **0x0024**가 `r30`과 `r31`(Z 레지스터)에 옮겨집니다.  \n   즉, Z 레지스터가 설정되는 것이죠.\n\n   ```\n   92:\tf9 01       \tmovw\tr30, r18\n   ```\n\n2. **`ld` 명령**  \n   `ld r18, Z`는 **Z 레지스터**에 들어 있는 **간접 주소**를 통해 값을 읽어 `r18`에 저장합니다.  \n   여기서 Z 레지스터에는 0x0024가 있으므로, 결과적으로 **0x0024번지**에 있는 데이터를 r18에 가져오게 됩니다.\n\n   ```\n   94:\t20 81       \tld\tr18, Z\n   ```\n\n3. **`ori` 명령**  \n   r18 레지스터의 내용과 `0x02`를 **OR 연산**합니다.  \n   즉, 0x0024번지에서 읽어 온 값에 0x02를 OR해, PB1 비트를 설정하는 셈입니다.\n\n   ```\n   96:\t22 60       \tori\tr18, 0x02\t; 2\n   ```\n\n4. **`movw` 명령**  \n   앞서와 동일하게, `movw r30, r24` 등을 통해 r24, r25에 있던 주소를 다시 `r30, r31`(Z 레지스터)로 옮깁니다.\n\n   ```\n   98:\tfc 01       \tmovw\tr30, r24\n   ```\n\n5. **`st` 명령**  \n   `st Z, r18`는 **Z 레지스터가 가리키는 번지(0x0024)**에 `r18`의 내용을 기록합니다.  \n   즉, OR 연산 결과를 0x0024번지(DDRB 레지스터)에 최종적으로 써 넣는 과정입니다.\n\n   ```\n   9a:\t20 83       \tst\tZ, r18\n   ```\n\n결국, **DDRB 제어**는 0x0024번지에 있는 **I/O 레지스터**에 값을 쓰는 방식임을 알 수 있고,  \n**PORTB**도 비슷하게 **0x0025** 번지에 기록함으로써 GPIO 출력을 제어합니다.\n\n---\n\n### 요약\n\n내부 범용 레지스터(r24, r25, r18, r19 등)를 활용해 **DDRB, PORTB** 레지스터 주소(0x0024, 0x0025)를 보관해 두고,  \n이 주소를 **Z 레지스터**(r30, r31)에 설정하여 **CPU 외부**(I/O 공간)의 주변장치 레지스터를 간접적으로 제어하게 됩니다.  \n즉,\n\n1. **제어 대상 레지스터**의 번지(0x0024, 0x0025 등)를 CPU 내장 레지스터에 로드  \n2. 그 번지를 **Z 레지스터**에 옮겨 간접 주소를 설정  \n3. **데이터 버스**를 통해 외부 I/O 레지스터에 읽기/쓰기 작업 수행\n\n이 과정을 거쳐 **GPIO 핀**(PB1 등)을 제어해 LED를 켜거나 끄는 동작을 완성하게 됩니다.\n\n\n> 책에서는 간단하게 delay 사용에 대해 다루지만, 일단 넘어가고 추후에 링크를 추가하겠습니다.\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }\n",
    "date": "2025-01-05",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-01-05-------4-2_chunk_0",
        "text": "[임베교과서] 4장 임베디드 시스템을 사용한 C언어 프로그래밍 (2)\n\n## Blink 프로그램 이해하기\n\n이전 페이지에서 간단히 **Blink 프로그램**을 작성해 보았습니다.  \n이번에는 그 코드를 **어셈블리 레벨**에서 살펴보면서, **레지스터 제어**가 어떻게 이루어지는지 간단히 확인해 보겠습니다.\n\n---\n\n### CPU의 관점에서 바라본 레지스터 제어\n\n**ATmega328P**(아두이노 우노에 탑재된 MCU)의 경우, **I/O Mapped I/O** 방식을 사용합니다.",
        "index": 0
      },
      {
        "id": "2025-01-05-------4-2_chunk_1",
        "text": "---\n\n### CPU의 관점에서 바라본 레지스터 제어\n\n**ATmega328P**(아두이노 우노에 탑재된 MCU)의 경우, **I/O Mapped I/O** 방식을 사용합니다.",
        "index": 1
      },
      {
        "id": "2025-01-05-------4-2_chunk_2",
        "text": "---\n\n### CPU의 관점에서 바라본 레지스터 제어\n\n**ATmega328P**(아두이노 우노에 탑재된 MCU)의 경우, **I/O Mapped I/O** 방식을 사용합니다.",
        "index": 2
      },
      {
        "id": "2025-01-05-------4-2_chunk_3",
        "text": "---\n\n### CPU의 관점에서 바라본 레지스터 제어\n\n**ATmega328P**(아두이노 우노에 탑재된 MCU)의 경우, **I/O Mapped I/O** 방식을 사용합니다.",
        "index": 3
      },
      {
        "id": "2025-01-05-------4-2_chunk_4",
        "text": "---\n\n### CPU의 관점에서 바라본 레지스터 제어\n\n**ATmega328P**(아두이노 우노에 탑재된 MCU)의 경우, **I/O Mapped I/O** 방식을 사용합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-01-02-------4",
    "title": "[임베교과서] 4장 임베디드 시스템을 사용한 C언어 프로그래밍 (1)",
    "path": "/2025/01/02/임베교과서-4장/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "## 아두이노의 하드웨어 확인하기\n\n이번 챕터에서는 아두이노 우노 보드를 활용합니다. 하지만, 현재 보드가 없어 QEMU 에뮬레이터를 활용해 진행할 것입니다.  \n\n추후에 보드를 구매하게 된다면 현재 게시글에 내용을 추가 할 예정입니다.  \n\n---\n\n### (참고) QEMU 사용하기\n\nQEMU 에뮬레이터에서는 ATmega128, ATmega328P, ATmega2560 등 AVR 시리즈를 지원합니다.  \n아두이노 우노는 ATmega328p 칩을 사용합니다.  \n\n> ATmega328P 데이터 시트  \n> [https://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-7810-Automotive-Microcontrollers-ATmega328P_Datasheet.pdf](https://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-7810-Automotive-Microcontrollers-ATmega328P_Datasheet.pdf)  \n> [https://ww1.microchip.com/downloads/en/DeviceDoc/ATmega48A-PA-88A-PA-168A-PA-328-P-DS-DS40002061A.pdf](https://ww1.microchip.com/downloads/en/DeviceDoc/ATmega48A-PA-88A-PA-168A-PA-328-P-DS-DS40002061A.pdf)  \n{: .prompt-tip }\n\n우선, QEMU를 설치해야 합니다. 설치하는환경은 Ubuntu 22.04입니다.  \n\n#### 1. QEMU 설치하기\n```\nsudo apt-get install qemu-system-avr -y\n```\n\n설치 후, 지원하는 보드를 확인하려면 아래 명령어로 확인할 수 있습니다.\n\n```\nqemu-system-avr -machine help\n```\n\n실행 결과  \n```\ngyu@gyu:~/qemuTest$ qemu-system-avr -machine help\nSupported machines are:\n2009                 Arduino Duemilanove (ATmega168) (alias of arduino-duemilanove)\narduino-duemilanove  Arduino Duemilanove (ATmega168)\nmega2560             Arduino Mega 2560 (ATmega2560) (alias of arduino-mega-2560-v3)\narduino-mega-2560-v3 Arduino Mega 2560 (ATmega2560)\nmega                 Arduino Mega (ATmega1280) (alias of arduino-mega)\narduino-mega         Arduino Mega (ATmega1280)\nuno                  Arduino UNO (ATmega328P) (alias of arduino-uno)\narduino-uno          Arduino UNO (ATmega328P)\nnone                 empty machine\n```\n\n#### 2. AVR 펌웨어 빌드\n\n간단하게 테스트 코드를 작성하고, 빌드해 정상 동작하는 지 확인하겠습니다.  \n```\n# 만약, 이전 페이지에서 AVR GCC를 설치하지 않았다면 아래 명령어 실행\nsudo apt-get install avr-gcc avr-libc\n\n# 예제 코드 컴파일(main.c는 아래에 있습니다)\navr-gcc -mmcu=atmega328p -Os -o main.elf main.c\n```\n\n예제 프로그램 소스 코드 **main.c**\n```c\n#define F_CPU 16000000UL // 16MHz delay함수에서 사용하기 위함\n#include <avr/io.h>\n#include <util/delay.h>\n\n#define LED_PIN PB0 // ATmega328P의 핀 8번 (Arduino의 디지털 13번)\n\nint main(void) {\n    DDRB |= (1 << LED_PIN);\n\n    while (1) {\n        PORTB |= (1 << LED_PIN);\n        _delay_ms(500);\n\n        PORTB &= ~(1 << LED_PIN);\n        _delay_ms(500);\n    }\n}\n```\n\n#### 3. QEMU 실행하기\n```\nqemu-system-avr -M uno -bios main.elf\n```\n\n![alt text](/assets/img/ebtb/eb40.png)\n\n에러 없이 실행되는 것은 확인했지만, 지금 상태로는 제대로 동작하고 있는 지 확인할 수가 없습니다.  \n\n모니터링하거나 디버깅할 방법이 필요합니다.  \n\n#### 4. QEMU 디버깅\n제대로 동작하는 것을 확인하기 위해, UART 출력을 이용하거나 GDB 디버거를 통해 디버깅할 수 있습니다.  \n\n> GDB 디버거를 이용해 확인해보았으나, 에뮬레이터가 GPIO 입출력을 제대로 제공되지 않는 것 같습니다.  \n> GPIO 핀 변경 후 `x/tb 0x25` 와 같은 식으로 메모리 확인 시 제대로 동작 테스트가 되지 않았습니다.  \n{: .prompt-warning }\n\nUART 출력을 이용해 제대로 컴파일 후 빌드가 되는지 확인해보겠습니다.  \n\n이를 위해, 새로운 **main2.c** 소스 코드를 작성하고, 테스트 하겠습니다.\n\n**main2.c**\n```c\n#include <avr/io.h>\n\nvoid uart_init(void) {\n    UBRR0H = 0;\n    UBRR0L = 103; // 9600 baud for 16MHz\n    UCSR0B = (1 << TXEN0); // Enable transmitter\n}\n\nvoid uart_transmit(char data) {\n    while (!(UCSR0A & (1 << UDRE0))); // Wait for empty transmit buffer\n    UDR0 = data; // Send data\n}\n\nint main(void) {\n    uart_init();\n    while (1) {\n        uart_transmit('A');\n    }\n    return 0;\n}\n\n```\n\n이전과 동일하게 빌드합니다.  \n```\navr-gcc -mmcu=atmega328p -Os -o main2.elf main2.c\n```\n\n이후, QEMU를 실행해야 하는데, UART 출력 확인을 위해 `-serial mon:stdio` 옵션을 사용합니다.  \n\n> `-serial mon:stdio` 를 추가해야 UART 출력을 QEMU의 표준 출력으로 연결할 수 있습니다.  \n\n```\nqemu-system-avr -M arduino-uno -bios main2.elf -serial mon:stdio\n```\n\n실행 화면  \n\n![alt text](/assets/img/ebtb/eb41.png)\n\n---\n\n### 아두이노란?\n\n아두이노는 이탈리아에서 개발된 임베디드 시스템으로, **MCU를 탑재한 보드**와 **소프트웨어 환경**을 포함해 \"아두이노\"라고 부릅니다.  \n이 책에서는 **아두이노 우노**를 예시로 하여 임베디드 프로그래밍 과정을 설명하려고 합니다.\n\n> 주로 **PC 상의 IDE**를 통해 GUI로 아두이노를 프로그래밍합니다.  \n> 그러나 **임베디드 개발의 핵심 포인트**를 파악하기 위해, 여기서는 GUI를 사용하지 않습니다.  \n{: .prompt-info }\n\n---\n\n### 아두이노 우노의 하드웨어 구성\n\n![alt text](/assets/img/ebtb/eb48.png)\n\n1. **커넥터**  \n   MCU 제어 신호를 외부로 출력하거나 입력을 받기 위한 **접속 단자**입니다.  \n   GPIO나 PWM 등의 제어 신호가 제공되며, 외부 기기에 **전원(5V/3.3V 등)을 공급**할 수 있는 **전원 단자**도 포함됩니다.\n\n2. **각종 LED**  \n   프로그램 동작 확인용 **LED**나 **USB 통신** 확인용 LED 등이 탑재되어 있습니다.  \n   이를 통해 동작 상태를 **시각적으로** 파악할 수 있습니다.\n\n3. **리셋 스위치**  \n   MCU를 **리셋**하기 위한 스위치입니다.  \n   누르면 CPU가 재시작되어 **처음부터 동작**을 시작합니다.\n\n4. **전원 커넥터**  \n   **직류 전원**(DC)을 공급하기 위한 커넥터입니다.  \n   USB 전원 대신 별도의 어댑터를 연결할 때 사용합니다.\n\n5. **레귤레이터**  \n   전원 커넥터로 입력된 전압을 **5V**(또는 일부 보드는 3.3V)로 변환해 주는 **전압 변환기**입니다.\n\n6. **마이크로컴퓨터(MCU)**  \n   **CPU, 메모리, 주변장치**가 한 칩에 통합된 하드웨어입니다.  \n   아두이노 우노의 경우 **ATmega328P**가 대표적 예시로,  \n   크로스 개발환경을 갖춘 뒤 **MCU에 소프트웨어**를 탑재해 동작시킬 수 있습니다.\n\n---\n\n### 마이크로컴퓨터의 데이터 시트 조사하기\n\n임베디드 소프트웨어를 제대로 작성하려면, **MCU 내부의 레지스터**나 **핀(Pin) 구성**을 알아야 합니다.  \n이를 위해 **데이터 시트(Data Sheet)**를 확인하는 것은 매우 중요합니다.\n\n> 제 개인적인 생각에 데이터 시트는 처음부터 끝까지 다 읽는 용도가 아닌, 필요한 부분을 잘 골라 찾아내는 능력이 중요하다고 생각합니다.  \n\n아래는 크롬 브라우저에서 데이터 시트 pdf를 열어놓은 화면인데, 좌측에서 목차를 보고 해당 위치로 점프할 수 있습니다.  \n\n우선, 기본적으로 제대로 된 데이터시트가 맞는지 핀 설정과 대조하여 확인해봅니다.  \n![alt text](/assets/img/ebtb/eb42.png)\n\n그리고, 데이터 시트의 **2. Overview** 섹션에는 MCU 내부를 나타내는 **블록 다이어그램**이 제공됩니다.  \n\n![alt text](/assets/img/ebtb/eb43.png)\n\n이를 통해 **CPU, 메모리, 버스**와 **주변장치**들이 어떻게 연결되어 있는지 전체적인 구성을 알 수 있습니다.\n\n---\n\n## LED ON/OFF 작성하기\n\n이번 예시는 실제 보드 없이, 코드로 **LED를 점멸(Blink)** 시키는 과정을 살펴보려 합니다.\n\n- **하드웨어 연결**  \n  - LED의 **+극**을 아두이노 커넥터 **9번 핀**에,  \n  - **-극**을 **GND**에 연결한다고 가정  \n  - 커넥터 9번 핀에 **HIGH(1)** 신호를 보내면 LED가 켜지고, **LOW(0)**면 꺼집니다.\n\n아두이노 우노에서는 커넥터 9번 핀이 **ATmega328P** 마이크로컨트롤러의 **15번 핀**(PB1)과 연결되어 있습니다.\n\n```c\n#include <avr/io.h>\n\nint main()\n{\n    int i;\n    DDRB |= (1 << PB1);\n\n    while(1)\n    {\n        PORTB ^= (1 << PB1);\n\n        // 간단한 딜레이\n        for(i = 0; i < 1000000; i++) {}\n    }\n    return 0;\n}\n```\nDDRB, PORTB, PB1 모두 **<avr/io.h>**에 정의된 레지스터 및 핀 매크로입니다.  \n데이터 시트 14. I/O-Ports 섹션을 보면, CPU와 I/O 포트가 어떻게 연결되고 설정되는지 확인할 수 있습니다.\n\n![alt text](/assets/img/ebtb/eb44.png)\n\n위 이미지를 보면 CPU와의 접속은 데이터 버스를 통해 연결되어 있으며, 결과적으로는 Pxn에 신호 출력을 위해서는 DDxn, PORTxn에 쓰기 설정을 해야한다는 것을 알 수 있습니다.  \n\n> 데이터 버스로부터 화살표 방향 참고\n\n그리고, 데이터 시트에 추가적인 설명으로\n![alt text](/assets/img/ebtb/eb45.png)\n\n즉, DDxn은 해당 핀을 입력(0) 또는 **출력(1)**으로 설정, PORTxn 출력 핀이 High(1) 인지 Low(0) 인지 결정한다고 합니다.  \n\n이 데이터시트에서는 친절하게도 이를 표로 정리해 나타내고 있습니다.  \n![alt text](/assets/img/ebtb/eb46.png)\n\n#### 정리\n\n현재 **LED를 켜고 끄는 동작**을 하고 싶은 상황입니다.  \n아두이노의 외부 커넥터 ~9번에 LED를 연결했고, 이 핀에 HIGH 혹은 LOW 신호를 출력해야 합니다.  \n\n이 외부 커넥터 ~9번 핀에 신호를 출력하기 위해, CPU와 어디에 연결되어 있는지(**PB1**)에 확인했습니다.  \n\n그리고, 이 PB1에 HIGH 혹은 LOW를 출력하기 위해서 어떤 설정을 해야하는 지 확인했습니다.  \n(**DDRB1**과 **PORTB1**에 설정을 해줘야 한다.)  \n\n그럼, 이제 DDRB와 PORTB에 대해 알아보기위해 데이터 시트의 스크롤을 조금 더 내리면 \n![alt text](/assets/img/ebtb/eb47.png)\n\n즉, PORTB와 DDRB는 포트 B와 관련된 레지스터들이며, 이전 페이지에서 확인했듯이\nPB1을 Ouput High로 쓰기 위해선 DDRB1과 PORTB1을 1로 설정해야한다는 것을 알 수 있습니다.  \n\n그렇기에 위 코드에서 `DDRB |= (1<<PB1)`과 `PORTB ^= (1<<PB1)`로 각 레지스터를 설정했던 것입니다.  \n> PB1은 `<avr/io.h>`에서 단순히 1로 정의되어 있습니다.(직관적으로 핀 구성을 파악하기 위함)  \n> 그리고, 위 코드는 LED를 Toggle하는 방식으로 동작하고 있습니다.  \n{: .prompt-tip }\n\n---\n\n## 동작 확인\n\n그럼 이제 동작 확인을 해보겠습니다.  \n\n우선, 빌드 후 elf 형식 파일을 만듭니다.\n```\navr-gcc -g -mmcu=atmega328p blink.c -o blink.elf\n```\n\n아두이노 우노에 업로드하기 위해서는 HEX 파일로 변환합니다.\n```\navr-objcopy -I elf32-avr -O ihex blink.elf blink.hex\n```\n\n이제 준비된 blink.hex를 우노 보드에 전송합니다.\n(일반적으로 Arduino IDE나 avrdude 등을 사용하여 USB로 업로드합니다.)\n\n실제 보드에 전송하면, 커넥터 9번 핀의 신호가 High/Low로 반복되어 LED가 깜빡이는 것을 확인할 수 있습니다.\n{: .prompt-info }\n\n> 코드는 아래 깃허브 레포에서 확인할 수 있습니다.  \n> [https://github.com/knowgyu/embedded-textbook](https://github.com/knowgyu/embedded-textbook)\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }\n",
    "date": "2025-01-02",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-01-02-------4_chunk_0",
        "text": "[임베교과서] 4장 임베디드 시스템을 사용한 C언어 프로그래밍 (1)\n\n## 아두이노의 하드웨어 확인하기\n\n이번 챕터에서는 아두이노 우노 보드를 활용합니다. 하지만, 현재 보드가 없어 QEMU 에뮬레이터를 활용해 진행할 것입니다.  \n\n추후에 보드를 구매하게 된다면 현재 게시글에 내용을 추가 할 예정입니다.  \n\n---\n\n### (참고) QEMU 사용하기\n\nQEMU 에뮬레이터에서는 ATmega128, ATmega328P, ATmega2560 등 AVR 시리즈를 지원합니다.  \n아두이노 우노는 ATmega328p 칩을 사용합니다.",
        "index": 0
      },
      {
        "id": "2025-01-02-------4_chunk_1",
        "text": "QEMU 에뮬레이터에서는 ATmega128, ATmega328P, ATmega2560 등 AVR 시리즈를 지원합니다.  \n아두이노 우노는 ATmega328p 칩을 사용합니다.  \n\n> ATmega328P 데이터 시트  \n> [https://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-7810-Automotive-Microcontrollers-ATmega328P_Datasheet.pdf](https://ww1.microchip.com/downloads/en/DeviceDoc/Atmel-7810-Automotive-Microcontrollers-ATmega328P_Datasheet.pdf)  \n> [https://ww1.microchip.com/downloads/en/DeviceDoc/ATmega48A-PA-88A-PA-168A-PA-328-P-DS-DS40002061A.pdf](https://ww1.microchip.com/downloads/en/DeviceDoc/ATmega48A-PA-88A-PA-168A-PA-328-P-DS-DS40002061A.pdf)  \n{: .prompt-tip }\n\n우선, QEMU를 설치해야 합니다. 설치하는환경은 Ubuntu 22.04입니다.  \n\n#### 1.",
        "index": 1
      },
      {
        "id": "2025-01-02-------4_chunk_2",
        "text": "8-P-DS-DS40002061A.pdf)  \n{: .prompt-tip }\n\n우선, QEMU를 설치해야 합니다. 설치하는환경은 Ubuntu 22.04입니다.  \n\n#### 1.",
        "index": 2
      },
      {
        "id": "2025-01-02-------4_chunk_3",
        "text": "8-P-DS-DS40002061A.pdf)  \n{: .prompt-tip }\n\n우선, QEMU를 설치해야 합니다. 설치하는환경은 Ubuntu 22.04입니다.  \n\n#### 1.",
        "index": 3
      },
      {
        "id": "2025-01-02-------4_chunk_4",
        "text": "8-P-DS-DS40002061A.pdf)  \n{: .prompt-tip }\n\n우선, QEMU를 설치해야 합니다. 설치하는환경은 Ubuntu 22.04입니다.  \n\n#### 1.",
        "index": 4
      }
    ]
  },
  {
    "id": "2025-01-01-------3-2",
    "title": "[임베교과서] 3장 임베디드 소프트웨어 (2)",
    "path": "/2025/01/01/임베교과서-3장2/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "## 어셈블리 언어로부터 알 수 있는 것\n\n이 전 페이지에서 **빌드 흐름**을 알아보았습니다. 이제는 **중간 과정**에서 생성된 **어셈블리어**를 살펴보겠습니다.\n\n앞서 사용했던 “Hello World” 프로그램을 조금 변경해 예시로 들어 보겠습니다.\n\n**main2.c**\n```c\n#include <stdio.h>\n\nchar str[]=\"Hello World\";\nint data;\n\nint func(int x,int y){\n    return x+y;\n}\n\nint main(){\n    data = func(2018,2019);\n    printf(\"%s:%x\\n\", str, data);\n    return 0;\n}\n```\n\n위 코드를 빌드할 때는 최적화 옵션을 없애기 위해 `-Os` 대신 `-O0`를 사용합니다.\n\n```bash\navr-gcc -O0 -Wall -mmcu=atmega328p main2.c -o main2.elf\n```\n\n생성된 ELF 파일은 바이너리 파일 형태이므로, **`avr-objdump`** 명령어를 이용해 텍스트 형태로 확인해 봅시다.\n\n```bash\navr-objdump -S main2.elf > main2.s\n```\n\n**main2.s** 파일에는 실제 어셈블리 코드가 담겨 있습니다.  \n![alt text](/assets/img/ebtb/eb33.png)\n\n---\n\n### 스타트업 루틴\n\n`main2.s`를 살펴보면 `000000d4 <main>:` 부분이 있습니다.  \n이는 **main 함수의 어셈블리 변환 코드**이며, `000000d4`는 **16진수 주소**를 의미합니다.\n\n그런데 **main 함수 이전**에도 여러 설정 코드가 있는데, 이를 **스타트업 루틴(start-up routine)**이라고 부릅니다.  \n- 하드웨어 초기 설정  \n- 프로그램 동작을 위한 **메모리 초기화**(전역변수, 스택 영역 등)  \n- 기타 **소프트웨어 환경** 구성\n\n이 과정을 마친 뒤 **main 함수**가 호출되어 C 코드가 동작하기 시작합니다.\n\n---\n\n### main 함수가 호출될 때까지 흐름 추적\n\n1. **전원 ON & 리셋 신호**  \n   - 임베디드 기기에 **전원이 켜지면**, CPU가 **리셋 신호**를 받아 **0번지**부터 명령을 실행합니다.\n\n2. **인터럽트 벡터 설정, 스택 초기화**  \n   - **인터럽트 벡터 테이블** 작성, **스택 영역** 설정, **데이터 영역** 초기화 등이 순차적으로 이루어집니다.\n\n3. **main 함수 진입**  \n   - 초기화가 끝나면 **main 함수** 주소로 점프해, 우리가 작성한 C 코드가 본격 실행됩니다.\n\n> **Tip**: 이런 부트 과정(Reset → 초기화 → main)은 아키텍처와 루틴 구현 방식에 따라 조금씩 달라집니다.  \n> 아래 깃허브 레포에 전체 코드를 확인할 수 있습니다.  \n> [링크](https://github.com/knowgyu/embedded-textbook)\n{: .prompt-tip }\n\n---\n\n### 메모리 맵\n\n프로그램이 어느 영역(ROM or RAM)에 배치되는지 나타낸 것을 **메모리 맵**이라 부릅니다.  \n이는 보통 **CPU 및 시스템 설계**에 의해 정해지며, 소프트웨어에서 임의로 바꿀 수 없는 경우가 많습니다.\n\n- **코드 영역**: 보통 **ROM**(플래시)에 위치, 여기엔 `.text` 세션(C 함수, 명령어)이 들어감  \n- **데이터 영역**: 보통 **RAM**에 위치, 전역변수(.data), 초기화되지 않은 전역변수(.bss) 등이 포함\n\n예를 들어, 아래 명령어로 ELF 헤더 정보를 확인할 수 있습니다.\n\n```bash\navr-objdump -x -h main2.elf\n```\n\n```\nmain2.elf:     file format elf32-avr\narchitecture: avr:5, flags 0x00000112:\nEXEC_P, HAS_SYMS, D_PAGED\nstart address 0x00000000\n\nProgram Header:\n    LOAD off    0x00000094 vaddr 0x00000000 paddr 0x00000000 align 2**1\n    ...\n\nSections:\nIdx Name       Size      VMA       LMA       File off  Algn\n 0  .data      00000014  00800100  000006f4  00000788  2**0\n               CONTENTS, ALLOC, LOAD, DATA\n 1  .text      000006f4  00000000  00000000  00000094  2**1\n               CONTENTS, ALLOC, LOAD, READONLY, CODE\n 2  .bss       00000008  00800114  00800114  0000079c  2**0\n               ALLOC\n 3  .comment   00000011  00000000  00000000  0000079c  2**0\n               CONTENTS, READONLY\n...\n```\n\n- `.text` → **프로그램 코드**(ROM)  \n- `.data` → 초기값이 있는 전역변수(RAM에 복사)  \n- `.bss` → 초기값이 없는 전역변수(RAM)  \n\n---\n\n## 임베디드 소프트웨어의 테스트 환경\n\n빌드를 마친 뒤에는, 실제 임베디드 하드웨어에 **ROM**을 기록하고 동작을 확인합니다.  \n하드웨어가 정상적으로 구동되는지 테스트해야 하며, 이를 위해 **특수 장비**가 쓰이기도 합니다.\n\n---\n\n### ICE (In-Circuit Emulator)\n\n- **ICE**는 임베디드 시스템에 탑재된 CPU를 대신해 **동작**시켜 볼 수 있는 장비입니다.  \n- 예: **JTAG ICE**, **Full ICE** 등  \n- 또한, PC와 연결해 **JTAG 인터페이스**를 통해 디버깅하거나, **시리얼 포트**나 **오실로스코프**로 회로 파형을 관찰하기도 합니다.\n\n> 이 부분에 대한 구체적인 사용 예시는 추후 별도 글에서 다룰 예정입니다.  \n{: .prompt-info }\n\n---\n\n## 임베디드 시스템 프로그래밍에서의 C언어\n\n임베디드 시스템은 **메모리나 처리 시간 제약**이 있을 가능성이 높아, **최적화**가 중요합니다.  \n여기서, 컴파일러 설정에 주의해야 합니다.  \n\n---\n\n### 최적화 옵션의 장점과 단점\n\n- **장점**: 제한된 메모리나 프로세싱 시간을 절약할 수 있어, 시스템 요구사항을 충족시키기 쉬워짐.  \n- **단점**: 최적화 과정에서 **컴파일러가 코드를 재배치**하거나 **불필요하다고 판단**한 부분을 제거해, **의도치 않은 동작**이 일어날 수 있음.\n\n---\n\n### volatile 선언\n\n주변장치 레지스터나 **하드웨어 상태**가 수시로 변경되는 값을 다룰 때는 **volatile**을 사용해야 합니다.  \n- 예: `while (flag == 0);` 형태로 하드웨어에서 바뀌는 **flag**를 체크할 경우,  \n- 컴파일러가 **“flag는 안 바뀐다”**고 판단해 캐싱해버릴 수 있음.  \n- **volatile**로 선언하면 “**이 변수는 언제든 바뀔 수 있음**”임을 컴파일러에 알려, 올바른 값으로 매번 읽게 해줍니다.\n\n> 위와 같이 주기적으로 상태를 점검하는 방식을 \"폴링(Polling)\"이라 합니다.  \n\n---\n\n### unsigned와 signed\n\n하드웨어 레지스터를 읽고 쓰는 경우, **부호 없는 정수(unsigned)**로 처리하는 것이 일반적입니다.  \n- 임베디드 시스템에서 레지스터의 상위 비트가 어떤 상태 플래그인지 모호해질 수 있으므로,  \n- **음수**로 해석되지 않도록 **unsigned**를 적절히 사용해야 합니다.\n\n---\n\n### pragma\n\n**pragma**는 컴파일러에게 특정 설정(메모리 배치 등)을 지시하는 기능입니다.  \n- 예를 들어, 특정 구조체를 **패킹(packing)** 처리하거나,  \n- 특정 코드/데이터를 **독자적인 메모리 섹션**에 배치하는 것도 가능합니다.  \n- 단, **컴파일러에 의존**하므로, 호환성에 주의해야 합니다.\n\n---\n\n### 포인터와 배열\n\n임베디드 CPU는 일반 PC보다 **처리 성능이나 메모리 용량이 작을** 가능성이 큽니다.  \n- 따라서 **포인터 연산**, **배열 접근** 등도 효율적으로 써야 하고,  \n- **컴파일러 최적화**와 함께 **코드 레벨 최적화**(메모리 접근 방식, 자료구조 선택 등)를 고민해야 합니다.\n\n---\n\n### 인터럽트 핸들러\n\n**인터럽트 핸들러**는 인터럽트 처리에 등록하기 위해 작성된 프로그램입니다.  \n- 일반 동작보다 **높은 우선순위**를 갖기 때문에, **처리 시간을 짧게** 유지하는 것이 좋습니다.  \n- 인터럽트가 끝나야 원래 작업(main 루프 등)이 재개되므로, 길고 복잡한 인터럽트 루틴은 시스템 응답성을 떨어뜨릴 수 있습니다.\n\nAVR 환경에서는 `<avr/interrupt.h>`에 정의된 **ISR** 매크로를 사용해, 특정 인터럽트 벡터에 함수를 등록합니다.\n\n```c\n#include <avr/io.h>\n#include <avr/interrupt.h>\n\nISR(TIMER0_OVF_vect) {\n    // 8비트 타이머0 오버플로 인터럽트 루틴\n    // 필요한 최소한의 작업만 빠르게 처리\n}\n```\n\n위처럼 **타이머0 오버플로** 인터럽트가 발생하면, CPU가 해당 ISR로 즉시 점프해 코드를 실행합니다.\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }\n",
    "date": "2025-01-01",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2025-01-01-------3-2_chunk_0",
        "text": "[임베교과서] 3장 임베디드 소프트웨어 (2)\n\n## 어셈블리 언어로부터 알 수 있는 것\n\n이 전 페이지에서 **빌드 흐름**을 알아보았습니다. 이제는 **중간 과정**에서 생성된 **어셈블리어**를 살펴보겠습니다.\n\n앞서 사용했던 “Hello World” 프로그램을 조금 변경해 예시로 들어 보겠습니다.\n\n**main2.c**\n```c\n#include <stdio.h>\n\nchar str[]=\"Hello World\";\nint data;\n\nint func(int x,int y){\n    return x+y;\n}\n\nint main(){\n    data = func(2018,2019);\n    printf(\"%s:%x\\n\", str, data);\n    return 0;\n}\n```\n\n위 코드를 빌드할 때는 최적화 옵션을 없애기 위해 `-Os` 대신 `-O0`를 사용합니다.\n\n```bash\navr-gcc -O0 -Wall -mmcu=atmega328p main2.c -o main2.elf\n```\n\n생성된 ELF 파일은 바이너리 파일 형태이므로, **`avr-objdump`** 명령어를 이용해 텍스트 형태로 확인해 봅시다.\n\n```bash\navr-objdump -S main2.elf > main2.s\n```\n\n**main2.s** 파일에는 실제 어셈블리 코드가 담겨 있습니다.  \n![alt text](/assets/img/ebtb/eb33.png)\n\n---\n\n### 스타트업 루틴\n\n`main2.s`를 살펴보면 `000000d4 <main>:` 부분이 있습니다.",
        "index": 0
      },
      {
        "id": "2025-01-01-------3-2_chunk_1",
        "text": "lt text](/assets/img/ebtb/eb33.png)\n\n---\n\n### 스타트업 루틴\n\n`main2.s`를 살펴보면 `000000d4 <main>:` 부분이 있습니다.  \n이는 **main 함수의 어셈블리 변환 코드**이며, `000000d4`는 **16진수 주소**를 의미합니다.\n\n그런데 **main 함수 이전**에도 여러 설정 코드가 있는데, 이를 **스타트업 루틴(start-up routine)**이라고 부릅니다.  \n- 하드웨어 초기 설정  \n- 프로그램 동작을 위한 **메모리 초기화**(전역변수, 스택 영역 등)  \n- 기타 **소프트웨어 환경** 구성\n\n이 과정을 마친 뒤 **main 함수**가 호출되어 C 코드가 동작하기 시작합니다.\n\n---\n\n### main 함수가 호출될 때까지 흐름 추적\n\n1. **전원 ON & 리셋 신호**  \n   - 임베디드 기기에 **전원이 켜지면**, CPU가 **리셋 신호**를 받아 **0번지**부터 명령을 실행합니다.\n\n2. **인터럽트 벡터 설정, 스택 초기화**  \n   - **인터럽트 벡터 테이블** 작성, **스택 영역** 설정, **데이터 영역** 초기화 등이 순차적으로 이루어집니다.\n\n3. **main 함수 진입**  \n   - 초기화가 끝나면 **main 함수** 주소로 점프해, 우리가 작성한 C 코드가 본격 실행됩니다.\n\n> **Tip**: 이런 부트 과정(Reset → 초기화 → main)은 아키텍처와 루틴 구현 방식에 따라 조금씩 달라집니다.  \n> 아래 깃허브 레포에 전체 코드를 확인할 수 있습니다.",
        "index": 1
      },
      {
        "id": "2025-01-01-------3-2_chunk_2",
        "text": "ip**: 이런 부트 과정(Reset → 초기화 → main)은 아키텍처와 루틴 구현 방식에 따라 조금씩 달라집니다.  \n> 아래 깃허브 레포에 전체 코드를 확인할 수 있습니다.  \n> [링크](https://github.com/knowgyu/embedded-textbook)\n{: .prompt-tip }\n\n---\n\n### 메모리 맵\n\n프로그램이 어느 영역(ROM or RAM)에 배치되는지 나타낸 것을 **메모리 맵**이라 부릅니다.",
        "index": 2
      },
      {
        "id": "2025-01-01-------3-2_chunk_3",
        "text": "textbook)\n{: .prompt-tip }\n\n---\n\n### 메모리 맵\n\n프로그램이 어느 영역(ROM or RAM)에 배치되는지 나타낸 것을 **메모리 맵**이라 부릅니다.",
        "index": 3
      },
      {
        "id": "2025-01-01-------3-2_chunk_4",
        "text": "textbook)\n{: .prompt-tip }\n\n---\n\n### 메모리 맵\n\n프로그램이 어느 영역(ROM or RAM)에 배치되는지 나타낸 것을 **메모리 맵**이라 부릅니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-31-------3",
    "title": "[임베교과서] 3장 임베디드 소프트웨어 (1)",
    "path": "/2024/12/31/임베교과서-3장/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "## 임베디드 시스템의 소프트웨어\n\n임베디드 소프트웨어는 **운영체제(OS)** 유무에 따라 크게 두 경우로 나눌 수 있습니다.  \n- **OS 없이 동작**: 아두이노 우노처럼 **단순한 기능**이 주 목적이고, 하드웨어가 비교적 **저사양**인 경우 직접 구현 가능  \n- **OS 위에서 동작**: 라즈베리 파이처럼 **리눅스** 등 범용 OS를 탑재해 **복잡한 기능**을 처리할 수 있습니다.  \n  - 이 경우 CPU 스케줄링, 메모리 관리 같은 기능을 OS가 담당하므로 편의성이 올라가지만, 그만큼 일정 수준 이상의 하드웨어 자원이 필요해집니다.  \n\nOS가 있는 임베디드 소프트웨어에서는 **미들웨어(middleware)**가 추가로 제공될 수 있습니다.  \n- 미들웨어는 **네트워크 스택**, **파일 시스템**처럼 애플리케이션에서 자주 쓰이는 기능을 모아 둔 **중간 계층**입니다.  \n  -> 덕분에 **애플리케이션** 개발 시, 이미 준비된 **API**를 활용해 **개발 효율**을 높일 수 있습니다.\n\n> 물론, OS 없이 개발하더라도 전부 바닥부터 짜는 건 아니고, **개발 환경**에서 기본 라이브러리를 제공하여 최소한의 기능을 지원하기도 합니다.\n{: .prompt-tip }\n\n---\n\n## 임베디드 소프트웨어를 개발하는 흐름\n\n보통 임베디드 소프트웨어는 **PC에서 고급 언어(C/C++ 등)로 작성**한 뒤,  \n이를 **임베디드 환경**에서 동작할 수 있도록 변환(크로스 컴파일)해 **내장**합니다.\n\n### 크로스 개발환경\n\nPC에서 에디터로 코드 작성까지는 일반 PC용 프로그램 개발과 똑같습니다.  \n하지만, **소스 코드**를 만든 이후에 **임베디드 시스템**이 이해할 수 있는 실행 형식으로 **변환**해야 합니다.  \n- 예를 들어, PC(리눅스)라면 `gcc` 명령어로 빌드 후 바로 실행 가능하지만,  \n- 임베디드용 CPU나 OS가 다르면, **명령어 셋**이나 **라이브러리 구조**가 달라 **그대로는 실행 불가**합니다.\n\n이를 위해 **임베디드 시스템용 툴체인**(컴파일러, 링커, 라이브러리 등)을 설치하고,  \n**크로스 컴파일**을 수행하는 개발 환경을 **크로스 개발환경**이라 부릅니다.\n\n#### (참고) 어떤 점이 다른가?\n이 개발환경이 다른 점에 대해 고민했던 부분이 있어 추가 설명합니다.  \n\n- **CPU 차이**: x86(CISC) vs. ARM(RISC)  \n  \n  우선, CPU 아키텍처가 다를 경우 명령어 셋이 다르기에 당연히 실행될 수 없습니다.  \n  또한, 32비트 OS와 64비트 OS는 메모리 주소 체계가 다르고 레지스터 사용 규칙 등의 차이가 있어 실행되지 않는 것이 당연하다고 느껴집니다.  \n\n- **OS/LIBC 차이**: PC용 리눅스 vs. 임베디드 RTOS (또는 Bare Metal)  \n  \n  PC용 리눅스와 RTOS는 서로 시스템 콜이 다릅니다.  \n  그렇기에, `malloc`같은 함수도 인터페이스가 동일하지 않을 수 있기에 실행되지 않습니다.  \n\n- **라이브러리 버전**: 임베디드 glibc 버전이 다르면 호환성 문제 발생\n  \n  이 부분이 헷갈렸는데, 만약 PC도 32비트 리눅스, 임베디드 시스템도 32비트 리눅스면 가능하지 않을까? 라고 생각했습니다.  \n  하지만, 임베디드 리눅스의 경우 조금 더 경량화된 `glibc` 라이브러리를 사용하는 등 라이브러리가 다르기에 호환되지 않는 상황이 발생할 수 있다고 합니다.\n\n즉, 대부분의 환경에서는 크로스 컴파일이 필수적이라고 생각할 수 있겠습니다.\n\n> **정말로 CPU·OS·라이브러리까지 전부 동일**하다면, 크로스 컴파일 없이 **네이티브 빌드**도 가능합니다.  \n> 라즈베리파이에서 `gcc`를 설치하고 PC역시 ARMv7에 동일한 운영체제를 사용하는  \n> 정말 완전 동일한 환경이라면 크로스 컴파일이 필요 없습니다.  \n{: .prompt-tip }\n\n\n### 빌드 작업\n\n빌드는 소스 코드를 **임베디드 시스템의 CPU가 이해할 수 있는 형태**로 만드는 일련의 과정입니다.  \n- **컴파일** → **어셈블** → **링크** → **HEX(ROM) 파일 생성**\n- 일반적으로 “컴파일”은 고급 언어를 기계어로 바꾸는 단계만 가리키고,  \n  “빌드”는 **최종 실행 파일**(또는 펌웨어 이미지)까지 생성하는 전체 과정을 의미합니다.\n\n#### 빌드 과정\n\n아래는 각 단계별 입출력을 간단히 나타낸 흐름도 예시입니다.\n\n```mermaid\nflowchart TD\n    A(\"소스 코드\") --> B[컴파일러]\n    B -- \"어셈블러파일\" --> C[어셈블러]\n    C -- \"OBJ파일\" --> D[링커]\n    D -- \"실행파일\" --> E[바이너리 도구]\n    E -- \"HEX파일\" --> F(\"완료\")\n\n```\n\n> - **컴파일**: C/C++ → 어셈블리 코드  \n> - **어셈블**: 어셈블리 코드 → OBJ 오브젝트 파일  \n> - **링크**: OBJ와 라이브러리를 합쳐 최종 실행 파일(ELF 등) 생성  \n> - **바이너리 변환**: ELF 등을 **HEX**나 **BIN** 형식으로 변환 (실제 ROM에 기록)\n\n---\n\n### 실제 빌드의 흐름 확인하기\n\n예를 들어, 아두이노용 임베디드 소프트웨어를 만들 때는 `avr-gcc` 툴체인을 사용합니다.  \n아래는 “Hello World!”를 예로 들어 간단히 살펴보겠습니다.\n\n```c\n#include <stdio.h>\n\nint main(){\n    printf(\"Hello World!\\n\");\n    return 0;\n}\n```\n\n#### (참고) 실습 전 환경 확인\n실습하는 환경은 Ubuntu 22.04 x86-64입니다.\n- `avr-gcc`를 설치\n  ```bash\n  sudo apt install gcc-avr\n  ```\n\n> 이후 빌드하더라도 `stdio.h` 표준 라이브러리를 제공하지 않기에 빌드되지 않습니다.  \n> 따라서, `avr/io.h` 를 사용해 `printf`가 아닌 다른 방식으로 작성해야합니다.\n> 하지만, 여기서는 툴체인을 추가 설치해 사용할 것입니다.  \n{: .prompt-warning }\n![img](/assets/img/ebtb/eb30.png)\n\n- 표준 C 라이브러리(`stdio.h` 등)를 아두이노 MCU에서 쓰려면, `avr-libc`도 추가 설치가 필요합니다.\n  ```bash\n  sudo apt install avr-libc\n  ```\n\n![img](/assets/img/ebtb/eb31.png)\n\n#### 컴파일 & 링크 & ELF 생성\n\n- 아래 명령어는 전처리·컴파일·어셈블·링크 과정을 거쳐 **ELF 형식**의 실행 파일(`test.elf`)을 만듭니다.\n  ```bash\n  avr-gcc -Os -Wall -mmcu=atmega328p main.c -o test.elf\n  ```\n- PC용이었다면 여기서 `./test.elf`로 실행할 수 있지만, 아두이노에서는 **HEX 파일** 형태로 ROM에 기록해야 합니다.\n\n> 각 과정에 대해선 후술하겠습니다.  \n\n\n#### HEX 파일 변환\n\n- **avr-objcopy** 유틸을 사용해 ELF를 **HEX** 형식으로 바꿉니다.\n  ```bash\n  avr-objcopy -I elf32-avr -O ihex test.elf test.hex\n  ```\n- 이렇게 생성된 **test.hex**가 **아두이노(ATmega328p MCU)**에서 실제로 실행할 수 있는 펌웨어 이미지입니다.\n- 이후, 아두이노 개발 툴(또는 avrdude 등)을 통해 이 HEX 파일을 **ROM**에 기록하면 프로그램이 동작하게 됩니다.\n\n---\n\n### 프리프로세스, 어셈블, 링크의 예시\n\n#### 프리프로세스(전처리)\nC언어의 매크로를 전개해 `#include`, `#ifdef`등 디렉티브(directive)를 처리합니다.  \n\n실제로 프리프로세스만을 수행하고 결과를 확인하겠습니다.  \n```\navr-gcc -Os -Wall -mmcu=atmega328p -E main.c > preprocess.c\n```\n\n**preprocess.c**\n```c\n# 1 \"main.c\"\n# 1 \"<built-in>\"\n# 1 \"<command-line>\"\n# 1 \"main.c\"\n# 1 \"/usr/lib/avr/include/stdio.h\" 1 3 \n# 44 \"/usr/lib/avr/include/stdio.h\" 3\n# 1 \"/usr/lib/avr/include/inttypes.h\" 1 3 \n# 37 \"/usr/lib/avr/include/inttypes.h\" 3\n# 1 \"/usr/lib/gcc/avr/5.4.0/include/stdint.h\" 1 3 4 \n# 9 \"/usr/lib/gcc/avr/5.4.0/include/stdint.h\" 3 4 \n# 1 \"/usr/lib/avr/include/stdint.h\" 1 3 4 \n# 125 \"/usr/lib/avr/include/stdint.h\" 3 4 \n\n# 125 \"/usr/lib/avr/include/stdint.h\" 3 4 \ntypedef signed int int8_t __attribute__((__mode__(__QI__)));\ntypedef unsigned int uint8_t __attribute__((__mode__(__QI__)));\ntypedef signed int int16_t __attribute__ ((__mode__ (__HI__)));\n\n...\n...(중략)\n...\n\nextern int setvbuf(FILE *stream, char *buf, int mode, size_t size);\nextern FILE *tmpfile(void);\nextern char *tmpnam (char *s);\n# 2 \"main.c\" 2\n\n\n# 3 \"main.c\"\nint main(){\n printf(\"Hello World!\\n\");\n return 0;\n}\n\n```\n\n#### 컴파일\n프리프로세스에 의해 전개된 소스 코드를 어셈블리어로 변환하는 작업입니다.  \n\n```\navr-gcc -Os -Wall -mmcu=atmega328p -S preprocess.c\n```\n\n**preprocess.s**\n```\n\t.file\t\"preprocess.c\"\n__SP_H__ = 0x3e\n__SP_L__ = 0x3d\n__SREG__ = 0x3f\n__tmp_reg__ = 0\n__zero_reg__ = 1\n\t.section\t.rodata.str1.1,\"aMS\",@progbits,1\n.LC0:\n\t.string\t\"Hello World!\"\n\t.section\t.text.startup,\"ax\",@progbits\n.global\tmain\n\t.type\tmain, @function\nmain:\n/* prologue: function */\n/* frame size = 0 */\n/* stack size = 0 */\n.L__stack_usage = 0\n\tldi r24,lo8(.LC0)\n\tldi r25,hi8(.LC0)\n\tcall puts\n\tldi r24,0\n\tldi r25,0\n\tret\n\t.size\tmain, .-main\n\t.ident\t\"GCC: (GNU) 5.4.0\"\n.global __do_copy_data\n\n```\n\n#### 어셈블\n어셈블리어로 변환한 결과를 목적 파일(OBJ 형식)으로 변환합니다.\n만약, 라이브러리를 사용하고 있다면 이 단계에서 목적 파일을 만들더라도 실행되지 않습니다.  \n```\navr-as -mmcu=atmega328p -o main.o preprocess.s\n```\n\n`main.o`의 내용은 바이너리파일이라 텍스트 에디터로는 확인할 수 없습니다.  \n```\ngyu@gyu:~/workspace/ebtb$ cat main.o\nELFS<�4(\n       Hello World!���������GCC: (GNU) 5.4.0��>��=�� ?��)��5��BGLpreprocess.c__SP_H____SP_L____SREG____tmp_reg____zero_reg__mainputs__do_copy_data\n\n@A;@�$b.strtab.shstrtab.text.data.bss.rodata.str1.1.rela.text.startup.comment!44,24\n        N0O�Wd\n```\n\n#### 링크\n링크 처리를 통해 의존하고 있는 라이브러리를 합체해 실제로 실행할 수 있는 파일로 변환합니다.  \n\n```\navr-ld -o test.elf main.o ~/work/arduino-1.8.xx/...\n```\n뒤에 들어가는 인자는 이번 프록그램에 필요한 네가지 파일의 장소를 지정합니다.  \n(crtatmega328p.o, libc.a, libatmega328p.a, libgcc.a) 이는 환경마다 달라서 필요에 따라 변경해야합니다.  \n\n\n근데, 일단 명령어가 복잡하니 간단하게 `avr-gcc`명령어를 사용하겠습니다.  \n```\navr-gcc -Os -mmcu=atmega328p -o test.elf main.c\n```\n\n![img](/assets/img/ebtb/eb32.png)\n\n#### HEX 파일 변환\n실제 ROM에 기록하기 위해 **HEX 파일**로 변환을 합니다.  \n인텔과 모토롤라 두 가지 형식이 있으며, 임베디드 시스템의 CPU에 맞춰 선택해야합니다.  \n\n```\navr-objcopy -I elf32-avr -O ihex test.elf test.hex\n```\n\n\n이런 과정을 모두 포함해 **빌드**라고 부르며, 각각의 단계는 명령어나 옵션을 달리하여 확인할 수 있습니다.\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }\n",
    "date": "2024-12-31",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-31-------3_chunk_0",
        "text": "[임베교과서] 3장 임베디드 소프트웨어 (1)\n\n## 임베디드 시스템의 소프트웨어\n\n임베디드 소프트웨어는 **운영체제(OS)** 유무에 따라 크게 두 경우로 나눌 수 있습니다.  \n- **OS 없이 동작**: 아두이노 우노처럼 **단순한 기능**이 주 목적이고, 하드웨어가 비교적 **저사양**인 경우 직접 구현 가능  \n- **OS 위에서 동작**: 라즈베리 파이처럼 **리눅스** 등 범용 OS를 탑재해 **복잡한 기능**을 처리할 수 있습니다.  \n  - 이 경우 CPU 스케줄링, 메모리 관리 같은 기능을 OS가 담당하므로 편의성이 올라가지만, 그만큼 일정 수준 이상의 하드웨어 자원이 필요해집니다.  \n\nOS가 있는 임베디드 소프트웨어에서는 **미들웨어(middleware)**가 추가로 제공될 수 있습니다.  \n- 미들웨어는 **네트워크 스택**, **파일 시스템**처럼 애플리케이션에서 자주 쓰이는 기능을 모아 둔 **중간 계층**입니다.",
        "index": 0
      },
      {
        "id": "2024-12-31-------3_chunk_1",
        "text": "ware)**가 추가로 제공될 수 있습니다.  \n- 미들웨어는 **네트워크 스택**, **파일 시스템**처럼 애플리케이션에서 자주 쓰이는 기능을 모아 둔 **중간 계층**입니다.  \n  -> 덕분에 **애플리케이션** 개발 시, 이미 준비된 **API**를 활용해 **개발 효율**을 높일 수 있습니다.\n\n> 물론, OS 없이 개발하더라도 전부 바닥부터 짜는 건 아니고, **개발 환경**에서 기본 라이브러리를 제공하여 최소한의 기능을 지원하기도 합니다.\n{: .prompt-tip }\n\n---\n\n## 임베디드 소프트웨어를 개발하는 흐름\n\n보통 임베디드 소프트웨어는 **PC에서 고급 언어(C/C++ 등)로 작성**한 뒤,  \n이를 **임베디드 환경**에서 동작할 수 있도록 변환(크로스 컴파일)해 **내장**합니다.\n\n### 크로스 개발환경\n\nPC에서 에디터로 코드 작성까지는 일반 PC용 프로그램 개발과 똑같습니다.  \n하지만, **소스 코드**를 만든 이후에 **임베디드 시스템**이 이해할 수 있는 실행 형식으로 **변환**해야 합니다.",
        "index": 1
      },
      {
        "id": "2024-12-31-------3_chunk_2",
        "text": "작성까지는 일반 PC용 프로그램 개발과 똑같습니다.  \n하지만, **소스 코드**를 만든 이후에 **임베디드 시스템**이 이해할 수 있는 실행 형식으로 **변환**해야 합니다.  \n- 예를 들어, PC(리눅스)라면 `gcc` 명령어로 빌드 후 바로 실행 가능하지만,  \n- 임베디드용 CPU나 OS가 다르면, **명령어 셋**이나 **라이브러리 구조**가 달라 **그대로는 실행 불가**합니다.\n\n이를 위해 **임베디드 시스템용 툴체인**(컴파일러, 링커, 라이브러리 등)을 설치하고,  \n**크로스 컴파일**을 수행하는 개발 환경을 **크로스 개발환경**이라 부릅니다.\n\n#### (참고) 어떤 점이 다른가?\n이 개발환경이 다른 점에 대해 고민했던 부분이 있어 추가 설명합니다.  \n\n- **CPU 차이**: x86(CISC) vs. ARM(RISC)  \n  \n  우선, CPU 아키텍처가 다를 경우 명령어 셋이 다르기에 당연히 실행될 수 없습니다.  \n  또한, 32비트 OS와 64비트 OS는 메모리 주소 체계가 다르고 레지스터 사용 규칙 등의 차이가 있어 실행되지 않는 것이 당연하다고 느껴집니다.  \n\n- **OS/LIBC 차이**: PC용 리눅스 vs. 임베디드 RTOS (또는 Bare Metal)  \n  \n  PC용 리눅스와 RTOS는 서로 시스템 콜이 다릅니다.  \n  그렇기에, `malloc`같은 함수도 인터페이스가 동일하지 않을 수 있기에 실행되지 않습니다.",
        "index": 2
      },
      {
        "id": "2024-12-31-------3_chunk_3",
        "text": "tal)  \n  \n  PC용 리눅스와 RTOS는 서로 시스템 콜이 다릅니다.  \n  그렇기에, `malloc`같은 함수도 인터페이스가 동일하지 않을 수 있기에 실행되지 않습니다.  \n\n- **라이브러리 버전**: 임베디드 glibc 버전이 다르면 호환성 문제 발생\n  \n  이 부분이 헷갈렸는데, 만약 PC도 32비트 리눅스, 임베디드 시스템도 32비트 리눅스면 가능하지 않을까? 라고 생각했습니다.  \n  하지만, 임베디드 리눅스의 경우 조금 더 경량화된 `glibc` 라이브러리를 사용하는 등 라이브러리가 다르기에 호환되지 않는 상황이 발생할 수 있다고 합니다.\n\n즉, 대부분의 환경에서는 크로스 컴파일이 필수적이라고 생각할 수 있겠습니다.\n\n> **정말로 CPU·OS·라이브러리까지 전부 동일**하다면, 크로스 컴파일 없이 **네이티브 빌드**도 가능합니다.  \n> 라즈베리파이에서 `gcc`를 설치하고 PC역시 ARMv7에 동일한 운영체제를 사용하는  \n> 정말 완전 동일한 환경이라면 크로스 컴파일이 필요 없습니다.  \n{: .prompt-tip }\n\n\n### 빌드 작업\n\n빌드는 소스 코드를 **임베디드 시스템의 CPU가 이해할 수 있는 형태**로 만드는 일련의 과정입니다.",
        "index": 3
      },
      {
        "id": "2024-12-31-------3_chunk_4",
        "text": "필요 없습니다.  \n{: .prompt-tip }\n\n\n### 빌드 작업\n\n빌드는 소스 코드를 **임베디드 시스템의 CPU가 이해할 수 있는 형태**로 만드는 일련의 과정입니다.  \n- **컴파일** → **어셈블** → **링크** → **HEX(ROM) 파일 생성**\n- 일반적으로 “컴파일”은 고급 언어를 기계어로 바꾸는 단계만 가리키고,  \n  “빌드”는 **최종 실행 파일**(또는 펌웨어 이미지)까지 생성하는 전체 과정을 의미합니다.\n\n#### 빌드 과정\n\n아래는 각 단계별 입출력을 간단히 나타낸 흐름도 예시입니다.\n\n```mermaid\nflowchart TD\n    A(\"소스 코드\") --> B[컴파일러]\n    B -- \"어셈블러파일\" --> C[어셈블러]\n    C -- \"OBJ파일\" --> D[링커]\n    D -- \"실행파일\" --> E[바이너리 도구]\n    E -- \"HEX파일\" --> F(\"완료\")\n\n```\n\n> - **컴파일**: C/C++ → 어셈블리 코드  \n> - **어셈블**: 어셈블리 코드 → OBJ 오브젝트 파일  \n> - **링크**: OBJ와 라이브러리를 합쳐 최종 실행 파일(ELF 등) 생성  \n> - **바이너리 변환**: ELF 등을 **HEX**나 **BIN** 형식으로 변환 (실제 ROM에 기록)\n\n---\n\n### 실제 빌드의 흐름 확인하기\n\n예를 들어, 아두이노용 임베디드 소프트웨어를 만들 때는 `avr-gcc` 툴체인을 사용합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-31-------2",
    "title": "[임베교과서] 2장 마이크로컴퓨터 하드웨어",
    "path": "/2024/12/31/임베교과서-2장/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "임베디드 시스템은 목적에 맞게 **하드웨어**와 **소프트웨어**가 **기기 내부에 내장**되어 동작하는 구조입니다.  \n이를 통해 특정 기능에 최적화된 **전용 동작**을 수행하며, 일반적인 PC나 서버와 달리 **운영 중 기능이 크게 바뀌지 않는** 경우가 많습니다.\n\n이번 장에서는 임베디드 시스템을 구성하는 **마이크로컴퓨터**(CPU·메모리·주변장치)의 핵심 부품들과, 이들이 **어떻게 상호 연결**되는지 간단히 살펴보겠습니다.\n\n---\n\n## 임베디드 시스템의 구성\n\n**임베디드 시스템**은 크게 **하드웨어**와 **소프트웨어**로 나뉩니다.  \n- 하드웨어: **CPU(연산 장치)**, **메모리(ROM, RAM)**, **주변장치(Peripheral)**  \n- 소프트웨어: CPU가 실행할 **프로그램(펌웨어, OS 등)**\n\n일반 PC와 달리, 임베디드 시스템은 **정해진 기능**을 수행하기 위해 설계됩니다.  \n운영 중에 새로운 기능이 추가되거나, 목적이 극단적으로 바뀌는 일은 상대적으로 드뭅니다.\n\n---\n\n## 임베디드 마이크로컴퓨터의 구성\n\n### 하드웨어의 종류\n\n1. **CPU** (Central Processing Unit)  \n   - 연산을 담당하는 **중앙 처리 장치**입니다.  \n   - 마이크로컴퓨터(MCU)의 두뇌 역할을 하며, 여러 비트 폭(4비트 ~ 64비트 등)에 따라 처리 성능이 달라집니다.\n\n2. **메모리**  \n   - **ROM**: 프로그램이나 데이터를 저장해 두고 **읽기만** 하는 영역  \n   - **RAM**: 프로그램이 동작할 때 **일시적으로** 데이터를 저장하는 영역\n\n3. **주변장치(Peripheral)**  \n   - 입출력을 담당하는 각종 부품들  \n   - 예: 타이머, UART, I2C, SPI, DMA 컨트롤러 등\n\n> PC에서는 고성능 하드웨어가 많지만, 임베디드 하드웨어는 **정해진 목적**에 맞춰 **필요 최소한의 구성**을 갖추는 경우가 많습니다.  \n{: .prompt-tip }\n\n---\n\n### CPU와 마이크로컴퓨터\n\nCPU는 **계산**에 필요한 여러 부품(연산 장치, 레지스터, 제어 장치 등)을 **하나의 칩**에 넣은 것입니다.  \n- **Intel 4004**(4비트)가 세계 최초의 상업용 마이크로컴퓨터로 알려져 있으며, 이후 성능이 꾸준히 발전해 왔습니다.  \n- 오늘날 마이크로컴퓨터(또는 마이크로컨트롤러)는 CPU뿐 아니라, **주변장치**(타이머, UART, I2C, SPI 등)를 **하나의 칩**에 내장해 기능을 확장합니다.\n\n> **CPU가 두뇌라면**, 주변장치는 **눈, 귀, 손**처럼 외부 정보를 받아들이고, 필요한 동작을 실제로 수행하는 역할을 담당합니다.  \n{: .prompt-info }\n\n#### 버스(bus)\n\nCPU와 주변장치는 **버스**라고 부르는 신호선을 통해 연결됩니다.  \n- CPU의 명령은 버스를 통해 주변장치로 전달되고,  \n- 주변장치의 출력은 다시 버스를 통해 CPU로 전송됩니다.\n\n---\n\n### 메모리\n\n임베디드 시스템이 **복잡한 기능**을 수행하기 위해서는 **CPU**가 **프로그램**을 실행해야 합니다.  \n- 프로그램(기계어 명령)과 함께, 실행 중 발생하는 **데이터**를 저장할 공간이 필요합니다.  \n- 이를 위해 **ROM**과 **RAM**을 활용합니다.\n\n#### ROM (Read Only Memory)\n\n- **읽기 전용 비휘발성** 메모리  \n- 프로그램(기계어 명령)은 주소(Address)에 따라 저장돼 있으며, CPU는 필요한 주소를 읽어 **명령**을 가져갑니다.\n\n#### RAM (Random Access Memory)\n\n- CPU가 프로그램 실행 중 **임시 저장** 공간으로 사용하는 **휘발성** 메모리  \n- 전원이 꺼지면 데이터가 지워지므로, 오직 **실행 시**에만 활용됩니다.\n\n---\n\n### 메모리의 종류\n\n위에서 메모리는 크게 ROM과 RAM이 있다했는데, 여기서도 추가적인 분류가 있습니다.  \n\n1. **ROM**  \n   - **마스크 ROM**: 제조 공정에서 데이터를 써 넣으면 **변경 불가**  \n   - **프로그램 가능 ROM(Programmable ROM)**: 데이터를 기록한 뒤 **수정 가능**\n\n2. **RAM**  \n   - **DRAM (Dynamic RAM)**: 주기적으로 **리프레시**가 필요하지만, 대용량 구성이 쉬움  \n   - **SRAM (Static RAM)**: 리프레시가 필요 없어 **고속 접근**이 가능하지만, 제조 단가가 높아 **캐시 메모리** 등에 주로 사용\n\n> **SRAM이 DRAM보다 빠른 이유**  \n> DRAM은 메모리 셀(1개의 트랜지스터 + 1개의 캐패시터)을 주기적으로 읽고 쓰는 **리프레시** 작업이 필요합니다. 반면, SRAM은 **6개의 트랜지스터**로 구성되어 리프레시가 필요 없으므로 속도가 빠릅니다. 다만, 구성 트랜지스터 수가 많아 대용량 구현이 어렵고 비용이 높은 단점이 있습니다.  \n> (즉, 캐패시터의 유무라는 구조적 차이로 인해 리프레시의 동작이 결정됩니다)  \n{: .prompt-info }\n\n---\n\n### 버스의 구성\n\n임베디드 시스템에서 CPU가 메모리나 주변장치와 **데이터를 주고받는** 통로를 **버스**라고 합니다.  \n버스는 성능과 목적에 따라 **메인 버스(Main Bus)**와 **로컬 버스(Local Bus)**로 나뉘어 동작하는 경우가 많습니다.\n\n1. **메인 버스**  \n   - **고속 동작**이 필요한 메모리나 주변장치가 연결되는 버스  \n   - **주소 버스(Address Bus)**: 접근하려는 **메모리 주소**나 **주변장치** 위치를 지정  \n   - **데이터 버스(Data Bus)**: 읽거나 써야 할 **데이터**가 오가는 경로  \n   - **컨트롤 버스(Control Bus)**: 메모리, 주변장치를 **제어**하기 위한 각종 신호\n   \n2. **로컬 버스**  \n   - **저속**으로 동작하는 주변장치가 연결되는 버스  \n   - **브릿지(Bridge)**: 메인 버스와 로컬 버스 간 **속도 차**를 조정하는 하드웨어 컨트롤러  \n\n> **브릿지**는 고속 메인 버스와 저속 로컬 버스를 연결해 주며, 통신 타이밍을 맞춰주는 역할을 수행합니다.  \n{: .prompt-info }\n\n---\n\n### 주변장치 (Peripheral)\n\n주변장치는 **임베디드 시스템의 용도**에 따라 다양하게 구성됩니다.  \n아래는 대표적인 주변장치들입니다.\n\n#### DMA(Direct Memory Access) 컨트롤러\n\n- CPU 개입 없이 **주변장치**와 **메모리** 간에 직접 데이터 전송이 가능하도록 하는 장치  \n- 대량 데이터 전송 시 **CPU 부하**를 줄이는 데 유용  \n- 버스 사용 충돌을 막기 위해 **버스 아비터(Bus Arbiter)**가 중재 역할을 수행\n\n> DMA 설정(주소, 전송 크기)을 잘못할 경우 큰 사고가 발생할 수 있기에, 신중하게 설정해야 합니다.  \n{: .prompt-warning }\n\n#### 타이머\n\n- 일정 시간이 흐른 뒤 **인터럽트**를 걸어, CPU가 필요한 작업을 **주기적**으로 수행하게 만듦  \n- 임베디드 시스템에서 **주기적 관측**(센서 감시, 데이터 출력 등)에 필수적\n\n#### RTC(Real Time Clock)\n\n- 실제 **날짜와 시간**을 카운팅하는 주변장치  \n- CPU 전원이 꺼진 상태에서도 **백업 배터리**를 통해 시간을 유지함\n\n#### GPIO(General Purpose Input/Output)\n\n- **범용 입출력 포트**  \n- 간단한 신호를 주고받거나, 외부 페리퍼럴에서 발생하는 **인터럽트** 신호를 처리하는 등 여러 용도로 사용\n\n---\n\n### 로컬 버스와 주변 통신\n\n**저속 주변장치**들은 보통 **로컬 버스**에 접속하며, **브릿지**를 통해 메인 버스와 연결됩니다.\n\n#### UART (Universal Asynchronous Receiver/Transmitter)\n\n- **병렬 신호**(CPU 내부 데이터)와 **직렬 신호**(Tx/Rx) 간 상호 변환을 담당  \n- 임베디드 시스템에서 **시리얼 콘솔**(디버깅, 메시지 출력)로 자주 쓰임\n\n> **예시**로, 우체국 서비스를 생각해 보겠습니다.  \n>   **CPU**가 편지(병렬 데이터)를 우체국(UART)에 맡기면, 우체국이 편지를 **한 줄(직렬)로** 정리해 전송(Tx)하고,  \n>   반대로 **다른 곳**에서 오는 편지(직렬 데이터)를 모아서, CPU가 읽기 쉬운 형태(병렬)로 바꿔주는 작업을 합니다.  \n{: .prompt-tip }\n\n#### I2C (Inter-Integrated Circuit)\n\n- **동기식 직렬 통신** 방식  \n- **SCL**(시리얼 클럭)과 양방향 **SDA**(시리얼 데이터) **두개의 신호선** 사용  \n- **마스터-슬레이브 구조**로, 마스터가 각 **슬레이브의 주소를 지정**해 통신  \n- 센서(가속도, 터치 등) 연결에 자주 사용\n\n#### SPI (Serial Peripheral Interface)\n\n- **동기식 직렬 통신** 방식  \n- **SCK**(시리얼 클럭), 단방향 **SDI**(시리얼 데이터 인), **SDO**(시리얼 데이터 아웃) **3개 신호선** 사용  \n- 슬레이브 장치 선택 시 **Slave Select(SS)** 제어 신호 활용  \n- 데이터 포맷이 단순하고 고속 전송이 가능하나, I2C보다 **배선이 많음**  \n- 플래시 메모리나 CPU 간 통신 등에 자주 쓰임\n\n> UART, I2C, SPI 모두 **GND(그라운드)** 선이 필요합니다. GND는 전위를 만들기 위해 사용되는 신호인데,\n> 각 장치 사이에 GND가 다르면 신호를 제대로 인식하지 못하는 상황이 발생할 수 있기에 GND를 사용하는 것이 일반적입니다.  \n{: .prompt-info }\n\n#### (참고) I2C와 SPI의 슬레이브 지정 방식\n위에서 I2C는 슬레이브의 주소를 지정해서, SPI는 SS 제어 신호를 활용한다고 했습니다.  \n이 부분에 대해 공부할 때 명확하지 않았어서, 예시 상황을 떠올려 보겠습니다.  \n\n##### I2C 예시 상황\n**MCU(마스터)** 와 **온도 센서**(0x48), **가속도 센서**(0x1D)가 한 I2C 버스에 연결  \nI2C는 SCL, SDA 단 두 신호선만 사용  \n각 슬레이브 센서는 고유한 주소를 가짐  \n\nMCU가 통신을 시작하면 SCL, SDA 라인을 통해 \"**0x48**을 불러서, **읽기** 작업을 할것이다!\" 라는 신호를 보냅니다.  \n-> 버스에 있는 모든 센서가 이 주소를 듣고, **온도 센서**만 자신의 주소가 맞기에, \"**ACK**\"라 응답하고, 나머지는 대기합니다.  \n\nMCU와 온도 센서 간 데이터가 SDA 선을 통해 주고받습니다.  \nMCU가 \"Stop\" 신호를 보내면 통신을 종료합니다.  \n\n> 위와 같이, I2C는 **주소**를 통해 슬레이브를 가려냅니다!\n\n##### SPI 예시 상황\n**MCU(마스터)**와 **SPI 플래시 메모리**, **SPI LCD**가 한 SPI 버스에 연결  \nSPI는 SCK, MOSI(SDI), MISO(SDO), SS(또는 CS) 신호선을 사용  \n각 슬레이브는 **별도의 SS 핀**으로 활성화 여부를 구분  \n\nMCU가 통신을 시작하려하면, 우선 \"**플래시 메모리**\"의 SS를 \"**Low**\"로 만들어 **활성화** 합니다.  \n-> 동시에, LCD 등 다른 슬레이브의 SS는 High로 둡니다.  \n\nMCU와 플래시 메모리 간에 **MOSI**와 **MISO**를 통해 데이터를 직렬로 주고 받으며,  \n**SCK**로 시그널의 타이밍(클럭)을 동기화 합니다.  \n\nMCU가 통신을 마치면, 플래시 메모리의 **SS**를 다시 High로 되돌려 **비활성화** 시킵니다.\n\n> 위와 같이, SPI는 **슬레이브 셀렉트**핀을 통해 통신할 슬레이브를 **직접** 지정합니다.  \n\n---\n\n### 주변장치의 제어 방식\n\n대부분의 주변장치는 **레지스터(Register)**라는 특수 메모리를 통해 **CPU가 읽고/쓰는 방식**으로 제어됩니다.\n\n1. **Memory Mapped I/O**  \n   - **ROM, RAM과 동일한 주소 공간**을 사용  \n   - 주변장치에 접근할 때 **특정 주소**를 읽고 쓰면, 레지스터로 매핑된 주변장치를 제어하는 방식  \n2. **I/O Mapped I/O**  \n   - **ROM, RAM과는 별도의 주소 공간** 및 **전용 명령**을 사용  \n   - CPU 아키텍처에 따라 구현 방식이 다르므로 **데이터시트**를 확인해야 합니다.\n\n---\n\n## CPU란?\n\nCPU는 **Central Processing Unit**의 약자이며, **ROM**에서 실행할 명령을 읽고 해석한 뒤 수행합니다. 그 결과는 **RAM** 등에 저장됩니다.\n\nCPU 내부는 크게 **프로그램 카운터(PC)**, **디코더**, **시스템 레지스터**, **범용 레지스터**, **ALU**(Arithmetic and Logic Unit)로 구성됩니다.\n\n---\n\n### 프로그램 카운터(PC)\n\n- **PC**는 ROM 안의 프로그램 중 **어느 명령을 실행할지**를 관리하는 하드웨어입니다.  \n- 프로그램은 기계어 형태로 ROM의 특정 주소(번지)에 나누어 저장되어 있습니다.  \n- PC는 **다음에 실행할 명령의 주소**를 CPU에 전달함으로써, CPU가 순서대로 명령을 가져오도록 돕습니다.\n\n### 디코더\n\n- **디코더**는 CPU가 읽어 들인 명령을 **해석**하는 하드웨어입니다.  \n- 명령에 따라 **어떤 연산**을 할지(ALU 사용, 데이터 이동 등) 정해 CPU 내부에서 실행이 이뤄집니다.\n\n### ALU (Arithmetic and Logic Unit)\n\n- **ALU**는 덧셈, 뺄셈, AND, OR, NOT 등 **논리 연산**을 수행합니다.  \n- 연산 결과는 **범용 레지스터**나 **시스템 레지스터**에 저장됩니다.\n\n### 범용 레지스터\n\n- CPU 내부에 있는 **고속 메모리**로, 작은 용량이지만 **데이터를 임시로 저장**하기에 유용합니다.  \n- ALU 연산 결과나 데이터 이동 시 **중간 저장소**로 자주 쓰입니다.\n\n### 시스템 레지스터\n\n- CPU가 명령을 실행할 때 사용하는 다양한 **특수 레지스터**입니다.  \n  - 예: **명령 레지스터(명령 저장)**, **주소 레지스터(번지 관리)**, **상태 레지스터(플래그 관리)** 등  \n- **상태 레지스터**는 ALU 연산 결과나 인터럽트 상태를 **비트 단위**로 기록합니다.\n\n| 비트  | 이름  | 용도                                               |\n| :---: | :---: | :------------------------------------------------- |\n|   0   |   C   | Carry (ALU 연산에서 오버플로 발생 여부 관리)       |\n|   1   |   Z   | Zero (연산 결과가 0인지 여부 관리)                 |\n|   2   |   N   | Negative (덧셈·뺄셈 종류·부호 상태를 관리)         |\n|   4   |   S   | Sign (연산 결과가 음수인지 양수인지 확인)          |\n|   5   |   H   | Half Carry (연산 과정 중 하프 캐리 발생 여부 관리) |\n|   7   |   I   | Interrupt (인터럽트를 허용할지 여부 관리)          |\n\n---\n\n### CPU의 명령 실행\n\nCPU가 명령을 실행하는 과정은 아키텍처마다 조금씩 다를 수 있지만, 기본적으로는 **4단계**입니다:\n\n1. **명령 패치 사이클**  \n   - PC가 가리키는 **ROM 주소**에서 기계어 명령을 가져옵니다.\n2. **명령 디코드 사이클**  \n   - 가져온 명령을 **디코더**가 해석하여, 어떤 연산을 실행할지 결정합니다.\n3. **실행 사이클**  \n   - ALU 등을 통해 **실제 연산**이나 데이터 이동이 이루어집니다.\n4. **라이트 백 사이클**  \n   - 연산 결과를 **범용 레지스터**나 **메모리** 등에 기록합니다.\n\n이 과정을 거쳐 한 명령의 실행이 완료됩니다.\n\n#### CPU의 명령 종류\n\nCPU가 처리하는 명령은 크게 **세 가지** 범주로 나눌 수 있습니다.\n\n1. **CPU ↔ 메모리** 사이의 데이터 교환  \n2. **CPU ↔ 주변장치** 사이의 데이터 교환  \n3. **CPU 내부에서만** 수행되는 명령 (레지스터 간 이동 등)\n\n데이터 연산은 주로 **ALU**에서 이뤄지며, 그 결과는 **범용 레지스터**를 통해 보관하거나 **메모리**로 옮깁니다.\n\n---\n\n### 인터럽트\n\n**인터럽트**는 주변장치 등이 CPU에게 “이 작업을 처리해 달라”고 **요청**하는 신호입니다.  \nCPU가 인터럽트 신호를 받으면, **인터럽트 벡터 테이블**에 기록된 **특정 루틴(ISR)**으로 실행 흐름을 바꿉니다.  \n이 루틴이 끝나면 원래 실행 중이던 위치로 되돌아가 작업을 이어갑니다.\n\n인터럽트는 크게  \n- **타이머 인터럽트**: CPU 내부 타이머에서 발생  \n- **외부 인터럽트**: 주변장치 등 외부 하드웨어에서 발생  \n등으로 나뉩니다.\n\n---\n\n#### 인터럽트 종류와 인터럽트 벡터\n\n- 임베디드 환경에서는 여러 인터럽트가 발생할 수 있으므로, 각 인터럽트 신호(타이머, UART Rx, GPIO 등)에 대응하는 **루틴의 시작 주소**를 **인터럽트 벡터 테이블**에 미리 등록합니다.  \n- CPU가 특정 인터럽트를 감지하면, **해당 인터럽트 번호**에 맞는 **프로그램 시작 주소**를 찾아가 루틴을 실행합니다.  \n\n#### 인터럽트의 우선순위\n\n- 여러 인터럽트가 **동시에** 발생할 때는 **우선순위(Priority)**를 따져 처리 순서를 결정합니다.  \n- CPU 내부 레지스터 등을 이용해 **긴급한 인터럽트(안전·보호 장치 등)는 우선순위 높게**, 덜 중요한 인터럽트는 낮게 설정하는 식입니다.\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }\n",
    "date": "2024-12-31",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-31-------2_chunk_0",
        "text": "[임베교과서] 2장 마이크로컴퓨터 하드웨어\n\n임베디드 시스템은 목적에 맞게 **하드웨어**와 **소프트웨어**가 **기기 내부에 내장**되어 동작하는 구조입니다.  \n이를 통해 특정 기능에 최적화된 **전용 동작**을 수행하며, 일반적인 PC나 서버와 달리 **운영 중 기능이 크게 바뀌지 않는** 경우가 많습니다.\n\n이번 장에서는 임베디드 시스템을 구성하는 **마이크로컴퓨터**(CPU·메모리·주변장치)의 핵심 부품들과, 이들이 **어떻게 상호 연결**되는지 간단히 살펴보겠습니다.\n\n---\n\n## 임베디드 시스템의 구성\n\n**임베디드 시스템**은 크게 **하드웨어**와 **소프트웨어**로 나뉩니다.  \n- 하드웨어: **CPU(연산 장치)**, **메모리(ROM, RAM)**, **주변장치(Peripheral)**  \n- 소프트웨어: CPU가 실행할 **프로그램(펌웨어, OS 등)**\n\n일반 PC와 달리, 임베디드 시스템은 **정해진 기능**을 수행하기 위해 설계됩니다.  \n운영 중에 새로운 기능이 추가되거나, 목적이 극단적으로 바뀌는 일은 상대적으로 드뭅니다.\n\n---\n\n## 임베디드 마이크로컴퓨터의 구성\n\n### 하드웨어의 종류\n\n1. **CPU** (Central Processing Unit)  \n   - 연산을 담당하는 **중앙 처리 장치**입니다.  \n   - 마이크로컴퓨터(MCU)의 두뇌 역할을 하며, 여러 비트 폭(4비트 ~ 64비트 등)에 따라 처리 성능이 달라집니다.\n\n2.",
        "index": 0
      },
      {
        "id": "2024-12-31-------2_chunk_1",
        "text": "을 담당하는 **중앙 처리 장치**입니다.  \n   - 마이크로컴퓨터(MCU)의 두뇌 역할을 하며, 여러 비트 폭(4비트 ~ 64비트 등)에 따라 처리 성능이 달라집니다.\n\n2. **메모리**  \n   - **ROM**: 프로그램이나 데이터를 저장해 두고 **읽기만** 하는 영역  \n   - **RAM**: 프로그램이 동작할 때 **일시적으로** 데이터를 저장하는 영역\n\n3. **주변장치(Peripheral)**  \n   - 입출력을 담당하는 각종 부품들  \n   - 예: 타이머, UART, I2C, SPI, DMA 컨트롤러 등\n\n> PC에서는 고성능 하드웨어가 많지만, 임베디드 하드웨어는 **정해진 목적**에 맞춰 **필요 최소한의 구성**을 갖추는 경우가 많습니다.  \n{: .prompt-tip }\n\n---\n\n### CPU와 마이크로컴퓨터\n\nCPU는 **계산**에 필요한 여러 부품(연산 장치, 레지스터, 제어 장치 등)을 **하나의 칩**에 넣은 것입니다.  \n- **Intel 4004**(4비트)가 세계 최초의 상업용 마이크로컴퓨터로 알려져 있으며, 이후 성능이 꾸준히 발전해 왔습니다.  \n- 오늘날 마이크로컴퓨터(또는 마이크로컨트롤러)는 CPU뿐 아니라, **주변장치**(타이머, UART, I2C, SPI 등)를 **하나의 칩**에 내장해 기능을 확장합니다.\n\n> **CPU가 두뇌라면**, 주변장치는 **눈, 귀, 손**처럼 외부 정보를 받아들이고, 필요한 동작을 실제로 수행하는 역할을 담당합니다.",
        "index": 1
      },
      {
        "id": "2024-12-31-------2_chunk_2",
        "text": "칩**에 내장해 기능을 확장합니다.\n\n> **CPU가 두뇌라면**, 주변장치는 **눈, 귀, 손**처럼 외부 정보를 받아들이고, 필요한 동작을 실제로 수행하는 역할을 담당합니다.  \n{: .prompt-info }\n\n#### 버스(bus)\n\nCPU와 주변장치는 **버스**라고 부르는 신호선을 통해 연결됩니다.  \n- CPU의 명령은 버스를 통해 주변장치로 전달되고,  \n- 주변장치의 출력은 다시 버스를 통해 CPU로 전송됩니다.\n\n---\n\n### 메모리\n\n임베디드 시스템이 **복잡한 기능**을 수행하기 위해서는 **CPU**가 **프로그램**을 실행해야 합니다.  \n- 프로그램(기계어 명령)과 함께, 실행 중 발생하는 **데이터**를 저장할 공간이 필요합니다.  \n- 이를 위해 **ROM**과 **RAM**을 활용합니다.\n\n#### ROM (Read Only Memory)\n\n- **읽기 전용 비휘발성** 메모리  \n- 프로그램(기계어 명령)은 주소(Address)에 따라 저장돼 있으며, CPU는 필요한 주소를 읽어 **명령**을 가져갑니다.\n\n#### RAM (Random Access Memory)\n\n- CPU가 프로그램 실행 중 **임시 저장** 공간으로 사용하는 **휘발성** 메모리  \n- 전원이 꺼지면 데이터가 지워지므로, 오직 **실행 시**에만 활용됩니다.\n\n---\n\n### 메모리의 종류\n\n위에서 메모리는 크게 ROM과 RAM이 있다했는데, 여기서도 추가적인 분류가 있습니다.  \n\n1.",
        "index": 2
      },
      {
        "id": "2024-12-31-------2_chunk_3",
        "text": "지므로, 오직 **실행 시**에만 활용됩니다.\n\n---\n\n### 메모리의 종류\n\n위에서 메모리는 크게 ROM과 RAM이 있다했는데, 여기서도 추가적인 분류가 있습니다.  \n\n1. **ROM**  \n   - **마스크 ROM**: 제조 공정에서 데이터를 써 넣으면 **변경 불가**  \n   - **프로그램 가능 ROM(Programmable ROM)**: 데이터를 기록한 뒤 **수정 가능**\n\n2. **RAM**  \n   - **DRAM (Dynamic RAM)**: 주기적으로 **리프레시**가 필요하지만, 대용량 구성이 쉬움  \n   - **SRAM (Static RAM)**: 리프레시가 필요 없어 **고속 접근**이 가능하지만, 제조 단가가 높아 **캐시 메모리** 등에 주로 사용\n\n> **SRAM이 DRAM보다 빠른 이유**  \n> DRAM은 메모리 셀(1개의 트랜지스터 + 1개의 캐패시터)을 주기적으로 읽고 쓰는 **리프레시** 작업이 필요합니다. 반면, SRAM은 **6개의 트랜지스터**로 구성되어 리프레시가 필요 없으므로 속도가 빠릅니다. 다만, 구성 트랜지스터 수가 많아 대용량 구현이 어렵고 비용이 높은 단점이 있습니다.  \n> (즉, 캐패시터의 유무라는 구조적 차이로 인해 리프레시의 동작이 결정됩니다)  \n{: .prompt-info }\n\n---\n\n### 버스의 구성\n\n임베디드 시스템에서 CPU가 메모리나 주변장치와 **데이터를 주고받는** 통로를 **버스**라고 합니다.",
        "index": 3
      },
      {
        "id": "2024-12-31-------2_chunk_4",
        "text": "다)  \n{: .prompt-info }\n\n---\n\n### 버스의 구성\n\n임베디드 시스템에서 CPU가 메모리나 주변장치와 **데이터를 주고받는** 통로를 **버스**라고 합니다.  \n버스는 성능과 목적에 따라 **메인 버스(Main Bus)**와 **로컬 버스(Local Bus)**로 나뉘어 동작하는 경우가 많습니다.\n\n1. **메인 버스**  \n   - **고속 동작**이 필요한 메모리나 주변장치가 연결되는 버스  \n   - **주소 버스(Address Bus)**: 접근하려는 **메모리 주소**나 **주변장치** 위치를 지정  \n   - **데이터 버스(Data Bus)**: 읽거나 써야 할 **데이터**가 오가는 경로  \n   - **컨트롤 버스(Control Bus)**: 메모리, 주변장치를 **제어**하기 위한 각종 신호\n   \n2. **로컬 버스**  \n   - **저속**으로 동작하는 주변장치가 연결되는 버스  \n   - **브릿지(Bridge)**: 메인 버스와 로컬 버스 간 **속도 차**를 조정하는 하드웨어 컨트롤러  \n\n> **브릿지**는 고속 메인 버스와 저속 로컬 버스를 연결해 주며, 통신 타이밍을 맞춰주는 역할을 수행합니다.  \n{: .prompt-info }\n\n---\n\n### 주변장치 (Peripheral)\n\n주변장치는 **임베디드 시스템의 용도**에 따라 다양하게 구성됩니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-21-------0",
    "title": "[임베교과서] 0장 시작하기 전",
    "path": "/2024/12/21/임베교과서-0장/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "![alt text](/assets/img/ebtb/pyoji.png)\n\n---\n\n# 도서 정보\n\n도서명 : 임베디드 엔지니어 교과서  \n출판사 : 제이펍  \n저자명 : 와타나베 노보루, 마키노 신지  \n역자명 : 정인식  \n출판일 : 2020년 7월 29일  \nISBN :  979-11-90665-40-7(93000)  \n\n링크 : [https://jpub.tistory.com/1066](https://jpub.tistory.com/1066)  \n\n---\n\n## 목차\n\nChapter 1. 임베디드 소프트웨어 엔지니어의 업무  \nChapter 2. 마이크로 컴퓨터 하드웨어  \nChapter 3. 임베디드 소프트웨어  \nChapter 4. 임베디드 시스템을 사용한 C언어 프로그래밍  \nChapter 5. 실시간 운영체제  \nChapter 6. 스마트 디바이스  \nChapter 7. 임베디드 리눅스  \nChapter 8. 임베디드 소프트웨어의 개발 프로세스  \nChapter 9. 사물인터넷/인공지능 시대의 임베디드 소프트웨어 개발  \n\n총 1장부터 9장으로 구성되어 있습니다.  \n\n\n예상 독자는 임베디드 기술을 처음 접하거나, 임베디드 분야로 진출하고 싶은 사회초년생을 대상으로 합니다.\n\n--- \n\n## 도서 선택 계기\n\n임베디드 소프트웨어의 입문서이자 기본이 되는 내용들을 다룬다는 평이 많았으며,  \n교재 목차와 샘플을 보고 책을 선택하게 되었습니다.  \n\n임베디드 개발자라는 커리어를 시작하기 전, 넓은 시야에서 이 분야에 대해 알아보고 싶었습니다.  \n기술적인 내용도 중요하지만, 결국 임베디드 엔지니어는 무엇을 하는 사람일까? 라는 의문과  \n지금까지는 어떻게 발전해 왔으며, 추후 동향까지 다루기에 이 책에 흥미가 생겨 구매하게 되었습니다.  \n\n---\n\n> 다른 도서 정리와 동일하게, 책을 읽고 간단하게 정리하는 방식으로 글을 작성하려 합니다.  \n>\n> \n",
    "date": "2024-12-21",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-21-------0_chunk_0",
        "text": "[임베교과서] 0장 시작하기 전\n\n![alt text](/assets/img/ebtb/pyoji.png)\n\n---\n\n# 도서 정보\n\n도서명 : 임베디드 엔지니어 교과서  \n출판사 : 제이펍  \n저자명 : 와타나베 노보루, 마키노 신지  \n역자명 : 정인식  \n출판일 : 2020년 7월 29일  \nISBN :  979-11-90665-40-7(93000)  \n\n링크 : [https://jpub.tistory.com/1066](https://jpub.tistory.com/1066)  \n\n---\n\n## 목차\n\nChapter 1. 임베디드 소프트웨어 엔지니어의 업무  \nChapter 2. 마이크로 컴퓨터 하드웨어  \nChapter 3. 임베디드 소프트웨어  \nChapter 4. 임베디드 시스템을 사용한 C언어 프로그래밍  \nChapter 5. 실시간 운영체제  \nChapter 6. 스마트 디바이스  \nChapter 7. 임베디드 리눅스  \nChapter 8. 임베디드 소프트웨어의 개발 프로세스  \nChapter 9. 사물인터넷/인공지능 시대의 임베디드 소프트웨어 개발  \n\n총 1장부터 9장으로 구성되어 있습니다.  \n\n\n예상 독자는 임베디드 기술을 처음 접하거나, 임베디드 분야로 진출하고 싶은 사회초년생을 대상으로 합니다.\n\n--- \n\n## 도서 선택 계기\n\n임베디드 소프트웨어의 입문서이자 기본이 되는 내용들을 다룬다는 평이 많았으며,  \n교재 목차와 샘플을 보고 책을 선택하게 되었습니다.  \n\n임베디드 개발자라는 커리어를 시작하기 전, 넓은 시야에서 이 분야에 대해 알아보고 싶었습니다.",
        "index": 0
      },
      {
        "id": "2024-12-21-------0_chunk_1",
        "text": "룬다는 평이 많았으며,  \n교재 목차와 샘플을 보고 책을 선택하게 되었습니다.  \n\n임베디드 개발자라는 커리어를 시작하기 전, 넓은 시야에서 이 분야에 대해 알아보고 싶었습니다.  \n기술적인 내용도 중요하지만, 결국 임베디드 엔지니어는 무엇을 하는 사람일까? 라는 의문과  \n지금까지는 어떻게 발전해 왔으며, 추후 동향까지 다루기에 이 책에 흥미가 생겨 구매하게 되었습니다.  \n\n---\n\n> 다른 도서 정리와 동일하게, 책을 읽고 간단하게 정리하는 방식으로 글을 작성하려 합니다.  \n>\n>",
        "index": 1
      },
      {
        "id": "2024-12-21-------0_chunk_2",
        "text": "향까지 다루기에 이 책에 흥미가 생겨 구매하게 되었습니다.  \n\n---\n\n> 다른 도서 정리와 동일하게, 책을 읽고 간단하게 정리하는 방식으로 글을 작성하려 합니다.  \n>\n>",
        "index": 2
      },
      {
        "id": "2024-12-21-------0_chunk_3",
        "text": "향까지 다루기에 이 책에 흥미가 생겨 구매하게 되었습니다.  \n\n---\n\n> 다른 도서 정리와 동일하게, 책을 읽고 간단하게 정리하는 방식으로 글을 작성하려 합니다.  \n>\n>",
        "index": 3
      },
      {
        "id": "2024-12-21-------0_chunk_4",
        "text": "향까지 다루기에 이 책에 흥미가 생겨 구매하게 되었습니다.  \n\n---\n\n> 다른 도서 정리와 동일하게, 책을 읽고 간단하게 정리하는 방식으로 글을 작성하려 합니다.  \n>\n>",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-21-------1",
    "title": "[임베교과서] 1장 임베디드 소프트웨어 엔지니어의 업무",
    "path": "/2024/12/21/임베교과서-1장/",
    "categories": [
      "Embedded System",
      "임베디드 엔지니어 교과서",
      "Embedded/EM_bible"
    ],
    "content": "# 임베디드 소프트웨어 엔지니어의 업무\n\n**임베디드 시스템**은 우리가 일상적으로 사용하는 수많은 기기와 장치에 탑재되어 있습니다.  \n인터폰, 조명, 에어컨, 공기청정기, 엘리베이터 등 많은 제품이 **임베디드 시스템**으로 동작합니다.  \n\n이번 장에서는 임베디드 시스템을 개발하는 **임베디드 소프트웨어 엔지니어**는 어떤 역할을 수행하는지,   \n그리고 임베디드 시스템은 어떻게 구성되어 있는지 알아보겠습니다.  \n\n---\n\n## 임베디드 시스템이란?\n\n임베디드 시스템은 **마이크로컴퓨터**나 **마이크로컨트롤러(MCU)**가 내장된 기계나 장치를 말합니다.  \nPC나 서버처럼 사람의 입력을 받아 정보를 처리하기도 하지만, **센서**와 **액추에이터**를 통해 외부 환경과 상호작용하며 **자율적으로** 동작하는 경우가 많습니다.\n\n> **액추에이터(actuator)**  \n> 제어 기기에서 출력된 신호를 바탕으로 실제 물리적 동작을 수행하는 기계 장치를 말합니다.  \n{: .prompt-info }\n\n### 임베디드 시스템의 특징: NTCR\n\n임베디드 시스템은 크게 **네 가지** 공통된 특징으로 정리할 수 있습니다.  \n`Nature`, `Time`, `Constraint`, `Reliability` — 이를 줄여서 **NTCR**이라고 부릅니다.\n\n1. **Nature**  \n   - 임베디드 시스템은 **외부 세계의 변화를 감지**(센서)하고, MCU에서 처리한 결과를 **외부로 피드백**(액추에이터)하는 작업을 수행합니다.  \n   - **자동차**, **로봇** 등 모션을 다루는 시스템에서는 **어떻게 감지하고, 어떻게 피드백할지**가 매우 중요합니다.  \n     이런 시스템의 경우 PC 기반의 정보 시스템과 달리, **제어 모델**을 통해 하드웨어를 직접 제어한다는 큰 특징이 있습니다.\n\n2. **Time**  \n   - 임베디드 시스템은 대부분 **실시간성(Real-Time)**이 요구됩니다.  \n   - 예를 들어, 스마트폰이나 PC는 상황에 따라 응답이 조금 느려져도 큰 문제가 되지 않을 수 있지만, 임베디드 시스템은 **목적에 맞춰 즉시** 작동해야 합니다.  \n   - 요구되는 실시간성은 기기에 따라 다릅니다.  \n     - **하드 리얼타임(Hard Real-Time)**: 자동차·항공기처럼 **밀리초 단위**의 데드라인을 반드시 준수해야 함.  \n     - **소프트 리얼타임(Soft Real-Time)**: 음악 플레이어나 영상 재생처럼 **일정 정도 지연**이 허용됨.\n\n3. **Constraint**  \n   - 임베디드 시스템은 **크기, 무게, 비용, 전력, 발열 등** 다양한 제약 조건을 충족해야 합니다.  \n   - 일반 PC처럼 **고성능**만 추구하는 것이 아니라, **적정 성능**을 필요로 하며 제한된 환경에서 **최적화**된 구성을 갖추어야 합니다.\n\n4. **Reliability**  \n   - **신뢰성**은 주어진 조건에서 정해진 시간 안에 **요구된 기능**을 수행해 낼 수 있는 능력입니다.  \n   - 임베디드 시스템은 특정 기기나 장치가 **안정적으로 동작**해야 하므로, 설계 단계부터 **품질**을 고려해야 합니다.  \n\n---\n\n## 임베디드 소프트웨어란?\n\n**임베디드 소프트웨어**는 말 그대로 임베디드 시스템에 탑재되어, **MCU를 구동**하는 **프로그램**을 뜻합니다.  \n- 일반 PC나 서버용 소프트웨어와 달리, **하드웨어**와 밀접하게 연동되어 있습니다.  \n- **펌웨어(Firmware)**라는 용어로도 불리며, 운영체제(OS)와 펌웨어를 통틀어 임베디드 소프트웨어라고 하기도 합니다.\n\n### 임베디드 소프트웨어의 특징\n\n- 임베디드 소프트웨어는 **직접 하드웨어를 제어**합니다.  \n- 때로는 **운영체제**(윈도우, 리눅스, 안드로이드 등)를 포함하여 PC나 기업용 소프트웨어가 동작할 **환경**을 만들어주기도 합니다.  \n  - 예를 들어 TV, 태블릿처럼 임베디드 OS 위에서 다양한 앱이 동작함.\n\n> **핵심 포인트**:  \n> PC나 서버용 소프트웨어는 사용자 입력과 데이터 처리를 중심으로 하지만, 임베디드 소프트웨어는 **하드웨어 조작**과 **실시간 제어**가 핵심입니다.  \n{: .prompt-info }\n\n\n## 임베디드 소프트웨어 엔지니어의 업무\n\n임베디드 소프트웨어 엔지니어는 **하드웨어와 소프트웨어**가 결합된 시스템을 개발합니다.  \n1. **사양 검토 및 설계**  \n2. **프로그래밍** (드라이버, 펌웨어, OS, 라이브러리 등)  \n3. **테스트 및 검증** (소프트웨어 단위 테스트, 하드웨어·시스템 테스트)  \n4. **개발 환경 및 검증 환경 구축**  \n\n이러한 **엔지니어링 작업**을 하는 이들이 곧 **임베디드 소프트웨어 엔지니어**입니다.  \n- 제조사, 시스템 통합(SI) 업체, **소프트웨어 하우스** 등 다양한 조직에 소속될 수 있습니다.  \n- 대규모 프로젝트에선 **모듈** 단위로 나눠 개발하며, **신입/초급 엔지니어**는 보통 작은 부분이나 특정 기능에 집중하게 됩니다.  \n\n> **벽돌을 쌓는 단순 작업**이 아니라, **큰 프로젝트의 일부를 책임지는** 과정임을 인식하면 좋습니다.  \n{: .prompt-warning }\n\n### 엔지니어의 성장 경로\n\n- **초급**: 간단한 기능 구현, 단위 테스트, 버그 수정 등  \n- **중급**: 모듈 설계, 시스템 전반 이해, 다른 팀과 협업  \n- **고급**: 임베디드 시스템 아키텍트, 프로젝트 매니저, 도메인 스페셜리스트 등으로 확장\n\n임베디드 소프트웨어 엔지니어는 **본인의 전문 기술**을 통해 기업과 제품에 **가치**를 더합니다.  \n하드웨어에 가까운 **드라이버** 개발부터, **테스트 자동화 환경** 구축, **안드로이드** 등 특정 OS 기반 개발까지, 여러 분야에서 활약할 수 있습니다.\n\n\n## 결론\n\n---\n\n임베디드 시스템은 **하드웨어와 소프트웨어**가 밀접하게 작동하여, 우리가 일상적으로 접하는 기계와 장치를 움직이는 핵심입니다.  \n임베디드 소프트웨어 엔지니어는 임베디드 시스템의 **설계, 프로그래밍, 테스트** 등을 수행하게됩니다.\n{: .prompt-info }\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }\n",
    "date": "2024-12-21",
    "tags": [
      "Embedded System",
      "임베디드 엔지니어 교과서"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-21-------1_chunk_0",
        "text": "[임베교과서] 1장 임베디드 소프트웨어 엔지니어의 업무\n\n# 임베디드 소프트웨어 엔지니어의 업무\n\n**임베디드 시스템**은 우리가 일상적으로 사용하는 수많은 기기와 장치에 탑재되어 있습니다.  \n인터폰, 조명, 에어컨, 공기청정기, 엘리베이터 등 많은 제품이 **임베디드 시스템**으로 동작합니다.  \n\n이번 장에서는 임베디드 시스템을 개발하는 **임베디드 소프트웨어 엔지니어**는 어떤 역할을 수행하는지,   \n그리고 임베디드 시스템은 어떻게 구성되어 있는지 알아보겠습니다.  \n\n---\n\n## 임베디드 시스템이란?\n\n임베디드 시스템은 **마이크로컴퓨터**나 **마이크로컨트롤러(MCU)**가 내장된 기계나 장치를 말합니다.  \nPC나 서버처럼 사람의 입력을 받아 정보를 처리하기도 하지만, **센서**와 **액추에이터**를 통해 외부 환경과 상호작용하며 **자율적으로** 동작하는 경우가 많습니다.\n\n> **액추에이터(actuator)**  \n> 제어 기기에서 출력된 신호를 바탕으로 실제 물리적 동작을 수행하는 기계 장치를 말합니다.  \n{: .prompt-info }\n\n### 임베디드 시스템의 특징: NTCR\n\n임베디드 시스템은 크게 **네 가지** 공통된 특징으로 정리할 수 있습니다.  \n`Nature`, `Time`, `Constraint`, `Reliability` — 이를 줄여서 **NTCR**이라고 부릅니다.\n\n1. **Nature**  \n   - 임베디드 시스템은 **외부 세계의 변화를 감지**(센서)하고, MCU에서 처리한 결과를 **외부로 피드백**(액추에이터)하는 작업을 수행합니다.",
        "index": 0
      },
      {
        "id": "2024-12-21-------1_chunk_1",
        "text": "**Nature**  \n   - 임베디드 시스템은 **외부 세계의 변화를 감지**(센서)하고, MCU에서 처리한 결과를 **외부로 피드백**(액추에이터)하는 작업을 수행합니다.  \n   - **자동차**, **로봇** 등 모션을 다루는 시스템에서는 **어떻게 감지하고, 어떻게 피드백할지**가 매우 중요합니다.  \n     이런 시스템의 경우 PC 기반의 정보 시스템과 달리, **제어 모델**을 통해 하드웨어를 직접 제어한다는 큰 특징이 있습니다.\n\n2. **Time**  \n   - 임베디드 시스템은 대부분 **실시간성(Real-Time)**이 요구됩니다.  \n   - 예를 들어, 스마트폰이나 PC는 상황에 따라 응답이 조금 느려져도 큰 문제가 되지 않을 수 있지만, 임베디드 시스템은 **목적에 맞춰 즉시** 작동해야 합니다.  \n   - 요구되는 실시간성은 기기에 따라 다릅니다.  \n     - **하드 리얼타임(Hard Real-Time)**: 자동차·항공기처럼 **밀리초 단위**의 데드라인을 반드시 준수해야 함.  \n     - **소프트 리얼타임(Soft Real-Time)**: 음악 플레이어나 영상 재생처럼 **일정 정도 지연**이 허용됨.\n\n3. **Constraint**  \n   - 임베디드 시스템은 **크기, 무게, 비용, 전력, 발열 등** 다양한 제약 조건을 충족해야 합니다.  \n   - 일반 PC처럼 **고성능**만 추구하는 것이 아니라, **적정 성능**을 필요로 하며 제한된 환경에서 **최적화**된 구성을 갖추어야 합니다.\n\n4.",
        "index": 1
      },
      {
        "id": "2024-12-21-------1_chunk_2",
        "text": "족해야 합니다.  \n   - 일반 PC처럼 **고성능**만 추구하는 것이 아니라, **적정 성능**을 필요로 하며 제한된 환경에서 **최적화**된 구성을 갖추어야 합니다.\n\n4. **Reliability**  \n   - **신뢰성**은 주어진 조건에서 정해진 시간 안에 **요구된 기능**을 수행해 낼 수 있는 능력입니다.  \n   - 임베디드 시스템은 특정 기기나 장치가 **안정적으로 동작**해야 하므로, 설계 단계부터 **품질**을 고려해야 합니다.  \n\n---\n\n## 임베디드 소프트웨어란?\n\n**임베디드 소프트웨어**는 말 그대로 임베디드 시스템에 탑재되어, **MCU를 구동**하는 **프로그램**을 뜻합니다.  \n- 일반 PC나 서버용 소프트웨어와 달리, **하드웨어**와 밀접하게 연동되어 있습니다.  \n- **펌웨어(Firmware)**라는 용어로도 불리며, 운영체제(OS)와 펌웨어를 통틀어 임베디드 소프트웨어라고 하기도 합니다.\n\n### 임베디드 소프트웨어의 특징\n\n- 임베디드 소프트웨어는 **직접 하드웨어를 제어**합니다.  \n- 때로는 **운영체제**(윈도우, 리눅스, 안드로이드 등)를 포함하여 PC나 기업용 소프트웨어가 동작할 **환경**을 만들어주기도 합니다.  \n  - 예를 들어 TV, 태블릿처럼 임베디드 OS 위에서 다양한 앱이 동작함.\n\n> **핵심 포인트**:  \n> PC나 서버용 소프트웨어는 사용자 입력과 데이터 처리를 중심으로 하지만, 임베디드 소프트웨어는 **하드웨어 조작**과 **실시간 제어**가 핵심입니다.",
        "index": 2
      },
      {
        "id": "2024-12-21-------1_chunk_3",
        "text": "*핵심 포인트**:  \n> PC나 서버용 소프트웨어는 사용자 입력과 데이터 처리를 중심으로 하지만, 임베디드 소프트웨어는 **하드웨어 조작**과 **실시간 제어**가 핵심입니다.  \n{: .prompt-info }\n\n\n## 임베디드 소프트웨어 엔지니어의 업무\n\n임베디드 소프트웨어 엔지니어는 **하드웨어와 소프트웨어**가 결합된 시스템을 개발합니다.  \n1. **사양 검토 및 설계**  \n2. **프로그래밍** (드라이버, 펌웨어, OS, 라이브러리 등)  \n3. **테스트 및 검증** (소프트웨어 단위 테스트, 하드웨어·시스템 테스트)  \n4. **개발 환경 및 검증 환경 구축**  \n\n이러한 **엔지니어링 작업**을 하는 이들이 곧 **임베디드 소프트웨어 엔지니어**입니다.  \n- 제조사, 시스템 통합(SI) 업체, **소프트웨어 하우스** 등 다양한 조직에 소속될 수 있습니다.  \n- 대규모 프로젝트에선 **모듈** 단위로 나눠 개발하며, **신입/초급 엔지니어**는 보통 작은 부분이나 특정 기능에 집중하게 됩니다.  \n\n> **벽돌을 쌓는 단순 작업**이 아니라, **큰 프로젝트의 일부를 책임지는** 과정임을 인식하면 좋습니다.",
        "index": 3
      },
      {
        "id": "2024-12-21-------1_chunk_4",
        "text": "지니어**는 보통 작은 부분이나 특정 기능에 집중하게 됩니다.  \n\n> **벽돌을 쌓는 단순 작업**이 아니라, **큰 프로젝트의 일부를 책임지는** 과정임을 인식하면 좋습니다.  \n{: .prompt-warning }\n\n### 엔지니어의 성장 경로\n\n- **초급**: 간단한 기능 구현, 단위 테스트, 버그 수정 등  \n- **중급**: 모듈 설계, 시스템 전반 이해, 다른 팀과 협업  \n- **고급**: 임베디드 시스템 아키텍트, 프로젝트 매니저, 도메인 스페셜리스트 등으로 확장\n\n임베디드 소프트웨어 엔지니어는 **본인의 전문 기술**을 통해 기업과 제품에 **가치**를 더합니다.  \n하드웨어에 가까운 **드라이버** 개발부터, **테스트 자동화 환경** 구축, **안드로이드** 등 특정 OS 기반 개발까지, 여러 분야에서 활약할 수 있습니다.\n\n\n## 결론\n\n---\n\n임베디드 시스템은 **하드웨어와 소프트웨어**가 밀접하게 작동하여, 우리가 일상적으로 접하는 기계와 장치를 움직이는 핵심입니다.  \n임베디드 소프트웨어 엔지니어는 임베디드 시스템의 **설계, 프로그래밍, 테스트** 등을 수행하게됩니다.\n{: .prompt-info }\n\n---\n\n> 위 내용은 **제이펍**의 \"**임베디드 엔지니어 교과서**\"를 읽고 공부한 것을 정리한 글입니다.  \n> 저자명 : 와타나베 노보루, 마키노 신지 / 역자명 : 정인식\n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-20-12",
    "title": "[혼공컴운] 12장 프로세스 동기화",
    "path": "/2024/12/20/12장-프로세스-동기화/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 12-1 동기화란\n\n---\n\n## 동기화의 의미\n\n**프로세스 동기화**란 여러 프로세스의 **수행 시기**를 맞추는 것을 의미합니다.  \n\n1. **실행 순서 제어**: 프로세스를 **올바른 순서**대로 실행합니다.  \n2. **상호 배제**: 동시에 접근해서는 안 되는 자원에 **하나의 프로세스만 접근**하도록 합니다.\n\n---\n\n### 동기화 문제 예시\n\n동기화가 제대로 이루어지지 않을 경우의 문제를 간단한 수도 코드로 살펴보겠습니다.\n\n```\n공유자원 shared_var = 0\n\n함수 increment():\n    반복 10000번:\n        shared_var += 1  // 공유 자원 증가\n\n메인:\n    스레드 t1 = increment 실행\n    스레드 t2 = increment 실행\n\n    t1과 t2가 완료될 때까지 기다림\n\n    출력: shared_var 값\n\n```\n\n> **출력 결과**  \n> 예상한 값 20000이 출력되지 않을 수 있습니다.  \n> **두 스레드가 동시에 공유 변수**에 접근하기 때문에 **레이스 컨디션**이 발생하기 때문입니다.  \n{: .prompt-warning }\n\n---\n\n## 임계 구역과 공유 자원  \n\n- **임계 구역**: 두 개 이상의 프로세스가 동시에 실행되어서는 안 되는 영역.  \n- **공유 자원**: 여러 프로세스가 공동으로 사용하는 변수, 파일, 장치 등.\n\n---\n\n### 레이스 컨디션 (Race Condition)\n\n여러 프로세스가 **동시에 임계 구역에 접근**하면 문제가 발생합니다. 이를 **레이스 컨디션**이라고 합니다.\n\n운영체제는 이러한 문제를 해결하기 위해 **3가지 원칙**을 적용합니다.\n\n1. **상호 배제 (Mutual Exclusion)**  \n   - 한 프로세스가 임계 구역에 진입했다면 다른 프로세스는 **진입할 수 없습니다**.  \n\n2. **진행 (Progress)**  \n   - 임계 구역에 **진입하려는 프로세스**가 있다면, 반드시 **진입할 수 있어야 합니다**.  \n\n3. **유한 대기 (Bounded Waiting)**  \n   - 한 프로세스가 **무한정 대기하지 않도록** 보장해야 합니다.\n\n---\n\n# 12-2 동기화 기법\n\n프로세스 동기화를 위한 대표적인 방법은 **뮤텍스 락**, **세마포**, **모니터**가 있습니다.\n\n---\n\n## 뮤텍스 락 (Mutex Lock)\n\n**뮤텍스 락**은 **상호 배제**를 위한 가장 기본적인 기법입니다.  \n화장실에 비유하자면, **한 명씩만 사용할 수 있도록 자물쇠**를 거는 방식입니다.\n\n### 구현 방식  \n\n- **전역 변수**: 자물쇠 역할을 하는 `lock`.  \n- **acquire 함수**: 임계 구역에 **진입 전** 호출하여 잠금을 설정합니다.  \n- **release 함수**: 임계 구역에서 작업을 마친 후 잠금을 해제합니다.\n\n---\n\n### 뮤텍스 락 예시\n\n```cpp\n#include <iostream>\n#include <thread>\nusing namespace std;\n\nint shared_var = 0;       // 공유 자원\nbool lock = false;        // 뮤텍스 역할의 전역 변수\n\nvoid acquire() {\n    while (lock);         // lock이 true일 동안 대기 (busy waiting)\n    lock = true;          // 잠금 설정\n}\n\nvoid release() {\n    lock = false;         // 잠금 해제\n}\n\nvoid increment() {\n    for (int i = 0; i < 10000; i++) {\n        acquire();        // 임계 구역 잠금\n        shared_var++;     // 공유 자원 증가\n        release();        // 임계 구역 잠금 해제\n    }\n}\n\nint main() {\n    thread t1(increment);\n    thread t2(increment);\n\n    t1.join();\n    t2.join();\n\n    cout << \"공유 자원의 값: \" << shared_var << endl;\n    return 0;\n}\n\n```\n\n> **단점**  \n> 뮤텍스 락은 **busy waiting**을 발생시킬 수 있습니다. 즉, 잠긴 상태를 **반복적으로 확인**해야 합니다.  \n{: .prompt-warning }\n\n---\n\n## 세마포 (Semaphore)\n\n**세마포**는 뮤텍스 락을 **일반화**한 방식입니다.  \n\n- **이진 세마포**: 뮤텍스와 동일하게 **하나의 자원**을 보호합니다.  \n- **카운팅 세마포**: **여러 개의 자원**을 동시에 관리할 수 있습니다.\n\n---\n\n### 세마포 구현 예시\n\n```cpp\n#include <iostream>\n#include <thread>\nusing namespace std;\n\nint shared_var = 0;           // 공유 자원\nint S = 3;                    // 세마포 변수\n\nvoid wait() {\n    while (S <= 0);           // 자원이 없으면 busy waiting\n    S--;                      // 자원 획득\n}\n\nvoid signal() {\n    S++;                      // 자원 반납\n}\n\nvoid increment() {\n    for (int i = 0; i < 10000; i++) {\n        wait();               // 자원 획득\n        shared_var++;         // 임계 구역 접근 (공유 자원 증가)\n        signal();             // 자원 반납\n    }\n}\n\nint main() {\n    thread t1(increment);\n    thread t2(increment);\n    thread t3(increment);\n    thread t4(increment);\n    thread t5(increment);\n\n    t1.join();\n    t2.join();\n    t3.join();\n    t4.join();\n    t5.join();\n\n    cout << \"공유 자원의 값: \" << shared_var << endl;\n    return 0;\n}\n```\n\n> 세마포는 뮤텍스와 달리 **여러 개의 자원**을 동시에 관리할 수 있습니다.  \n> 위 코드에선 5개의 스레드가 실행되지만, 3개의 스레드만 공유자원에 접근할 수 있게 됩니다.\n{: .prompt-tip }\n\n---\n\n## 모니터 (Monitor)\n\n**모니터**는 **세마포**에 비해 **더 간편**하고 **안전한 동기화 기법**입니다.  \n\n- **정의**: 공유 자원과 자원 접근 인터페이스를 **하나의 객체**로 묶어 관리합니다.  \n- **특징**: 프로세스는 반드시 **모니터 인터페이스**를 통해서만 공유 자원에 접근할 수 있습니다.  \n\n---\n\n## 동기화 기법 비교\n\n| **구분**      | **뮤텍스 락**             | **세마포**                         | **모니터**                      |\n| ------------- | ------------------------- | ---------------------------------- | ------------------------------- |\n| **자원 개수** | 하나만                    | 여러 가지 가능                     | 여러 가지 가능                  |\n| **사용법**    | 명시적으로 잠금/해제 설정 | 자원 획득(`wait`)과 반납(`signal`) | 큐를 사용해 자동으로 관리       |\n| **단점**      | busy waiting 발생 가능    | 구현 복잡도 증가                   | 구현이 복잡하지만 사용자 친화적 |\n\n---\n\n> **모니터**는 공유 자원 접근을 보다 **편리하게 관리**할 수 있는 고수준 동기화 기법입니다.  \n{: .prompt-tip }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-20",
    "tags": [
      "동기화",
      "운영체제",
      "뮤텍스",
      "세마포",
      "모니터"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-20-12_chunk_0",
        "text": "[혼공컴운] 12장 프로세스 동기화\n\n# 12-1 동기화란\n\n---\n\n## 동기화의 의미\n\n**프로세스 동기화**란 여러 프로세스의 **수행 시기**를 맞추는 것을 의미합니다.  \n\n1. **실행 순서 제어**: 프로세스를 **올바른 순서**대로 실행합니다.  \n2. **상호 배제**: 동시에 접근해서는 안 되는 자원에 **하나의 프로세스만 접근**하도록 합니다.\n\n---\n\n### 동기화 문제 예시\n\n동기화가 제대로 이루어지지 않을 경우의 문제를 간단한 수도 코드로 살펴보겠습니다.\n\n```\n공유자원 shared_var = 0\n\n함수 increment():\n    반복 10000번:\n        shared_var += 1  // 공유 자원 증가\n\n메인:\n    스레드 t1 = increment 실행\n    스레드 t2 = increment 실행\n\n    t1과 t2가 완료될 때까지 기다림\n\n    출력: shared_var 값\n\n```\n\n> **출력 결과**  \n> 예상한 값 20000이 출력되지 않을 수 있습니다.  \n> **두 스레드가 동시에 공유 변수**에 접근하기 때문에 **레이스 컨디션**이 발생하기 때문입니다.  \n{: .prompt-warning }\n\n---\n\n## 임계 구역과 공유 자원  \n\n- **임계 구역**: 두 개 이상의 프로세스가 동시에 실행되어서는 안 되는 영역.  \n- **공유 자원**: 여러 프로세스가 공동으로 사용하는 변수, 파일, 장치 등.\n\n---\n\n### 레이스 컨디션 (Race Condition)\n\n여러 프로세스가 **동시에 임계 구역에 접근**하면 문제가 발생합니다.",
        "index": 0
      },
      {
        "id": "2024-12-20-12_chunk_1",
        "text": "공동으로 사용하는 변수, 파일, 장치 등.\n\n---\n\n### 레이스 컨디션 (Race Condition)\n\n여러 프로세스가 **동시에 임계 구역에 접근**하면 문제가 발생합니다. 이를 **레이스 컨디션**이라고 합니다.\n\n운영체제는 이러한 문제를 해결하기 위해 **3가지 원칙**을 적용합니다.\n\n1. **상호 배제 (Mutual Exclusion)**  \n   - 한 프로세스가 임계 구역에 진입했다면 다른 프로세스는 **진입할 수 없습니다**.  \n\n2. **진행 (Progress)**  \n   - 임계 구역에 **진입하려는 프로세스**가 있다면, 반드시 **진입할 수 있어야 합니다**.  \n\n3. **유한 대기 (Bounded Waiting)**  \n   - 한 프로세스가 **무한정 대기하지 않도록** 보장해야 합니다.\n\n---\n\n# 12-2 동기화 기법\n\n프로세스 동기화를 위한 대표적인 방법은 **뮤텍스 락**, **세마포**, **모니터**가 있습니다.\n\n---\n\n## 뮤텍스 락 (Mutex Lock)\n\n**뮤텍스 락**은 **상호 배제**를 위한 가장 기본적인 기법입니다.  \n화장실에 비유하자면, **한 명씩만 사용할 수 있도록 자물쇠**를 거는 방식입니다.\n\n### 구현 방식  \n\n- **전역 변수**: 자물쇠 역할을 하는 `lock`.  \n- **acquire 함수**: 임계 구역에 **진입 전** 호출하여 잠금을 설정합니다.",
        "index": 1
      },
      {
        "id": "2024-12-20-12_chunk_2",
        "text": ".\n\n### 구현 방식  \n\n- **전역 변수**: 자물쇠 역할을 하는 `lock`.  \n- **acquire 함수**: 임계 구역에 **진입 전** 호출하여 잠금을 설정합니다.",
        "index": 2
      },
      {
        "id": "2024-12-20-12_chunk_3",
        "text": ".\n\n### 구현 방식  \n\n- **전역 변수**: 자물쇠 역할을 하는 `lock`.  \n- **acquire 함수**: 임계 구역에 **진입 전** 호출하여 잠금을 설정합니다.",
        "index": 3
      },
      {
        "id": "2024-12-20-12_chunk_4",
        "text": ".\n\n### 구현 방식  \n\n- **전역 변수**: 자물쇠 역할을 하는 `lock`.  \n- **acquire 함수**: 임계 구역에 **진입 전** 호출하여 잠금을 설정합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-20-15",
    "title": "[혼공컴운] 15장 파일 시스템",
    "path": "/2024/12/20/15장-파일-시스템/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 15-1 파일과 디렉터리\n\n---\n\n## 파일\n\n**파일(File)**은 **보조기억장치**에 저장된 관련 정보의 집합입니다.  \n즉, 의미 있고 관련 있는 데이터를 묶어 놓은 **논리적 단위**입니다.\n\n- **파일 속성 (Attribute)**:  \n  파일의 이름, 크기, 생성일, 수정일, 접근 권한 등 **부가 정보**를 말합니다.  \n  이러한 부가 정보를 **메타데이터 (Metadata)**라고 부릅니다.\n\n---\n\n## 디렉터리\n\n파일을 **효율적으로 관리**하기 위해 **디렉터리(Directory)**를 사용합니다.  \n**디렉터리**는 파일들을 논리적으로 묶어서 관리하는 구조입니다.  \n\n- **윈도우**: 디렉터리를 **폴더(Folder)**라고 부릅니다.  \n- **디렉터리 구조**:  \n  - **단일 레벨 디렉터리**: 하나의 디렉터리만 존재.  \n  - **트리 구조 디렉터리**: 여러 계층의 디렉터리를 가지며 **트리 형태**로 확장됩니다.\n\n> **경로 (Path)**:  \n> 파일이나 디렉터리를 찾기 위한 **위치 정보**입니다.  \n> 트리 구조의 등장으로 **절대 경로**와 **상대 경로** 개념이 생겨났습니다.  \n{: .prompt-tip }\n\n---\n\n# 15-2 파일 시스템\n\n파일 시스템은 **파일과 디렉터리**를 보조기억장치에 **어떻게 할당하고 관리**하는지에 대한 방식을 정의합니다.\n\n---\n\n## 파티셔닝과 포매팅\n\n### 파티셔닝 (Partitioning)\n\n- **정의**: 보조기억장치를 여러 개의 **논리적 영역**으로 구획하는 작업입니다.  \n- **파티션**: 나눠진 논리적 영역을 **파티션**이라고 합니다.\n\n### 포매팅 (Formatting)\n\n- **정의**: 파일 시스템을 설정해 **파일을 저장하고 관리**할 수 있도록 준비하는 작업입니다.  \n- **논리적 포매팅**: 파일 시스템을 생성하는 포매팅으로, 새로운 데이터를 저장할 준비를 합니다.\n\n> **저수준 포매팅**은 공장에서 수행되는 **물리적 포매팅**이며, 논리적 포매팅과 다릅니다.  \n{: .prompt-info }\n\n---\n\n## 파일 할당 방법\n\n운영체제는 파일을 **블록 단위**로 읽고 씁니다.  \n파일이 보조기억장치에 저장될 때 사용하는 **할당 방법**은 다음과 같습니다.\n\n---\n\n### 1. 연속 할당 (Contiguous Allocation)\n\n- **정의**: 파일을 **연속된 블록**에 저장하는 방식입니다.  \n- **특징**:  \n  - 파일의 **첫 번째 블록 주소**와 **길이**만 알면 접근이 가능합니다.  \n- **단점**:  \n  - **외부 단편화** 문제가 발생할 수 있습니다.\n\n> Contiguous가 오타인 줄 알았는데 정말 있는 단어였습니다..\n\n---\n\n### 2. 연결 할당 (Linked Allocation)\n\n- **정의**: 각 블록에 **다음 블록의 주소**를 저장하는 방식입니다.  \n- **특징**:  \n  - 파일 블록들은 **연결 리스트** 형태로 관리됩니다.  \n- **단점**:  \n  - 랜덤 접근이 불가능합니다. (첫 번째 블록부터 차례대로 접근)  \n  - **블록 손상** 시 그 이후 블록에 접근할 수 없습니다.\n\n---\n\n### 3. 색인 할당 (Indexed Allocation)\n\n- **정의**: 파일의 모든 블록 주소를 **색인 블록**에 저장하는 방식입니다.  \n- **특징**:  \n  - **색인 블록**을 통해 파일의 블록들을 **랜덤 접근**할 수 있습니다.\n\n---\n\n## 파일 시스템 살펴보기\n\n---\n\n### FAT 파일 시스템\n\n**FAT (File Allocation Table)**은 **연결 할당**을 보완한 파일 시스템입니다.\n\n- **구조**: 각 블록의 **다음 블록 주소**를 **테이블 형태**로 관리합니다.  \n- **파일 접근 방식**:  \n  - **파일 할당 테이블**을 참조해 첫 번째 블록 주소에서 시작하여 파일을 읽습니다.\n\n---\n\n#### FAT 파일 시스템 예시\n\n| **블록 번호** | **파일 할당 테이블 (FAT)** |\n| ------------- | -------------------------- |\n| 1             | 3                          |\n| 2             | -1                         |\n| 3             | 5                          |\n| 4             | -1                         |\n| 5             | -1                         |\n\n1. 파일 `A`는 **블록 1 → 3 → 5**에 저장됩니다.  \n2. **-1**은 파일의 **끝**을 나타냅니다.\n\n---\n\n### 유닉스 파일 시스템 (UNIX File System)\n\n유닉스 파일 시스템은 **색인 할당** 기반이며, **색인 블록**을 **i-node (index-node)**라 부릅니다.\n\n- **i-node**: 파일의 **메타데이터**와 **데이터 블록의 주소**를 저장합니다.  \n- **특징**: 색인 블록(i-node)에 파일의 블록 번호가 저장되므로 **랜덤 접근**이 가능합니다.\n\n---\n\n#### 유닉스 파일 시스템 예시\n\n| **i-node** | **데이터 블록 주소** |\n| ---------- | -------------------- |\n| 5          | 10, 12, 15           |\n\n1. 파일 `A`의 **i-node**는 블록 `5`에 저장됩니다.  \n2. 파일 `A`는 **블록 10 → 12 → 15**에 데이터가 저장됩니다.\n\n---\n\n> **비교**:  \n> - **FAT 파일 시스템**: 연결 할당을 테이블로 구현. 단순하지만 대용량 파일 접근 시 비효율적입니다.  \n> - **유닉스 파일 시스템**: 색인 할당 기반으로, **i-node**를 통해 빠르고 효율적으로 접근할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-20",
    "tags": [
      "파일 시스템",
      "FAT",
      "유닉스 파일 시스템",
      "디렉터리"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-20-15_chunk_0",
        "text": "[혼공컴운] 15장 파일 시스템\n\n# 15-1 파일과 디렉터리\n\n---\n\n## 파일\n\n**파일(File)**은 **보조기억장치**에 저장된 관련 정보의 집합입니다.  \n즉, 의미 있고 관련 있는 데이터를 묶어 놓은 **논리적 단위**입니다.\n\n- **파일 속성 (Attribute)**:  \n  파일의 이름, 크기, 생성일, 수정일, 접근 권한 등 **부가 정보**를 말합니다.  \n  이러한 부가 정보를 **메타데이터 (Metadata)**라고 부릅니다.\n\n---\n\n## 디렉터리\n\n파일을 **효율적으로 관리**하기 위해 **디렉터리(Directory)**를 사용합니다.  \n**디렉터리**는 파일들을 논리적으로 묶어서 관리하는 구조입니다.  \n\n- **윈도우**: 디렉터리를 **폴더(Folder)**라고 부릅니다.  \n- **디렉터리 구조**:  \n  - **단일 레벨 디렉터리**: 하나의 디렉터리만 존재.  \n  - **트리 구조 디렉터리**: 여러 계층의 디렉터리를 가지며 **트리 형태**로 확장됩니다.\n\n> **경로 (Path)**:  \n> 파일이나 디렉터리를 찾기 위한 **위치 정보**입니다.  \n> 트리 구조의 등장으로 **절대 경로**와 **상대 경로** 개념이 생겨났습니다.",
        "index": 0
      },
      {
        "id": "2024-12-20-15_chunk_1",
        "text": "**경로 (Path)**:  \n> 파일이나 디렉터리를 찾기 위한 **위치 정보**입니다.  \n> 트리 구조의 등장으로 **절대 경로**와 **상대 경로** 개념이 생겨났습니다.  \n{: .prompt-tip }\n\n---\n\n# 15-2 파일 시스템\n\n파일 시스템은 **파일과 디렉터리**를 보조기억장치에 **어떻게 할당하고 관리**하는지에 대한 방식을 정의합니다.\n\n---\n\n## 파티셔닝과 포매팅\n\n### 파티셔닝 (Partitioning)\n\n- **정의**: 보조기억장치를 여러 개의 **논리적 영역**으로 구획하는 작업입니다.  \n- **파티션**: 나눠진 논리적 영역을 **파티션**이라고 합니다.\n\n### 포매팅 (Formatting)\n\n- **정의**: 파일 시스템을 설정해 **파일을 저장하고 관리**할 수 있도록 준비하는 작업입니다.  \n- **논리적 포매팅**: 파일 시스템을 생성하는 포매팅으로, 새로운 데이터를 저장할 준비를 합니다.\n\n> **저수준 포매팅**은 공장에서 수행되는 **물리적 포매팅**이며, 논리적 포매팅과 다릅니다.  \n{: .prompt-info }\n\n---\n\n## 파일 할당 방법\n\n운영체제는 파일을 **블록 단위**로 읽고 씁니다.  \n파일이 보조기억장치에 저장될 때 사용하는 **할당 방법**은 다음과 같습니다.\n\n---\n\n### 1. 연속 할당 (Contiguous Allocation)\n\n- **정의**: 파일을 **연속된 블록**에 저장하는 방식입니다.  \n- **특징**:  \n  - 파일의 **첫 번째 블록 주소**와 **길이**만 알면 접근이 가능합니다.",
        "index": 1
      },
      {
        "id": "2024-12-20-15_chunk_2",
        "text": "- **정의**: 파일을 **연속된 블록**에 저장하는 방식입니다.  \n- **특징**:  \n  - 파일의 **첫 번째 블록 주소**와 **길이**만 알면 접근이 가능합니다.  \n- **단점**:  \n  - **외부 단편화** 문제가 발생할 수 있습니다.\n\n> Contiguous가 오타인 줄 알았는데 정말 있는 단어였습니다..\n\n---\n\n### 2. 연결 할당 (Linked Allocation)\n\n- **정의**: 각 블록에 **다음 블록의 주소**를 저장하는 방식입니다.  \n- **특징**:  \n  - 파일 블록들은 **연결 리스트** 형태로 관리됩니다.  \n- **단점**:  \n  - 랜덤 접근이 불가능합니다. (첫 번째 블록부터 차례대로 접근)  \n  - **블록 손상** 시 그 이후 블록에 접근할 수 없습니다.\n\n---\n\n### 3. 색인 할당 (Indexed Allocation)\n\n- **정의**: 파일의 모든 블록 주소를 **색인 블록**에 저장하는 방식입니다.  \n- **특징**:  \n  - **색인 블록**을 통해 파일의 블록들을 **랜덤 접근**할 수 있습니다.\n\n---\n\n## 파일 시스템 살펴보기\n\n---\n\n### FAT 파일 시스템\n\n**FAT (File Allocation Table)**은 **연결 할당**을 보완한 파일 시스템입니다.\n\n- **구조**: 각 블록의 **다음 블록 주소**를 **테이블 형태**로 관리합니다.",
        "index": 2
      },
      {
        "id": "2024-12-20-15_chunk_3",
        "text": "le Allocation Table)**은 **연결 할당**을 보완한 파일 시스템입니다.\n\n- **구조**: 각 블록의 **다음 블록 주소**를 **테이블 형태**로 관리합니다.  \n- **파일 접근 방식**:  \n  - **파일 할당 테이블**을 참조해 첫 번째 블록 주소에서 시작하여 파일을 읽습니다.\n\n---\n\n#### FAT 파일 시스템 예시\n\n| **블록 번호** | **파일 할당 테이블 (FAT)** |\n| ------------- | -------------------------- |\n| 1             | 3                          |\n| 2             | -1                         |\n| 3             | 5                          |\n| 4             | -1                         |\n| 5             | -1                         |\n\n1. 파일 `A`는 **블록 1 → 3 → 5**에 저장됩니다.  \n2. **-1**은 파일의 **끝**을 나타냅니다.\n\n---\n\n### 유닉스 파일 시스템 (UNIX File System)\n\n유닉스 파일 시스템은 **색인 할당** 기반이며, **색인 블록**을 **i-node (index-node)**라 부릅니다.\n\n- **i-node**: 파일의 **메타데이터**와 **데이터 블록의 주소**를 저장합니다.",
        "index": 3
      },
      {
        "id": "2024-12-20-15_chunk_4",
        "text": "반이며, **색인 블록**을 **i-node (index-node)**라 부릅니다.\n\n- **i-node**: 파일의 **메타데이터**와 **데이터 블록의 주소**를 저장합니다.  \n- **특징**: 색인 블록(i-node)에 파일의 블록 번호가 저장되므로 **랜덤 접근**이 가능합니다.\n\n---\n\n#### 유닉스 파일 시스템 예시\n\n| **i-node** | **데이터 블록 주소** |\n| ---------- | -------------------- |\n| 5          | 10, 12, 15           |\n\n1. 파일 `A`의 **i-node**는 블록 `5`에 저장됩니다.  \n2. 파일 `A`는 **블록 10 → 12 → 15**에 데이터가 저장됩니다.\n\n---\n\n> **비교**:  \n> - **FAT 파일 시스템**: 연결 할당을 테이블로 구현. 단순하지만 대용량 파일 접근 시 비효율적입니다.  \n> - **유닉스 파일 시스템**: 색인 할당 기반으로, **i-node**를 통해 빠르고 효율적으로 접근할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-20-13",
    "title": "[혼공컴운] 13장 교착 상태",
    "path": "/2024/12/20/13장-교착-상태/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 13-1 교착 상태란\n\n---\n\n## 교착 상태의 개념\n\n**교착 상태(Deadlock)**란 두 개 이상의 프로세스가 서로 상대방이 가진 **자원**을 기다리면서,  \n더 이상 진행할 수 없는 **상태**를 의미합니다.\n\n> 간단히 말해 프로세스들이 서로 **서로의 자원**을 기다리며 **막혀버리는 상태**입니다.  \n{: .prompt-info }\n\n---\n\n## 식사하는 철학자 문제\n\n**식사하는 철학자 문제**는 교착 상태를 설명하는 고전적인 예시입니다.\n\n- **문제 상황**:  \n  다섯 명의 철학자가 **원형 테이블**에 앉아 있으며, 각 철학자는 **왼쪽과 오른쪽의 포크**를 사용해 식사합니다.  \n  만약, 모든 철학자가 왼쪽의 포크를 들고, 오른쪽의 포크를 사용하려 한다면 어느 누구도 식사를 할 수 없는 교착 상태가 발생할 수 있게 됩니다.\n\n---\n\n## 교착 상태 발생 조건\n\n교착 상태가 발생하는 **4가지 조건**은 다음과 같습니다.\n\n1. **상호 배제 (Mutual Exclusion)**  \n   - 공유 자원을 **한 번에 하나의 프로세스만 사용할 수 있습니다**.  \n   - 철학자 예시: **포크**는 한 명의 철학자만 사용할 수 있습니다.\n\n2. **점유와 대기 (Hold and Wait)**  \n   - 프로세스가 **이미 자원을 점유**한 상태에서 **다른 자원**을 기다립니다.  \n   - 철학자 예시: 한 철학자가 **한쪽 포크**를 들고, 다른 쪽 포크를 기다리는 상태입니다.\n\n3. **비선점 (No Preemption)**  \n   - 다른 프로세스의 자원을 **강제로 빼앗을 수 없습니다**.  \n   - 철학자 예시: 철학자는 다른 사람이 이미 사용 중인 포크를 **빼앗을 수 없습니다**.\n\n4. **원형 대기 (Circular Wait)**  \n   - 프로세스들이 서로 **순환적으로 자원**을 기다립니다.  \n   - 철학자 예시: 포크를 **시계 방향**으로 순서대로 잡으려다 보면 **순환 대기** 상태가 됩니다.\n\n> **교착 상태는 위 4가지 조건이 모두 만족될 때 발생합니다.**  \n{: .prompt-danger }\n\n---\n\n# 13-2 교착 상태 해결 방법\n\n---\n\n## 교착 상태 해결 접근법\n\n운영체제에서 교착 상태를 해결하는 방법은 크게 세 가지입니다.\n\n1. **교착 상태 예방**  \n2. **교착 상태 회피**  \n3. **교착 상태 검출 후 회복**  \n\n---\n\n## 교착 상태 예방\n\n**교착 상태 예방**은 교착 상태 발생 조건 4가지 중 **하나라도 제거**하는 방법입니다.\n\n### 1. 점유와 대기 제거  \n\n- 프로세스가 **모든 자원을 한꺼번에 할당**받도록 합니다.  \n- 철학자 예시: **두 개의 포크를 동시에 잡거나**, **아무것도 잡지 않습니다**.  \n\n> **단점**: 자원 활용률이 **낮아지며**, 많은 자원을 요구하는 프로세스가 자원을 할당받지 못하는 기아 상태가 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n### 2. 비선점 조건 제거  \n\n- 자원을 점유한 프로세스에서 **강제로 자원을 빼앗을 수 있도록** 합니다.  \n- **예시**: CPU는 선점이 가능하지만, 프린터 같은 자원은 빼앗기 어렵습니다.  \n\n> **단점**: 모든 자원이 선점 가능한 것은 아니므로 범용성이 떨어집니다.  \n{: .prompt-info }\n\n---\n\n### 3. 원형 대기 제거  \n\n- 자원에 **순서를 부여**하고, 순서대로 자원을 할당합니다.  \n- 철학자 예시: 포크에 번호를 붙이고, **낮은 번호부터 순서대로** 집게 합니다.\n\n> **비유**: 원형 테이블 대신 **일렬 테이블**에 앉아 순서대로 식사하는 상황입니다.  \n{: .prompt-tip }\n\n---\n\n## 교착 상태 회피\n\n**교착 상태 회피**는 교착 상태를 **피하기 위해** 자원을 신중하게 할당하는 방법입니다.\n\n- **안전 상태 (Safe State)**: 교착 상태가 발생하지 않고 **모든 프로세스가 종료될 수 있는 상태**입니다.  \n- **불안전 상태 (Unsafe State)**: 교착 상태가 발생할 수 있는 상태입니다.  \n- **안전 순서열**: 교착 상태 없이 프로세스에 자원을 할당할 수 있는 **순서**입니다.\n\n---\n\n### 예시\n\n| **프로세스** | **최대 요구량** | **현재 사용량** | **남은 필요량** |\n| ------------ | --------------- | --------------- | --------------- |\n| P1           | 7               | 5               | 2               |\n| P2           | 3               | 1               | 2               |\n| P3           | 9               | 6               | 3               |\n\n- 현재 자원이 충분하면, P2 → P1 → P3 순서로 할당할 수 있습니다.  \n- 이 순서를 **안전 순서열**이라고 합니다.  \n\n---\n\n## 교착 상태 검출 후 회복\n\n**교착 상태 검출**은 **주기적으로 상태를 검사**하고, 교착 상태가 발견되면 해결하는 방법입니다.\n\n1. **선점을 통한 회복**  \n   - 교착 상태를 해결하기 위해 **자원을 강제로 빼앗아** 특정 프로세스에 몰아줍니다.\n\n2. **프로세스 강제 종료**  \n   - 교착 상태에 있는 프로세스 중 일부를 **강제 종료**합니다.  \n   - 가장 단순하면서 확실한 방법입니다.\n\n> **단점**: 프로세스의 작업 내역이 손실되거나, **오버헤드**가 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n## 타조 알고리즘 (Ostrich Algorithm)\n\n**타조 알고리즘**은 교착 상태를 **무시**하는 방법입니다.  \n교착 상태가 발생해도 큰 문제가 없으면, **교착 상태를 해결하지 않는** 전략입니다.  \n\n문제의 발생 빈도나 심각성에 따라 최대 효율을 추구하는 엔지니어 입장에서는 때때로 이 방식이 적합할 때도 많습니다.\n\n> 타조가 위험이 발생해도 **머리를 모래에 박고** 무시하는 것과 비슷합니다.  \n{: .prompt-tip }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-20",
    "tags": [
      "교착 상태",
      "운영체제",
      "동기화"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-20-13_chunk_0",
        "text": "[혼공컴운] 13장 교착 상태\n\n# 13-1 교착 상태란\n\n---\n\n## 교착 상태의 개념\n\n**교착 상태(Deadlock)**란 두 개 이상의 프로세스가 서로 상대방이 가진 **자원**을 기다리면서,  \n더 이상 진행할 수 없는 **상태**를 의미합니다.\n\n> 간단히 말해 프로세스들이 서로 **서로의 자원**을 기다리며 **막혀버리는 상태**입니다.  \n{: .prompt-info }\n\n---\n\n## 식사하는 철학자 문제\n\n**식사하는 철학자 문제**는 교착 상태를 설명하는 고전적인 예시입니다.\n\n- **문제 상황**:  \n  다섯 명의 철학자가 **원형 테이블**에 앉아 있으며, 각 철학자는 **왼쪽과 오른쪽의 포크**를 사용해 식사합니다.  \n  만약, 모든 철학자가 왼쪽의 포크를 들고, 오른쪽의 포크를 사용하려 한다면 어느 누구도 식사를 할 수 없는 교착 상태가 발생할 수 있게 됩니다.\n\n---\n\n## 교착 상태 발생 조건\n\n교착 상태가 발생하는 **4가지 조건**은 다음과 같습니다.\n\n1. **상호 배제 (Mutual Exclusion)**  \n   - 공유 자원을 **한 번에 하나의 프로세스만 사용할 수 있습니다**.  \n   - 철학자 예시: **포크**는 한 명의 철학자만 사용할 수 있습니다.\n\n2. **점유와 대기 (Hold and Wait)**  \n   - 프로세스가 **이미 자원을 점유**한 상태에서 **다른 자원**을 기다립니다.  \n   - 철학자 예시: 한 철학자가 **한쪽 포크**를 들고, 다른 쪽 포크를 기다리는 상태입니다.\n\n3.",
        "index": 0
      },
      {
        "id": "2024-12-20-13_chunk_1",
        "text": "**이미 자원을 점유**한 상태에서 **다른 자원**을 기다립니다.  \n   - 철학자 예시: 한 철학자가 **한쪽 포크**를 들고, 다른 쪽 포크를 기다리는 상태입니다.\n\n3. **비선점 (No Preemption)**  \n   - 다른 프로세스의 자원을 **강제로 빼앗을 수 없습니다**.  \n   - 철학자 예시: 철학자는 다른 사람이 이미 사용 중인 포크를 **빼앗을 수 없습니다**.\n\n4. **원형 대기 (Circular Wait)**  \n   - 프로세스들이 서로 **순환적으로 자원**을 기다립니다.  \n   - 철학자 예시: 포크를 **시계 방향**으로 순서대로 잡으려다 보면 **순환 대기** 상태가 됩니다.\n\n> **교착 상태는 위 4가지 조건이 모두 만족될 때 발생합니다.**  \n{: .prompt-danger }\n\n---\n\n# 13-2 교착 상태 해결 방법\n\n---\n\n## 교착 상태 해결 접근법\n\n운영체제에서 교착 상태를 해결하는 방법은 크게 세 가지입니다.\n\n1. **교착 상태 예방**  \n2. **교착 상태 회피**  \n3. **교착 상태 검출 후 회복**  \n\n---\n\n## 교착 상태 예방\n\n**교착 상태 예방**은 교착 상태 발생 조건 4가지 중 **하나라도 제거**하는 방법입니다.\n\n### 1. 점유와 대기 제거  \n\n- 프로세스가 **모든 자원을 한꺼번에 할당**받도록 합니다.  \n- 철학자 예시: **두 개의 포크를 동시에 잡거나**, **아무것도 잡지 않습니다**.",
        "index": 1
      },
      {
        "id": "2024-12-20-13_chunk_2",
        "text": "점유와 대기 제거  \n\n- 프로세스가 **모든 자원을 한꺼번에 할당**받도록 합니다.  \n- 철학자 예시: **두 개의 포크를 동시에 잡거나**, **아무것도 잡지 않습니다**.  \n\n> **단점**: 자원 활용률이 **낮아지며**, 많은 자원을 요구하는 프로세스가 자원을 할당받지 못하는 기아 상태가 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n### 2. 비선점 조건 제거  \n\n- 자원을 점유한 프로세스에서 **강제로 자원을 빼앗을 수 있도록** 합니다.  \n- **예시**: CPU는 선점이 가능하지만, 프린터 같은 자원은 빼앗기 어렵습니다.  \n\n> **단점**: 모든 자원이 선점 가능한 것은 아니므로 범용성이 떨어집니다.  \n{: .prompt-info }\n\n---\n\n### 3. 원형 대기 제거  \n\n- 자원에 **순서를 부여**하고, 순서대로 자원을 할당합니다.  \n- 철학자 예시: 포크에 번호를 붙이고, **낮은 번호부터 순서대로** 집게 합니다.\n\n> **비유**: 원형 테이블 대신 **일렬 테이블**에 앉아 순서대로 식사하는 상황입니다.  \n{: .prompt-tip }\n\n---\n\n## 교착 상태 회피\n\n**교착 상태 회피**는 교착 상태를 **피하기 위해** 자원을 신중하게 할당하는 방법입니다.\n\n- **안전 상태 (Safe State)**: 교착 상태가 발생하지 않고 **모든 프로세스가 종료될 수 있는 상태**입니다.  \n- **불안전 상태 (Unsafe State)**: 교착 상태가 발생할 수 있는 상태입니다.",
        "index": 2
      },
      {
        "id": "2024-12-20-13_chunk_3",
        "text": ": 교착 상태가 발생하지 않고 **모든 프로세스가 종료될 수 있는 상태**입니다.  \n- **불안전 상태 (Unsafe State)**: 교착 상태가 발생할 수 있는 상태입니다.  \n- **안전 순서열**: 교착 상태 없이 프로세스에 자원을 할당할 수 있는 **순서**입니다.\n\n---\n\n### 예시\n\n| **프로세스** | **최대 요구량** | **현재 사용량** | **남은 필요량** |\n| ------------ | --------------- | --------------- | --------------- |\n| P1           | 7               | 5               | 2               |\n| P2           | 3               | 1               | 2               |\n| P3           | 9               | 6               | 3               |\n\n- 현재 자원이 충분하면, P2 → P1 → P3 순서로 할당할 수 있습니다.  \n- 이 순서를 **안전 순서열**이라고 합니다.  \n\n---\n\n## 교착 상태 검출 후 회복\n\n**교착 상태 검출**은 **주기적으로 상태를 검사**하고, 교착 상태가 발견되면 해결하는 방법입니다.\n\n1. **선점을 통한 회복**  \n   - 교착 상태를 해결하기 위해 **자원을 강제로 빼앗아** 특정 프로세스에 몰아줍니다.\n\n2. **프로세스 강제 종료**  \n   - 교착 상태에 있는 프로세스 중 일부를 **강제 종료**합니다.",
        "index": 3
      },
      {
        "id": "2024-12-20-13_chunk_4",
        "text": "결하기 위해 **자원을 강제로 빼앗아** 특정 프로세스에 몰아줍니다.\n\n2. **프로세스 강제 종료**  \n   - 교착 상태에 있는 프로세스 중 일부를 **강제 종료**합니다.  \n   - 가장 단순하면서 확실한 방법입니다.\n\n> **단점**: 프로세스의 작업 내역이 손실되거나, **오버헤드**가 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n## 타조 알고리즘 (Ostrich Algorithm)\n\n**타조 알고리즘**은 교착 상태를 **무시**하는 방법입니다.  \n교착 상태가 발생해도 큰 문제가 없으면, **교착 상태를 해결하지 않는** 전략입니다.  \n\n문제의 발생 빈도나 심각성에 따라 최대 효율을 추구하는 엔지니어 입장에서는 때때로 이 방식이 적합할 때도 많습니다.\n\n> 타조가 위험이 발생해도 **머리를 모래에 박고** 무시하는 것과 비슷합니다.  \n{: .prompt-tip }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-20-14",
    "title": "[혼공컴운] 14장 가상 메모리",
    "path": "/2024/12/20/14장-가상-메모리/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 14-1 연속 메모리 할당\n\n운영체제의 **메모리 관리** 방식 중 하나로, 프로세스에 **연속적인 메모리 공간**을 할당하는 방식을 설명합니다.  \n이 절에서는 **스와핑**, **메모리 할당 전략**, 그리고 **외부 단편화** 문제를 다룹니다.\n\n---\n\n## 스와핑 (Swapping)\n\n메모리에는 **실행 중인 프로세스**만이 적재되어야 합니다.  \n그런데 입출력 작업을 기다리거나 **오랫동안 사용되지 않는 프로세스**도 메모리에 있을 수 있습니다.  \n\n**스와핑**은 이러한 프로세스를 **보조기억장치**의 일부 영역으로 **옮겨서** 메모리를 확보하는 방식입니다.\n\n- **스왑 영역 (Swap Space)**: 보조기억장치의 스와핑을 위한 영역입니다.  \n- **스왑 아웃 (Swap Out)**: 프로세스를 **메모리 → 스왑 영역**으로 옮기는 동작입니다.  \n- **스왑 인 (Swap In)**: 프로세스를 **스왑 영역 → 메모리**로 다시 옮기는 동작입니다.  \n\n> 스왑된 프로세스는 **다른 물리 주소**에 적재될 수 있습니다.  \n{: .prompt-info }\n\n> **유닉스 기반 시스템**에서는 `free`, `top` 명령어를 사용해 **스왑 영역의 크기**를 확인할 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n## 메모리 할당 전략\n\n프로세스는 메모리의 **빈 공간**에 할당되어야 합니다.  \n여러 개의 빈 공간이 있을 때, 프로세스를 어디에 배치하는 것이 효율적일까요?  \n대표적인 방법은 **최초 적합**, **최적 적합**, **최악 적합**이 있습니다.\n\n---\n\n### 1. 최초 적합 (First Fit)\n\n- **동작 원리**: 메모리의 **빈 공간을 순서대로 검색**하며, **적합한 공간을 발견**하면 바로 할당합니다.  \n- **장점**: 검색 시간을 최소화하여 **빠른 할당**이 가능합니다.\n\n### 2. 최적 적합 (Best Fit)\n\n- **동작 원리**: **모든 빈 공간을 검색**한 후, 프로세스를 할당할 수 있는 **가장 작은 빈 공간**에 배치합니다.  \n- **장점**: 메모리 낭비를 최소화할 수 있습니다.\n\n---\n\n### 3. 최악 적합 (Worst Fit)\n\n- **동작 원리**: **모든 빈 공간을 검색**한 후, 프로세스를 할당할 수 있는 **가장 큰 빈 공간**에 배치합니다.  \n- **장점**: 큰 빈 공간이 남아 있어 **추후 큰 프로세스**를 할당할 수 있습니다.\n\n## 외부 단편화 (External Fragmentation)\n\n연속 메모리 할당 방식은 **외부 단편화** 문제를 초래할 수 있습니다.\n\n- **외부 단편화**: 메모리의 **빈 공간이 여러 조각**으로 나뉘어, 프로세스가 할당되기 어려워지는 현상입니다.  \n\n**예시**:  \n프로세스가 100MB의 메모리를 요구하지만, 빈 공간이 **50MB씩 6칸**으로 나뉘어 있으면,  \n총 300MB의 빈 공간이 있어도 프로세스를 적재할 수 없습니다.\n\n> **외부 단편화**는 메모리 공간을 비효율적으로 사용하게 만듭니다.  \n{: .prompt-warning }\n\n---\n\n### 해결 방법: 메모리 압축 (Compaction)\n\n**메모리 압축**은 흩어져 있는 작은 빈 공간들을 **하나로 모아** 큰 공간을 만드는 방식입니다.  \n이 방식을 **메모리 조각 모음**이라고도 합니다.\n\n- **장점**: 외부 단편화 문제를 해결할 수 있습니다.  \n- **단점**: 메모리 내용을 옮기는 동안 **시스템이 중지**되며, **오버헤드**가 발생합니다.\n\n---\n\n## 가상 메모리와 페이징 기법\n\n**외부 단편화 문제**를 근본적으로 해결하기 위해 **가상 메모리**와 **페이징 기법**이 등장하게 되었습니다.\n\n> **페이징 기법**은 연속적인 메모리 할당을 **비연속적**으로 관리할 수 있도록 하는 기법입니다.  \n{: .prompt-tip }\n\n---\n\n# 14-2 페이지를 통한 가상 메모리 관리\n\n---\n\n## 가상 메모리와 페이징\n\n**가상 메모리**는 실행하려는 프로그램의 일부만 메모리에 적재해도, **실제 물리 메모리보다 큰 프로그램**을 실행할 수 있게 해주는 기술입니다.  \n\n이를 위해 사용하는 대표적인 기법은 **페이징(Paging)**입니다.\n\n> **페이징 기법의 장점**:  \n> - 외부 단편화 문제를 해결합니다.  \n> - 메모리를 **불연속적으로 할당**할 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n## 페이징이란?\n\n**페이징**은 메모리와 프로세스를 **일정한 크기**로 잘라서 할당하는 기법입니다.\n\n- **페이지(Page)**: 프로세스의 **논리 주소**를 일정한 단위로 나눈 조각입니다.  \n- **프레임(Frame)**: 메모리의 **물리 주소**를 페이지와 동일한 크기로 나눈 조각입니다.  \n\n페이징은 **페이지 단위**로 **페이지 인/아웃**이 이루어지기 때문에, **프로세스 전체를 메모리에 적재할 필요가 없습니다**.  \n\n---\n\n## 페이지 테이블 (Page Table)\n\n페이징 기법을 사용하면 **프로세스의 페이지**가 **메모리의 여러 프레임**에 **불연속적으로 저장**됩니다.  \nCPU가 명령어를 실행하기 위해 페이지가 **어느 프레임에 위치하는지**를 알려주는 **페이지 테이블**이 필요합니다.\n\n- **페이지 테이블**: **페이지 번호**와 **프레임 번호**를 매핑하는 테이블입니다.  \n- **페이지 테이블 베이스 레지스터 (PTBR)**: 페이지 테이블이 저장된 **메모리 주소**를 저장합니다.\n\n---\n\n> **페이지 테이블의 문제**  \n> 페이지 테이블은 **메모리에 저장**되기 때문에 CPU가 접근할 때마다 **메모리 접근 시간이 증가**합니다.  \n{: .prompt-warning }\n\n---\n\n## TLB (Translation Lookaside Buffer)\n\n**페이지 테이블 접근 시간**을 줄이기 위해 **페이지 테이블의 캐시** 역할을 하는 **TLB**가 사용됩니다.\n\n- **TLB**: MMU(메모리 관리 장치) 내에 위치한 **캐시 메모리**입니다.  \n- **TLB 히트**: 원하는 페이지가 TLB에 존재하여 **빠르게 접근**할 수 있습니다.  \n- **TLB 미스**: 원하는 페이지가 TLB에 존재하지 않아 **페이지 테이블**에 접근해야 합니다.\n\n> **참조 지역성 원리** 덕분에 TLB는 페이지 테이블 접근 속도를 크게 개선할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n## 페이징에서의 주소 변환\n\n페이징 시스템에서 논리 주소는 **페이지 번호(Page Number)**와 **변위(Offset)**로 구성됩니다.\n\n**주소 변환 과정**  \n\n1. **페이지 번호**를 사용해 **페이지 테이블**에서 해당 페이지가 저장된 **프레임 번호**를 찾습니다.  \n2. **프레임 번호**와 **변위**를 조합해 **물리 주소**를 생성합니다.  \n\n---\n\n### **주소 변환 예시**\n\n| **논리 주소** | **페이지 번호** | **변위** |\n| ------------- | --------------- | -------- |\n| `2056`        | `2`             | `56`     |\n\n1. 논리 주소 `2056` → 페이지 크기가 `1000`이라면:  \n   - 페이지 번호 = `2056 / 1000` = `2`  \n   - 변위 = `2056 % 1000` = `56`  \n\n2. **페이지 테이블**에서 페이지 `2`의 프레임 번호를 확인합니다.  \n   - 예: 페이지 `2` → 프레임 `5`  \n\n3. 물리 주소 = **프레임 번호** × **페이지 크기** + **변위**  \n   - 물리 주소 = `5 × 1000 + 56 = 5056`  \n\n> **결론**: 논리 주소 `2056`은 물리 주소 `5056`으로 변환됩니다.  \n{: .prompt-tip }\n\n---\n\n## 페이지 테이블 엔트리 (Page Table Entry)\n\n페이지 테이블은 단순히 페이지 번호와 프레임 번호만 저장하지 않습니다.  \n추가적으로 **페이지 보호** 및 **상태 정보**를 나타내는 **페이지 테이블 엔트리 (PTE)**가 있습니다.\n\n| **비트**      | **설명**                                                                                      |\n| ------------- | --------------------------------------------------------------------------------------------- |\n| **유효 비트** | 페이지가 메모리에 적재되었는지 여부를 나타냅니다. (`1`: 메모리에 있음, `0`: 스왑 영역에 있음) |\n| **보호 비트** | 페이지의 접근 권한을 나타냅니다. (`R`: 읽기, `W`: 쓰기, `X`: 실행)                            |\n| **참조 비트** | CPU가 페이지에 접근했는지를 나타냅니다. (`1`: 접근됨, `0`: 접근되지 않음)                     |\n| **수정 비트** | 페이지가 수정되었는지 여부를 나타냅니다. (`1`: 수정됨, `0`: 수정되지 않음)                    |\n\n---\n\n### 페이지 폴트 (Page Fault)\n\n- **페이지 폴트**: CPU가 접근한 페이지가 **메모리에 존재하지 않을 때** 발생하는 예외입니다.  \n- **동작 과정**:  \n  1. 페이지 폴트 발생  \n  2. 스왑 영역에서 해당 페이지를 메모리로 가져옵니다.  \n  3. 페이지 테이블을 업데이트한 후, 다시 프로세스를 실행합니다.\n\n> 페이지 폴트는 하드웨어 인터럽트 처리와 유사하게 동작합니다.  \n{: .prompt-info }\n\n---\n\n> **페이징의 장단점**  \n> - **장점**: 외부 단편화를 해결하고 메모리를 효율적으로 사용할 수 있습니다.  \n> - **단점**: 내부 단편화가 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n# 14-3 페이지 교체와 프레임 할당\n\n---\n\n## 요구 페이징 (Demand Paging)\n\n**요구 페이징**은 **프로세스의 모든 페이지**를 메모리에 적재하지 않고, **필요한 페이지만 적재**하는 방식입니다.\n\n### 요구 페이징의 동작 과정\n\n1. CPU가 **특정 페이지**에 접근하는 명령을 실행합니다.  \n2. 페이지가 **메모리에 존재**하면(유효 비트 `1`), CPU는 해당 프레임에 접근합니다.  \n3. 페이지가 **메모리에 존재하지 않으면**(유효 비트 `0`), **페이지 폴트**가 발생합니다.  \n4. **페이지 폴트 처리 루틴**이 스왑 영역에서 해당 페이지를 메모리로 적재하고, 유효 비트를 `1`로 설정합니다.  \n5. 다시 1번으로 돌아가 CPU는 해당 페이지를 실행합니다.\n\n> **순수 요구 페이징 (Pure Demand Paging)**  \n> 아무런 페이지도 메모리에 적재하지 않고 **실행부터 시작**하는 방식을 말합니다.  \n{: .prompt-tip }\n\n---\n\n## 페이지 교체 알고리즘\n\n요구 페이징 시스템에서는 메모리가 **가득 차게 되면** 새로운 페이지를 적재하기 위해 **기존 페이지를 교체**해야 합니다.  \n어떤 페이지를 교체할지 결정하는 방법이 **페이지 교체 알고리즘**입니다.\n\n---\n\n### 1. FIFO 페이지 교체 알고리즘 (First-In-First-Out)\n\n- **동작 원리**:  \n  메모리에 가장 **먼저 들어온 페이지**를 교체합니다.  \n- **장점**:  \n  - 구현이 단순합니다.  \n- **단점**:  \n  - 오래된 페이지라고 해서 **필요하지 않은 페이지**라고 단정할 수 없습니다.  \n\n### 2. 최적 페이지 교체 알고리즘 (Optimal Page Replacement)\n\n- **동작 원리**:  \n  앞으로 **가장 오랫동안 사용되지 않을 페이지**를 교체합니다.  \n- **장점**:  \n  - **가장 낮은 페이지 폴트율**을 보장합니다.  \n- **단점**:  \n  - **미래의 페이지 참조를 예측해야 하기 때문에** 실제 구현이 불가능합니다.  \n\n> **비유**:  \n> \"앞으로 한동안 쓰지 않을 페이지\"를 예측해서 교체하는 가장 이상적인 방법입니다.  \n{: .prompt-info }\n\n### 3. LRU 페이지 교체 알고리즘 (Least Recently Used)\n\n- **동작 원리**:  \n  **가장 오랫동안 사용되지 않은 페이지**를 교체합니다.  \n- **특징**:  \n  - 최근에 사용되지 않은 페이지는 **앞으로도 사용되지 않을 가능성이 높다**는 가정입니다.  \n- **단점**:  \n  - 높은 오버헤드\n\n> 즉, 페이지 교체 알고리즘 역시 하나의 만능 키는 존재하지 않습니다.  \n> 각 알고리즘이 어떤 아이디어인지에 집중하면 좋을 것이라 생각합니다.\n{: .prompt-info }\n\n\n## 스래싱과 프레임 할당\n\n### 스래싱 (Thrashing)\n\n**스래싱**이란 프로세스가 실행되는 시간보다 **페이지 교체에 더 많은 시간**을 소모하여 성능이 저하되는 현상입니다.\n\n- **발생 원인**: 프로세스가 필요로 하는 **최소한의 프레임 수**를 확보하지 못할 때 발생합니다.  \n\n> **예시**:  \n> 물리 메모리는 `10KB`인데, 페이지가 `10KB × 1000개` 있다면 페이지 교체가 계속 발생해 **CPU 이용률**이 크게 저하됩니다.  \n{: .prompt-warning }\n\n---\n\n### 프레임 할당 방식\n\n메모리의 **프레임을 어떻게 각 프로세스에 할당할지** 결정하는 방식입니다.\n\n#### 1. 균등 할당 (Equal Allocation)\n\n- **정의**: 모든 프로세스에 **동일한 수의 프레임**을 할당합니다.  \n- **단점**: 각 프로세스의 **프레임 요구량**을 고려하지 않기 때문에 비효율적입니다.\n\n#### 2. 비례 할당 (Proportional Allocation)\n\n- **정의**: 프로세스의 크기에 **비례해서** 프레임을 할당합니다.  \n- **특징**: 크기가 큰 프로세스는 더 많은 프레임을 할당받습니다.  \n\n> 하지만, 꼭 프로세스가 크다고 많은 프레임을 사용할 것이라는 보장은 없습니다.\n{: .prompt-warning}\n\n---\n\n## 프레임 요구량 결정 방식\n\n프레임의 할당량을 동적으로 조정하는 방법에는 **작업 집합 모델**과 **페이지 폴트 빈도** 방식이 있습니다.\n\n---\n\n### 1. 작업 집합 모델 (Working Set Model)\n\n- **정의**: 프로세스가 일정 시간 동안 **자주 참조하는 페이지 집합**을 **작업 집합**이라고 합니다.  \n- **작동 원리**:  \n  - 프로세스에 **작업 집합 크기**만큼 프레임을 할당합니다.  \n  - 작업 집합이 메모리에 존재하면 **페이지 폴트가 줄어들어** 성능이 개선됩니다.  \n\n> 자주 사용하는 데이터만 **메모리**에 두고 나머지는 **보조 기억장치**로 옮기는 방식입니다.  \n{: .prompt-tip }\n\n---\n\n### 2. 페이지 폴트 빈도 (Page-Fault Frequency, PFF)\n\n- **정의**: 페이지 폴트가 발생하는 **빈도**를 기준으로 프레임을 조정하는 방식입니다.  \n- **작동 원리**:  \n  - 페이지 폴트 빈도가 **높으면** 더 많은 프레임을 할당합니다.  \n  - 페이지 폴트 빈도가 **낮으면** 프레임을 회수합니다.\n\n> **목표**: 페이지 폴트 빈도를 일정한 수준으로 유지하면서, **최적의 프레임 수**를 할당합니다.  \n{: .prompt-info }\n\n\n\n> 정리하자면 스래싱을 방지하기 위해 **프레임 수** 를 동적으로 **적절하게 조정**하는 것이 중요합니다.  \n{: .prompt-tip }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-20",
    "tags": [
      "메모리 관리",
      "연속 메모리 할당",
      "스와핑"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-20-14_chunk_0",
        "text": "[혼공컴운] 14장 가상 메모리\n\n# 14-1 연속 메모리 할당\n\n운영체제의 **메모리 관리** 방식 중 하나로, 프로세스에 **연속적인 메모리 공간**을 할당하는 방식을 설명합니다.  \n이 절에서는 **스와핑**, **메모리 할당 전략**, 그리고 **외부 단편화** 문제를 다룹니다.\n\n---\n\n## 스와핑 (Swapping)\n\n메모리에는 **실행 중인 프로세스**만이 적재되어야 합니다.  \n그런데 입출력 작업을 기다리거나 **오랫동안 사용되지 않는 프로세스**도 메모리에 있을 수 있습니다.  \n\n**스와핑**은 이러한 프로세스를 **보조기억장치**의 일부 영역으로 **옮겨서** 메모리를 확보하는 방식입니다.\n\n- **스왑 영역 (Swap Space)**: 보조기억장치의 스와핑을 위한 영역입니다.  \n- **스왑 아웃 (Swap Out)**: 프로세스를 **메모리 → 스왑 영역**으로 옮기는 동작입니다.  \n- **스왑 인 (Swap In)**: 프로세스를 **스왑 영역 → 메모리**로 다시 옮기는 동작입니다.  \n\n> 스왑된 프로세스는 **다른 물리 주소**에 적재될 수 있습니다.  \n{: .prompt-info }\n\n> **유닉스 기반 시스템**에서는 `free`, `top` 명령어를 사용해 **스왑 영역의 크기**를 확인할 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n## 메모리 할당 전략\n\n프로세스는 메모리의 **빈 공간**에 할당되어야 합니다.  \n여러 개의 빈 공간이 있을 때, 프로세스를 어디에 배치하는 것이 효율적일까요?",
        "index": 0
      },
      {
        "id": "2024-12-20-14_chunk_1",
        "text": "}\n\n---\n\n## 메모리 할당 전략\n\n프로세스는 메모리의 **빈 공간**에 할당되어야 합니다.  \n여러 개의 빈 공간이 있을 때, 프로세스를 어디에 배치하는 것이 효율적일까요?  \n대표적인 방법은 **최초 적합**, **최적 적합**, **최악 적합**이 있습니다.\n\n---\n\n### 1. 최초 적합 (First Fit)\n\n- **동작 원리**: 메모리의 **빈 공간을 순서대로 검색**하며, **적합한 공간을 발견**하면 바로 할당합니다.  \n- **장점**: 검색 시간을 최소화하여 **빠른 할당**이 가능합니다.\n\n### 2. 최적 적합 (Best Fit)\n\n- **동작 원리**: **모든 빈 공간을 검색**한 후, 프로세스를 할당할 수 있는 **가장 작은 빈 공간**에 배치합니다.  \n- **장점**: 메모리 낭비를 최소화할 수 있습니다.\n\n---\n\n### 3. 최악 적합 (Worst Fit)\n\n- **동작 원리**: **모든 빈 공간을 검색**한 후, 프로세스를 할당할 수 있는 **가장 큰 빈 공간**에 배치합니다.  \n- **장점**: 큰 빈 공간이 남아 있어 **추후 큰 프로세스**를 할당할 수 있습니다.\n\n## 외부 단편화 (External Fragmentation)\n\n연속 메모리 할당 방식은 **외부 단편화** 문제를 초래할 수 있습니다.\n\n- **외부 단편화**: 메모리의 **빈 공간이 여러 조각**으로 나뉘어, 프로세스가 할당되기 어려워지는 현상입니다.",
        "index": 1
      },
      {
        "id": "2024-12-20-14_chunk_2",
        "text": "당 방식은 **외부 단편화** 문제를 초래할 수 있습니다.\n\n- **외부 단편화**: 메모리의 **빈 공간이 여러 조각**으로 나뉘어, 프로세스가 할당되기 어려워지는 현상입니다.  \n\n**예시**:  \n프로세스가 100MB의 메모리를 요구하지만, 빈 공간이 **50MB씩 6칸**으로 나뉘어 있으면,  \n총 300MB의 빈 공간이 있어도 프로세스를 적재할 수 없습니다.\n\n> **외부 단편화**는 메모리 공간을 비효율적으로 사용하게 만듭니다.  \n{: .prompt-warning }\n\n---\n\n### 해결 방법: 메모리 압축 (Compaction)\n\n**메모리 압축**은 흩어져 있는 작은 빈 공간들을 **하나로 모아** 큰 공간을 만드는 방식입니다.  \n이 방식을 **메모리 조각 모음**이라고도 합니다.\n\n- **장점**: 외부 단편화 문제를 해결할 수 있습니다.  \n- **단점**: 메모리 내용을 옮기는 동안 **시스템이 중지**되며, **오버헤드**가 발생합니다.\n\n---\n\n## 가상 메모리와 페이징 기법\n\n**외부 단편화 문제**를 근본적으로 해결하기 위해 **가상 메모리**와 **페이징 기법**이 등장하게 되었습니다.\n\n> **페이징 기법**은 연속적인 메모리 할당을 **비연속적**으로 관리할 수 있도록 하는 기법입니다.  \n{: .prompt-tip }\n\n---\n\n# 14-2 페이지를 통한 가상 메모리 관리\n\n---\n\n## 가상 메모리와 페이징\n\n**가상 메모리**는 실행하려는 프로그램의 일부만 메모리에 적재해도, **실제 물리 메모리보다 큰 프로그램**을 실행할 수 있게 해주는 기술입니다.",
        "index": 2
      },
      {
        "id": "2024-12-20-14_chunk_3",
        "text": "## 가상 메모리와 페이징\n\n**가상 메모리**는 실행하려는 프로그램의 일부만 메모리에 적재해도, **실제 물리 메모리보다 큰 프로그램**을 실행할 수 있게 해주는 기술입니다.  \n\n이를 위해 사용하는 대표적인 기법은 **페이징(Paging)**입니다.\n\n> **페이징 기법의 장점**:  \n> - 외부 단편화 문제를 해결합니다.  \n> - 메모리를 **불연속적으로 할당**할 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n## 페이징이란?\n\n**페이징**은 메모리와 프로세스를 **일정한 크기**로 잘라서 할당하는 기법입니다.\n\n- **페이지(Page)**: 프로세스의 **논리 주소**를 일정한 단위로 나눈 조각입니다.  \n- **프레임(Frame)**: 메모리의 **물리 주소**를 페이지와 동일한 크기로 나눈 조각입니다.  \n\n페이징은 **페이지 단위**로 **페이지 인/아웃**이 이루어지기 때문에, **프로세스 전체를 메모리에 적재할 필요가 없습니다**.  \n\n---\n\n## 페이지 테이블 (Page Table)\n\n페이징 기법을 사용하면 **프로세스의 페이지**가 **메모리의 여러 프레임**에 **불연속적으로 저장**됩니다.  \nCPU가 명령어를 실행하기 위해 페이지가 **어느 프레임에 위치하는지**를 알려주는 **페이지 테이블**이 필요합니다.\n\n- **페이지 테이블**: **페이지 번호**와 **프레임 번호**를 매핑하는 테이블입니다.",
        "index": 3
      },
      {
        "id": "2024-12-20-14_chunk_4",
        "text": "지가 **어느 프레임에 위치하는지**를 알려주는 **페이지 테이블**이 필요합니다.\n\n- **페이지 테이블**: **페이지 번호**와 **프레임 번호**를 매핑하는 테이블입니다.  \n- **페이지 테이블 베이스 레지스터 (PTBR)**: 페이지 테이블이 저장된 **메모리 주소**를 저장합니다.\n\n---\n\n> **페이지 테이블의 문제**  \n> 페이지 테이블은 **메모리에 저장**되기 때문에 CPU가 접근할 때마다 **메모리 접근 시간이 증가**합니다.  \n{: .prompt-warning }\n\n---\n\n## TLB (Translation Lookaside Buffer)\n\n**페이지 테이블 접근 시간**을 줄이기 위해 **페이지 테이블의 캐시** 역할을 하는 **TLB**가 사용됩니다.\n\n- **TLB**: MMU(메모리 관리 장치) 내에 위치한 **캐시 메모리**입니다.  \n- **TLB 히트**: 원하는 페이지가 TLB에 존재하여 **빠르게 접근**할 수 있습니다.  \n- **TLB 미스**: 원하는 페이지가 TLB에 존재하지 않아 **페이지 테이블**에 접근해야 합니다.\n\n> **참조 지역성 원리** 덕분에 TLB는 페이지 테이블 접근 속도를 크게 개선할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n## 페이징에서의 주소 변환\n\n페이징 시스템에서 논리 주소는 **페이지 번호(Page Number)**와 **변위(Offset)**로 구성됩니다.\n\n**주소 변환 과정**  \n\n1. **페이지 번호**를 사용해 **페이지 테이블**에서 해당 페이지가 저장된 **프레임 번호**를 찾습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-19-9",
    "title": "[혼공컴운] 9장 운영체제 시작하기",
    "path": "/2024/12/19/9장-운영체제-시작하기/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 9-1 운영체제를 알아야 하는 이유\n\n---\n\n## 운영체제란\n\n프로그램 실행에 필요한 자원을 **시스템 자원**이라고 합니다.  \nCPU, 메모리, 보조기억장치, 입출력장치 등 모든 **컴퓨터 부품**이 시스템 자원에 해당합니다.\n\n모든 프로그램은 실행되기 위해 **시스템 자원**이 필요합니다.  \n이 자원을 할당하고 프로그램이 **올바르게 실행되도록 돕는 특별한 프로그램**이 바로 **운영체제(Operating System)**입니다.\n\n> 운영체제는 **시스템 자원을 관리**하는 특별한 프로그램입니다.  \n{: .prompt-tip }\n\n---\n\n운영체제도 다른 프로그램처럼 메모리에 적재되어야 실행됩니다.  \n하지만 **운영체제는 특별**하기 때문에 **부팅 시 메모리의 커널 영역**(Kernel Space)에 적재되어 실행됩니다.  \n커널 영역을 제외한 나머지 공간은 **사용자 영역**(User Space)이라고 부릅니다.\n\n> 운영체제가 응용 프로그램과 하드웨어 사이에서 자원을 할당하고 관리하기 때문에 우리가 컴퓨터를 잘 사용할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n## 운영체제를 알아야 하는 이유\n\n운영체제가 없다면 **하드웨어를 직접 조작하는 코드**를 작성해야 합니다.  \n이런 작업은 복잡하고 비효율적이기 때문에 운영체제가 **하드웨어 관리 기능**을 제공함으로써 간편하게 개발할 수 있습니다.\n\n그렇다면 운영체제가 알아서 하드웨어를 관리하는데 왜 알아야 할까요?  \n그 이유는 **문제 해결 능력**과 관련이 있습니다.\n\n> 운영체제를 이해하면 **내 코드가 동작할 때 하드웨어 상태**를 파악할 수 있고, 발생한 문제의 원인을 분석하여 해결할 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n# 9-2 운영체제의 큰 그림\n\n---\n\n## 커널(Kernel)\n\n운영체제가 제공하는 서비스 중에서도 핵심적인 기능을 담당하는 부분을 **커널(Kernel)**이라고 합니다.  \n\n- **커널**: 핵심적인 서비스(프로세스 관리, 자원 관리)를 제공하는 영역.  \n- **사용자 인터페이스**: 커널에 포함되지 않는 서비스로, **CLI**(명령어 기반)와 **GUI**(그래픽 기반)가 있습니다.\n\n---\n\n## 이중 모드와 시스템 콜\n\n운영체제는 응용 프로그램이 **하드웨어 자원에 직접 접근**하는 것을 방지하여 자원을 보호합니다.  \n응용 프로그램이 **자원이 필요**하면 **운영체제에 요청**하고, 운영체제가 대신 자원을 관리합니다.\n\n여기서 **이중 모드**가 등장합니다.\n\n### 이중 모드\n\n1. **커널 모드**  \n   - **운영체제 서비스**를 제공받을 수 있는 모드입니다.  \n   - **커널 영역의 코드**를 실행할 수 있습니다.\n\n2. **사용자 모드**  \n   - 커널 영역의 코드를 실행할 수 없는 모드입니다.  \n   - **응용 프로그램**이 실행되는 모드입니다.\n\n---\n\n### 시스템 콜(System Call)\n\n사용자 모드에서 실행되는 프로그램이 **자원 접근**을 요청할 때 **커널 모드로 전환**되어야 합니다.  \n이때 운영체제에 보내는 요청을 **시스템 콜**이라고 합니다.\n\n> 시스템 콜은 **소프트웨어 인터럽트**의 일종입니다.  \n{: .prompt-info }\n\n---\n\n## 운영체제의 핵심 서비스\n\n운영체제가 제공하는 핵심 서비스는 다음과 같습니다.\n\n### 1. 프로세스 관리\n\n운영체제는 여러 **프로세스**를 관리하며, 동시에 실행될 수 있도록 지원합니다.  \n- **프로세스 동기화**: 여러 프로세스가 동시에 실행될 때 문제를 방지.  \n- **교착 상태**: 프로세스 간의 자원 대기 문제 처리.\n\n---\n\n### 2. 자원 접근 및 할당\n\n**CPU**(혹은 코어)는 한 번에 하나의 프로세스만 실행할 수 있습니다.  \n어떤 프로세스가 **얼마나 CPU를 사용할지**를 결정하는 것이 **CPU 스케줄링**입니다.\n\n---\n\n### 3. 파일 시스템 관리\n\n보조기억장치에 있는 데이터를 **파일**과 **디렉토리** 형태로 관리하는 기능입니다.  \n운영체제가 **파일 시스템**을 지원하기 때문에 데이터를 쉽게 관리하고 접근할 수 있습니다.\n\n\n> **위 세 가지 내용들은 이후 장에서 다룰 예정입니다.**\n{: .prompt-info }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-19",
    "tags": [
      "운영체제",
      "컴퓨터구조"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-19-9_chunk_0",
        "text": "[혼공컴운] 9장 운영체제 시작하기\n\n# 9-1 운영체제를 알아야 하는 이유\n\n---\n\n## 운영체제란\n\n프로그램 실행에 필요한 자원을 **시스템 자원**이라고 합니다.  \nCPU, 메모리, 보조기억장치, 입출력장치 등 모든 **컴퓨터 부품**이 시스템 자원에 해당합니다.\n\n모든 프로그램은 실행되기 위해 **시스템 자원**이 필요합니다.  \n이 자원을 할당하고 프로그램이 **올바르게 실행되도록 돕는 특별한 프로그램**이 바로 **운영체제(Operating System)**입니다.\n\n> 운영체제는 **시스템 자원을 관리**하는 특별한 프로그램입니다.  \n{: .prompt-tip }\n\n---\n\n운영체제도 다른 프로그램처럼 메모리에 적재되어야 실행됩니다.  \n하지만 **운영체제는 특별**하기 때문에 **부팅 시 메모리의 커널 영역**(Kernel Space)에 적재되어 실행됩니다.  \n커널 영역을 제외한 나머지 공간은 **사용자 영역**(User Space)이라고 부릅니다.\n\n> 운영체제가 응용 프로그램과 하드웨어 사이에서 자원을 할당하고 관리하기 때문에 우리가 컴퓨터를 잘 사용할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n## 운영체제를 알아야 하는 이유\n\n운영체제가 없다면 **하드웨어를 직접 조작하는 코드**를 작성해야 합니다.  \n이런 작업은 복잡하고 비효율적이기 때문에 운영체제가 **하드웨어 관리 기능**을 제공함으로써 간편하게 개발할 수 있습니다.\n\n그렇다면 운영체제가 알아서 하드웨어를 관리하는데 왜 알아야 할까요?",
        "index": 0
      },
      {
        "id": "2024-12-19-9_chunk_1",
        "text": "잡하고 비효율적이기 때문에 운영체제가 **하드웨어 관리 기능**을 제공함으로써 간편하게 개발할 수 있습니다.\n\n그렇다면 운영체제가 알아서 하드웨어를 관리하는데 왜 알아야 할까요?  \n그 이유는 **문제 해결 능력**과 관련이 있습니다.\n\n> 운영체제를 이해하면 **내 코드가 동작할 때 하드웨어 상태**를 파악할 수 있고, 발생한 문제의 원인을 분석하여 해결할 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n# 9-2 운영체제의 큰 그림\n\n---\n\n## 커널(Kernel)\n\n운영체제가 제공하는 서비스 중에서도 핵심적인 기능을 담당하는 부분을 **커널(Kernel)**이라고 합니다.  \n\n- **커널**: 핵심적인 서비스(프로세스 관리, 자원 관리)를 제공하는 영역.  \n- **사용자 인터페이스**: 커널에 포함되지 않는 서비스로, **CLI**(명령어 기반)와 **GUI**(그래픽 기반)가 있습니다.\n\n---\n\n## 이중 모드와 시스템 콜\n\n운영체제는 응용 프로그램이 **하드웨어 자원에 직접 접근**하는 것을 방지하여 자원을 보호합니다.  \n응용 프로그램이 **자원이 필요**하면 **운영체제에 요청**하고, 운영체제가 대신 자원을 관리합니다.\n\n여기서 **이중 모드**가 등장합니다.\n\n### 이중 모드\n\n1. **커널 모드**  \n   - **운영체제 서비스**를 제공받을 수 있는 모드입니다.  \n   - **커널 영역의 코드**를 실행할 수 있습니다.\n\n2. **사용자 모드**  \n   - 커널 영역의 코드를 실행할 수 없는 모드입니다.",
        "index": 1
      },
      {
        "id": "2024-12-19-9_chunk_2",
        "text": "제공받을 수 있는 모드입니다.  \n   - **커널 영역의 코드**를 실행할 수 있습니다.\n\n2. **사용자 모드**  \n   - 커널 영역의 코드를 실행할 수 없는 모드입니다.  \n   - **응용 프로그램**이 실행되는 모드입니다.\n\n---\n\n### 시스템 콜(System Call)\n\n사용자 모드에서 실행되는 프로그램이 **자원 접근**을 요청할 때 **커널 모드로 전환**되어야 합니다.  \n이때 운영체제에 보내는 요청을 **시스템 콜**이라고 합니다.\n\n> 시스템 콜은 **소프트웨어 인터럽트**의 일종입니다.  \n{: .prompt-info }\n\n---\n\n## 운영체제의 핵심 서비스\n\n운영체제가 제공하는 핵심 서비스는 다음과 같습니다.\n\n### 1. 프로세스 관리\n\n운영체제는 여러 **프로세스**를 관리하며, 동시에 실행될 수 있도록 지원합니다.  \n- **프로세스 동기화**: 여러 프로세스가 동시에 실행될 때 문제를 방지.  \n- **교착 상태**: 프로세스 간의 자원 대기 문제 처리.\n\n---\n\n### 2. 자원 접근 및 할당\n\n**CPU**(혹은 코어)는 한 번에 하나의 프로세스만 실행할 수 있습니다.  \n어떤 프로세스가 **얼마나 CPU를 사용할지**를 결정하는 것이 **CPU 스케줄링**입니다.\n\n---\n\n### 3. 파일 시스템 관리\n\n보조기억장치에 있는 데이터를 **파일**과 **디렉토리** 형태로 관리하는 기능입니다.",
        "index": 2
      },
      {
        "id": "2024-12-19-9_chunk_3",
        "text": "를 결정하는 것이 **CPU 스케줄링**입니다.\n\n---\n\n### 3. 파일 시스템 관리\n\n보조기억장치에 있는 데이터를 **파일**과 **디렉토리** 형태로 관리하는 기능입니다.  \n운영체제가 **파일 시스템**을 지원하기 때문에 데이터를 쉽게 관리하고 접근할 수 있습니다.\n\n\n> **위 세 가지 내용들은 이후 장에서 다룰 예정입니다.**\n{: .prompt-info }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 3
      },
      {
        "id": "2024-12-19-9_chunk_4",
        "text": "{: .prompt-info }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-19-6",
    "title": "[혼공컴운] 6장 메모리와 캐시 메모리",
    "path": "/2024/12/19/6장-메모리와-캐시-메모리/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 6-1 RAM의 특징과 종류\n\n이번 절에서는 메모리라고 지칭했던 **RAM**에 대해 학습합니다.  \n**DRAM**, **SRAM**, **SDRAM**, **DDR SDRAM**의 특징과 차이점을 알아보겠습니다.\n\n---\n\n## RAM의 특징\n\nRAM(Random Access Memory)은 프로그램이 실행될 때 **명령어**와 **데이터**를 저장하는 메모리입니다.\n\n- **휘발성(Volatile) 저장 장치**: 전원이 꺼지면 저장된 내용이 사라집니다.\n- **비휘발성 저장 장치**(HDD, SSD 등)와 달리 **현재 실행 중인 데이터**만 저장합니다.\n\nCPU는 보조기억장치에 직접 접근할 수 없기 때문에 실행할 데이터를 **RAM**에 불러온 뒤 처리합니다.\n\n> RAM은 휘발성이며, SSD나 HDD는 비휘발성입니다.  \n{: .prompt-tip }\n\n---\n\n## RAM의 용량과 성능\n\n- **RAM의 용량이 적다면**: CPU는 보조기억장치에 자주 접근해야 하므로 실행 시간이 길어집니다.\n- **RAM의 용량이 크다면**: 더 많은 데이터를 미리 저장할 수 있어 **다중 프로그램 실행**에 유리합니다.\n\n> RAM의 용량이 커진다고 해서 실행 속도가 무조건 빨라지는 것은 아닙니다.  \n{: .prompt-warning }\n\n---\n\n## RAM의 종류\n\n### 1. DRAM (Dynamic RAM)\n\n- **Dynamic**: 저장된 데이터가 시간이 지나면 점차 사라집니다.\n- **특징**: 일정 주기마다 **재활성화(Refresh)**가 필요합니다.\n- **장점**: 저렴하고 소비 전력이 낮으며 집적도가 높아 **대용량 설계**에 유리합니다.\n\n> DRAM은 재활성화가 필요하지만 저렴하고 대용량으로 설계할 수 있어 주로 메모리에 사용됩니다.  \n{: .prompt-info }\n\n---\n\n### 2. SRAM (Static RAM)\n\n- **Static**: 저장된 데이터가 변하지 않아 재활성화가 필요 없습니다.\n- **특징**: DRAM보다 **속도가 빠릅니다**.\n- **단점**: 집적도가 낮고 소비 전력이 높아 가격이 비쌉니다.  \n- **사용처**: CPU의 **캐시 메모리**로 사용됩니다.\n\n> SRAM은 비싸지만 속도가 빠르기 때문에 **캐시 메모리**로 사용됩니다.  \n{: .prompt-tip }\n\n---\n\n### 3. SDRAM (Synchronous DRAM)\n\n- **Synchronous**: 클럭 신호와 동기화되어 CPU와 데이터를 주고받습니다.  \n- **장점**: CPU의 클럭 타이밍에 맞춰 효율적으로 동작합니다.\n\n---\n\n### 4. DDR SDRAM (Double Data Rate SDRAM)\n\n- 기존 SDRAM에서 **대역폭**을 확장해 속도를 높였습니다.\n- **특징**: 한 클럭 주기에서 **더 많은 데이터**를 주고받을 수 있습니다.\n- 현재 가장 많이 사용되는 RAM의 형태입니다.\n\n> 최근 대부분의 시스템에서 사용됩니다.  \n{: .prompt-info }\n\n---\n\n# 6-2 메모리의 주소 공간\n\n이 절에서는 **메모리 주소**에 대해 배우며, **물리주소**와 **논리주소**의 개념을 다룹니다.\n\n---\n\n## 물리주소와 논리주소\n\n- **물리주소**(Physical Address): 실제 메모리에서 데이터가 저장된 **하드웨어 주소**입니다.\n- **논리주소**(Logical Address): 프로그램이 실행될 때 부여되는 **가상의 주소**입니다.\n\n**MMU**(Memory Management Unit)라는 하드웨어가 논리주소를 물리주소로 변환합니다.\n\n> MMU는 CPU와 주소 버스 사이에 위치해 논리주소를 물리주소로 변환합니다.  \n{: .highlight }\n\n---\n\n### 메모리 주소 변환 과정\n\n1. **CPU**가 논리주소를 발생시킵니다.\n2. **MMU**가 **베이스 레지스터** 값을 더해 물리주소로 변환합니다.\n\n> 베이스 레지스터는 프로그램이 사용하는 **가장 첫 물리주소**를 가리킵니다.  \n{: .prompt-info }\n\n---\n\n## 메모리 보호 기법\n\n다른 프로그램의 주소를 침범하지 않도록 **한계 레지스터**(Limit Register)를 사용합니다.\n\n> 논리주소가 한계를 초과하면 **인터럽트(트랩)**를 발생시켜 프로그램 실행을 중단시킵니다.  \n{: .prompt-danger }\n\n---\n\n# 6-3 캐시 메모리\n\nCPU와 메모리 간의 **속도 차이**를 극복하기 위해 **캐시 메모리**가 사용됩니다.\n\n---\n\n## 캐시 메모리의 개념\n\n- **캐시 메모리**는 **CPU와 메모리 사이**에 위치하며, **SRAM 기반**의 저장 장치입니다.\n- **특징**:\n  - **메모리**보다 빠르지만, **용량**은 작습니다.\n  - CPU가 자주 사용할 데이터를 미리 가져와 저장합니다.\n\n---\n\n## 참조 지역성 원리 (Locality of Reference)\n\n캐시 메모리는 **CPU가 사용할 법한 데이터를 예측**해 저장합니다.\n\n**참조 지역성의 원리**  \n- **시간 지역성**: 최근에 접근한 메모리는 다시 접근할 가능성이 니다.  \n- **공간 지역성**: 접근한 메모리 근처의 데이터도 접근할 가능성이 높습니다.  \n\n> **캐시 적중률**  \n> 캐시가 데이터를 예측해서 CPU에 제공하는 비율입니다.  \n{: .highlight }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-19",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-19-6_chunk_0",
        "text": "[혼공컴운] 6장 메모리와 캐시 메모리\n\n# 6-1 RAM의 특징과 종류\n\n이번 절에서는 메모리라고 지칭했던 **RAM**에 대해 학습합니다.  \n**DRAM**, **SRAM**, **SDRAM**, **DDR SDRAM**의 특징과 차이점을 알아보겠습니다.\n\n---\n\n## RAM의 특징\n\nRAM(Random Access Memory)은 프로그램이 실행될 때 **명령어**와 **데이터**를 저장하는 메모리입니다.\n\n- **휘발성(Volatile) 저장 장치**: 전원이 꺼지면 저장된 내용이 사라집니다.\n- **비휘발성 저장 장치**(HDD, SSD 등)와 달리 **현재 실행 중인 데이터**만 저장합니다.\n\nCPU는 보조기억장치에 직접 접근할 수 없기 때문에 실행할 데이터를 **RAM**에 불러온 뒤 처리합니다.\n\n> RAM은 휘발성이며, SSD나 HDD는 비휘발성입니다.  \n{: .prompt-tip }\n\n---\n\n## RAM의 용량과 성능\n\n- **RAM의 용량이 적다면**: CPU는 보조기억장치에 자주 접근해야 하므로 실행 시간이 길어집니다.\n- **RAM의 용량이 크다면**: 더 많은 데이터를 미리 저장할 수 있어 **다중 프로그램 실행**에 유리합니다.\n\n> RAM의 용량이 커진다고 해서 실행 속도가 무조건 빨라지는 것은 아닙니다.  \n{: .prompt-warning }\n\n---\n\n## RAM의 종류\n\n### 1.",
        "index": 0
      },
      {
        "id": "2024-12-19-6_chunk_1",
        "text": "유리합니다.\n\n> RAM의 용량이 커진다고 해서 실행 속도가 무조건 빨라지는 것은 아닙니다.  \n{: .prompt-warning }\n\n---\n\n## RAM의 종류\n\n### 1. DRAM (Dynamic RAM)\n\n- **Dynamic**: 저장된 데이터가 시간이 지나면 점차 사라집니다.\n- **특징**: 일정 주기마다 **재활성화(Refresh)**가 필요합니다.\n- **장점**: 저렴하고 소비 전력이 낮으며 집적도가 높아 **대용량 설계**에 유리합니다.\n\n> DRAM은 재활성화가 필요하지만 저렴하고 대용량으로 설계할 수 있어 주로 메모리에 사용됩니다.  \n{: .prompt-info }\n\n---\n\n### 2. SRAM (Static RAM)\n\n- **Static**: 저장된 데이터가 변하지 않아 재활성화가 필요 없습니다.\n- **특징**: DRAM보다 **속도가 빠릅니다**.\n- **단점**: 집적도가 낮고 소비 전력이 높아 가격이 비쌉니다.  \n- **사용처**: CPU의 **캐시 메모리**로 사용됩니다.\n\n> SRAM은 비싸지만 속도가 빠르기 때문에 **캐시 메모리**로 사용됩니다.  \n{: .prompt-tip }\n\n---\n\n### 3. SDRAM (Synchronous DRAM)\n\n- **Synchronous**: 클럭 신호와 동기화되어 CPU와 데이터를 주고받습니다.  \n- **장점**: CPU의 클럭 타이밍에 맞춰 효율적으로 동작합니다.\n\n---\n\n### 4.",
        "index": 1
      },
      {
        "id": "2024-12-19-6_chunk_2",
        "text": "Synchronous**: 클럭 신호와 동기화되어 CPU와 데이터를 주고받습니다.  \n- **장점**: CPU의 클럭 타이밍에 맞춰 효율적으로 동작합니다.\n\n---\n\n### 4. DDR SDRAM (Double Data Rate SDRAM)\n\n- 기존 SDRAM에서 **대역폭**을 확장해 속도를 높였습니다.\n- **특징**: 한 클럭 주기에서 **더 많은 데이터**를 주고받을 수 있습니다.\n- 현재 가장 많이 사용되는 RAM의 형태입니다.\n\n> 최근 대부분의 시스템에서 사용됩니다.  \n{: .prompt-info }\n\n---\n\n# 6-2 메모리의 주소 공간\n\n이 절에서는 **메모리 주소**에 대해 배우며, **물리주소**와 **논리주소**의 개념을 다룹니다.\n\n---\n\n## 물리주소와 논리주소\n\n- **물리주소**(Physical Address): 실제 메모리에서 데이터가 저장된 **하드웨어 주소**입니다.\n- **논리주소**(Logical Address): 프로그램이 실행될 때 부여되는 **가상의 주소**입니다.\n\n**MMU**(Memory Management Unit)라는 하드웨어가 논리주소를 물리주소로 변환합니다.\n\n> MMU는 CPU와 주소 버스 사이에 위치해 논리주소를 물리주소로 변환합니다.  \n{: .highlight }\n\n---\n\n### 메모리 주소 변환 과정\n\n1. **CPU**가 논리주소를 발생시킵니다.\n2. **MMU**가 **베이스 레지스터** 값을 더해 물리주소로 변환합니다.\n\n> 베이스 레지스터는 프로그램이 사용하는 **가장 첫 물리주소**를 가리킵니다.",
        "index": 2
      },
      {
        "id": "2024-12-19-6_chunk_3",
        "text": "를 발생시킵니다.\n2. **MMU**가 **베이스 레지스터** 값을 더해 물리주소로 변환합니다.\n\n> 베이스 레지스터는 프로그램이 사용하는 **가장 첫 물리주소**를 가리킵니다.  \n{: .prompt-info }\n\n---\n\n## 메모리 보호 기법\n\n다른 프로그램의 주소를 침범하지 않도록 **한계 레지스터**(Limit Register)를 사용합니다.\n\n> 논리주소가 한계를 초과하면 **인터럽트(트랩)**를 발생시켜 프로그램 실행을 중단시킵니다.  \n{: .prompt-danger }\n\n---\n\n# 6-3 캐시 메모리\n\nCPU와 메모리 간의 **속도 차이**를 극복하기 위해 **캐시 메모리**가 사용됩니다.\n\n---\n\n## 캐시 메모리의 개념\n\n- **캐시 메모리**는 **CPU와 메모리 사이**에 위치하며, **SRAM 기반**의 저장 장치입니다.\n- **특징**:\n  - **메모리**보다 빠르지만, **용량**은 작습니다.\n  - CPU가 자주 사용할 데이터를 미리 가져와 저장합니다.\n\n---\n\n## 참조 지역성 원리 (Locality of Reference)\n\n캐시 메모리는 **CPU가 사용할 법한 데이터를 예측**해 저장합니다.\n\n**참조 지역성의 원리**  \n- **시간 지역성**: 최근에 접근한 메모리는 다시 접근할 가능성이 니다.  \n- **공간 지역성**: 접근한 메모리 근처의 데이터도 접근할 가능성이 높습니다.  \n\n> **캐시 적중률**  \n> 캐시가 데이터를 예측해서 CPU에 제공하는 비율입니다.",
        "index": 3
      },
      {
        "id": "2024-12-19-6_chunk_4",
        "text": "- **공간 지역성**: 접근한 메모리 근처의 데이터도 접근할 가능성이 높습니다.  \n\n> **캐시 적중률**  \n> 캐시가 데이터를 예측해서 CPU에 제공하는 비율입니다.  \n{: .highlight }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-19-11--CPU",
    "title": "[혼공컴운] 11장 CPU 스케줄링",
    "path": "/2024/12/19/11장-CPU-스케줄링/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 11-1 CPU 스케줄링 개요\n\n---\n\n## CPU 스케줄링이란?\n\n모든 **프로세스**는 실행을 위해 **CPU**를 필요로 합니다.  \n이 프로세스들에게 **자원을 합리적으로 할당**하는 것을 **CPU 스케줄링(CPU Scheduling)**이라고 합니다.  \n\n> **CPU 스케줄링**은 **컴퓨터 성능**과 직결되는 중요한 문제입니다.  \n{: .prompt-info }\n\n---\n\n## 프로세스 우선순위\n\n프로세스마다 **CPU 작업 시간**과 **입출력 대기 시간**은 다르게 나타납니다.  \n\n- **입출력 집중 프로세스 (I/O Bound Process)**  \n   - 입출력 작업이 많아 CPU를 적게 사용합니다.  \n   - 예: **비디오 재생, 디스크 백업**  \n\n- **CPU 집중 프로세스 (CPU Bound Process)**  \n   - CPU를 많이 사용하며 입출력 대기 시간은 적습니다.  \n   - 예: **수학 연산, 컴파일, 그래픽 처리**  \n\n> **CPU Burst**: CPU를 사용하는 시간  \n> **I/O Burst**: 입출력 장치를 기다리는 시간  \n{: .prompt-tip }\n\n---\n\n### 우선순위의 필요성\n\n입출력 집중 프로세스는 **입출력 작업 시간**이 길기 때문에 CPU를 동일하게 배정하면 **효율적이지 않습니다**.  \n따라서 프로세스에 **우선순위(priority)**를 부여해 자원을 효율적으로 관리합니다.\n\n---\n\n## 스케줄링 큐\n\n프로세스의 **우선순위**는 PCB에 기록되지만, 이를 일일이 확인하는 것은 비효율적입니다.  \n그래서 프로세스는 **스케줄링 큐**로 관리됩니다.\n\n### 주요 스케줄링 큐  \n\n1. **준비 큐 (Ready Queue)**  \n   - CPU를 사용하기 위해 **대기 중인 프로세스**가 서 있는 큐입니다.\n\n2. **대기 큐 (Waiting Queue)**  \n   - 입출력 장치를 이용하기 위해 **대기 중인 프로세스**가 서 있는 큐입니다.\n\n> 스케줄링 큐는 **FIFO** 구조일 수도 있지만, 스케줄링 방식에 따라 다르게 동작할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n## 선점형과 비선점형 스케줄링\n\nCPU 스케줄링 방식은 크게 **선점형**과 **비선점형**으로 나뉩니다.\n\n### 선점형 스케줄링 (Preemptive Scheduling)\n\n- **정의**: 프로세스가 CPU를 사용하고 있어도 **강제로 자원을 빼앗아** 다른 프로세스에 할당할 수 있는 방식입니다.  \n- **특징**: 프로세스가 **자원을 독점할 수 없습니다**.  \n- **예시**: **타이머 인터럽트**가 발생하면, 운영체제가 CPU를 강제로 다른 프로세스에 할당합니다.\n\n---\n\n### 비선점형 스케줄링 (Non-Preemptive Scheduling)\n\n- **정의**: 한 프로세스가 CPU를 사용하고 있다면, 해당 프로세스가 **종료되거나 대기 상태**가 되기 전까지 다른 프로세스는 끼어들 수 없습니다.  \n- **특징**: 프로세스가 **자원을 독점**할 수 있습니다.  \n\n---\n\n### 선점형과 비선점형 스케줄링 비교  \n\n| **구분**      | **선점형 스케줄링**               | **비선점형 스케줄링**                     |\n| ------------- | --------------------------------- | ----------------------------------------- |\n| **자원 관리** | 자원을 강제로 **빼앗을 수 있음**  | 자원을 **독점**할 수 있음                 |\n| **응답 시간** | **빠름**                          | 상대적으로 **느림**                       |\n| **복잡성**    | **문맥 교환**이 필요하므로 복잡함 | 단순하지만 **자원 낭비**가 발생할 수 있음 |\n| **예시**      | **RR 스케줄링**                   | **FCFS**(선입선처리 스케줄링)             |\n\n---\n\n> 대부분의 현대 운영체제는 **선점형 스케줄링**을 채택하지만, **상황과 목적에 따라** 적절한 방식을 선택합니다.  \n{: .prompt-info }\n\n---\n\n# 11-2 CPU 스케줄링 알고리즘\n\n---\n\n## CPU 스케줄링 알고리즘의 이해\n\nCPU 스케줄링 알고리즘은 **프로세스에 CPU를 할당하는 방식**을 결정합니다.  \n운영체제마다 스케줄링 알고리즘은 다를 수 있으며, 알고리즘의 **작동 원리**와 **장단점**을 이해하는 것이 중요합니다.\n\n---\n\n## 주요 CPU 스케줄링 알고리즘\n\n### 1. 선입선처리 스케줄링 (First Come First Served, FCFS)\n\n- **정의**:  \n  프로세스가 **도착한 순서대로** CPU를 할당받는 **비선점형** 스케줄링 방식입니다.  \n- **특징**:  \n  - 단순하고 구현이 쉽습니다.  \n  - **FIFO** 큐와 같은 구조를 사용합니다.\n\n> **호위 효과 (Convoy Effect)**  \n> 실행 시간이 긴 프로세스가 먼저 도착하면 뒤에 있는 **짧은 작업**이 **오랫동안 기다리는 현상**이 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n### 2. 최단 작업 우선 스케줄링 (Shortest Job First, SJF)\n\n- **정의**:  \n  **CPU 사용 시간이 가장 짧은 프로세스**를 먼저 실행하는 **비선점형** 스케줄링 방식입니다.  \n- **특징**:  \n  - **호위 효과**를 방지할 수 있습니다.  \n  - **평균 대기 시간**이 가장 짧은 이상적인 스케줄링입니다.  \n\n> **단점**  \n> 현실적으로 각 프로세스의 **CPU 실행 시간**을 **정확히 예측**하는건 어렵기에, 완벽하게 구현하는건 어렵다고 생각합니다.\n{: .prompt-warning }\n\n---\n\n### 3. 라운드 로빈 스케줄링 (Round Robin, RR)\n\n- **정의**:  \n  **FCFS**에 **타임 슬라이스(Time Slice)** 개념이 추가된 **선점형** 스케줄링 방식입니다.  \n- **작동 원리**:  \n  - 각 프로세스는 **정해진 시간**만큼 CPU를 사용하고, 타이머 인터럽트 발생 시 **다음 프로세스**로 전환됩니다.  \n\n> **타임 슬라이스 설정**  \n> 타임 슬라이스가 **너무 짧으면** 문맥 교환이 자주 발생해 **오버헤드**가 커지고,  \n> **너무 길면** FCFS와 유사해져 **응답 시간이 길어질 수 있습니다**.  \n{: .prompt-info }\n\n---\n\n### 4. 최소 잔여 시간 우선 스케줄링 (Shortest Remaining Time, SRT)\n\n- **정의**:  \n  **SJF**와 **RR**을 결합한 **선점형** 스케줄링 방식입니다.  \n- **작동 원리**:  \n  - CPU를 사용 중인 프로세스와 대기 중인 프로세스 중 **남은 작업 시간이 가장 짧은 프로세스**에 CPU를 할당합니다.  \n\n---\n\n### 5. 우선순위 스케줄링 (Priority Scheduling)\n\n- **정의**:  \n  프로세스에 **우선순위(priority)**를 부여하고, **우선순위가 높은 프로세스**부터 실행하는 방식입니다.  \n- **특징**:  \n  - SJF는 작업 시간이 짧은 프로세스에 **우선순위**를 부여한 **특수한 형태**입니다.  \n  - **우선순위가 동일**하면 **FCFS**처럼 동작합니다.  \n\n> **기아 현상 (Starvation)**  \n> 우선순위가 낮은 프로세스는 **계속 뒤로 밀려** 실행되지 못할 수 있습니다.   \n> 이를 해결하기 위해 **에이징(Aging)** 기법이 사용됩니다.  \n{: .prompt-warning }\n\n---\n\n### 6. 다단계 큐 스케줄링 (Multilevel Queue Scheduling)\n\n- **정의**:  \n  여러 개의 **준비 큐(Ready Queue)**를 사용하여 **우선순위별**로 프로세스를 관리하는 스케줄링 방식입니다.  \n- **작동 원리**:  \n  - 가장 높은 우선순위의 큐를 먼저 처리하고, **비어있으면** 다음 우선순위 큐를 처리합니다.  \n\n---\n\n### 7. 다단계 피드백 큐 스케줄링 (Multilevel Feedback Queue Scheduling)\n\n- **정의**:  \n  **다단계 큐 스케줄링**에서 **큐 사이 이동**이 가능한 방식입니다.  \n- **작동 원리**:  \n  - 프로세스는 처음에 **우선순위가 높은 큐**에 배정되며, **타임 슬라이스**를 모두 사용하면 **낮은 우선순위 큐**로 이동합니다.  \n\n> **에이징 기법**을 적용해 기아 현상을 방지할 수 있습니다.  \n{: .prompt-tip }\n\n> **다단계 피드백 큐 스케줄링**은 구현이 복잡하지만, **가장 효율적인 CPU 스케줄링**으로 알려져 있습니다.  \n{: .prompt-info }\n---\n\n## CPU 스케줄링 알고리즘 요약\n\n| **스케줄링 방식**     | **선점형 여부** | **특징**                                    | **단점**                           |\n| --------------------- | --------------- | ------------------------------------------- | ---------------------------------- |\n| **FCFS**              | 비선점형        | 도착 순서대로 실행                          | 호위 효과 발생                     |\n| **SJF**               | 비선점형        | CPU 실행 시간이 가장 짧은 프로세스 우선     | 실행 시간을 정확히 예측하기 어려움 |\n| **RR**                | 선점형          | 정해진 타임 슬라이스만큼 CPU 사용 후 교체   | 타임 슬라이스 설정이 중요          |\n| **SRT**               | 선점형          | 남은 실행 시간이 가장 짧은 프로세스 우선    | 문맥 교환 오버헤드 발생            |\n| **우선순위 스케줄링** | 혼합            | 우선순위가 높은 프로세스부터 실행           | 기아 현상 발생 가능                |\n| **다단계 큐**         | 혼합            | 우선순위별 큐를 사용하여 프로세스 관리      | 큐 간 이동 불가                    |\n| **다단계 피드백 큐**  | 선점형          | 프로세스가 큐를 이동하며 우선순위 조정 가능 | 구현이 복잡함                      |\n\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-19",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-19-11--CPU_chunk_0",
        "text": "[혼공컴운] 11장 CPU 스케줄링\n\n# 11-1 CPU 스케줄링 개요\n\n---\n\n## CPU 스케줄링이란?\n\n모든 **프로세스**는 실행을 위해 **CPU**를 필요로 합니다.  \n이 프로세스들에게 **자원을 합리적으로 할당**하는 것을 **CPU 스케줄링(CPU Scheduling)**이라고 합니다.  \n\n> **CPU 스케줄링**은 **컴퓨터 성능**과 직결되는 중요한 문제입니다.  \n{: .prompt-info }\n\n---\n\n## 프로세스 우선순위\n\n프로세스마다 **CPU 작업 시간**과 **입출력 대기 시간**은 다르게 나타납니다.  \n\n- **입출력 집중 프로세스 (I/O Bound Process)**  \n   - 입출력 작업이 많아 CPU를 적게 사용합니다.  \n   - 예: **비디오 재생, 디스크 백업**  \n\n- **CPU 집중 프로세스 (CPU Bound Process)**  \n   - CPU를 많이 사용하며 입출력 대기 시간은 적습니다.  \n   - 예: **수학 연산, 컴파일, 그래픽 처리**  \n\n> **CPU Burst**: CPU를 사용하는 시간  \n> **I/O Burst**: 입출력 장치를 기다리는 시간  \n{: .prompt-tip }\n\n---\n\n### 우선순위의 필요성\n\n입출력 집중 프로세스는 **입출력 작업 시간**이 길기 때문에 CPU를 동일하게 배정하면 **효율적이지 않습니다**.",
        "index": 0
      },
      {
        "id": "2024-12-19-11--CPU_chunk_1",
        "text": "prompt-tip }\n\n---\n\n### 우선순위의 필요성\n\n입출력 집중 프로세스는 **입출력 작업 시간**이 길기 때문에 CPU를 동일하게 배정하면 **효율적이지 않습니다**.  \n따라서 프로세스에 **우선순위(priority)**를 부여해 자원을 효율적으로 관리합니다.\n\n---\n\n## 스케줄링 큐\n\n프로세스의 **우선순위**는 PCB에 기록되지만, 이를 일일이 확인하는 것은 비효율적입니다.  \n그래서 프로세스는 **스케줄링 큐**로 관리됩니다.\n\n### 주요 스케줄링 큐  \n\n1. **준비 큐 (Ready Queue)**  \n   - CPU를 사용하기 위해 **대기 중인 프로세스**가 서 있는 큐입니다.\n\n2. **대기 큐 (Waiting Queue)**  \n   - 입출력 장치를 이용하기 위해 **대기 중인 프로세스**가 서 있는 큐입니다.\n\n> 스케줄링 큐는 **FIFO** 구조일 수도 있지만, 스케줄링 방식에 따라 다르게 동작할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n## 선점형과 비선점형 스케줄링\n\nCPU 스케줄링 방식은 크게 **선점형**과 **비선점형**으로 나뉩니다.\n\n### 선점형 스케줄링 (Preemptive Scheduling)\n\n- **정의**: 프로세스가 CPU를 사용하고 있어도 **강제로 자원을 빼앗아** 다른 프로세스에 할당할 수 있는 방식입니다.  \n- **특징**: 프로세스가 **자원을 독점할 수 없습니다**.",
        "index": 1
      },
      {
        "id": "2024-12-19-11--CPU_chunk_2",
        "text": "프로세스가 CPU를 사용하고 있어도 **강제로 자원을 빼앗아** 다른 프로세스에 할당할 수 있는 방식입니다.  \n- **특징**: 프로세스가 **자원을 독점할 수 없습니다**.  \n- **예시**: **타이머 인터럽트**가 발생하면, 운영체제가 CPU를 강제로 다른 프로세스에 할당합니다.\n\n---\n\n### 비선점형 스케줄링 (Non-Preemptive Scheduling)\n\n- **정의**: 한 프로세스가 CPU를 사용하고 있다면, 해당 프로세스가 **종료되거나 대기 상태**가 되기 전까지 다른 프로세스는 끼어들 수 없습니다.  \n- **특징**: 프로세스가 **자원을 독점**할 수 있습니다.",
        "index": 2
      },
      {
        "id": "2024-12-19-11--CPU_chunk_3",
        "text": "하고 있다면, 해당 프로세스가 **종료되거나 대기 상태**가 되기 전까지 다른 프로세스는 끼어들 수 없습니다.  \n- **특징**: 프로세스가 **자원을 독점**할 수 있습니다.  \n\n---\n\n### 선점형과 비선점형 스케줄링 비교  \n\n| **구분**      | **선점형 스케줄링**               | **비선점형 스케줄링**                     |\n| ------------- | --------------------------------- | ----------------------------------------- |\n| **자원 관리** | 자원을 강제로 **빼앗을 수 있음**  | 자원을 **독점**할 수 있음                 |\n| **응답 시간** | **빠름**                          | 상대적으로 **느림**                       |\n| **복잡성**    | **문맥 교환**이 필요하므로 복잡함 | 단순하지만 **자원 낭비**가 발생할 수 있음 |\n| **예시**      | **RR 스케줄링**                   | **FCFS**(선입선처리 스케줄링)             |\n\n---\n\n> 대부분의 현대 운영체제는 **선점형 스케줄링**을 채택하지만, **상황과 목적에 따라** 적절한 방식을 선택합니다.",
        "index": 3
      },
      {
        "id": "2024-12-19-11--CPU_chunk_4",
        "text": "(선입선처리 스케줄링)             |\n\n---\n\n> 대부분의 현대 운영체제는 **선점형 스케줄링**을 채택하지만, **상황과 목적에 따라** 적절한 방식을 선택합니다.  \n{: .prompt-info }\n\n---\n\n# 11-2 CPU 스케줄링 알고리즘\n\n---\n\n## CPU 스케줄링 알고리즘의 이해\n\nCPU 스케줄링 알고리즘은 **프로세스에 CPU를 할당하는 방식**을 결정합니다.  \n운영체제마다 스케줄링 알고리즘은 다를 수 있으며, 알고리즘의 **작동 원리**와 **장단점**을 이해하는 것이 중요합니다.\n\n---\n\n## 주요 CPU 스케줄링 알고리즘\n\n### 1. 선입선처리 스케줄링 (First Come First Served, FCFS)\n\n- **정의**:  \n  프로세스가 **도착한 순서대로** CPU를 할당받는 **비선점형** 스케줄링 방식입니다.  \n- **특징**:  \n  - 단순하고 구현이 쉽습니다.  \n  - **FIFO** 큐와 같은 구조를 사용합니다.\n\n> **호위 효과 (Convoy Effect)**  \n> 실행 시간이 긴 프로세스가 먼저 도착하면 뒤에 있는 **짧은 작업**이 **오랫동안 기다리는 현상**이 발생할 수 있습니다.  \n{: .prompt-warning }\n\n---\n\n### 2. 최단 작업 우선 스케줄링 (Shortest Job First, SJF)\n\n- **정의**:  \n  **CPU 사용 시간이 가장 짧은 프로세스**를 먼저 실행하는 **비선점형** 스케줄링 방식입니다.  \n- **특징**:  \n  - **호위 효과**를 방지할 수 있습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-19-7",
    "title": "[혼공컴운] 7장 보조기억장치",
    "path": "/2024/12/19/7장-보조기억장치/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "> 보조기억장치와 RAID에 대한 내용은 운영체제의 **파일시스템**에서 더욱 자세히 다룰 예정입니다.  \n>  여기서는 가볍게 핵심 개념만 이해하고 넘어가겠습니다. \n{: .prompt-tip }\n\n# 7-1 다양한 보조기억장치\n\n보조기억장치는 데이터를 **장기적으로 저장**하는 장치입니다.  \n\n대표적으로 **하드디스크**와 **플래시 메모리**가 있습니다.\n\n---\n\n## 하드디스크 (HDD)\n\n하드디스크는 **플래터**, **스핀들**, **헤드**, **디스크 암**으로 구성됩니다.  \n- **플래터**: 데이터를 저장하는 원형 판.  \n- **스핀들**: 플래터를 회전시키는 장치.  \n- **헤드**: 데이터를 읽고 쓰는 장치.  \n- **디스크 암**: 헤드를 이동시키는 장치.\n\n---\n\n## 플래시 메모리\n\n플래시 메모리는 한 셀에 저장되는 비트 수에 따라 다음과 같이 구분됩니다.  \n\n- **SLC** (Single-Level Cell): 1비트 저장. 빠르고 내구성이 높지만 비쌉니다.  \n- **MLC** (Multi-Level Cell): 2비트 저장. SLC보다 저렴하지만 성능과 내구성은 낮습니다.  \n- **TLC** (Triple-Level Cell): 3비트 저장. 저렴하지만 성능과 수명이 더 떨어집니다.\n\n\n---\n\n# 7-2 RAID의 정의와 종류\n\n**1TB 하드디스크 4개**를 사용하는 것과 **4TB 하드디스크 하나**를 사용하는 것은 용량만 보면 같습니다. 하지만 **RAID**를 구성하면 성능과 안정성을 더욱 높일 수 있습니다.\n\n---\n\n## RAID의 정의\n\nRAID는 **Redundant Array of Independent Disks**의 약어입니다.  \n여러 개의 물리적 보조기억장치를 마치 **하나의 논리적 장치**처럼 사용하는 기술입니다.  \n**목적**: 데이터를 더욱 **안정적**으로 저장하거나 **높은 성능**을 제공하기 위함입니다.\n\n---\n\n## RAID의 종류\n\nRAID의 구성 방식은 **RAID 레벨**이라고 부르며, 대표적으로 다음과 같습니다.\n\n- **RAID 0**: 데이터를 여러 디스크에 나눠서 저장. **속도**는 빠르지만 **안정성**은 떨어집니다.  \n- **RAID 1**: 데이터를 두 개 이상의 디스크에 **복제**해 저장. **안정성**이 높습니다.  \n- **RAID 2, 3, 4**: 데이터를 나누고 **패리티** 정보를 저장하는 방식입니다. 사용 빈도가 낮습니다.  \n- **RAID 5**: 데이터를 나누고 **패리티 정보를 분산 저장**해 성능과 안정성을 동시에 제공.  \n- **RAID 6**: RAID 5와 유사하지만 **2개의 패리티** 정보를 저장해 더 높은 안정성을 제공.  \n\n이외에도 RAID **10**, **50** 등 다양한 조합이 존재합니다.\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-19",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-19-7_chunk_0",
        "text": "[혼공컴운] 7장 보조기억장치\n\n> 보조기억장치와 RAID에 대한 내용은 운영체제의 **파일시스템**에서 더욱 자세히 다룰 예정입니다.  \n>  여기서는 가볍게 핵심 개념만 이해하고 넘어가겠습니다. \n{: .prompt-tip }\n\n# 7-1 다양한 보조기억장치\n\n보조기억장치는 데이터를 **장기적으로 저장**하는 장치입니다.  \n\n대표적으로 **하드디스크**와 **플래시 메모리**가 있습니다.\n\n---\n\n## 하드디스크 (HDD)\n\n하드디스크는 **플래터**, **스핀들**, **헤드**, **디스크 암**으로 구성됩니다.  \n- **플래터**: 데이터를 저장하는 원형 판.  \n- **스핀들**: 플래터를 회전시키는 장치.  \n- **헤드**: 데이터를 읽고 쓰는 장치.  \n- **디스크 암**: 헤드를 이동시키는 장치.\n\n---\n\n## 플래시 메모리\n\n플래시 메모리는 한 셀에 저장되는 비트 수에 따라 다음과 같이 구분됩니다.  \n\n- **SLC** (Single-Level Cell): 1비트 저장. 빠르고 내구성이 높지만 비쌉니다.  \n- **MLC** (Multi-Level Cell): 2비트 저장. SLC보다 저렴하지만 성능과 내구성은 낮습니다.  \n- **TLC** (Triple-Level Cell): 3비트 저장. 저렴하지만 성능과 수명이 더 떨어집니다.\n\n\n---\n\n# 7-2 RAID의 정의와 종류\n\n**1TB 하드디스크 4개**를 사용하는 것과 **4TB 하드디스크 하나**를 사용하는 것은 용량만 보면 같습니다.",
        "index": 0
      },
      {
        "id": "2024-12-19-7_chunk_1",
        "text": "떨어집니다.\n\n\n---\n\n# 7-2 RAID의 정의와 종류\n\n**1TB 하드디스크 4개**를 사용하는 것과 **4TB 하드디스크 하나**를 사용하는 것은 용량만 보면 같습니다. 하지만 **RAID**를 구성하면 성능과 안정성을 더욱 높일 수 있습니다.\n\n---\n\n## RAID의 정의\n\nRAID는 **Redundant Array of Independent Disks**의 약어입니다.  \n여러 개의 물리적 보조기억장치를 마치 **하나의 논리적 장치**처럼 사용하는 기술입니다.  \n**목적**: 데이터를 더욱 **안정적**으로 저장하거나 **높은 성능**을 제공하기 위함입니다.\n\n---\n\n## RAID의 종류\n\nRAID의 구성 방식은 **RAID 레벨**이라고 부르며, 대표적으로 다음과 같습니다.\n\n- **RAID 0**: 데이터를 여러 디스크에 나눠서 저장. **속도**는 빠르지만 **안정성**은 떨어집니다.  \n- **RAID 1**: 데이터를 두 개 이상의 디스크에 **복제**해 저장. **안정성**이 높습니다.  \n- **RAID 2, 3, 4**: 데이터를 나누고 **패리티** 정보를 저장하는 방식입니다. 사용 빈도가 낮습니다.  \n- **RAID 5**: 데이터를 나누고 **패리티 정보를 분산 저장**해 성능과 안정성을 동시에 제공.  \n- **RAID 6**: RAID 5와 유사하지만 **2개의 패리티** 정보를 저장해 더 높은 안정성을 제공.",
        "index": 1
      },
      {
        "id": "2024-12-19-7_chunk_2",
        "text": "**패리티 정보를 분산 저장**해 성능과 안정성을 동시에 제공.  \n- **RAID 6**: RAID 5와 유사하지만 **2개의 패리티** 정보를 저장해 더 높은 안정성을 제공.  \n\n이외에도 RAID **10**, **50** 등 다양한 조합이 존재합니다.\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 2
      },
      {
        "id": "2024-12-19-7_chunk_3",
        "text": "* 등 다양한 조합이 존재합니다.\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 3
      },
      {
        "id": "2024-12-19-7_chunk_4",
        "text": "* 등 다양한 조합이 존재합니다.\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-19-8",
    "title": "[혼공컴운] 8장 입출력장치",
    "path": "/2024/12/19/8장-입출력장치/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 8-1 장치 컨트롤러와 장치 드라이버\n\n---\n\n## 장치 컨트롤러\n\n입출력장치는 **CPU**나 **메모리**보다 다루기 까다롭습니다.  \n그 이유는 다음과 같습니다.  \n\n- **입출력장치의 종류가 매우 많음**  \n- **데이터 전송률이 낮음**  \n\n이 때문에 입출력장치는 컴퓨터에 **직접 연결되지 않고**, **장치 컨트롤러**(Device Controller)라는 **하드웨어**를 통해 연결됩니다.\n\n장치 컨트롤러는 다음과 같은 역할을 수행합니다.  \n\n- **CPU와 입출력장치 간의 통신 중개**  \n- **오류 검출**  \n- **데이터 버퍼링**  \n\n> **버퍼링**이란?  \n> 전송률이 높은 장치와 낮은 장치 사이에서 데이터를 **임시 저장 공간(버퍼)**에 저장해 전송률 차이를 맞추는 방법입니다.  \n{: .prompt-info }\n\n---\n\n### 장치 컨트롤러의 내부 구조  \n\n장치 컨트롤러는 **세 가지 레지스터**로 구성됩니다.\n\n1. **데이터 레지스터**  \n   - CPU와 입출력장치 사이의 데이터를 저장합니다.  \n   - 최근에는 **RAM**이 데이터를 저장하는 경우도 많습니다.\n\n2. **상태 레지스터**  \n   - 입출력장치의 상태 정보(작업 준비, 완료 여부, 오류 여부)를 저장합니다.\n\n3. **제어 레지스터**  \n   - 입출력장치가 수행할 **명령**과 **제어 정보**를 저장합니다.\n\n---\n\n## 장치 드라이버\n\n**장치 드라이버**는 장치 컨트롤러의 동작을 감지하고 제어하는 **소프트웨어**입니다.  \n- **장치 컨트롤러**가 하드웨어적 통로라면,  \n- **장치 드라이버**는 **소프트웨어적 통로**라고 할 수 있습니다.\n\n---\n\n# 8-2 다양한 입출력 방법\n\n입출력 방법은 크게 **세 가지**가 있습니다.  \n\n1. **프로그램 입출력**  \n2. **인터럽트 기반 입출력**  \n3. **DMA 입출력**\n\n---\n\n## 프로그램 입출력\n\n프로그램 입출력은 **CPU**가 **프로그램 명령어**를 통해 입출력 장치를 제어하는 방식입니다.  \nCPU는 장치 컨트롤러와 상호작용하며 입출력 작업을 수행합니다.\n\n입출력 장치의 레지스터를 읽고 쓰기 위해 **주소 공간**을 사용하는데, 크게 두 가지 방식이 있습니다.\n\n---\n\n### 메모리 맵 입출력\n\n- **메모리와 입출력 장치**가 **하나의 주소 공간**을 공유합니다.  \n- 예를 들어, 주소 공간이 `0~1023`이라면  \n  - `0~511`은 **메모리**  \n  - `512~1023`은 **입출력 장치**에 할당됩니다.\n\n> 메모리와 입출력장치가 같은 주소 공간을 공유합니다.  \n{: .prompt-tip }\n\n---\n\n### 고립형 입출력\n\n- **메모리와 입출력 장치**의 주소 공간을 **분리**합니다.  \n- 별도의 **제어 버스**를 사용하며, 입출력 전용 명령어를 사용합니다.\n\n---\n\n## 인터럽트 기반 입출력\n\n인터럽트 기반 입출력은 **CPU가 입출력장치의 요청**을 **인터럽트**로 처리하는 방식입니다.\n\n- **폴링**(Polling): CPU가 장치 상태를 계속 확인하는 방법. 비효율적입니다.  \n- **인터럽트**: 입출력장치가 완료 신호를 보내면 CPU가 이를 처리합니다.  \n\n입출력장치의 인터럽트는 **PIC**(Programmable Interrupt Controller)를 통해 관리됩니다.\n\n> **인터럽트**에 대한 내용은 운영체제에서 자세히 다룰 예정입니다.  \n{: .prompt-info }\n\n---\n\n## DMA 입출력\n\nDMA(Direct Memory Access)는 **CPU를 거치지 않고** **메모리와 입출력장치**가 직접 데이터를 전송하는 방식입니다.\n\n이를 위해 **DMA 컨트롤러**라는 하드웨어가 시스템 버스에 연결됩니다.\n\n### DMA의 장단점\n\n- **장점**: CPU의 개입 없이 데이터 전송이 가능하므로 **CPU의 부담**이 줄어듭니다.  \n- **단점**: DMA 컨트롤러가 시스템 버스를 점유하기 때문에 **다른 작업**에 영향을 줄 수 있습니다.\n\n---\n\n### PCI 버스\n\n**PCI 버스**(Peripheral Component Interconnect)는 DMA가 작동할 때 사용되는 **고속 데이터 전송 통로**입니다.  \n- 입출력장치와 메모리 사이에서 **고속 데이터 전송**을 지원합니다.\n\n> **PCI 버스**는 입출력 장치와 메모리의 데이터 전송을 더욱 효율적으로 만드는 기술입니다.  \n{: .highlight }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-19",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-19-8_chunk_0",
        "text": "[혼공컴운] 8장 입출력장치\n\n# 8-1 장치 컨트롤러와 장치 드라이버\n\n---\n\n## 장치 컨트롤러\n\n입출력장치는 **CPU**나 **메모리**보다 다루기 까다롭습니다.  \n그 이유는 다음과 같습니다.  \n\n- **입출력장치의 종류가 매우 많음**  \n- **데이터 전송률이 낮음**  \n\n이 때문에 입출력장치는 컴퓨터에 **직접 연결되지 않고**, **장치 컨트롤러**(Device Controller)라는 **하드웨어**를 통해 연결됩니다.\n\n장치 컨트롤러는 다음과 같은 역할을 수행합니다.  \n\n- **CPU와 입출력장치 간의 통신 중개**  \n- **오류 검출**  \n- **데이터 버퍼링**  \n\n> **버퍼링**이란?  \n> 전송률이 높은 장치와 낮은 장치 사이에서 데이터를 **임시 저장 공간(버퍼)**에 저장해 전송률 차이를 맞추는 방법입니다.  \n{: .prompt-info }\n\n---\n\n### 장치 컨트롤러의 내부 구조  \n\n장치 컨트롤러는 **세 가지 레지스터**로 구성됩니다.\n\n1. **데이터 레지스터**  \n   - CPU와 입출력장치 사이의 데이터를 저장합니다.  \n   - 최근에는 **RAM**이 데이터를 저장하는 경우도 많습니다.\n\n2. **상태 레지스터**  \n   - 입출력장치의 상태 정보(작업 준비, 완료 여부, 오류 여부)를 저장합니다.\n\n3. **제어 레지스터**  \n   - 입출력장치가 수행할 **명령**과 **제어 정보**를 저장합니다.\n\n---\n\n## 장치 드라이버\n\n**장치 드라이버**는 장치 컨트롤러의 동작을 감지하고 제어하는 **소프트웨어**입니다.",
        "index": 0
      },
      {
        "id": "2024-12-19-8_chunk_1",
        "text": "가 수행할 **명령**과 **제어 정보**를 저장합니다.\n\n---\n\n## 장치 드라이버\n\n**장치 드라이버**는 장치 컨트롤러의 동작을 감지하고 제어하는 **소프트웨어**입니다.  \n- **장치 컨트롤러**가 하드웨어적 통로라면,  \n- **장치 드라이버**는 **소프트웨어적 통로**라고 할 수 있습니다.\n\n---\n\n# 8-2 다양한 입출력 방법\n\n입출력 방법은 크게 **세 가지**가 있습니다.  \n\n1. **프로그램 입출력**  \n2. **인터럽트 기반 입출력**  \n3. **DMA 입출력**\n\n---\n\n## 프로그램 입출력\n\n프로그램 입출력은 **CPU**가 **프로그램 명령어**를 통해 입출력 장치를 제어하는 방식입니다.  \nCPU는 장치 컨트롤러와 상호작용하며 입출력 작업을 수행합니다.\n\n입출력 장치의 레지스터를 읽고 쓰기 위해 **주소 공간**을 사용하는데, 크게 두 가지 방식이 있습니다.\n\n---\n\n### 메모리 맵 입출력\n\n- **메모리와 입출력 장치**가 **하나의 주소 공간**을 공유합니다.  \n- 예를 들어, 주소 공간이 `0~1023`이라면  \n  - `0~511`은 **메모리**  \n  - `512~1023`은 **입출력 장치**에 할당됩니다.\n\n> 메모리와 입출력장치가 같은 주소 공간을 공유합니다.  \n{: .prompt-tip }\n\n---\n\n### 고립형 입출력\n\n- **메모리와 입출력 장치**의 주소 공간을 **분리**합니다.",
        "index": 1
      },
      {
        "id": "2024-12-19-8_chunk_2",
        "text": "입출력장치가 같은 주소 공간을 공유합니다.  \n{: .prompt-tip }\n\n---\n\n### 고립형 입출력\n\n- **메모리와 입출력 장치**의 주소 공간을 **분리**합니다.  \n- 별도의 **제어 버스**를 사용하며, 입출력 전용 명령어를 사용합니다.\n\n---\n\n## 인터럽트 기반 입출력\n\n인터럽트 기반 입출력은 **CPU가 입출력장치의 요청**을 **인터럽트**로 처리하는 방식입니다.\n\n- **폴링**(Polling): CPU가 장치 상태를 계속 확인하는 방법. 비효율적입니다.  \n- **인터럽트**: 입출력장치가 완료 신호를 보내면 CPU가 이를 처리합니다.  \n\n입출력장치의 인터럽트는 **PIC**(Programmable Interrupt Controller)를 통해 관리됩니다.\n\n> **인터럽트**에 대한 내용은 운영체제에서 자세히 다룰 예정입니다.  \n{: .prompt-info }\n\n---\n\n## DMA 입출력\n\nDMA(Direct Memory Access)는 **CPU를 거치지 않고** **메모리와 입출력장치**가 직접 데이터를 전송하는 방식입니다.\n\n이를 위해 **DMA 컨트롤러**라는 하드웨어가 시스템 버스에 연결됩니다.\n\n### DMA의 장단점\n\n- **장점**: CPU의 개입 없이 데이터 전송이 가능하므로 **CPU의 부담**이 줄어듭니다.",
        "index": 2
      },
      {
        "id": "2024-12-19-8_chunk_3",
        "text": "컨트롤러**라는 하드웨어가 시스템 버스에 연결됩니다.\n\n### DMA의 장단점\n\n- **장점**: CPU의 개입 없이 데이터 전송이 가능하므로 **CPU의 부담**이 줄어듭니다.  \n- **단점**: DMA 컨트롤러가 시스템 버스를 점유하기 때문에 **다른 작업**에 영향을 줄 수 있습니다.\n\n---\n\n### PCI 버스\n\n**PCI 버스**(Peripheral Component Interconnect)는 DMA가 작동할 때 사용되는 **고속 데이터 전송 통로**입니다.  \n- 입출력장치와 메모리 사이에서 **고속 데이터 전송**을 지원합니다.\n\n> **PCI 버스**는 입출력 장치와 메모리의 데이터 전송을 더욱 효율적으로 만드는 기술입니다.  \n{: .highlight }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 3
      },
      {
        "id": "2024-12-19-8_chunk_4",
        "text": "{: .highlight }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-19-10",
    "title": "[혼공컴운] 10장 프로세스와 스레드",
    "path": "/2024/12/19/10장-프로세스와-스레드/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 10-1 프로세스 개요\n\n---\n\n## 프로그램과 프로세스\n\n**프로그램**은 실행 전까지는 **보조기억장치**에 저장된 **데이터**에 불과합니다.  \n하지만 프로그램이 **메모리에 적재**되어 **실행**되는 순간, **프로세스**가 됩니다.  \n이것을 **\"프로세스를 생성한다\"**라고 합니다.\n\n---\n\n## 프로세스 확인하기\n\n프로세스는 다음과 같은 방법으로 확인할 수 있습니다.  \n\n- **Windows**: 작업 관리자(Task Manager)  \n- **Linux/Unix**: `ps -ef` 명령어  \n\n프로세스는 실행 형태에 따라 두 가지로 구분됩니다.\n\n1. **포그라운드 프로세스**: 사용자가 직접 실행하고 상호작용하는 프로세스.  \n2. **백그라운드 프로세스**: 화면에 보이지 않지만 실행되는 프로세스.  \n\n> **데몬(Daemon)**: 유닉스 체계에서 사용자와 상호작용 없이 정해진 일만 수행하는 백그라운드 프로세스.  \n> **서비스(Service)**: 윈도우에서 동일한 역할을 수행합니다.  \n{: .prompt-info }\n\n---\n\n## 프로세스 제어 블록(PCB)\n\n운영체제는 여러 프로세스를 **번갈아 가며 실행**하고 자원을 **효율적으로 분배**합니다.  \n이를 위해 프로세스 정보를 저장하는 **프로세스 제어 블록(PCB)**을 사용합니다.\n\n### PCB에 포함되는 정보  \n\n- **프로세스 ID (PID)**  \n  특정 프로세스를 식별하기 위한 **고유한 번호**입니다.\n\n- **레지스터 값**  \n  프로그램 카운터를 포함한 **레지스터 정보**를 저장합니다.\n\n- **프로세스 상태**  \n  프로세스가 **CPU를 기다리는지**, **실행 중인지**, **입출력 작업 중인지** 등의 상태를 기록합니다.\n\n- **CPU 스케줄링 정보**  \n  언제, 어떤 순서로 **CPU를 할당받는지**에 대한 정보가 기록됩니다.\n\n- **메모리 관리 정보**  \n  프로세스의 메모리 영역 정보가 저장됩니다.  \n  예: 베이스 레지스터, 한계 레지스터, 페이지 테이블 등.\n\n---\n\n## 문맥 교환(Context Switching)\n\n**문맥 교환**은 프로세스 A의 실행이 중단되고 프로세스 B로 **전환될 때** 발생합니다.  \n\n1. **프로세스 A의 컨텍스트(실행 정보)**를 PCB에 저장합니다.  \n2. **프로세스 B의 컨텍스트**를 PCB에서 복구해 실행을 재개합니다.\n\n> **컨텍스트**란 프로세스 수행을 재개하기 위해 필요한 **모든 정보**입니다.  \n{: .prompt-info }\n\n> **문맥 교환의 특징**  \n> 문맥 교환은 **오버헤드**를 발생시킵니다. 편리하지만 성능 저하를 초래할 수 있으므로 효율적으로 관리해야 합니다.  \n{: .prompt-warning }\n\n---\n\n## 프로세스의 메모리 영역\n\n**PCB**는 **커널 영역**에 저장되며, **사용자 영역**에는 다음과 같은 메모리 영역이 존재합니다.\n\n| **메모리 영역** | **설명**                                                            |\n| --------------- | ------------------------------------------------------------------- |\n| **코드 영역**   | 실행할 수 있는 기계어 명령어가 저장된 **읽기 전용** 공간입니다.     |\n| **데이터 영역** | 프로그램 실행 동안 유지되는 **전역 변수, 정적 변수**를 저장합니다.  |\n| **힙 영역**     | **프로그래머가 동적으로 할당**하는 메모리입니다. 반환이 필요합니다. |\n| **스택 영역**   | **함수 실행 시** 생성되는 매개변수, 지역 변수를 저장합니다.         |\n\n---\n\n### 동적 할당과 정적 할당\n\n- **코드 영역과 데이터 영역**: **정적 할당** 영역입니다. 크기가 고정되어 있습니다.  \n- **힙 영역과 스택 영역**: **동적 할당** 영역입니다.  \n\n> **할당 방향**  \n> - **스택 영역**: 상위 주소 → 하위 주소로 할당됩니다.  \n> - **힙 영역**: 하위 주소 → 상위 주소로 할당됩니다.  \n{: .prompt-tip }\n\n> **메모리 누수(Memory Leak)**  \n> 힙 영역에 할당한 메모리를 반환하지 않으면 **메모리 낭비**가 발생합니다. 이를 **메모리 누수**라고 합니다.  \n{: .prompt-warning }\n\n---\n\n# 10-2 프로세스 상태와 계층 구조\n\n---\n\n## 프로세스 상태\n\n운영체제마다 조금씩 다를 수 있지만, 일반적으로 **프로세스의 상태**는 다음과 같이 나뉩니다.\n\n1. **생성 상태 (New)**  \n   - 이제 막 **메모리에 적재**되어 **PCB**를 할당받은 상태입니다.  \n   - 이 상태를 거쳐 실행 준비가 완료되면 **준비 상태**로 전환됩니다.  \n\n2. **준비 상태 (Ready)**  \n   - CPU를 **할당받기 위해 대기 중**인 상태입니다.  \n   - 아직 실행되지 않았지만, 언제든 실행될 준비가 되어 있습니다.  \n\n3. **실행 상태 (Running)**  \n   - CPU를 할당받아 **명령어를 실행 중**인 상태입니다.  \n   - 할당된 시간을 모두 사용하면 **준비 상태**로 돌아가거나, **입출력 장치**의 작업을 기다려야 하면 **대기 상태**로 전환됩니다.\n\n4. **대기 상태 (Blocked)**  \n   - 입출력 장치의 작업을 **기다리는 상태**입니다.  \n   - 입출력이 완료되면 **인터럽트**를 받아 다시 **준비 상태**로 전환됩니다.  \n\n5. **종료 상태 (Terminated)**  \n   - 프로세스의 실행이 **완료된 상태**입니다.  \n   - 운영체제는 PCB와 프로세스가 사용한 **메모리**를 정리합니다.\n\n> **디스패치 (Dispatch)**:  \n> 준비 상태에서 CPU를 할당받아 실행 상태로 전환되는 것을 **디스패치**라고 합니다.  \n{: .prompt-info }\n---\n\n## 프로세스 계층 구조\n\n프로세스는 **시스템 콜**을 통해 **다른 프로세스를 생성**할 수 있습니다.  \n\n- **부모 프로세스**가 **자식 프로세스**를 생성합니다.  \n- 부모와 자식 프로세스는 **서로 다른 PID**(Process ID)를 가집니다.  \n- 자식 프로세스도 다른 프로세스를 생성할 수 있으며, 이 구조는 **트리 구조**를 형성합니다.\n\n---\n\n### 최초의 프로세스\n\n모든 프로세스의 시작점은 **최초의 프로세스**입니다.\n\n| **운영체제** | **최초의 프로세스** | **PID** |\n| ------------ | ------------------- | ------- |\n| **유닉스**   | `init`              | 1       |\n| **리눅스**   | `systemd`           | 1       |\n| **macOS**    | `launchd`           | 1       |\n\n> **최초의 프로세스**는 항상 PID가 **1번**이며, 모든 프로세스의 **최상위 부모 프로세스**입니다.  \n{: .prompt-tip }\n\n---\n\n## 프로세스 생성 기법\n\n프로세스를 생성하는 주요 시스템 콜은 **`fork`**와 **`exec`**입니다.\n\n1. **fork**  \n   - 부모 프로세스의 **복사본**을 자식 프로세스로 생성합니다.  \n   - 자식 프로세스는 부모의 모든 자원을 **상속**받지만, **PID**는 다릅니다.  \n\n2. **exec**  \n   - 자식 프로세스의 메모리 공간을 **다른 프로그램**으로 교체합니다.  \n   - 새로운 프로그램이 메모리에 적재되고 실행됩니다.\n\n---\n\n### 프로세스 생성 과정 예시\n\n1. 부모 프로세스가 **fork** 시스템 콜을 호출해 자신의 복사본을 생성합니다.  \n2. 자식 프로세스는 **exec** 시스템 콜을 호출해 **새로운 프로그램**을 실행합니다.  \n\n> **참고**:  \n> `fork` 후 자식 프로세스가 `exec`를 호출하지 않고 부모와 **같은 코드**를 병행해 실행하는 경우도 있습니다.  \n{: .prompt-info }\n\n---\n\n# 10-3 스레드\n\n---\n\n## 프로세스와 스레드\n\n**스레드(Thread)**는 프로세스를 구성하는 **실행의 흐름 단위**입니다.  \n하나의 프로세스는 여러 개의 **스레드**를 가질 수 있습니다.\n\n---\n\n### 단일 스레드와 스레드 개념의 도입  \n\n- **단일 스레드 프로세스**:  \n  코드가 **위에서 아래로 순차적으로** 하나의 일을 실행합니다.\n\n- **스레드의 도입**:  \n  하나의 프로세스에서 여러 개의 스레드를 생성하여 **동시에 여러 작업을 처리**할 수 있게 되었습니다.\n\n---\n\n### 스레드의 구성 요소\n\n각 스레드는 다음과 같은 구성 요소를 가집니다.  \n\n- **스레드 ID**: 스레드를 식별하는 고유한 ID.  \n- **프로그램 카운터**: 실행할 명령어의 위치를 가리킵니다.  \n- **레지스터 값**: 스레드마다 별도의 레지스터 값을 가집니다.  \n- **스택**: 각 스레드의 함수 호출 정보와 지역 변수를 저장합니다.  \n\n> **공유 자원**  \n> 스레드들은 같은 **코드 영역, 힙 영역, 데이터 영역**을 공유합니다.  \n> 하지만 **스택**과 **레지스터**는 독립적으로 가집니다.  \n{: .prompt-tip }\n\n---\n\n> **참고**  \n> 리눅스에서는 프로세스와 스레드를 명확히 구분하지 않고 **태스크(Task)**라는 용어를 사용합니다.  \n{: .prompt-info }\n\n---\n\n## 멀티프로세스와 멀티스레드\n\n**멀티프로세스**와 **멀티스레드**는 동시에 여러 작업을 처리하는 방법입니다.\n\n1. **멀티프로세스**  \n   - 여러 **독립된 프로세스**를 동시에 실행하는 방식입니다.  \n   - 각 프로세스는 **메모리 공간**을 독립적으로 사용합니다.\n\n2. **멀티스레드**  \n   - 하나의 **프로세스 내**에서 여러 **스레드**를 동시에 실행하는 방식입니다.  \n   - 스레드들은 **코드, 힙, 데이터 영역**을 공유합니다.\n\n---\n\n### 멀티프로세스와 멀티스레드 비교  \n\n| **구분**           | **멀티프로세스**                         | **멀티스레드**                                |\n| ------------------ | ---------------------------------------- | --------------------------------------------- |\n| **정의**           | 여러 개의 **프로세스**를 동시에 실행     | 하나의 프로세스에서 여러 **스레드** 실행      |\n| **메모리 사용**    | 각 프로세스가 **독립적인 메모리** 사용   | **코드, 힙, 데이터 영역** 공유, 스택은 독립적 |\n| **문맥 교환 비용** | 프로세스 간 **문맥 교환** 비용이 큼      | 스레드 간 문맥 교환 비용이 상대적으로 적음    |\n| **안정성**         | 프로세스 간 격리로 오류 전파 위험이 낮음 | 하나의 스레드 오류가 **전체 프로세스**에 영향 |\n| **자원 공유**      | 자원 공유가 어렵고, **IPC** 필요         | 자원을 자연스럽게 공유                        |\n\n---\n\n## 프로세스 간 통신(IPC)\n\n프로세스는 기본적으로 **자원을 공유하지 않기** 때문에 데이터를 주고받기 위해 **프로세스 간 통신(IPC)**이 필요합니다.\n\n- **IPC 기법**:  \n  프로세스들이 데이터를 주고받는 다양한 방법입니다.  \n\n- **공유 메모리 (Shared Memory, shm)**:  \n  특정 메모리 영역을 여러 프로세스가 공유하여 데이터를 주고받는 방식입니다.\n\n> **IPC**를 통해 독립된 프로세스 간에도 데이터를 효율적으로 공유할 수 있습니다.  \n{: .prompt-info }\n\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고 정리한 글입니다.  \n{: .prompt-tip }\n",
    "date": "2024-12-19",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-19-10_chunk_0",
        "text": "[혼공컴운] 10장 프로세스와 스레드\n\n# 10-1 프로세스 개요\n\n---\n\n## 프로그램과 프로세스\n\n**프로그램**은 실행 전까지는 **보조기억장치**에 저장된 **데이터**에 불과합니다.  \n하지만 프로그램이 **메모리에 적재**되어 **실행**되는 순간, **프로세스**가 됩니다.  \n이것을 **\"프로세스를 생성한다\"**라고 합니다.\n\n---\n\n## 프로세스 확인하기\n\n프로세스는 다음과 같은 방법으로 확인할 수 있습니다.  \n\n- **Windows**: 작업 관리자(Task Manager)  \n- **Linux/Unix**: `ps -ef` 명령어  \n\n프로세스는 실행 형태에 따라 두 가지로 구분됩니다.\n\n1. **포그라운드 프로세스**: 사용자가 직접 실행하고 상호작용하는 프로세스.  \n2. **백그라운드 프로세스**: 화면에 보이지 않지만 실행되는 프로세스.  \n\n> **데몬(Daemon)**: 유닉스 체계에서 사용자와 상호작용 없이 정해진 일만 수행하는 백그라운드 프로세스.  \n> **서비스(Service)**: 윈도우에서 동일한 역할을 수행합니다.  \n{: .prompt-info }\n\n---\n\n## 프로세스 제어 블록(PCB)\n\n운영체제는 여러 프로세스를 **번갈아 가며 실행**하고 자원을 **효율적으로 분배**합니다.",
        "index": 0
      },
      {
        "id": "2024-12-19-10_chunk_1",
        "text": ".  \n{: .prompt-info }\n\n---\n\n## 프로세스 제어 블록(PCB)\n\n운영체제는 여러 프로세스를 **번갈아 가며 실행**하고 자원을 **효율적으로 분배**합니다.  \n이를 위해 프로세스 정보를 저장하는 **프로세스 제어 블록(PCB)**을 사용합니다.\n\n### PCB에 포함되는 정보  \n\n- **프로세스 ID (PID)**  \n  특정 프로세스를 식별하기 위한 **고유한 번호**입니다.\n\n- **레지스터 값**  \n  프로그램 카운터를 포함한 **레지스터 정보**를 저장합니다.\n\n- **프로세스 상태**  \n  프로세스가 **CPU를 기다리는지**, **실행 중인지**, **입출력 작업 중인지** 등의 상태를 기록합니다.\n\n- **CPU 스케줄링 정보**  \n  언제, 어떤 순서로 **CPU를 할당받는지**에 대한 정보가 기록됩니다.\n\n- **메모리 관리 정보**  \n  프로세스의 메모리 영역 정보가 저장됩니다.  \n  예: 베이스 레지스터, 한계 레지스터, 페이지 테이블 등.\n\n---\n\n## 문맥 교환(Context Switching)\n\n**문맥 교환**은 프로세스 A의 실행이 중단되고 프로세스 B로 **전환될 때** 발생합니다.  \n\n1. **프로세스 A의 컨텍스트(실행 정보)**를 PCB에 저장합니다.  \n2. **프로세스 B의 컨텍스트**를 PCB에서 복구해 실행을 재개합니다.\n\n> **컨텍스트**란 프로세스 수행을 재개하기 위해 필요한 **모든 정보**입니다.  \n{: .prompt-info }\n\n> **문맥 교환의 특징**  \n> 문맥 교환은 **오버헤드**를 발생시킵니다.",
        "index": 1
      },
      {
        "id": "2024-12-19-10_chunk_2",
        "text": "로세스 수행을 재개하기 위해 필요한 **모든 정보**입니다.  \n{: .prompt-info }\n\n> **문맥 교환의 특징**  \n> 문맥 교환은 **오버헤드**를 발생시킵니다. 편리하지만 성능 저하를 초래할 수 있으므로 효율적으로 관리해야 합니다.  \n{: .prompt-warning }\n\n---\n\n## 프로세스의 메모리 영역\n\n**PCB**는 **커널 영역**에 저장되며, **사용자 영역**에는 다음과 같은 메모리 영역이 존재합니다.\n\n| **메모리 영역** | **설명**                                                            |\n| --------------- | ------------------------------------------------------------------- |\n| **코드 영역**   | 실행할 수 있는 기계어 명령어가 저장된 **읽기 전용** 공간입니다.     |\n| **데이터 영역** | 프로그램 실행 동안 유지되는 **전역 변수, 정적 변수**를 저장합니다.  |\n| **힙 영역**     | **프로그래머가 동적으로 할당**하는 메모리입니다. 반환이 필요합니다. |\n| **스택 영역**   | **함수 실행 시** 생성되는 매개변수, 지역 변수를 저장합니다.         |\n\n---\n\n### 동적 할당과 정적 할당\n\n- **코드 영역과 데이터 영역**: **정적 할당** 영역입니다. 크기가 고정되어 있습니다.  \n- **힙 영역과 스택 영역**: **동적 할당** 영역입니다.",
        "index": 2
      },
      {
        "id": "2024-12-19-10_chunk_3",
        "text": "과 정적 할당\n\n- **코드 영역과 데이터 영역**: **정적 할당** 영역입니다. 크기가 고정되어 있습니다.  \n- **힙 영역과 스택 영역**: **동적 할당** 영역입니다.  \n\n> **할당 방향**  \n> - **스택 영역**: 상위 주소 → 하위 주소로 할당됩니다.  \n> - **힙 영역**: 하위 주소 → 상위 주소로 할당됩니다.  \n{: .prompt-tip }\n\n> **메모리 누수(Memory Leak)**  \n> 힙 영역에 할당한 메모리를 반환하지 않으면 **메모리 낭비**가 발생합니다. 이를 **메모리 누수**라고 합니다.  \n{: .prompt-warning }\n\n---\n\n# 10-2 프로세스 상태와 계층 구조\n\n---\n\n## 프로세스 상태\n\n운영체제마다 조금씩 다를 수 있지만, 일반적으로 **프로세스의 상태**는 다음과 같이 나뉩니다.\n\n1. **생성 상태 (New)**  \n   - 이제 막 **메모리에 적재**되어 **PCB**를 할당받은 상태입니다.  \n   - 이 상태를 거쳐 실행 준비가 완료되면 **준비 상태**로 전환됩니다.  \n\n2. **준비 상태 (Ready)**  \n   - CPU를 **할당받기 위해 대기 중**인 상태입니다.  \n   - 아직 실행되지 않았지만, 언제든 실행될 준비가 되어 있습니다.  \n\n3. **실행 상태 (Running)**  \n   - CPU를 할당받아 **명령어를 실행 중**인 상태입니다.  \n   - 할당된 시간을 모두 사용하면 **준비 상태**로 돌아가거나, **입출력 장치**의 작업을 기다려야 하면 **대기 상태**로 전환됩니다.\n\n4.",
        "index": 3
      },
      {
        "id": "2024-12-19-10_chunk_4",
        "text": "중**인 상태입니다.  \n   - 할당된 시간을 모두 사용하면 **준비 상태**로 돌아가거나, **입출력 장치**의 작업을 기다려야 하면 **대기 상태**로 전환됩니다.\n\n4. **대기 상태 (Blocked)**  \n   - 입출력 장치의 작업을 **기다리는 상태**입니다.  \n   - 입출력이 완료되면 **인터럽트**를 받아 다시 **준비 상태**로 전환됩니다.  \n\n5. **종료 상태 (Terminated)**  \n   - 프로세스의 실행이 **완료된 상태**입니다.  \n   - 운영체제는 PCB와 프로세스가 사용한 **메모리**를 정리합니다.\n\n> **디스패치 (Dispatch)**:  \n> 준비 상태에서 CPU를 할당받아 실행 상태로 전환되는 것을 **디스패치**라고 합니다.  \n{: .prompt-info }\n---\n\n## 프로세스 계층 구조\n\n프로세스는 **시스템 콜**을 통해 **다른 프로세스를 생성**할 수 있습니다.  \n\n- **부모 프로세스**가 **자식 프로세스**를 생성합니다.  \n- 부모와 자식 프로세스는 **서로 다른 PID**(Process ID)를 가집니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-17",
    "title": "제어에 자주 사용되는 센서들",
    "path": "/2024/12/17/제어에-자주-사용되는-센서들/",
    "categories": [
      "Embedded System",
      "Control Engineering",
      "Embedded/Control"
    ],
    "content": "# Inertial Sensors & Misc. Sensors\n---\n\n## 1. Introduction\n\n피드백 제어에서 시스템의 상태를 측정하고 제어 알고리즘이 동작하기 위해선 **센서**는 매우 중요합니다.  \n\n특히 **관성 센서(IMU)**는 시스템의 **자세**와 **가속도**를 측정하여 동적 시스템을 안정적으로 제어하는 데 필수적입니다.  \n이 글에서는 IMU 센서와 함께 **AHRS**, **INS**, 그리고 다양한 거리 측정 센서들(초음파, IR, LiDAR)에 대해 다루겠습니다.\n\n---\n\n## 2. IMU: Inertial Measurement Unit\n\n### **IMU의 정의**\n\nIMU는 다음과 같은 **3가지 센서**로 구성된 장치입니다:\n\n1. **자이로스코프(Gyroscope)**: 각속도 \\$$\\vec{\\omega} = [p~q~r]^T$$  \n2. **가속도계(Accelerometer)**: 병진 가속도 \\$$\\vec{a} = [a_x~a_y~a_z]^T$$  \n3. **자기장 센서(Magnetometer)**: 지구 자기장 \\$$\\vec{M} = [m_x~m_y~m_z]^T$$    \n\n이 데이터를 통해 시스템의 **속도**, **가속도**, **자세**를 추정할 수 있습니다.\n\n> **IMU 센서의 역할**  \n> IMU는 로봇, 드론, 스마트폰 등 다양한 시스템에서 **자세 안정화**와 **위치 추정**을 위해 사용됩니다.  \n{: .prompt-tip }\n\n---\n\n### **IMU의 오차 문제**\n\nIMU의 각 센서는 고유의 오차를 가집니다:\n\n- **자이로스코프**: **Bias**로 인해 오랜 시간 적분하면 누적 오차 발생.  \n- **가속도계**: 모션 가속도($$a^l$$)가 추가되면서 **중력가속도**와 구분하기 어려움.  \n\n따라서 IMU만으로는 장기적인 **정확도**를 보장하기 어렵습니다.\n\n> 즉, 한마디로 적분 오차로 인해 오래 사용할 경우 부정확함.\n{: .highlight }\n\n#### **IMU의 오차를 개선하기 위해선?**\n\n**Sensor Fusion**을 통해 오차를 보정하고 정확한 상태 추정을 수행합니다.  \n-> **AHRS**와 **INS**\n\n\n---\n\n\n## 3. AHRS: Attitude and Heading Reference System\n\n### **AHRS란?**\n\nAHRS는 IMU에서 수집한 데이터를 기반으로 **소프트웨어 알고리즘**을 통해 자세를 추정합니다.  \n주요 목표는 **IMU 데이터 안정화**이며, 이를 위해 아래와 과정을 수행합니다:\n\n1. **Gyroscope 기반 자세 추정** (단기 정확도 Good)  \n   \\$$\n   \\dot{\\Theta}_{gyro}(k+1) = \\dot{\\Theta}(k) + \\dot{\\omega} \\Delta t\n   $$\n\n2. **Accelerometer 기반 자세 추정** (장기 정확도 Good)  \n   \\$$\n   \\Theta_{acc} = \\text{atan2}\\left(\\frac{s_y}{a}, \\frac{s_z}{a}\\right)\n   $$\n\n3. **Complementary Filter**를 통한 보정\n   \\$$\n   \\Theta(k+1) = K \\cdot \\Theta_{gyro} + (1-K) \\cdot \\Theta_{acc}, \\quad 0 \\leq K \\leq 1\n   $$\n\n   > 가중치 K를 이용해 gyro와 accel의 값을 얼마나 신뢰할 것인지 보정하는 느낌!\n   {: .highlight}\n\n> **AHRS의 장점**  \n> 자이로스코프의 단기 정확도와 가속도계의 장기 안정성을 결합해 **안정적이고 빠른 자세 추정**이 가능합니다.  \n{: .prompt-info }\n\n> 즉, 한마디로 AHRS는 IMU에서 나온 Raw data를 보정해 안전하고 보장된 데이터를 제공합니다.  \n> 하지만, 그럼에도 불구하고 **누적오차가 완벽히 해결되진 않습니다**!  \n{: .prompt-warning }\n\n---\n\n## 4. INS: Inertial Navigation System\n\n### **INS란?**\n\nINS는 AHRS에 **GPS**를 결합하여 누적 오차를 보정하는 시스템입니다.  \n\n- **AHRS**: 고속 데이터(약 100~1000 Hz) 제공  \n  - bias O, noise O 하지만, 높은 갱신률을 제공하기에 단기 정확성에 유리합니다.\n- **GPS**: 장기적 정확도(약 4~10 Hz) 제공 \n  - bias X, noise O 하지만, 낮은 갱신률을 제공하기에 장기 정확성에 유리합니다.\n\n> #### GPS : Global Positioning System\n> \n> 미국이 만든 시스템으로, GPS는 GNSS의 하위 항목입니다.  \n> 어디에 있든 최소 4개 이상의 위성이 관측가능하다고 합니다.  \n>\n> GPS의 신호는 위성 시간, 위성 상태, 궤도 정보 등 ..\n>\n> GPS만 사용할 경우, 갱신률이 느려 피드백 루프 구성에 불리하며  \n> 약 수평 1m, 수직 2m정도의 오차가 있어 정확히 어디있는지 찾기가 어렵습니다.\n{: .highlight }\n\n\n### **칼만 필터(Kalman Filter)를 이용한 센서 융합**\n\n**칼만 필터**는 두 센서의 데이터를 융합하여 **최적의 상태 추정**을 제공합니다:\n\n\\$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k \\left( z_k - H \\hat{x}_{k|k-1} \\right)\n$$   \n여기서 $$ K_k $$: 칼만 게인, $$ z_k $$: 측정값, $$ H $$: 측정 행렬  \n\n### (참고) GPS의 정확도를 높이기 위한 방법?\n\n**DGPS** (Differential GPS)\n- RTK DGPS\n- Post processing\n- SBAS\n\n> 이 부분은 잘 모르겠습니다.  \n> SBAS를 사용하면 GPS의 오차를 약 20cm정도로 줄일 수 있으며  \n> RTK를 사용할 경우 오차를 1~2cm정도로 줄일 수 있다고 합니다.\n{: .prompt-info }\n\n---\n\n## 5. Displacement Sensors\n\n### **초음파 센서 (Ultrasonic Sensor)**\n\n**원리**: 음파의 왕복 시간을 통해 거리 측정  \n\\$$\nd = \\frac{v_{\\text{sound}} \\cdot t_m}{2}\n$$\n  \n여기서 $$t_m$$: 음파 왕복 시간, $$v_{\\text{sound}}$$: 음속(약 340m/s)\n\n**장점**:  \n- 저렴하고 에너지 소모가 적음  \n- 환경(색, 투명도 등)에 둔감  \n\n**단점**:  \n- 감지 거리 제한  \n- 빠른 물체 감지 어려움  \n\n---\n\n### **IR 센서 (Infrared Sensor)**\n\n**원리**: 적외선 반사광의 세기를 이용하여 거리 측정  \n\n**장점**:  \n- 복잡한 표면에서도 거리 측정 가능  \n- 작은 폼팩터  \n\n**단점**:  \n- 주변의 적외선 간섭에 취약  \n\n---\n\n### **LiDAR (Light Detection and Ranging)**\n\n**원리**: 빛의 **왕복 시간(Time of Flight)**을 이용해 거리 측정  \n\n$$\nd = \\frac{c \\cdot t_m}{2}, \\quad c: \\text{광속}\n$$\n\n**장점**:  \n- 고정밀 거리 측정 가능  \n- 자율 주행, 드론에 사용  \n\n**단점**:  \n- 고가  \n\n### 거리 센서 관련 참고하면 좋을 사이트\n[https://www.seeedstudio.com/blog/2019/12/23/distance-sensors-types-and-selection-guide/](https://www.seeedstudio.com/blog/2019/12/23/distance-sensors-types-and-selection-guide/)\n\n---\n\n## 6. Misc. Sensors\n\n### **홀 센서 (Hall-effect Sensor)**\n\n- **원리**: 자기장이 전류가 흐르는 도체에 작용할 때 발생하는 **홀 전압**을 측정  \n- **응용**:  \n  - **Rotary Encoder**: 회전수 측정  \n  - **Proximity Sensor**: 금속 감지  \n\n### **CdS 센서 (Photoresistor)**\n\n- **원리**: 빛의 세기에 따라 저항 값이 변하는 원리를 활용  \n- **응용**:  \n  - **자동차 Auto-light 센서**  \n  - **스마트폰 근접 센서**  \n",
    "date": "2024-12-17",
    "tags": [
      "Embedded System",
      "Control"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-17_chunk_0",
        "text": "제어에 자주 사용되는 센서들\n\n# Inertial Sensors & Misc. Sensors\n---\n\n## 1. Introduction\n\n피드백 제어에서 시스템의 상태를 측정하고 제어 알고리즘이 동작하기 위해선 **센서**는 매우 중요합니다.  \n\n특히 **관성 센서(IMU)**는 시스템의 **자세**와 **가속도**를 측정하여 동적 시스템을 안정적으로 제어하는 데 필수적입니다.  \n이 글에서는 IMU 센서와 함께 **AHRS**, **INS**, 그리고 다양한 거리 측정 센서들(초음파, IR, LiDAR)에 대해 다루겠습니다.\n\n---\n\n## 2. IMU: Inertial Measurement Unit\n\n### **IMU의 정의**\n\nIMU는 다음과 같은 **3가지 센서**로 구성된 장치입니다:\n\n1. **자이로스코프(Gyroscope)**: 각속도 \\$$\\vec{\\omega} = [p~q~r]^T$$  \n2. **가속도계(Accelerometer)**: 병진 가속도 \\$$\\vec{a} = [a_x~a_y~a_z]^T$$  \n3. **자기장 센서(Magnetometer)**: 지구 자기장 \\$$\\vec{M} = [m_x~m_y~m_z]^T$$    \n\n이 데이터를 통해 시스템의 **속도**, **가속도**, **자세**를 추정할 수 있습니다.\n\n> **IMU 센서의 역할**  \n> IMU는 로봇, 드론, 스마트폰 등 다양한 시스템에서 **자세 안정화**와 **위치 추정**을 위해 사용됩니다.",
        "index": 0
      },
      {
        "id": "2024-12-17_chunk_1",
        "text": "*를 추정할 수 있습니다.\n\n> **IMU 센서의 역할**  \n> IMU는 로봇, 드론, 스마트폰 등 다양한 시스템에서 **자세 안정화**와 **위치 추정**을 위해 사용됩니다.  \n{: .prompt-tip }\n\n---\n\n### **IMU의 오차 문제**\n\nIMU의 각 센서는 고유의 오차를 가집니다:\n\n- **자이로스코프**: **Bias**로 인해 오랜 시간 적분하면 누적 오차 발생.  \n- **가속도계**: 모션 가속도($$a^l$$)가 추가되면서 **중력가속도**와 구분하기 어려움.  \n\n따라서 IMU만으로는 장기적인 **정확도**를 보장하기 어렵습니다.\n\n> 즉, 한마디로 적분 오차로 인해 오래 사용할 경우 부정확함.\n{: .highlight }\n\n#### **IMU의 오차를 개선하기 위해선?**\n\n**Sensor Fusion**을 통해 오차를 보정하고 정확한 상태 추정을 수행합니다.  \n-> **AHRS**와 **INS**\n\n\n---\n\n\n## 3. AHRS: Attitude and Heading Reference System\n\n### **AHRS란?**\n\nAHRS는 IMU에서 수집한 데이터를 기반으로 **소프트웨어 알고리즘**을 통해 자세를 추정합니다.  \n주요 목표는 **IMU 데이터 안정화**이며, 이를 위해 아래와 과정을 수행합니다:\n\n1. **Gyroscope 기반 자세 추정** (단기 정확도 Good)  \n   \\$$\n   \\dot{\\Theta}_{gyro}(k+1) = \\dot{\\Theta}(k) + \\dot{\\omega} \\Delta t\n   $$\n\n2.",
        "index": 1
      },
      {
        "id": "2024-12-17_chunk_2",
        "text": "정확도 Good)  \n   \\$$\n   \\dot{\\Theta}_{gyro}(k+1) = \\dot{\\Theta}(k) + \\dot{\\omega} \\Delta t\n   $$\n\n2. **Accelerometer 기반 자세 추정** (장기 정확도 Good)  \n   \\$$\n   \\Theta_{acc} = \\text{atan2}\\left(\\frac{s_y}{a}, \\frac{s_z}{a}\\right)\n   $$\n\n3. **Complementary Filter**를 통한 보정\n   \\$$\n   \\Theta(k+1) = K \\cdot \\Theta_{gyro} + (1-K) \\cdot \\Theta_{acc}, \\quad 0 \\leq K \\leq 1\n   $$\n\n   > 가중치 K를 이용해 gyro와 accel의 값을 얼마나 신뢰할 것인지 보정하는 느낌!\n   {: .highlight}\n\n> **AHRS의 장점**  \n> 자이로스코프의 단기 정확도와 가속도계의 장기 안정성을 결합해 **안정적이고 빠른 자세 추정**이 가능합니다.  \n{: .prompt-info }\n\n> 즉, 한마디로 AHRS는 IMU에서 나온 Raw data를 보정해 안전하고 보장된 데이터를 제공합니다.  \n> 하지만, 그럼에도 불구하고 **누적오차가 완벽히 해결되진 않습니다**!  \n{: .prompt-warning }\n\n---\n\n## 4. INS: Inertial Navigation System\n\n### **INS란?**\n\nINS는 AHRS에 **GPS**를 결합하여 누적 오차를 보정하는 시스템입니다.",
        "index": 2
      },
      {
        "id": "2024-12-17_chunk_3",
        "text": "## 4. INS: Inertial Navigation System\n\n### **INS란?**\n\nINS는 AHRS에 **GPS**를 결합하여 누적 오차를 보정하는 시스템입니다.  \n\n- **AHRS**: 고속 데이터(약 100~1000 Hz) 제공  \n  - bias O, noise O 하지만, 높은 갱신률을 제공하기에 단기 정확성에 유리합니다.\n- **GPS**: 장기적 정확도(약 4~10 Hz) 제공 \n  - bias X, noise O 하지만, 낮은 갱신률을 제공하기에 장기 정확성에 유리합니다.\n\n> #### GPS : Global Positioning System\n> \n> 미국이 만든 시스템으로, GPS는 GNSS의 하위 항목입니다.  \n> 어디에 있든 최소 4개 이상의 위성이 관측가능하다고 합니다.",
        "index": 3
      },
      {
        "id": "2024-12-17_chunk_4",
        "text": "al Positioning System\n> \n> 미국이 만든 시스템으로, GPS는 GNSS의 하위 항목입니다.  \n> 어디에 있든 최소 4개 이상의 위성이 관측가능하다고 합니다.  \n>\n> GPS의 신호는 위성 시간, 위성 상태, 궤도 정보 등 ..\n>\n> GPS만 사용할 경우, 갱신률이 느려 피드백 루프 구성에 불리하며  \n> 약 수평 1m, 수직 2m정도의 오차가 있어 정확히 어디있는지 찾기가 어렵습니다.\n{: .highlight }\n\n\n### **칼만 필터(Kalman Filter)를 이용한 센서 융합**\n\n**칼만 필터**는 두 센서의 데이터를 융합하여 **최적의 상태 추정**을 제공합니다:\n\n\\$$\n\\hat{x}_{k|k} = \\hat{x}_{k|k-1} + K_k \\left( z_k - H \\hat{x}_{k|k-1} \\right)\n$$   \n여기서 $$ K_k $$: 칼만 게인, $$ z_k $$: 측정값, $$ H $$: 측정 행렬  \n\n### (참고) GPS의 정확도를 높이기 위한 방법?\n\n**DGPS** (Differential GPS)\n- RTK DGPS\n- Post processing\n- SBAS\n\n> 이 부분은 잘 모르겠습니다.  \n> SBAS를 사용하면 GPS의 오차를 약 20cm정도로 줄일 수 있으며  \n> RTK를 사용할 경우 오차를 1~2cm정도로 줄일 수 있다고 합니다.\n{: .prompt-info }\n\n---\n\n## 5.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-17--BOJ--21944-----------Version-2",
    "title": "[BOJ] 21944 문제 추천 시스템 Version 2",
    "path": "/2024/12/17/[BOJ]-21944-문제-추천-시스템-Version-2/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 21944번](https://www.acmicpc.net/problem/21944)  \n{: .prompt-tip }\n\n## 문제 요약\n\n이 문제는 **문제 번호**, **난이도**, **알고리즘 분류**를 바탕으로 여러 명령어를 수행하는 추천 시스템을 구현하는 문제입니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 이전 문제(Version 1)에서 **알고리즘 분류**라는 조건이 추가되었습니다.  \n이를 관리하기 위해 **2차원 `set` 배열**을 사용합니다.\n\n### 핵심 아이디어\n\n**자료구조**:\n  - **`set` 배열** (`tbl[난이도][알고리즘]`):  \n    - `tbl[L][G]`는 **난이도 $$L$$**와 **알고리즘 분류 $$G$$**에 해당하는 문제 번호들을 저장합니다.  \n    - `set`은 문제 번호를 자동 정렬해주기 때문에 최댓값/최솟값 조회가 빠릅니다.\n  - **`unordered_map`** (`n2l`):  \n    - 문제 번호 $$P$$가 속한 난이도 $$L$$와 알고리즘 $$G$$를 저장합니다.  \n    - 문제를 삭제할 때 필요한 정보를 빠르게 찾습니다.\n\n---\n\n## 이전 문제와의 차이점\n\n1. **조건 추가**:\n   - 문제를 난이도뿐만 아니라 **알고리즘 분류**에 따라 필터링해야 합니다.\n   - 이를 위해 2차원 `set` 배열 (`tbl[L][G]`)을 사용했습니다.\n\n2. **여러 조건의 명령어 추가**:\n   - `recommend3` 명령어는 특정 난이도를 기준으로 필터링하고 최댓값 또는 최솟값을 찾는 기능입니다.  \n\n---\n\n## 전체 코드\n\n```cpp\n#define _CRT_SECURE_NO_WARNINGS\n#include<bits/stdc++.h>\nusing namespace std;\n\nint N, M;\nset<int> tbl[101][101]; // tbl[난이도][알고리즘]에 문제 번호 저장\nunordered_map<int, pair<int, int>> n2l; // 문제 번호 -> {난이도, 알고리즘 분류}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    // 초기 문제 입력\n    cin >> N;\n    int P, L, G;\n    for (int i = 0; i < N; i++) {\n        cin >> P >> L >> G;\n        tbl[L][G].insert(P);\n        n2l[P] = {L, G};\n    }\n\n    // 명령어 처리\n    cin >> M;\n    string cmd;\n    for (int i = 0; i < M; i++) {\n        cin >> cmd;\n\n        if (cmd == \"recommend\") {\n            int G, x;\n            cin >> G >> x;\n\n            if (x == 1) { // 가장 어려운 문제\n                for (int level = 100; level > 0; level--) {\n                    if (!tbl[level][G].empty()) {\n                        cout << *tbl[level][G].rbegin() << '\\n';\n                        break;\n                    }\n                }\n            } else { // 가장 쉬운 문제\n                for (int level = 1; level <= 100; level++) {\n                    if (!tbl[level][G].empty()) {\n                        cout << *tbl[level][G].begin() << '\\n';\n                        break;\n                    }\n                }\n            }\n        } \n        else if (cmd == \"recommend2\") {\n            int x;\n            cin >> x;\n\n            if (x == 1) { // 전체에서 가장 어려운 문제\n                for (int level = 100; level > 0; level--) {\n                    for (int cate = 1; cate <= 100; cate++) {\n                        if (!tbl[level][cate].empty()) {\n                            cout << *tbl[level][cate].rbegin() << '\\n';\n                            return;\n                        }\n                    }\n                }\n            } \n            else { // 전체에서 가장 쉬운 문제\n                for (int level = 1; level <= 100; level++) {\n                    for (int cate = 1; cate <= 100; cate++) {\n                        if (!tbl[level][cate].empty()) {\n                            cout << *tbl[level][cate].begin() << '\\n';\n                            return;\n                        }\n                    }\n                }\n            }\n        } \n        else if (cmd == \"recommend3\") {\n            int x, L;\n            cin >> x >> L;\n\n            if (x == 1) { // 난이도 L 이상 중 가장 쉬운 문제\n                for (int level = L; level <= 100; level++) {\n                    for (int cate = 1; cate <= 100; cate++) {\n                        if (!tbl[level][cate].empty()) {\n                            cout << *tbl[level][cate].begin() << '\\n';\n                            return;\n                        }\n                    }\n                }\n                cout << -1 << '\\n';\n            } \n            else { // 난이도 L 미만 중 가장 어려운 문제\n                for (int level = L - 1; level > 0; level--) {\n                    for (int cate = 1; cate <= 100; cate++) {\n                        if (!tbl[level][cate].empty()) {\n                            cout << *tbl[level][cate].rbegin() << '\\n';\n                            return;\n                        }\n                    }\n                }\n                cout << -1 << '\\n';\n            }\n        } \n        else if (cmd == \"add\") {\n            cin >> P >> L >> G;\n            tbl[L][G].insert(P);\n            n2l[P] = {L, G};\n        } \n        else if (cmd == \"solved\") {\n            cin >> P;\n            auto LG = n2l[P];\n            tbl[LG.first][LG.second].erase(P);\n        }\n    }\n    return 0;\n}\n```\n",
    "date": "2024-12-17",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-17--BOJ--21944-----------Version-2_chunk_0",
        "text": "[BOJ] 21944 문제 추천 시스템 Version 2\n\n> **문제 링크**: [백준 21944번](https://www.acmicpc.net/problem/21944)  \n{: .prompt-tip }\n\n## 문제 요약\n\n이 문제는 **문제 번호**, **난이도**, **알고리즘 분류**를 바탕으로 여러 명령어를 수행하는 추천 시스템을 구현하는 문제입니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 이전 문제(Version 1)에서 **알고리즘 분류**라는 조건이 추가되었습니다.  \n이를 관리하기 위해 **2차원 `set` 배열**을 사용합니다.\n\n### 핵심 아이디어\n\n**자료구조**:\n  - **`set` 배열** (`tbl[난이도][알고리즘]`):  \n    - `tbl[L][G]`는 **난이도 $$L$$**와 **알고리즘 분류 $$G$$**에 해당하는 문제 번호들을 저장합니다.  \n    - `set`은 문제 번호를 자동 정렬해주기 때문에 최댓값/최솟값 조회가 빠릅니다.\n  - **`unordered_map`** (`n2l`):  \n    - 문제 번호 $$P$$가 속한 난이도 $$L$$와 알고리즘 $$G$$를 저장합니다.  \n    - 문제를 삭제할 때 필요한 정보를 빠르게 찾습니다.\n\n---\n\n## 이전 문제와의 차이점\n\n1. **조건 추가**:\n   - 문제를 난이도뿐만 아니라 **알고리즘 분류**에 따라 필터링해야 합니다.\n   - 이를 위해 2차원 `set` 배열 (`tbl[L][G]`)을 사용했습니다.\n\n2.",
        "index": 0
      },
      {
        "id": "2024-12-17--BOJ--21944-----------Version-2_chunk_1",
        "text": "*:\n   - 문제를 난이도뿐만 아니라 **알고리즘 분류**에 따라 필터링해야 합니다.\n   - 이를 위해 2차원 `set` 배열 (`tbl[L][G]`)을 사용했습니다.\n\n2. **여러 조건의 명령어 추가**:\n   - `recommend3` 명령어는 특정 난이도를 기준으로 필터링하고 최댓값 또는 최솟값을 찾는 기능입니다.",
        "index": 1
      },
      {
        "id": "2024-12-17--BOJ--21944-----------Version-2_chunk_2",
        "text": "]`)을 사용했습니다.\n\n2. **여러 조건의 명령어 추가**:\n   - `recommend3` 명령어는 특정 난이도를 기준으로 필터링하고 최댓값 또는 최솟값을 찾는 기능입니다.",
        "index": 2
      },
      {
        "id": "2024-12-17--BOJ--21944-----------Version-2_chunk_3",
        "text": "]`)을 사용했습니다.\n\n2. **여러 조건의 명령어 추가**:\n   - `recommend3` 명령어는 특정 난이도를 기준으로 필터링하고 최댓값 또는 최솟값을 찾는 기능입니다.",
        "index": 3
      },
      {
        "id": "2024-12-17--BOJ--21944-----------Version-2_chunk_4",
        "text": "]`)을 사용했습니다.\n\n2. **여러 조건의 명령어 추가**:\n   - `recommend3` 명령어는 특정 난이도를 기준으로 필터링하고 최댓값 또는 최솟값을 찾는 기능입니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-17--BOJ--22940",
    "title": "[BOJ] 22940 선형 연립 방정식",
    "path": "/2024/12/17/[BOJ]-22940-선형-연립-방정식/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "---\n\n> **문제 링크**: [백준 22940번](https://www.acmicpc.net/problem/22940)  \n{: .prompt-tip }\n\n## 문제 풀이 아이디어\n\n이 문제는 **선형 연립 방정식**을 풀기 위해 **가우스 소거법**을 적용하면 됩니다.  \n주어진 행렬을 변형해 **사다리꼴 형태**로 만들어 해를 구하면 끝입니다.\n\n1. **주대각선 요소를 1로 정규화**:  \n   - 각 행의 주대각선 요소를 기준으로 해당 행 전체를 나눕니다.  \n2. **다른 행의 해당 열을 0으로 만듦**:  \n   - 정규화된 행을 이용해 다른 행들의 주대각선 요소가 아닌 값을 제거합니다.  \n3. **해 출력**:  \n   - 마지막 열이 $$ x_1, x_2, \\ldots, x_N $$의 값이 됩니다.\n\n> 플레티넘 5 치고는 되게 쉬운 문제라 생각합니다. 아마 수학적인 내용이 포함되어 있기에 난이도가 비교적 높게 책정된 느낌?\n\n---\n\n## 정답 코드\n\n```cpp\n#include <bits/stdc++.h>\nusing namespace std;\n\ndouble arr[10][10];\n\nint main() {\n    ios_base::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    int N; \n    cin >> N; // 미지수의 수 입력\n\n    // 행렬 입력\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N + 1; j++) {\n            cin >> arr[i][j];\n        }\n    }\n\n    // 가우스 소거법 적용\n    for (int i = 0; i < N; i++) {\n        // 1. 행 정규화\n        double d = arr[i][i];\n        for (int j = i; j <= N; j++) {\n            arr[i][j] /= d;\n        }\n\n        // 2. 다른 행의 해당 열을 0으로 만듦\n        for (int j = 0; j < N; j++) {\n            if (i == j) continue;\n\n            double w = arr[j][i];\n            for (int k = i; k <= N; k++) {\n                arr[j][k] -= arr[i][k] * w;\n            }\n        }\n    }\n\n    for (int i = 0; i < N; i++) {\n        cout << round(arr[i][N]) << ' ';\n    }\n\n    return 0;\n}\n```\n",
    "date": "2024-12-17",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-17--BOJ--22940_chunk_0",
        "text": "[BOJ] 22940 선형 연립 방정식\n\n---\n\n> **문제 링크**: [백준 22940번](https://www.acmicpc.net/problem/22940)  \n{: .prompt-tip }\n\n## 문제 풀이 아이디어\n\n이 문제는 **선형 연립 방정식**을 풀기 위해 **가우스 소거법**을 적용하면 됩니다.  \n주어진 행렬을 변형해 **사다리꼴 형태**로 만들어 해를 구하면 끝입니다.\n\n1. **주대각선 요소를 1로 정규화**:  \n   - 각 행의 주대각선 요소를 기준으로 해당 행 전체를 나눕니다.  \n2. **다른 행의 해당 열을 0으로 만듦**:  \n   - 정규화된 행을 이용해 다른 행들의 주대각선 요소가 아닌 값을 제거합니다.  \n3. **해 출력**:  \n   - 마지막 열이 $$ x_1, x_2, \\ldots, x_N $$의 값이 됩니다.\n\n> 플레티넘 5 치고는 되게 쉬운 문제라 생각합니다.",
        "index": 0
      },
      {
        "id": "2024-12-17--BOJ--22940_chunk_1",
        "text": "다.  \n3. **해 출력**:  \n   - 마지막 열이 $$ x_1, x_2, \\ldots, x_N $$의 값이 됩니다.\n\n> 플레티넘 5 치고는 되게 쉬운 문제라 생각합니다. 아마 수학적인 내용이 포함되어 있기에 난이도가 비교적 높게 책정된 느낌?\n\n---\n\n## 정답 코드\n\n```cpp\n#include <bits/stdc++.h>\nusing namespace std;\n\ndouble arr[10][10];\n\nint main() {\n    ios_base::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    int N; \n    cin >> N; // 미지수의 수 입력\n\n    // 행렬 입력\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N + 1; j++) {\n            cin >> arr[i][j];\n        }\n    }\n\n    // 가우스 소거법 적용\n    for (int i = 0; i < N; i++) {\n        // 1. 행 정규화\n        double d = arr[i][i];\n        for (int j = i; j <= N; j++) {\n            arr[i][j] /= d;\n        }\n\n        // 2.",
        "index": 1
      },
      {
        "id": "2024-12-17--BOJ--22940_chunk_2",
        "text": "[i][i];\n        for (int j = i; j <= N; j++) {\n            arr[i][j] /= d;\n        }\n\n        // 2. 다른 행의 해당 열을 0으로 만듦\n        for (int j = 0; j < N; j++) {\n            if (i == j) continue;\n\n            double w = arr[j][i];\n            for (int k = i; k <= N; k++) {\n                arr[j][k] -= arr[i][k] * w;\n            }\n        }\n    }\n\n    for (int i = 0; i < N; i++) {\n        cout << round(arr[i][N]) << ' ';\n    }\n\n    return 0;\n}\n```",
        "index": 2
      },
      {
        "id": "2024-12-17--BOJ--22940_chunk_3",
        "text": "for (int i = 0; i < N; i++) {\n        cout << round(arr[i][N]) << ' ';\n    }\n\n    return 0;\n}\n```",
        "index": 3
      },
      {
        "id": "2024-12-17--BOJ--22940_chunk_4",
        "text": "for (int i = 0; i < N; i++) {\n        cout << round(arr[i][N]) << ' ';\n    }\n\n    return 0;\n}\n```",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-17--BOJ--1327",
    "title": "[BOJ] 1327 소트 게임",
    "path": "/2024/12/17/[BOJ]-1327-소트-게임/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "---\n\n> **문제 링크**: [백준 1327번](https://www.acmicpc.net/problem/1327)  \n{: .prompt-tip }\n\n## 문제 요약\n\n1부터 $$ N $$까지 정수로 이루어진 **순열**이 주어집니다. 특정 **구간의 K개의 수를 뒤집는** 연산을 반복하여 순열을 오름차순으로 만들어야 합니다.  \n**최소 몇 번의 연산**으로 오름차순을 만들 수 있는지 구하는 문제입니다.  \n오름차순으로 만들 수 없다면 **-1**을 출력합니다.\n\n---\n\n## 문제 풀이 아이디어\n\n처음 문제를 읽고 그저 단순한 구현 문제라고 생각했습니다.\n\n하지만, 결국 최적해를 구하기 위해 모든 상태를 탐색해야 하며,  \n그 중, 최소 연산을 구하는 문제이기에 BFS 알고리즘을 떠올려야 합니다.\n\n또한, BFS 알고리즘을 떠올리며 어떻게 방문처리를 수행할 지 떠올려야 하는데,\n\n저는 **unordered_map**을 활용해 각 상태를 문자열로 나타내어 처리했습니다.\n\n> 재밌는 문제라 생각합니다. BFS 알고리즘을 떠올리는 게 꽤나 어려웠습니다.\n\n\n---\n\n### 풀이 단계\n\n1. **초기 상태**와 **목표 상태**:\n   - 입력으로 주어진 순열을 문자열로 저장합니다.  \n   - 목표 상태는 이 문자열을 **오름차순 정렬**한 결과입니다.\n\n2. **BFS 탐색**:\n   - 초기 상태에서 시작하여 가능한 모든 **K개의 수를 뒤집는 연산**을 수행합니다.  \n   - 새로운 상태를 **큐에 넣고** 방문 여부를 기록합니다.  \n   - 이미 방문한 상태는 다시 탐색하지 않도록 **`unordered_map`**을 사용합니다.\n\n3. **연산 과정**:\n   - $$ i $$번째 위치에서 K개의 수를 뒤집습니다.  \n   - 새로운 상태를 확인하고, 목표 상태와 일치하는지 검사합니다.\n\n4. **정답**:\n   - 목표 상태에 도달하면 그때의 연산 횟수를 출력합니다.  \n   - 모든 상태를 탐색한 후에도 목표 상태에 도달하지 못하면 **-1**을 출력합니다.\n\n---\n\n## 전체 코드\n\n```cpp\n#include<bits/stdc++.h>\nusing namespace std;\n\nint N, K;               // N: 순열 크기, K: 뒤집는 수의 개수\nstring arr;             // 초기 순열 상태\nstring narr;            // 목표 오름차순 상태\nunordered_map<string, int> um;  // 방문 상태 기록 (순열 -> 연산 횟수)\n\nint bfs() {\n    queue<string> q;\n    q.push(arr);        // 초기 상태 큐에 삽입\n    um[arr] = 1;        // 시작 상태 방문 처리 (1로 시작)\n\n    while (!q.empty()) {\n        auto cur = q.front(); q.pop();\n\n        // 목표 상태에 도달하면 연산 횟수 반환\n        if (cur == narr) {\n            return um[cur] - 1;  // 시작 상태가 1이므로 -1 반환\n        }\n\n        // K개의 수를 뒤집는 모든 가능한 위치 탐색\n        for (int i = 0; i < N - K + 1; i++) {\n            string tmp = cur;\n            // K개의 수를 뒤집기\n            for (int j = i, jj = i + K - 1; j < jj; j++, jj--) {\n                swap(tmp[j], tmp[jj]);\n            }\n\n            // 방문하지 않았거나 더 빠른 경로로 도달했다면 큐에 삽입\n            if (um[tmp] == 0 || um[cur] + 1 < um[tmp]) {\n                q.push(tmp);\n                um[tmp] = um[cur] + 1;\n            }\n        }\n    }\n    return -1;  // 목표 상태에 도달하지 못한 경우\n}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    // 입력 처리\n    cin >> N >> K;\n    arr.reserve(N);  // 순열 저장을 위한 메모리 예약\n\n    char tmp;\n    for (int i = 0; i < N; i++) {\n        cin >> tmp;\n        arr.push_back(tmp);\n    }\n\n    // 목표 상태: 오름차순 정렬된 상태\n    narr = arr;\n    sort(narr.begin(), narr.end());\n\n    // BFS 탐색 결과 출력\n    cout << bfs();\n\n    return 0;\n}\n```\n\n> 이 문제는 BFS 알고리즘을 떠올리는 것과 방문처리를 어떻게 수행할 지 떠올리는게 매우 중요한 문제라 생각됩니다.\n> 난이도는 낮으나 참신한 문제였다고 느껴집니다.\n{: .prompt-tip }\n",
    "date": "2024-12-17",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-17--BOJ--1327_chunk_0",
        "text": "[BOJ] 1327 소트 게임\n\n---\n\n> **문제 링크**: [백준 1327번](https://www.acmicpc.net/problem/1327)  \n{: .prompt-tip }\n\n## 문제 요약\n\n1부터 $$ N $$까지 정수로 이루어진 **순열**이 주어집니다. 특정 **구간의 K개의 수를 뒤집는** 연산을 반복하여 순열을 오름차순으로 만들어야 합니다.  \n**최소 몇 번의 연산**으로 오름차순을 만들 수 있는지 구하는 문제입니다.  \n오름차순으로 만들 수 없다면 **-1**을 출력합니다.\n\n---\n\n## 문제 풀이 아이디어\n\n처음 문제를 읽고 그저 단순한 구현 문제라고 생각했습니다.\n\n하지만, 결국 최적해를 구하기 위해 모든 상태를 탐색해야 하며,  \n그 중, 최소 연산을 구하는 문제이기에 BFS 알고리즘을 떠올려야 합니다.\n\n또한, BFS 알고리즘을 떠올리며 어떻게 방문처리를 수행할 지 떠올려야 하는데,\n\n저는 **unordered_map**을 활용해 각 상태를 문자열로 나타내어 처리했습니다.\n\n> 재밌는 문제라 생각합니다. BFS 알고리즘을 떠올리는 게 꽤나 어려웠습니다.\n\n\n---\n\n### 풀이 단계\n\n1. **초기 상태**와 **목표 상태**:\n   - 입력으로 주어진 순열을 문자열로 저장합니다.  \n   - 목표 상태는 이 문자열을 **오름차순 정렬**한 결과입니다.\n\n2. **BFS 탐색**:\n   - 초기 상태에서 시작하여 가능한 모든 **K개의 수를 뒤집는 연산**을 수행합니다.  \n   - 새로운 상태를 **큐에 넣고** 방문 여부를 기록합니다.",
        "index": 0
      },
      {
        "id": "2024-12-17--BOJ--1327_chunk_1",
        "text": "BFS 탐색**:\n   - 초기 상태에서 시작하여 가능한 모든 **K개의 수를 뒤집는 연산**을 수행합니다.  \n   - 새로운 상태를 **큐에 넣고** 방문 여부를 기록합니다.  \n   - 이미 방문한 상태는 다시 탐색하지 않도록 **`unordered_map`**을 사용합니다.\n\n3. **연산 과정**:\n   - $$ i $$번째 위치에서 K개의 수를 뒤집습니다.  \n   - 새로운 상태를 확인하고, 목표 상태와 일치하는지 검사합니다.\n\n4. **정답**:\n   - 목표 상태에 도달하면 그때의 연산 횟수를 출력합니다.",
        "index": 1
      },
      {
        "id": "2024-12-17--BOJ--1327_chunk_2",
        "text": "의 수를 뒤집습니다.  \n   - 새로운 상태를 확인하고, 목표 상태와 일치하는지 검사합니다.\n\n4. **정답**:\n   - 목표 상태에 도달하면 그때의 연산 횟수를 출력합니다.",
        "index": 2
      },
      {
        "id": "2024-12-17--BOJ--1327_chunk_3",
        "text": "의 수를 뒤집습니다.  \n   - 새로운 상태를 확인하고, 목표 상태와 일치하는지 검사합니다.\n\n4. **정답**:\n   - 목표 상태에 도달하면 그때의 연산 횟수를 출력합니다.",
        "index": 3
      },
      {
        "id": "2024-12-17--BOJ--1327_chunk_4",
        "text": "의 수를 뒤집습니다.  \n   - 새로운 상태를 확인하고, 목표 상태와 일치하는지 검사합니다.\n\n4. **정답**:\n   - 목표 상태에 도달하면 그때의 연산 횟수를 출력합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-17--BOJ--1422",
    "title": "[BOJ] 1422 숫자의 신",
    "path": "/2024/12/17/[BOJ]-1422-숫자의-신/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "---\n\n> **문제 링크**: [백준 1422번](https://www.acmicpc.net/problem/1422)  \n{: .prompt-tip }\n\n## 문제 요약\n\n주어진 $$ K $$개의 숫자를 적어도 한 번씩 사용하고, 총 $$ N $$개의 숫자를 뽑아 연결해서 만들 수 있는 **가장 큰 수**를 구하는 문제입니다.  \n같은 숫자를 여러 번 사용할 수 있지만 **적어도 한 번은 모든 숫자를 사용해야** 합니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **가장 큰 수를 만들기 위해 그리디 알고리즘**을 사용해야 합니다.\n\n하지만, 단순히 그냥 가장 큰 숫자를 선택하는 것이 아닌 상황을 고려하며 큰 수를 만들어야 합니다.\n\n> 이전에 많은 문제들을 풀며 유사한 문제를 풀어봤기에 그나마 쉽게 풀 수 있었으나, 만약 처음으로 이런 문제를 마주했다면 꽤 어려웠을 것이라 생각됩니다.\n\n\n### 핵심 아이디어\n\n1. **숫자의 연결 순서를 정렬**:\n   - 숫자 $$ a $$와 $$ b $$를 **문자열로 연결**했을 때:  \n     - $$ a + b > b + a $$가 성립하면 $$ a $$를 $$ b $$ 앞에 배치합니다.  \n     - 이렇게 정렬하면 **가장 큰 수**를 만들 수 있습니다.  \n\n  > 이것만을 이용해 풀 수 있는 플레티넘5 정렬 문제도 있습니다.\n  {: .highlight }\n\n2. **N > K인 경우**:\n   - 모든 숫자는 적어도 한 번 사용해야 합니다.  \n   - 나머지 $$ N - K $$개의 숫자는 **가장 큰 숫자**를 여러 번 반복해서 사용하면 됩니다.  \n     - 가장 큰 숫자는 문자열 길이와 값을 비교해서 찾습니다.\n\n3. **두 가지 정렬 조건**:\n   - 첫 번째 정렬(`cmp1`): 가장 큰 숫자를 찾기 위해 **길이가 긴 숫자** 또는 **숫자값이 큰 경우**를 우선합니다.  \n   - 두 번째 정렬(`cmp2`): 숫자를 연결했을 때 $$ a + b > b + a $$ 조건을 기반으로 정렬합니다.\n\n---\n\n## 정답 코드\n\n```cpp\n#include<bits/stdc++.h>\nusing namespace std;\n\n// 가장 큰 숫자를 만들기 위한 첫 번째 비교 함수\nbool cmp1(const string& a, const string& b) {\n    if (a.length() == b.length()) return a + b > b + a; // 문자열 연결 비교\n    return a.length() > b.length(); // 길이가 긴 숫자를 우선\n}\n\n// 숫자를 연결했을 때 더 큰 값을 만드는 두 번째 비교 함수\nbool cmp2(const string& a, const string& b) {\n    return a + b > b + a; // 연결 순서로 비교\n}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    int K, N;\n    cin >> K >> N; // K: 입력 숫자 개수, N: 최종 숫자 개수\n    int n = N;\n\n    vector<string> arr(K);\n    for (int i = 0; i < K; i++) {\n        cin >> arr[i];\n    }\n\n    // N이 K보다 큰 경우, 가장 큰 숫자를 반복해서 사용해야 함\n    if (N > K) {\n        sort(arr.begin(), arr.end(), cmp1); // 가장 큰 숫자를 찾기 위해 정렬\n        while (N > K) { \n            arr.push_back(arr[0]); // 가장 큰 숫자를 반복 삽입\n            --N;\n        }\n    }\n\n    // 숫자를 연결했을 때 가장 큰 값을 만들기 위해 정렬\n    sort(arr.begin(), arr.end(), cmp2);\n\n    // 결과 출력\n    for (int i = 0; i < n; i++) {\n        cout << arr[i];\n    }\n\n    return 0;\n}\n```\n\n---\n\n## 코드 설명\n\n1. **첫 번째 정렬 함수 (`cmp1`)**:  \n   - 가장 큰 숫자를 찾기 위해 문자열의 길이와 연결 결과를 비교합니다.  \n   - 가장 긴 숫자 또는 연결 시 더 큰 결과를 만드는 숫자를 우선합니다.\n\n2. **N > K인 경우**:  \n   - 가장 큰 숫자를 반복해서 사용해야 하므로 첫 번째 정렬로 가장 큰 숫자를 찾고, **남은 자리를 채웁니다**.\n\n3. **두 번째 정렬 함수 (`cmp2`)**:  \n   - 숫자를 연결했을 때 $$ a + b > b + a $$를 만족하도록 정렬합니다.  \n   - 이를 통해 숫자를 이어 붙였을 때 최종 결과가 가장 크게 됩니다.\n\n---\n\n## 시간 복잡도 분석\n\n- **정렬 연산**: $$ O(K \\log K) $$  \n- **N > K 처리**: 가장 큰 숫자를 반복 추가하는데 $$ O(N - K) $$  \n- **전체 시간 복잡도**: $$ O(K \\log K + N) $$  \n  $$ K $$와 $$ N $$은 최대 $$ 50 $$이므로 충분히 동작합니다.\n",
    "date": "2024-12-17",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-17--BOJ--1422_chunk_0",
        "text": "[BOJ] 1422 숫자의 신\n\n---\n\n> **문제 링크**: [백준 1422번](https://www.acmicpc.net/problem/1422)  \n{: .prompt-tip }\n\n## 문제 요약\n\n주어진 $$ K $$개의 숫자를 적어도 한 번씩 사용하고, 총 $$ N $$개의 숫자를 뽑아 연결해서 만들 수 있는 **가장 큰 수**를 구하는 문제입니다.  \n같은 숫자를 여러 번 사용할 수 있지만 **적어도 한 번은 모든 숫자를 사용해야** 합니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **가장 큰 수를 만들기 위해 그리디 알고리즘**을 사용해야 합니다.\n\n하지만, 단순히 그냥 가장 큰 숫자를 선택하는 것이 아닌 상황을 고려하며 큰 수를 만들어야 합니다.\n\n> 이전에 많은 문제들을 풀며 유사한 문제를 풀어봤기에 그나마 쉽게 풀 수 있었으나, 만약 처음으로 이런 문제를 마주했다면 꽤 어려웠을 것이라 생각됩니다.\n\n\n### 핵심 아이디어\n\n1. **숫자의 연결 순서를 정렬**:\n   - 숫자 $$ a $$와 $$ b $$를 **문자열로 연결**했을 때:  \n     - $$ a + b > b + a $$가 성립하면 $$ a $$를 $$ b $$ 앞에 배치합니다.  \n     - 이렇게 정렬하면 **가장 큰 수**를 만들 수 있습니다.  \n\n  > 이것만을 이용해 풀 수 있는 플레티넘5 정렬 문제도 있습니다.\n  {: .highlight }\n\n2. **N > K인 경우**:\n   - 모든 숫자는 적어도 한 번 사용해야 합니다.",
        "index": 0
      },
      {
        "id": "2024-12-17--BOJ--1422_chunk_1",
        "text": "만을 이용해 풀 수 있는 플레티넘5 정렬 문제도 있습니다.\n  {: .highlight }\n\n2. **N > K인 경우**:\n   - 모든 숫자는 적어도 한 번 사용해야 합니다.  \n   - 나머지 $$ N - K $$개의 숫자는 **가장 큰 숫자**를 여러 번 반복해서 사용하면 됩니다.  \n     - 가장 큰 숫자는 문자열 길이와 값을 비교해서 찾습니다.\n\n3. **두 가지 정렬 조건**:\n   - 첫 번째 정렬(`cmp1`): 가장 큰 숫자를 찾기 위해 **길이가 긴 숫자** 또는 **숫자값이 큰 경우**를 우선합니다.",
        "index": 1
      },
      {
        "id": "2024-12-17--BOJ--1422_chunk_2",
        "text": "습니다.\n\n3. **두 가지 정렬 조건**:\n   - 첫 번째 정렬(`cmp1`): 가장 큰 숫자를 찾기 위해 **길이가 긴 숫자** 또는 **숫자값이 큰 경우**를 우선합니다.",
        "index": 2
      },
      {
        "id": "2024-12-17--BOJ--1422_chunk_3",
        "text": "습니다.\n\n3. **두 가지 정렬 조건**:\n   - 첫 번째 정렬(`cmp1`): 가장 큰 숫자를 찾기 위해 **길이가 긴 숫자** 또는 **숫자값이 큰 경우**를 우선합니다.",
        "index": 3
      },
      {
        "id": "2024-12-17--BOJ--1422_chunk_4",
        "text": "습니다.\n\n3. **두 가지 정렬 조건**:\n   - 첫 번째 정렬(`cmp1`): 가장 큰 숫자를 찾기 위해 **길이가 긴 숫자** 또는 **숫자값이 큰 경우**를 우선합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-17--BOJ--21939-----------Version-1",
    "title": "[BOJ] 21939 문제 추천 시스템 Version 1",
    "path": "/2024/12/17/[BOJ]-21939-문제-추천-시스템-Version-1/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 21939번](https://www.acmicpc.net/problem/21939)  \n{: .prompt-tip }\n\n## 문제 요약\n\n문제 번호와 난이도를 기반으로 문제를 관리하고 특정 명령에 따라 문제를 추천하거나 수정하는 시스템을 구현해야 합니다.  \n주어진 명령어는 **`recommend`, `add`, `solved`**의 3가지입니다.\n\n1. **`recommend 1`**: 가장 **어려운 문제** 중 번호가 큰 것을 출력.  \n2. **`recommend -1`**: 가장 **쉬운 문제** 중 번호가 작은 것을 출력.  \n3. **`add P L`**: 난이도가 $$L$$인 문제 번호 $$P$$를 추가.  \n4. **`solved P`**: 문제 번호 $$P$$를 제거.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **문제의 난이도와 번호를 빠르게 관리**해야 하기에, 자료구조를 잘 선정하는게 중요합니다.\n\n1. **`set` 배열** (`set<int> tbl[101]`):  \n   - `tbl[L]`은 난이도가 $$L$$인 문제 번호들을 저장합니다.  \n   - `set`은 자동으로 오름차순 정렬되므로, 번호의 최소/최대값을 빠르게 찾을 수 있습니다.\n\n2. **`unordered_map`** (`unordered_map<int, int> num2level`):  \n   - 문제 번호 $$P$$가 어떤 난이도 $$L$$에 속하는지 저장합니다.  \n   - 이를 통해 문제를 삭제할 때 **난이도를 빠르게 조회**할 수 있습니다.\n\n---\n\n## 전체 코드\n\n```cpp\n#include<bits/stdc++.h>\nusing namespace std;\n\nint N, M;\nset<int> tbl[101]; // 난이도별 문제 번호 저장\nunordered_map<int, int> num2level; // 문제 번호 -> 난이도 매핑\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    // 초기 문제 입력\n    cin >> N;\n    int P, L;\n    for (int i = 0; i < N; i++) {\n        cin >> P >> L;\n        tbl[L].insert(P);     // 난이도 L에 문제 번호 P 삽입\n        num2level[P] = L;     // 문제 번호와 난이도 매핑\n    }\n\n    // 명령어 처리\n    cin >> M;\n    string cmd;\n    for (int i = 0; i < M; i++) {\n        cin >> cmd;\n        \n        if (cmd == \"recommend\") {\n            int x;\n            cin >> x;\n            if (x == 1) { // 가장 어려운 문제 출력\n                for (int i = 100; i > 0; i--) {\n                    if (tbl[i].empty()) continue;\n                    cout << *tbl[i].rbegin() << '\\n'; // 가장 큰 번호\n                    break;\n                }\n            } \n            else { // 가장 쉬운 문제 출력\n                for (int i = 1; i <= 100; i++) {\n                    if (tbl[i].empty()) continue;\n                    cout << *tbl[i].begin() << '\\n'; // 가장 작은 번호\n                    break;\n                }\n            }\n        } \n        else if (cmd == \"add\") {\n            cin >> P >> L;\n            tbl[L].insert(P);  // 난이도 L에 문제 번호 P 추가\n            num2level[P] = L;  // 매핑 업데이트\n        } \n        else if (cmd == \"solved\") {\n            cin >> P;\n            int level = num2level[P]; // 문제 번호 P의 난이도 조회\n            tbl[level].erase(P);      // 해당 난이도의 set에서 문제 제거\n        }\n    }\n\n    return 0;\n}\n```\n\n---\n\n## 시간 복잡도 계산\n\n1. **`recommend`**:\n   - $$O(100)$$번 탐색하며 첫 번째 비어있지 않은 `set`을 찾고, **최댓값/최솟값**을 출력합니다.  \n     → $$O(\\log N)$$ (최댓값/최솟값 조회)\n\n2. **`add`**:\n   - `set`에 값을 추가하는 연산 → $$O(\\log N)$$\n\n3. **`solved`**:\n   - `unordered_map`에서 난이도를 조회 → $$O(1)$$  \n   - `set`에서 값을 제거 → $$O(\\log N)$$\n\n4. **전체 시간 복잡도**:\n   - 명령어 $$M$$개에 대해 각 명령어의 연산이 $$O(\\log N)$$ 이므로 총 시간 복잡도는 **$$O(M \\log N)$$**입니다.\n",
    "date": "2024-12-17",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-17--BOJ--21939-----------Version-1_chunk_0",
        "text": "[BOJ] 21939 문제 추천 시스템 Version 1\n\n> **문제 링크**: [백준 21939번](https://www.acmicpc.net/problem/21939)  \n{: .prompt-tip }\n\n## 문제 요약\n\n문제 번호와 난이도를 기반으로 문제를 관리하고 특정 명령에 따라 문제를 추천하거나 수정하는 시스템을 구현해야 합니다.  \n주어진 명령어는 **`recommend`, `add`, `solved`**의 3가지입니다.\n\n1. **`recommend 1`**: 가장 **어려운 문제** 중 번호가 큰 것을 출력.  \n2. **`recommend -1`**: 가장 **쉬운 문제** 중 번호가 작은 것을 출력.  \n3. **`add P L`**: 난이도가 $$L$$인 문제 번호 $$P$$를 추가.  \n4. **`solved P`**: 문제 번호 $$P$$를 제거.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **문제의 난이도와 번호를 빠르게 관리**해야 하기에, 자료구조를 잘 선정하는게 중요합니다.\n\n1. **`set` 배열** (`set<int> tbl[101]`):  \n   - `tbl[L]`은 난이도가 $$L$$인 문제 번호들을 저장합니다.  \n   - `set`은 자동으로 오름차순 정렬되므로, 번호의 최소/최대값을 빠르게 찾을 수 있습니다.\n\n2. **`unordered_map`** (`unordered_map<int, int> num2level`):  \n   - 문제 번호 $$P$$가 어떤 난이도 $$L$$에 속하는지 저장합니다.",
        "index": 0
      },
      {
        "id": "2024-12-17--BOJ--21939-----------Version-1_chunk_1",
        "text": "ordered_map`** (`unordered_map<int, int> num2level`):  \n   - 문제 번호 $$P$$가 어떤 난이도 $$L$$에 속하는지 저장합니다.",
        "index": 1
      },
      {
        "id": "2024-12-17--BOJ--21939-----------Version-1_chunk_2",
        "text": "ordered_map`** (`unordered_map<int, int> num2level`):  \n   - 문제 번호 $$P$$가 어떤 난이도 $$L$$에 속하는지 저장합니다.",
        "index": 2
      },
      {
        "id": "2024-12-17--BOJ--21939-----------Version-1_chunk_3",
        "text": "ordered_map`** (`unordered_map<int, int> num2level`):  \n   - 문제 번호 $$P$$가 어떤 난이도 $$L$$에 속하는지 저장합니다.",
        "index": 3
      },
      {
        "id": "2024-12-17--BOJ--21939-----------Version-1_chunk_4",
        "text": "ordered_map`** (`unordered_map<int, int> num2level`):  \n   - 문제 번호 $$P$$가 어떤 난이도 $$L$$에 속하는지 저장합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-16----------SLAM",
    "title": "아두이노와 초음파센서를 활용한 SLAM 따라하기",
    "path": "/2024/12/16/아두이노-초음파-SLAM/",
    "categories": [
      "Embedded System",
      "Project",
      "Embedded"
    ],
    "content": "## 개요\n\n**초음파 센서**와 **서보 모터**를 활용해 주변을 인식하고 시각적으로 맵핑하는 시스템을 만들어 보겠습니다.   \n\n이 과정에서 **마이크로컨트롤러 (Arduino)**를 이용해 데이터 수집과 제어를 수행하고, **C# 기반 GUI**를 통해 실시간으로 데이터를 시각화합니다.\n\n\n- 저렴한 **초음파 센서**로 라이다(LiDAR)와 유사한 SLAM 구현\n- 서보 모터를 회전시켜 여러 각도에서 거리 데이터를 수집\n- 실시간 데이터 시각화 및 맵핑\n- 시리얼 통신을 통해 아두이노와 PC 간 데이터 전송\n\n---\n\n## 시스템 구성도\n```mermaid\nflowchart TD\n    subgraph  \n        A[<b>Ultrasonic Sensor<br></b>] \n        C[<b>Servo Motor<br></b>]\n    end\n\n    A -->|<b>Distance</b>| B[<b>Arduino</b>]\n    C -->|<b>Angle</b>| B\n\n    B -->|<b>Serial Communication</b>| D[<b>PC</b>]\n\n    subgraph   \n        D -->|<b>Data Processing</b>| E[<b>C# GUI Program</b>]\n        E -->|<b>Display</b>| F[<b>2D Mapping Visualization</b>]\n    end\n\n    %% Node styling for better visibility\n    classDef sensors fill:#f9f,stroke:#333,stroke-width:2px,color:#000,font-weight:bold\n    classDef arduino fill:#bbf,stroke:#333,stroke-width:2px,color:#000,font-weight:bold\n    classDef pc fill:#ff9,stroke:#333,stroke-width:2px,color:#000,font-weight:bold\n    classDef gui fill:#afa,stroke:#333,stroke-width:2px,color:#000,font-weight:bold\n    classDef mapping fill:#fea,stroke:#333,stroke-width:2px,color:#000,font-weight:bold\n\n    class A,C sensors\n    class B arduino\n    class D pc\n    class E gui\n    class F mapping\n\n```\n\n### HW 구성\n1. **초음파 센서** (HC-SR04): 거리 데이터 수집\n2. **서보 모터** (SG90): 회전 제어 및 각도 조절\n3. **Arduino UNO**: 센서 데이터 처리 및 시리얼 통신 수행\n4. **PC**: 데이터 시각화 (C# GUI 프로그램)\n\n---\n\n## 코드 구현\n\n### **1. Sensor.c (초음파 센서)**\n```cpp\n#include \"Sensor.h\"\n#include <Arduino.h>\n\nvoid Sensor::setting(int trig) {\n    pinMode(trig, OUTPUT);\n    pinMode(echo, INPUT);\n    Trigger();\n}\n\nvoid Sensor::Trigger() {\n    wave_finished = false;\n    digitalWrite(trig, LOW);\n    delayMicroseconds(2);\n    digitalWrite(trig, HIGH);\n    delayMicroseconds(10);\n    digitalWrite(trig, LOW);\n}\n\ndouble Sensor::send_dist() {\n    if (wave_finished) {\n        double dist = (pulsein - pulseout) / 58.2;\n        Trigger();\n        return dist;\n    }\n    return 0;\n}\n```\n  \n**설명:**\n- 초음파 센서에서 거리 데이터를 수집하는 함수입니다.\n- **Trigger()** 함수를 통해 동작합니다다.\n\n---\n\n### **2. Wiper.c (서보 모터)**\n```cpp\n#include \"Wiper.h\"\n#include <Arduino.h>\n\nvoid Wiper::attach(int pin) {\n    servo.attach(pin);\n    increment = 1;\n    angle = 0;\n}\n\nvoid Wiper::wipe() {\n    angle += increment;\n    servo.write(angle);\n    if (angle >= 180 || angle <= 0) {\n        increment = -increment; // 방향 전환\n    }\n}\n\ndouble Wiper::send_deg() {\n    return double(angle); // 현재 각도 반환\n}\n```\n**설명:**\n- 서보 모터를 일정 각도(1도)만큼 회전시키며 데이터를 수집합니다.\n- **wipe()** 함수는 서보의 각도를 변화시키고 방향을 자동으로 전환합니다.\n\n---\n\n### **3. 메인 코드.ino**\n```cpp\n#include \"Wiper.h\"\n#include \"Sensor.h\"\n\nWiper wiper;\nSensor sensor;\n\nvoid setup() {\n    Serial.begin(9600);\n    wiper.attach(11);  // 서보 모터 핀\n    sensor.setting(3); // 초음파 센서 Trigger 핀\n}\n\nvoid loop() {\n    wiper.wipe();\n    double distance = sensor.send_dist();\n    double angle = wiper.send_deg();\n\n    Serial.print(\"Distance:\");\n    Serial.print(distance);\n    Serial.print(\" Angle:\");\n    Serial.println(angle);\n    delay(100);\n}\n```\n**설명:**\n- 거리 데이터와 서보 모터의 각도 값을 시리얼 포트로 전송합니다.\n- 이 데이터를 **PC**에서 수신하여 시각화합니다.\n\n---\n\n## C# GUI 프로그램 구현\n\nC# 기반 GUI는 데이터를 수신하고 **TCanvas** 클래스를 이용해 실시간으로 맵핑 데이터를 시각화합니다.\n\n> PC기반제어프로그래밍 강의에서 사용한 TCanvas 클래스\n\n\n### **데이터 수신**\n```csharp\nprivate void serialPort1_DataReceived(object sender, SerialDataReceivedEventArgs e) {\n    string data = serialPort1.ReadLine();\n    string[] split = data.Split(':');\n    double distance = Convert.ToDouble(split[0]);\n    double angle = Convert.ToDouble(split[1]) * Math.PI / 180;\n\n    double x = distance * Math.Cos(angle);\n    double y = distance * Math.Sin(angle);\n    canvas.DrawEllipse(Color.Black, -x, y, 3, 3);\n}\n```\n**설명:**\n- 시리얼 포트로 수신된 데이터를 파싱하여 거리와 각도 값을 구합니다.\n- 구해진 데이터를 기반으로 2D 좌표를 계산하고 화면에 점을 그립니다.\n\n### **맵핑 실행**\n```csharp\nprivate void btnMap_Click(object sender, EventArgs e) {\n    canvas.ClearDrawing(Color.White);\n    timer1.Start();\n}\n\nprivate void btnStop_Click(object sender, EventArgs e) {\n    timer1.Stop();\n    canvas.ClearDrawing(Color.White);\n}\n```\n\n---\n\n## 결과\n\n![맵핑 결과](/assets/img/arduino-slam/mapping_result.png)\n\n어느정도 맵을 그리긴 했습니다.\n\n하지만, 중간중간 Outlier가 많이 보이는 것을 알 수 있으며,\n\n앞에 있는 물체가 모니터임에 불구하고 살짝 곡선의 형태로 맵핑되는 것을 확인할 수 있습니다.\n\n**시연 영상:**\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/UwfWkVGb4H8?si=KGuCzvKeu35lX-6y\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n---\n\n## 개선사항 및 확장 방향\n\n1. **데이터 보정**:  \n   한 각도에서 약 5개 정도의 거리 데이터를 획득한 후, 중앙값을 선택하는 방식으로?  \n\n2. **센서 교체**:    \n    더 정밀한 초음파 센서와 모터를 사용한다면?\n\n3. **3D 구현**: \n    모터를 하나 더 추가해 시간은 오래걸리지만, 3D 매핑으로 확장 가능?\n\n---\n\n## Git Repo\n[https://github.com/knowgyu/arduino-ultrasonic-mapping](https://github.com/knowgyu/arduino-ultrasonic-mapping)\n",
    "date": "2024-12-16",
    "tags": [
      "Embedded System",
      "Arduino",
      "PJT"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-16----------SLAM_chunk_0",
        "text": "아두이노와 초음파센서를 활용한 SLAM 따라하기\n\n## 개요\n\n**초음파 센서**와 **서보 모터**를 활용해 주변을 인식하고 시각적으로 맵핑하는 시스템을 만들어 보겠습니다.",
        "index": 0
      },
      {
        "id": "2024-12-16----------SLAM_chunk_1",
        "text": "",
        "index": 1
      },
      {
        "id": "2024-12-16----------SLAM_chunk_2",
        "text": "",
        "index": 2
      },
      {
        "id": "2024-12-16----------SLAM_chunk_3",
        "text": "",
        "index": 3
      },
      {
        "id": "2024-12-16----------SLAM_chunk_4",
        "text": "",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-16--BOJ--12904-2048-Hard",
    "title": "[BOJ] 12904 2048(Hard)",
    "path": "/2024/12/16/[BOJ]-12904-2048(Hard)/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 12094번](https://www.acmicpc.net/problem/12094)  \n{: .prompt-tip }\n\n## 문제 요약\n\n2048 게임을 최대 **10번 이동**하여 만들 수 있는 가장 큰 블록의 값을 구하는 문제입니다. 보드의 크기는 **N×N (1 ≤ N ≤ 20)**이며, 상하좌우로 이동하면서 블록을 합치는 규칙을 따릅니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **DFS(깊이 우선 탐색)** 기반의 완전 탐색을 수행해야 하지만, **가지치기**가 핵심입니다.  \n**불필요한 탐색을 최소화**하는 가지치기를 통해 시간 초과를 방지해야 합니다.\n\n> 2048(Easy)의 경우 가지치기를 신경쓰지 않아도 해결됩니다.\n{: .prompt-tip }\n\n### 주요 아이디어\n\n1. **DFS 탐색 구조**:  \n   - 4가지 방향(상, 하, 좌, 우)으로 이동한 후 상태를 재귀적으로 탐색합니다.\n\n2. **가지치기**:  \n   - 후술\n\n3. **이동 후 상태 비교**:  \n   - 이동한 보드 상태가 이전 상태와 같으면 더 이상 탐색하지 않습니다.  \n\n4. **최적화된 이동 구현**:  \n   - 블록 이동 및 합치기 과정은 상, 하, 좌, 우에 따라 별도로 구현됩니다.\n   - 큐 자료구조를 활용하여 블록을 이동하고 합칩니다.\n\n---\n\n## 가지치기의 핵심\n\n- **불필요한 탐색 제거**:  \n  \"현재 보드에서 나올 수 있는 최적의 값이 이미 정답(ans)을 갱신할 수 없는 경우\" 탐색을 중단합니다.  \n  이를 **현재 최대값 `curMax`**와 **남은 이동 횟수**를 이용해 계산합니다.\n\n   ```cpp\n   if (curMX << (MOVE - now) <= ans) return;\n   ```\n   - `curMX << (MOVE - now)`는 **이론적으로 남은 이동 횟수 동안 최대한 합쳐질 경우**를 의미합니다.\n   - 만약 이 값이 현재 정답 `ans`보다 작거나 같으면 더 이상 탐색할 필요가 없습니다.\n\n---\n\n## 정답 코드\n```cpp\n#define _CRT_SECURE_NO_WARNINGS\n#include<bits/stdc++.h>\nusing namespace std;\n\n#define MOVE 10\n#define UP 0\n#define RIGHT 1\n#define DOWN 2\n#define LEFT 3\n\nint N, ans;\nint di[] = { -1,0,1,0 };\nint dj[] = { 0,1,0,-1 };\n\n// 보드 상태가 변했는지 확인\nbool isChange(const vector<vector<int>>& arr, const vector<vector<int>>& narr) {\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (arr[i][j] != narr[i][j]) return true;\n        }\n    }\n    return false;\n}\n\n// 블록을 상하좌우로 이동시키는 함수\nvoid move(int dr, vector<vector<int>>& arr, vector<vector<int>>& ret) {\n    switch (dr) {\n    case UP:\n        for (int j = 0; j < N; j++) {\n            queue<int> q;\n            for (int i = 0; i < N; i++) if (arr[i][j]) q.push(arr[i][j]);\n            int idx = 0;\n            while (!q.empty()) {\n                int cur = q.front(); q.pop();\n                if (!q.empty() && cur == q.front()) { ret[idx++][j] = cur * 2; q.pop(); }\n                else { ret[idx++][j] = cur; }\n            }\n        }\n        break;\n    case DOWN:\n        for (int j = 0; j < N; j++) {\n            queue<int> q;\n            for (int i = N - 1; i >= 0; i--) if (arr[i][j]) q.push(arr[i][j]);\n            int idx = N - 1;\n            while (!q.empty()) {\n                int cur = q.front(); q.pop();\n                if (!q.empty() && cur == q.front()) { ret[idx--][j] = cur * 2; q.pop(); }\n                else { ret[idx--][j] = cur; }\n            }\n        }\n        break;\n    case LEFT:\n        for (int i = 0; i < N; i++) {\n            queue<int> q;\n            for (int j = 0; j < N; j++) if (arr[i][j]) q.push(arr[i][j]);\n            int idx = 0;\n            while (!q.empty()) {\n                int cur = q.front(); q.pop();\n                if (!q.empty() && cur == q.front()) { ret[i][idx++] = cur * 2; q.pop(); }\n                else { ret[i][idx++] = cur; }\n            }\n        }\n        break;\n    case RIGHT:\n        for (int i = 0; i < N; i++) {\n            queue<int> q;\n            for (int j = N - 1; j >= 0; j--) if (arr[i][j]) q.push(arr[i][j]);\n            int idx = N - 1;\n            while (!q.empty()) {\n                int cur = q.front(); q.pop();\n                if (!q.empty() && cur == q.front()) { ret[i][idx--] = cur * 2; q.pop(); }\n                else { ret[i][idx--] = cur; }\n            }\n        }\n        break;\n    }\n}\n\n// DFS 탐색 함수\nvoid solve(int now, vector<vector<int>> arr) {\n    // 현재 보드 최대값 계산\n    int curMX = 0;\n    for (int i = 0; i < N; i++) for (int j = 0; j < N; j++) curMX = max(curMX, arr[i][j]);\n    // 가지치기: 남은 이동으로 최대값을 갱신할 수 없는 경우\n    if (curMX << (MOVE - now) <= ans) return;\n\n    // 최대 이동 횟수에 도달하면 정답 갱신\n    if (now == MOVE) {\n        ans = max(ans, curMX);\n        return;\n    }\n\n    // 4가지 방향으로 이동\n    for (int dr = 0; dr < 4; dr++) {\n        vector<vector<int>> ret(N, vector<int>(N, 0));\n        move(dr, arr, ret);\n        // 상태가 변했을 때만 탐색\n        if (isChange(arr, ret)) solve(now + 1, ret);\n    }\n}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    // 입력 및 초기화\n    cin >> N;\n    vector<vector<int>> arr(N, vector<int>(N, 0));\n    for (int i = 0; i < N; i++) for (int j = 0; j < N; j++) cin >> arr[i][j];\n\n    // N이 1인 경우 바로 출력\n    if (N == 1) {\n        cout << arr[0][0];\n        return 0;\n    }\n\n    // DFS 탐색 시작\n    solve(0, arr);\n    cout << ans;\n\n    return 0;\n}\n```\n",
    "date": "2024-12-16",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-16--BOJ--12904-2048-Hard_chunk_0",
        "text": "[BOJ] 12904 2048(Hard)\n\n> **문제 링크**: [백준 12094번](https://www.acmicpc.net/problem/12094)  \n{: .prompt-tip }\n\n## 문제 요약\n\n2048 게임을 최대 **10번 이동**하여 만들 수 있는 가장 큰 블록의 값을 구하는 문제입니다. 보드의 크기는 **N×N (1 ≤ N ≤ 20)**이며, 상하좌우로 이동하면서 블록을 합치는 규칙을 따릅니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **DFS(깊이 우선 탐색)** 기반의 완전 탐색을 수행해야 하지만, **가지치기**가 핵심입니다.  \n**불필요한 탐색을 최소화**하는 가지치기를 통해 시간 초과를 방지해야 합니다.\n\n> 2048(Easy)의 경우 가지치기를 신경쓰지 않아도 해결됩니다.\n{: .prompt-tip }\n\n### 주요 아이디어\n\n1. **DFS 탐색 구조**:  \n   - 4가지 방향(상, 하, 좌, 우)으로 이동한 후 상태를 재귀적으로 탐색합니다.\n\n2. **가지치기**:  \n   - 후술\n\n3. **이동 후 상태 비교**:  \n   - 이동한 보드 상태가 이전 상태와 같으면 더 이상 탐색하지 않습니다.  \n\n4. **최적화된 이동 구현**:  \n   - 블록 이동 및 합치기 과정은 상, 하, 좌, 우에 따라 별도로 구현됩니다.\n   - 큐 자료구조를 활용하여 블록을 이동하고 합칩니다.\n\n---\n\n## 가지치기의 핵심\n\n- **불필요한 탐색 제거**:  \n  \"현재 보드에서 나올 수 있는 최적의 값이 이미 정답(ans)을 갱신할 수 없는 경우\" 탐색을 중단합니다.",
        "index": 0
      },
      {
        "id": "2024-12-16--BOJ--12904-2048-Hard_chunk_1",
        "text": "---\n\n## 가지치기의 핵심\n\n- **불필요한 탐색 제거**:  \n  \"현재 보드에서 나올 수 있는 최적의 값이 이미 정답(ans)을 갱신할 수 없는 경우\" 탐색을 중단합니다.",
        "index": 1
      },
      {
        "id": "2024-12-16--BOJ--12904-2048-Hard_chunk_2",
        "text": "---\n\n## 가지치기의 핵심\n\n- **불필요한 탐색 제거**:  \n  \"현재 보드에서 나올 수 있는 최적의 값이 이미 정답(ans)을 갱신할 수 없는 경우\" 탐색을 중단합니다.",
        "index": 2
      },
      {
        "id": "2024-12-16--BOJ--12904-2048-Hard_chunk_3",
        "text": "---\n\n## 가지치기의 핵심\n\n- **불필요한 탐색 제거**:  \n  \"현재 보드에서 나올 수 있는 최적의 값이 이미 정답(ans)을 갱신할 수 없는 경우\" 탐색을 중단합니다.",
        "index": 3
      },
      {
        "id": "2024-12-16--BOJ--12904-2048-Hard_chunk_4",
        "text": "---\n\n## 가지치기의 핵심\n\n- **불필요한 탐색 제거**:  \n  \"현재 보드에서 나올 수 있는 최적의 값이 이미 정답(ans)을 갱신할 수 없는 경우\" 탐색을 중단합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-16--BOJ--5446",
    "title": "[BOJ] 5446번 용량부족",
    "path": "/2024/12/16/[BOJ]-5446번-용량부족/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 5446번](https://www.acmicpc.net/problem/5446)  \n{: .prompt-tip }\n\n## 문제 요약\n\n특정 파일들을 삭제하려고 할 때, `rm 문자열*` 형식을 사용해 최소 명령 횟수로 삭제해야 합니다. 단, 지우면 안 되는 파일들은 존재하며, 이 파일들을 잘못 삭제하지 않아야 합니다.\n\n> 단, \"rm 문자열*\"형식으로 명령하면 이름이 \"문자열\"인 파일도 삭제됨을 꼭 생각해야 합니다!\n{: .prompt-warning }\n\n---\n\n## 문제 풀이 아이디어\n\n**Trie(트라이)** 자료구조를 활용합니다.  \n트라이를 사용하면 공통 부분을 빠르게 탐색하고 관리할 수 있기 때문에 효율적으로 `rm` 명령 횟수를 계산할 수 있습니다.\n\n### 주요 아이디어\n\n1. **Trie 자료구조를 활용**:\n   - 삭제해야 하는 파일은 **erase** 카운트를 증가시킵니다.\n   - 지우면 안 되는 파일은 **Nerase** 카운트를 증가시킵니다.\n   \n2. **재귀적으로 탐색**:\n   - 각 노드에서 `Nerase`가 0인 경우, 즉 자식 노드에 지우면 안 되는 파일이 없는 경우, 현재 노드를 `rm` 명령 한 번으로 처리할 수 있습니다.\n   - 노드가 끝나는 지점에 `isEnd` 플래그가 설정되어 있으면, 그 파일은 직접 `rm` 명령을 사용합니다.\n\n3. **불필요한 삭제 방지**:\n   - `Nerase`가 0이 아니면 해당 노드 아래에 지우면 안 되는 파일이 존재하는 것이므로, 안전하게 하위 노드를 확인하면서 명령 횟수를 계산합니다.\n\n---\n\n## 정답 코드\n\n```cpp\n#include<bits/stdc++.h>\nusing namespace std;\n\nstruct Trie {\n    bool isEnd = false;  // 파일 끝인지 여부\n    int erase = 0;       // 삭제해야 하는 파일 수\n    int Nerase = 0;      // 지우면 안 되는 파일 수\n    map<char, Trie*> next;\n\n    ~Trie() {  // 소멸자(메모리 관리를 위함)\n        for (auto& pair : next) delete pair.second;\n    }\n};\n\nint pCnt;\nTrie* root;\nint ans;\n\n// 삭제해야 하는 파일 삽입\nvoid insert1(string word) {\n    auto cur = root;\n    for (const auto c : word) {\n        cur->erase++;  // 현재 노드의 erase 증가\n        if (cur->next.find(c) == cur->next.end()) {\n            cur->next[c] = new Trie();\n        }\n        cur = cur->next[c];\n    }\n    cur->isEnd = true;  // 파일 끝\n}\n\n// 지우면 안 되는 파일 삽입\nvoid insert2(string word) {\n    auto cur = root;\n    for (const auto c : word) {\n        cur->Nerase++;\n        if (cur->next.find(c) == cur->next.end()) {\n            cur->next[c] = new Trie();\n        }\n        cur = cur->next[c];\n    }\n    cur->Nerase++;\n}\n\n// 재귀적으로 삭제 명령 계산\nvoid recurRemove(Trie* cur) {\n    // 자식에 지우면 안 되는 파일이 없으면 한 번에 삭제 가능\n    if (cur->Nerase == 0) {\n        ans++;\n        return;\n    }\n\n    // 현재 노드가 파일 끝이면 개별 삭제 필요\n    if (cur->isEnd) {\n        ans++;\n    }\n\n    // 자식 노드를 재귀적으로 탐색\n    for (const auto& nxt : cur->next) {\n        recurRemove(nxt.second);\n    }\n}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    int TC; \n    cin >> TC;  // 테스트 케이스 개수\n    while (TC--) {\n        ans = 0;\n        root = new Trie();  // 루트 Trie 초기화\n\n        int N1, N2;\n        string data;\n\n        // 삭제해야 하는 파일 입력\n        cin >> N1;\n        for (int i = 0; i < N1; i++) {\n            cin >> data;\n            insert1(data);\n        }\n\n        // 지우면 안 되는 파일 입력\n        cin >> N2;\n        for (int i = 0; i < N2; i++) {\n            cin >> data;\n            insert2(data);\n        }\n\n        // 삭제 명령 계산\n        recurRemove(root);\n\n        cout << ans << '\\n';\n\n        // 동적 메모리 해제\n        delete root;\n    }\n    return 0;\n}\n```\n",
    "date": "2024-12-16",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-16--BOJ--5446_chunk_0",
        "text": "[BOJ] 5446번 용량부족\n\n> **문제 링크**: [백준 5446번](https://www.acmicpc.net/problem/5446)  \n{: .prompt-tip }\n\n## 문제 요약\n\n특정 파일들을 삭제하려고 할 때, `rm 문자열*` 형식을 사용해 최소 명령 횟수로 삭제해야 합니다. 단, 지우면 안 되는 파일들은 존재하며, 이 파일들을 잘못 삭제하지 않아야 합니다.\n\n> 단, \"rm 문자열*\"형식으로 명령하면 이름이 \"문자열\"인 파일도 삭제됨을 꼭 생각해야 합니다!\n{: .prompt-warning }\n\n---\n\n## 문제 풀이 아이디어\n\n**Trie(트라이)** 자료구조를 활용합니다.  \n트라이를 사용하면 공통 부분을 빠르게 탐색하고 관리할 수 있기 때문에 효율적으로 `rm` 명령 횟수를 계산할 수 있습니다.\n\n### 주요 아이디어\n\n1. **Trie 자료구조를 활용**:\n   - 삭제해야 하는 파일은 **erase** 카운트를 증가시킵니다.\n   - 지우면 안 되는 파일은 **Nerase** 카운트를 증가시킵니다.\n   \n2. **재귀적으로 탐색**:\n   - 각 노드에서 `Nerase`가 0인 경우, 즉 자식 노드에 지우면 안 되는 파일이 없는 경우, 현재 노드를 `rm` 명령 한 번으로 처리할 수 있습니다.\n   - 노드가 끝나는 지점에 `isEnd` 플래그가 설정되어 있으면, 그 파일은 직접 `rm` 명령을 사용합니다.\n\n3.",
        "index": 0
      },
      {
        "id": "2024-12-16--BOJ--5446_chunk_1",
        "text": "노드를 `rm` 명령 한 번으로 처리할 수 있습니다.\n   - 노드가 끝나는 지점에 `isEnd` 플래그가 설정되어 있으면, 그 파일은 직접 `rm` 명령을 사용합니다.\n\n3.",
        "index": 1
      },
      {
        "id": "2024-12-16--BOJ--5446_chunk_2",
        "text": "노드를 `rm` 명령 한 번으로 처리할 수 있습니다.\n   - 노드가 끝나는 지점에 `isEnd` 플래그가 설정되어 있으면, 그 파일은 직접 `rm` 명령을 사용합니다.\n\n3.",
        "index": 2
      },
      {
        "id": "2024-12-16--BOJ--5446_chunk_3",
        "text": "노드를 `rm` 명령 한 번으로 처리할 수 있습니다.\n   - 노드가 끝나는 지점에 `isEnd` 플래그가 설정되어 있으면, 그 파일은 직접 `rm` 명령을 사용합니다.\n\n3.",
        "index": 3
      },
      {
        "id": "2024-12-16--BOJ--5446_chunk_4",
        "text": "노드를 `rm` 명령 한 번으로 처리할 수 있습니다.\n   - 노드가 끝나는 지점에 `isEnd` 플래그가 설정되어 있으면, 그 파일은 직접 `rm` 명령을 사용합니다.\n\n3.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-16--BOJ--20541",
    "title": "[BOJ] 20541번 앨범정리",
    "path": "/2024/12/16/[BOJ]-20541번-앨범정리/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 20541번](https://www.acmicpc.net/problem/20541)  \n{: .prompt-tip }\n\n## 문제 요약\n\n주어진 명령어를 기반으로 폴더와 이미지를 관리하는 앨범 정리 프로그램을 구현해야 합니다.  \n명령어는 폴더 생성/삭제, 이미지 추가/삭제, 폴더 이동이며 결과에 따라 출력을 다르게 해야 합니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **파일 시스템** 구조를 떠올리면 쉽게 해결할 수 있습니다.  \n**디렉토리 구조**를 **트리 구조**와 유사하게 구현하되, 자식 디렉토리나 이미지 이름의 중복 검사 및 빠른 접근을 고려하면 됩니다.\n\n### 주요 아이디어\n\n1. **Directory 구조체**를 사용하여 다음을 관리:\n   - 현재 폴더의 이름 (`dirName`)\n   - 부모 폴더의 포인터 (`parDir`)\n   - 자식 폴더의 포인터를 담는 `map` (`childDirs`)\n   - 현재 폴더에 속한 이미지 이름들을 담는 `set` (`curImgs`)\n\n2. **메모리 풀** 기법:\n   - `new` 키워드 대신 미리 선언된 `pool` 배열을 사용하여 메모리 할당 속도를 높임.\n\n3. **재귀적 삭제**:\n   - `rmalb` 명령어에서 폴더를 삭제할 때 **하위 폴더와 이미지** 개수를 재귀적으로 계산하여 출력.\n\n4. **명령어 실행**:\n   - `switch-case`를 통해 각 명령어를 빠르게 구분하고 실행.\n\n---\n\n## 코드 설명\n\n```cpp\n#define _CRT_SECURE_NO_WARNINGS\n#include<bits/stdc++.h>\nusing namespace std;\n\n// 명령어 타입 정의\n#define MKALB 0\n#define RMALB 1\n#define INSERT 2\n#define DELETE 3\n#define CA 4\n\n// 명령어를 숫자로 변환하는 함수\ninline int getCmd(const string& cmd) {\n    if (cmd[0] == 'm') return MKALB;\n    if (cmd[0] == 'r') return RMALB;\n    if (cmd[0] == 'i') return INSERT;\n    if (cmd[0] == 'd') return DELETE;\n    if (cmd[0] == 'c') return CA;\n}\n\n// 디렉토리 구조체 정의\nstruct Directory {\n    string dirName;\n    Directory* parDir;              // 부모 폴더\n    map<string, Directory*> childDirs;  // 자식 폴더\n    set<string> curImgs;            // 현재 폴더에 속한 이미지\n\n    Directory() {\n        parDir = nullptr;\n        childDirs.clear();\n        curImgs.clear();\n    }\n};\n\n// 전역 변수 선언\nDirectory root;        // 최상위 폴더\nDirectory pool[100000]; // 메모리 풀\nint pCnt;              // 메모리 풀 카운트\n\n// 재귀적으로 폴더 내의 앨범 및 이미지 개수를 계산\nvoid getRMcnt(Directory* curDir, int& albumCnt, int& imgCnt) {\n    albumCnt += curDir->childDirs.size();\n    imgCnt += curDir->curImgs.size();\n    for (const auto& next : curDir->childDirs) {\n        getRMcnt(next.second, albumCnt, imgCnt);\n    }\n}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    int N; cin >> N;  // 명령어 개수\n    string cmd, val;\n    int imgCnt, albumCnt;\n\n    Directory* curDir = &root;\n    curDir->dirName = \"album\";  // 초기 폴더 이름 설정\n\n    for (int i = 0; i < N; i++) {\n        cin >> cmd >> val;\n\n        switch (getCmd(cmd)) {\n        case MKALB:  // 앨범 생성\n            if (curDir->childDirs.find(val) == curDir->childDirs.end()) {\n                Directory* child = &pool[pCnt++];\n                child->dirName = val;\n                child->parDir = curDir;\n                curDir->childDirs[val] = child;\n            } else {\n                cout << \"duplicated album name\\n\";\n            }\n            break;\n\n        case RMALB:  // 앨범 삭제\n            albumCnt = 0, imgCnt = 0;\n            if (val == \"-1\") { /* 사전순으로 가장 앞의 폴더 삭제 */ }\n            else if (val == \"1\") { /* 사전순으로 가장 뒤의 폴더 삭제 */ }\n            else if (val == \"0\") { /* 모든 자식 폴더 삭제 */ }\n            cout << albumCnt << ' ' << imgCnt << '\\n';\n            break;\n\n        case INSERT:  // 이미지 추가\n            if (curDir->curImgs.find(val) == curDir->curImgs.end()) {\n                curDir->curImgs.insert(val);\n            } else {\n                cout << \"duplicated photo name\\n\";\n            }\n            break;\n\n        case DELETE:  // 이미지 삭제\n            imgCnt = 0;\n            if (curDir->curImgs.find(val) != curDir->curImgs.end()) {\n                curDir->curImgs.erase(val);\n                ++imgCnt;\n            }\n            cout << imgCnt << '\\n';\n            break;\n\n        case CA:  // 폴더 이동\n            if (val == \"..\" && curDir->parDir != nullptr) {\n                curDir = curDir->parDir;\n            } else if (val == \"/\") {\n                curDir = &root;\n            } else if (curDir->childDirs.find(val) != curDir->childDirs.end()) {\n                curDir = curDir->childDirs[val];\n            }\n            cout << curDir->dirName << '\\n';\n            break;\n        }\n    }\n    return 0;\n}\n```\n",
    "date": "2024-12-16",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-16--BOJ--20541_chunk_0",
        "text": "[BOJ] 20541번 앨범정리\n\n> **문제 링크**: [백준 20541번](https://www.acmicpc.net/problem/20541)  \n{: .prompt-tip }\n\n## 문제 요약\n\n주어진 명령어를 기반으로 폴더와 이미지를 관리하는 앨범 정리 프로그램을 구현해야 합니다.  \n명령어는 폴더 생성/삭제, 이미지 추가/삭제, 폴더 이동이며 결과에 따라 출력을 다르게 해야 합니다.\n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **파일 시스템** 구조를 떠올리면 쉽게 해결할 수 있습니다.  \n**디렉토리 구조**를 **트리 구조**와 유사하게 구현하되, 자식 디렉토리나 이미지 이름의 중복 검사 및 빠른 접근을 고려하면 됩니다.\n\n### 주요 아이디어\n\n1. **Directory 구조체**를 사용하여 다음을 관리:\n   - 현재 폴더의 이름 (`dirName`)\n   - 부모 폴더의 포인터 (`parDir`)\n   - 자식 폴더의 포인터를 담는 `map` (`childDirs`)\n   - 현재 폴더에 속한 이미지 이름들을 담는 `set` (`curImgs`)\n\n2. **메모리 풀** 기법:\n   - `new` 키워드 대신 미리 선언된 `pool` 배열을 사용하여 메모리 할당 속도를 높임.\n\n3. **재귀적 삭제**:\n   - `rmalb` 명령어에서 폴더를 삭제할 때 **하위 폴더와 이미지** 개수를 재귀적으로 계산하여 출력.\n\n4.",
        "index": 0
      },
      {
        "id": "2024-12-16--BOJ--20541_chunk_1",
        "text": "여 메모리 할당 속도를 높임.\n\n3. **재귀적 삭제**:\n   - `rmalb` 명령어에서 폴더를 삭제할 때 **하위 폴더와 이미지** 개수를 재귀적으로 계산하여 출력.\n\n4.",
        "index": 1
      },
      {
        "id": "2024-12-16--BOJ--20541_chunk_2",
        "text": "여 메모리 할당 속도를 높임.\n\n3. **재귀적 삭제**:\n   - `rmalb` 명령어에서 폴더를 삭제할 때 **하위 폴더와 이미지** 개수를 재귀적으로 계산하여 출력.\n\n4.",
        "index": 2
      },
      {
        "id": "2024-12-16--BOJ--20541_chunk_3",
        "text": "여 메모리 할당 속도를 높임.\n\n3. **재귀적 삭제**:\n   - `rmalb` 명령어에서 폴더를 삭제할 때 **하위 폴더와 이미지** 개수를 재귀적으로 계산하여 출력.\n\n4.",
        "index": 3
      },
      {
        "id": "2024-12-16--BOJ--20541_chunk_4",
        "text": "여 메모리 할당 속도를 높임.\n\n3. **재귀적 삭제**:\n   - `rmalb` 명령어에서 폴더를 삭제할 때 **하위 폴더와 이미지** 개수를 재귀적으로 계산하여 출력.\n\n4.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-16--BOJ--19585",
    "title": "[BOJ] 19585 전설",
    "path": "/2024/12/16/[BOJ]-19585-전설/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [백준 19585번](https://www.acmicpc.net/problem/19585)  \n{: .prompt-tip }\n\n## 문제 요약\n\n색상 이름과 닉네임이 주어졌을 때, 팀명이 **색상 이름 + 닉네임** 형태라면 \"Yes\", 아니라면 \"No\"를 출력하는 문제입니다.  \n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **Trie(트라이)** 자료구조와 **해쉬 셋**을 조합하여 해결할 수 있습니다.   \n색상 이름과 닉네임을 효율적으로 탐색하기 위해 각각 다른 자료구조를 사용합니다.\n\n### 주요 아이디어\n\n1. **Trie(트라이)를 이용한 색상 이름 저장**:\n   - 색상 이름은 **Trie**에 저장합니다.\n   - 팀명에서 첫 번째 부분(색상 이름)을 빠르게 탐색하면서 가능한 문자열을 확인합니다.\n\n2. **unordered_set를 이용한 닉네임 확인**:\n   - 색상 이름 이후의 나머지 문자열이 닉네임 집합에 존재하는지 빠르게 확인하기 위해 **unordered_set**에 저장합니다.\n\n3. **팀명 검증**:\n   - 주어진 팀명을 탐색하면서 **Trie**에서 색상 이름을 부분적으로 확인합니다.\n   - Trie에서 색상 이름이 끝나는 위치를 찾았을 때   \n     -> 나머지 문자열이 **unordered_set**에 있는지 검사합니다.\n\n> 문제의 시간제한이 3초이기에, 꽤 여유롭습니다.\n{: .prompt-tip }\n\n---\n\n## 정답 코드\n\n```cpp\n#include<bits/stdc++.h>\nusing namespace std;\n\nint C, N, Q;\nunordered_set<string> us;\n\nstruct Node {\n    bool isEnd = false;\n    Node* next[26] = { 0, };\n};\nNode* root = new Node();\n\n// 색상 이름을 Trie에 삽입\nvoid insert(string word) {\n    Node* cur = root;\n    for (const auto& c : word) {\n        int idx = c - 'a';\n        if (cur->next[idx] == nullptr) {\n            cur->next[idx] = new Node();\n        }\n        cur = cur->next[idx];\n    }\n    cur->isEnd = true;\n}\n\n// 팀명이 조건을 만족하는지 확인\nbool query(string word) {\n    Node* cur = root;\n    for (int i = 0; i < word.length(); i++) {\n        int idx = word[i] - 'a';\n\n        // Trie에서 색상 이름이 끝났을 때\n        if (cur->isEnd) {\n            string chkTeam(word.begin() + i, word.end());\n            if (us.count(chkTeam)) return true;\n        }\n\n        // Trie 탐색을 계속 진행\n        if (cur->next[idx] == nullptr) return false;\n        cur = cur->next[idx];\n    }\n    return false;\n}\n\nint main() {\n    ios::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    // 입력\n    cin >> C >> N;\n    string color;\n    for (int i = 0; i < C; i++) {\n        cin >> color;\n        insert(color);\n    }\n\n    string name;\n    for (int i = 0; i < N; i++) {\n        cin >> name;\n        us.insert(name);\n    }\n\n    // 쿼리\n    cin >> Q;\n    string teamName;\n    for (int i = 0; i < Q; i++) {\n        cin >> teamName;\n        cout << (query(teamName) ? \"Yes\" : \"No\") << '\\n';\n    }\n\n    return 0;\n}\n```\n",
    "date": "2024-12-16",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-16--BOJ--19585_chunk_0",
        "text": "[BOJ] 19585 전설\n\n> **문제 링크**: [백준 19585번](https://www.acmicpc.net/problem/19585)  \n{: .prompt-tip }\n\n## 문제 요약\n\n색상 이름과 닉네임이 주어졌을 때, 팀명이 **색상 이름 + 닉네임** 형태라면 \"Yes\", 아니라면 \"No\"를 출력하는 문제입니다.  \n\n---\n\n## 문제 풀이 아이디어\n\n이 문제는 **Trie(트라이)** 자료구조와 **해쉬 셋**을 조합하여 해결할 수 있습니다.   \n색상 이름과 닉네임을 효율적으로 탐색하기 위해 각각 다른 자료구조를 사용합니다.\n\n### 주요 아이디어\n\n1. **Trie(트라이)를 이용한 색상 이름 저장**:\n   - 색상 이름은 **Trie**에 저장합니다.\n   - 팀명에서 첫 번째 부분(색상 이름)을 빠르게 탐색하면서 가능한 문자열을 확인합니다.\n\n2. **unordered_set를 이용한 닉네임 확인**:\n   - 색상 이름 이후의 나머지 문자열이 닉네임 집합에 존재하는지 빠르게 확인하기 위해 **unordered_set**에 저장합니다.\n\n3.",
        "index": 0
      },
      {
        "id": "2024-12-16--BOJ--19585_chunk_1",
        "text": "_set를 이용한 닉네임 확인**:\n   - 색상 이름 이후의 나머지 문자열이 닉네임 집합에 존재하는지 빠르게 확인하기 위해 **unordered_set**에 저장합니다.\n\n3.",
        "index": 1
      },
      {
        "id": "2024-12-16--BOJ--19585_chunk_2",
        "text": "_set를 이용한 닉네임 확인**:\n   - 색상 이름 이후의 나머지 문자열이 닉네임 집합에 존재하는지 빠르게 확인하기 위해 **unordered_set**에 저장합니다.\n\n3.",
        "index": 2
      },
      {
        "id": "2024-12-16--BOJ--19585_chunk_3",
        "text": "_set를 이용한 닉네임 확인**:\n   - 색상 이름 이후의 나머지 문자열이 닉네임 집합에 존재하는지 빠르게 확인하기 위해 **unordered_set**에 저장합니다.\n\n3.",
        "index": 3
      },
      {
        "id": "2024-12-16--BOJ--19585_chunk_4",
        "text": "_set를 이용한 닉네임 확인**:\n   - 색상 이름 이후의 나머지 문자열이 닉네임 집합에 존재하는지 빠르게 확인하기 위해 **unordered_set**에 저장합니다.\n\n3.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-16--BOJ--5670",
    "title": "[BOJ] 5670번 휴대폰 자판",
    "path": "/2024/12/16/[BOJ]-5670번-휴대폰-자판/",
    "categories": [
      "Computer Science",
      "Problem Solving",
      "Computer_Science/problem-solving"
    ],
    "content": "> **문제 링크**: [https://www.acmicpc.net/problem/5670](https://www.acmicpc.net/problem/5670)\n{: .prompt-tip }\n\n## 문제 요약\n사전에 있는 단어를 입력할 때, 자동완성 기능을 사용하여 버튼을 누르는 횟수의 평균을 계산하는 문제입니다.\n\n---\n\n## 문제 풀이 아이디어\n\n트라이 자료구조를 활용해서 문제를 해결합니다.  \n대략적인 시간 복잡도를 생각해보면, 단어의 개수 N은 최대 1E5 길이 |S|는 80입니다.\n\n즉, O(N*S)의 시간복잡도를 가진다면, 충분히 제한시간 1초 내에 수행할 수 있을 것이라 생각됩니다.\n\n1. Trie(트라이) 자료구조를 사용해 단어를 삽입  \n2. 각 단어를 입력할 때, 자동완성이 가능한 조건은  \n   - 노드의 자식이 2개 이상일 때  \n   - 노드가 단어의 끝일 때  \n   - 루트 노드인 경우  \n3. 입력 횟수를 계산하면서 모든 단어에 대해 버튼 입력 횟수를 누적.  \n\n\n**정답 코드**:  \n```cpp\n#define _CRT_SECURE_NO_WARNINGS\n#include <bits/stdc++.h>\n\nusing namespace std;\n\nint N, M;\n\nstruct Trie {\n    map<char, Trie*> next;\n    bool isEnd = false;\n};\n\nTrie pool[1000001];\nint pCnt;\n\nTrie* root;\n\nvoid insert(string& str) {\n    Trie* cur = root;\n    for (const auto& c : str) {\n        if (cur->next.count(c) == 0) {\n            cur->next[c] = &pool[pCnt++];\n        }\n        cur = cur->next[c];\n    }\n    cur->isEnd = 1;\n}\n\nint query(string& str) {\n    Trie* cur = root;\n    int typeCnt = 0;\n    for (const auto& c : str) {\n        // 처음이거나 두개이상이면 입력\n        if (cur == root || cur->next.size() > 1 || cur->isEnd) {\n            typeCnt++;\n        }\n\n        cur = cur->next[c];\n    }\n    return typeCnt;\n}\n\nint main() {\n    ios_base::sync_with_stdio(0);\n    cin.tie(0);\n    cout.tie(0);\n\n    while (cin >> N) {\n        pCnt = 0;\n        root = &pool[pCnt++];\n        vector<string> wordLst;\n\n        wordLst.resize(N);\n        for (int i = 0; i < N; i++) {\n            cin >> wordLst[i];\n            insert(wordLst[i]);\n        }\n\n        int ans = 0;\n        for (int i = 0; i < N; i++) {\n            ans += query(wordLst[i]);\n        }\n\n        printf(\"%.2f\\n\", (float)ans / (float)N);\n\n        for (int i = 0; i < pCnt; i++) pool[i] = {};\n    }\n\n    return 0;\n}\n```\n",
    "date": "2024-12-16",
    "tags": [
      "Algorithm",
      "Problem Solving",
      "BOJ"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-16--BOJ--5670_chunk_0",
        "text": "[BOJ] 5670번 휴대폰 자판\n\n> **문제 링크**: [https://www.acmicpc.net/problem/5670](https://www.acmicpc.net/problem/5670)\n{: .prompt-tip }\n\n## 문제 요약\n사전에 있는 단어를 입력할 때, 자동완성 기능을 사용하여 버튼을 누르는 횟수의 평균을 계산하는 문제입니다.\n\n---\n\n## 문제 풀이 아이디어\n\n트라이 자료구조를 활용해서 문제를 해결합니다.  \n대략적인 시간 복잡도를 생각해보면, 단어의 개수 N은 최대 1E5 길이 |S|는 80입니다.\n\n즉, O(N*S)의 시간복잡도를 가진다면, 충분히 제한시간 1초 내에 수행할 수 있을 것이라 생각됩니다.\n\n1. Trie(트라이) 자료구조를 사용해 단어를 삽입  \n2. 각 단어를 입력할 때, 자동완성이 가능한 조건은  \n   - 노드의 자식이 2개 이상일 때  \n   - 노드가 단어의 끝일 때  \n   - 루트 노드인 경우  \n3. 입력 횟수를 계산하면서 모든 단어에 대해 버튼 입력 횟수를 누적.",
        "index": 0
      },
      {
        "id": "2024-12-16--BOJ--5670_chunk_1",
        "text": "- 노드의 자식이 2개 이상일 때  \n   - 노드가 단어의 끝일 때  \n   - 루트 노드인 경우  \n3. 입력 횟수를 계산하면서 모든 단어에 대해 버튼 입력 횟수를 누적.",
        "index": 1
      },
      {
        "id": "2024-12-16--BOJ--5670_chunk_2",
        "text": "- 노드의 자식이 2개 이상일 때  \n   - 노드가 단어의 끝일 때  \n   - 루트 노드인 경우  \n3. 입력 횟수를 계산하면서 모든 단어에 대해 버튼 입력 횟수를 누적.",
        "index": 2
      },
      {
        "id": "2024-12-16--BOJ--5670_chunk_3",
        "text": "- 노드의 자식이 2개 이상일 때  \n   - 노드가 단어의 끝일 때  \n   - 루트 노드인 경우  \n3. 입력 횟수를 계산하면서 모든 단어에 대해 버튼 입력 횟수를 누적.",
        "index": 3
      },
      {
        "id": "2024-12-16--BOJ--5670_chunk_4",
        "text": "- 노드의 자식이 2개 이상일 때  \n   - 노드가 단어의 끝일 때  \n   - 루트 노드인 경우  \n3. 입력 횟수를 계산하면서 모든 단어에 대해 버튼 입력 횟수를 누적.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-13-Augmentation-----Albumentations",
    "title": "Data Augmentation을 위해 Albumentations 사용해보기",
    "path": "/2024/12/13/Augmentation을-위한-Albumentations-사용법/",
    "categories": [
      "AI & CV",
      "Dataset",
      "DL"
    ],
    "content": "## 1. Albumentations란?\n\n**Albumentations**는 **다양한 이미지 변형 기법**을 제공하는 Python 라이브러리입니다.  \n주요 특징은 **빠른 속도**, **편리함**, 그리고 **다양한 기능**입니다.\n\n> **주요 이미지 변형 기법**:  \n> - **회전**  \n> - **이동**  \n> - **확대/축소**  \n> - **반전**  \n> - **색상 변경**  \n> - **잡음 추가**  \n{: .highlight }\n\n이 변형들은 **데이터셋을 다양화**하여 모델의 **일반화 능력**을 높일 수 있도록 돕습니다.\n\n---\n\n## 2. Albumentations 설치하기\n\n```bash\npip install albumentations\n```\n\n---\n\n## 3. 데이터 증강 파이프라인 구성하기\n\n아래의 코드는 **YOLO 형식**의 바운딩 박스를 지원하는 **Albumentations**를 사용해 데이터 증강을 수행합니다.\n\n### 3.1 필요한 라이브러리 불러오기\n\n```python\nimport os\nimport cv2\nimport numpy as np\nimport albumentations as A\nfrom tqdm import tqdm\n```\n\n### 3.2 데이터 증강 함수 정의\n\n```python\ndef apply_transformations(image, bboxes, class_labels):\n    \"\"\"\n    이미지와 바운딩 박스에 변형을 적용하는 함수.\n    \"\"\"\n    transformed = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n    augmented_image = transformed['image']\n    augmented_bboxes = transformed['bboxes']\n    augmented_class_labels = transformed['class_labels']\n    return augmented_image, augmented_bboxes, augmented_class_labels\n\ndef save_augmented_data(image_file, augmented_image, augmented_bboxes, augmented_class_labels, output_dir):\n    \"\"\"\n    증강된 데이터를 이미지 파일과 라벨 파일로 저장하는 함수.\n    \"\"\"\n    cv2.imwrite(os.path.join(output_dir, image_file), augmented_image)\n    label_file = image_file.replace('.jpg', '.txt')\n    with open(os.path.join(output_dir, label_file), 'w') as f:\n        for i in range(len(augmented_bboxes)):\n            f.write(f\"{augmented_class_labels[i]} {' '.join(map(str, augmented_bboxes[i]))}\\n\")\n```\n\n---\n\n## 4. 전체 증강 스크립트\n\n아래는 데이터셋의 모든 이미지를 증강하는 스크립트입니다.\n\n```python\ndef main(input_dir, output_dir, n):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    image_files = [f for f in os.listdir(input_dir) if f.endswith('.jpg')]\n    for image_file in tqdm(image_files, desc=\"Processing Images\"):\n        image = cv2.imread(os.path.join(input_dir, image_file))\n        label_file = image_file.replace('.jpg', '.txt')\n\n        with open(os.path.join(input_dir, label_file), 'r') as f:\n            lines = f.readlines()\n        \n        bboxes = np.array([line.split()[1:5] for line in lines], dtype=float)\n        class_labels = np.array([line.split()[0] for line in lines], dtype=int)\n\n        for i in range(n):\n            try:\n                augmented_image, augmented_bboxes, augmented_class_labels = apply_transformations(image, bboxes, class_labels)\n                output_image_file = f\"aug_{i}_{image_file}\"\n                save_augmented_data(output_image_file, augmented_image, augmented_bboxes, augmented_class_labels, output_dir)\n            except Exception as e:\n                print(f\"에러: {e}, 파일 이름: {image_file}\")\n```\n\n---\n\n## 5. 증강 파라미터 설정하기\n\n다양한 변형 기법을 `A.Compose`를 통해 적용합니다.\n\n```python\ntransform = A.Compose([\n    A.FancyPCA(alpha=0.1, p=0.5),  # 색상 변형\n    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.5),  # 밝기/대비\n    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=15, p=0.5),  # 색상 변형\n    A.OneOf([\n        A.GaussNoise(var_limit=(1, 7), p=0.5),  # 가우시안 잡음 추가\n        A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.5),\n        A.JpegCompression(quality_lower=90, quality_upper=100, p=0.5)\n    ], p=0.7),\n    A.OneOf([\n        A.Blur(blur_limit=(1, 2), p=0.5),\n        A.CLAHE(p=0.5)  # 히스토그램 균등화\n    ], p=0.25)\n], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n```\n\n---\n\n## 6. 스크립트 실행 방법\n\n**파라미터**:\n- `--input`: 입력 데이터셋 경로\n- `--output`: 증강된 데이터를 저장할 경로\n- `--n`: 이미지당 생성할 증강 개수\n\n### 실행 예제\n\n```bash\npython augment.py --input ./input_data --output ./augmented_data --n 5\n```\n\n전체 코드는 아래 저장소에 있습니다.  \n[https://github.com/knowgyu/dataset-tools](https://github.com/knowgyu/dataset-tools)\n\n\n---\n\n## 7. 결론 및 요약\n\n**Albumentations**를 사용하면 다양한 이미지 변형 기법을 빠르게 적용할 수 있습니다.  \n\n---\n> [Albumentations 공식 GitHub](https://github.com/albumentations-team/albumentations){: .prompt-tip }\n> [Albumentations Documentation](https://albumentations.ai/docs/){: .prompt-tip }\n",
    "date": "2024-12-13",
    "tags": [
      "Augmentation",
      "Albumentations"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-13-Augmentation-----Albumentations_chunk_0",
        "text": "Data Augmentation을 위해 Albumentations 사용해보기\n\n## 1. Albumentations란?\n\n**Albumentations**는 **다양한 이미지 변형 기법**을 제공하는 Python 라이브러리입니다.  \n주요 특징은 **빠른 속도**, **편리함**, 그리고 **다양한 기능**입니다.\n\n> **주요 이미지 변형 기법**:  \n> - **회전**  \n> - **이동**  \n> - **확대/축소**  \n> - **반전**  \n> - **색상 변경**  \n> - **잡음 추가**  \n{: .highlight }\n\n이 변형들은 **데이터셋을 다양화**하여 모델의 **일반화 능력**을 높일 수 있도록 돕습니다.\n\n---\n\n## 2. Albumentations 설치하기\n\n```bash\npip install albumentations\n```\n\n---\n\n## 3.",
        "index": 0
      },
      {
        "id": "2024-12-13-Augmentation-----Albumentations_chunk_1",
        "text": "높일 수 있도록 돕습니다.\n\n---\n\n## 2. Albumentations 설치하기\n\n```bash\npip install albumentations\n```\n\n---\n\n## 3.",
        "index": 1
      },
      {
        "id": "2024-12-13-Augmentation-----Albumentations_chunk_2",
        "text": "높일 수 있도록 돕습니다.\n\n---\n\n## 2. Albumentations 설치하기\n\n```bash\npip install albumentations\n```\n\n---\n\n## 3.",
        "index": 2
      },
      {
        "id": "2024-12-13-Augmentation-----Albumentations_chunk_3",
        "text": "높일 수 있도록 돕습니다.\n\n---\n\n## 2. Albumentations 설치하기\n\n```bash\npip install albumentations\n```\n\n---\n\n## 3.",
        "index": 3
      },
      {
        "id": "2024-12-13-Augmentation-----Albumentations_chunk_4",
        "text": "높일 수 있도록 돕습니다.\n\n---\n\n## 2. Albumentations 설치하기\n\n```bash\npip install albumentations\n```\n\n---\n\n## 3.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-13-Grounding-DINO------Object-Detection",
    "title": "Grounding DINO를 활용한 Object Detection 데이터 오토 라벨링",
    "path": "/2024/12/13/Grounding-DINO를-활용한-Object-Detection-데이터-오토-라벨링/",
    "categories": [
      "AI & CV",
      "Dataset",
      "DL"
    ],
    "content": "**본 문서에서는 Zero-Shot Object Detector 모델인 Grounding DINO를 활용해 이미지 라벨링 작업을 자동화하는 방법을 다룹니다.**   \n오토 라벨링을 통해 시간 소모를 최소화하고 효율적으로 데이터셋을 구축할 수 있습니다.\n\n> Grounding DINO를 통해 자동으로 객체를 탐지하고 라벨링한 데이터를 검수할 수 있도록 준비합니다.  \n{: .prompt-tip }\n\n---\n\n## 1. 이미지 라벨링 작업의 필요성\n\n이미지 라벨링 작업은 **시간과 비용이 많이 소모되는 반복적 작업**입니다. 특히 **대규모 데이터셋**을 구축하려면 상당한 인력과 시간이 필요합니다. 하지만 Zero-Shot Object Detection 모델인 **Grounding DINO**를 활용하면 특정 카테고리의 객체를 빠르게 탐지하고 라벨링할 수 있습니다. 사용자는 결과만 검수하면 되므로 **생산성을 극대화**할 수 있습니다.\n\n---\n\n## 2. Grounding DINO 소개\n\nGrounding DINO는 **텍스트 프롬프트**를 입력으로 받아 객체를 인식하는 **Zero-Shot Object Detector**입니다. \n\n### 특징\n\n1. **Open-set Object Detection**: 제한된 객체 클래스 대신 사용자가 원하는 **카테고리 이름**이나 **참조 표현**을 입력하면 탐지할 수 있습니다.\n2. **언어와 시각 모달 융합**: \n   - **Backbone**: Feature Extraction\n   - **Neck**: Query Initialization\n   - **Head**: Detection 결과 출력 (Grounding DINO는 이 과정에서 언어 정보를 융합합니다).\n\n---\n\n## 3. Auto Annotation 준비\n\n### 3.1 GPU 설정 확인\n\nGPU가 정상적으로 인식되는지 확인합니다.\n\n```bash\nnvidia-smi\n```\n\n### 3.2 환경 설정 및 Grounding DINO 설치\n\n> 주피터 노트북을 활용해 코드를 따라하는 것을 권장합니다.\n{: .prompt-tip }\n\n1. **Grounding DINO 저장소 다운로드 및 설치**:\n   ```bash\n   git clone https://github.com/IDEA-Research/GroundingDINO.git\n   cd GroundingDINO\n   git checkout feature/more_compact_inference_api\n   pip install -q -e .\n   ```\n\n2. **Supervision 패키지 설치**:\n   ```bash\n   pip uninstall -y supervision\n   pip install -q supervision==0.6.0\n   ```\n\n### 3.3 Weights 및 Configuration 파일 준비\n\nGrounding DINO를 실행하기 위해 필요한 Weight 파일과 Configuration 파일을 설정합니다.\n\n```python\nimport os\n\nHOME = os.getcwd()\nCONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\nWEIGHTS_PATH = os.path.join(HOME, \"weights\", \"groundingdino_swint_ogc.pth\")\n\n# Weights 파일 다운로드\n!mkdir -p {HOME}/weights\n!wget -q -P {HOME}/weights https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n```\n\n---\n\n## 4. Auto Annotation 테스트\n\n### 4.1 예시 이미지 다운로드\n\n```python\n!mkdir -p {HOME}/data\n!wget -q -P {HOME}/data https://media.roboflow.com/notebooks/examples/dog-3.jpeg\n```\n\n### 4.2 Grounding DINO 모델 로드\n\n```python\nfrom groundingdino.util.inference import Model\n\nmodel = Model(model_config_path=CONFIG_PATH, model_checkpoint_path=WEIGHTS_PATH)\n```\n\n### 4.3 단일 이미지 오토 라벨링\n\n```python\nimport cv2\nimport supervision as sv\n\n# 설정\nSOURCE_IMAGE_PATH = f\"{HOME}/data/dog-3.jpeg\"\nCLASSES = ['person', 'dog']\nBOX_THRESHOLD = 0.35\nTEXT_THRESHOLD = 0.25\n\n# 이미지 불러오기 및 라벨링\nimage = cv2.imread(SOURCE_IMAGE_PATH)\ndetections = model.predict_with_classes(\n    image=image,\n    classes=[f\"all {cls}s\" for cls in CLASSES],\n    box_threshold=BOX_THRESHOLD,\n    text_threshold=TEXT_THRESHOLD\n)\n\n# 결과 시각화\nannotator = sv.BoxAnnotator()\nlabels = [f\"{CLASSES[class_id]} {confidence:.2f}\" for _, _, confidence, class_id, _ in detections]\nannotated_frame = annotator.annotate(image.copy(), detections, labels)\n\nsv.plot_image(annotated_frame, (16, 16))\n```\n\n---\n\n## 5. 전체 데이터셋 오토 라벨링 및 저장\n\n```python\nfrom tqdm.notebook import tqdm\n\nIMAGES_DIRECTORY = \"./data\"\nANNOTATIONS_DIRECTORY = \"./annotations\"\n\n# 이미지 리스트 추출\nimage_paths = sv.list_files_with_extensions(directory=IMAGES_DIRECTORY, extensions=['jpg', 'jpeg', 'png'])\n\n# 라벨링 및 저장\nimages, annotations = {}, {}\nfor image_path in tqdm(image_paths):\n    image_name = image_path.name\n    image = cv2.imread(str(image_path))\n    detections = model.predict_with_classes(\n        image=image,\n        classes=[f\"all {cls}s\" for cls in CLASSES],\n        box_threshold=BOX_THRESHOLD,\n        text_threshold=TEXT_THRESHOLD\n    )\n    images[image_name] = image\n    annotations[image_name] = detections\n\n# Pascal VOC 형식으로 저장\nsv.Dataset(classes=CLASSES, images=images, annotations=annotations).as_pascal_voc(\n    annotations_directory_path=ANNOTATIONS_DIRECTORY\n)\n```\n\n---\n\n## 6. 결론 및 요약\n\nGrounding DINO를 활용하면 **텍스트 프롬프트**만으로 원하는 카테고리의 객체를 자동으로 라벨링할 수 있습니다.  \n이를 통해 대규모 데이터셋 구축 시간을 절약하고 검수 작업만 수행하면 되므로 **효율성과 생산성**을 극대화할 수 있습니다.\n",
    "date": "2024-12-13",
    "tags": [
      "Auto Annotation",
      "Grounding DINO"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-13-Grounding-DINO------Object-Detection_chunk_0",
        "text": "Grounding DINO를 활용한 Object Detection 데이터 오토 라벨링\n\n**본 문서에서는 Zero-Shot Object Detector 모델인 Grounding DINO를 활용해 이미지 라벨링 작업을 자동화하는 방법을 다룹니다.**   \n오토 라벨링을 통해 시간 소모를 최소화하고 효율적으로 데이터셋을 구축할 수 있습니다.\n\n> Grounding DINO를 통해 자동으로 객체를 탐지하고 라벨링한 데이터를 검수할 수 있도록 준비합니다.  \n{: .prompt-tip }\n\n---\n\n## 1. 이미지 라벨링 작업의 필요성\n\n이미지 라벨링 작업은 **시간과 비용이 많이 소모되는 반복적 작업**입니다. 특히 **대규모 데이터셋**을 구축하려면 상당한 인력과 시간이 필요합니다. 하지만 Zero-Shot Object Detection 모델인 **Grounding DINO**를 활용하면 특정 카테고리의 객체를 빠르게 탐지하고 라벨링할 수 있습니다. 사용자는 결과만 검수하면 되므로 **생산성을 극대화**할 수 있습니다.\n\n---\n\n## 2. Grounding DINO 소개\n\nGrounding DINO는 **텍스트 프롬프트**를 입력으로 받아 객체를 인식하는 **Zero-Shot Object Detector**입니다. \n\n### 특징\n\n1. **Open-set Object Detection**: 제한된 객체 클래스 대신 사용자가 원하는 **카테고리 이름**이나 **참조 표현**을 입력하면 탐지할 수 있습니다.\n2.",
        "index": 0
      },
      {
        "id": "2024-12-13-Grounding-DINO------Object-Detection_chunk_1",
        "text": "**Open-set Object Detection**: 제한된 객체 클래스 대신 사용자가 원하는 **카테고리 이름**이나 **참조 표현**을 입력하면 탐지할 수 있습니다.\n2. **언어와 시각 모달 융합**: \n   - **Backbone**: Feature Extraction\n   - **Neck**: Query Initialization\n   - **Head**: Detection 결과 출력 (Grounding DINO는 이 과정에서 언어 정보를 융합합니다).\n\n---\n\n## 3. Auto Annotation 준비\n\n### 3.1 GPU 설정 확인\n\nGPU가 정상적으로 인식되는지 확인합니다.\n\n```bash\nnvidia-smi\n```\n\n### 3.2 환경 설정 및 Grounding DINO 설치\n\n> 주피터 노트북을 활용해 코드를 따라하는 것을 권장합니다.\n{: .prompt-tip }\n\n1. **Grounding DINO 저장소 다운로드 및 설치**:\n   ```bash\n   git clone https://github.com/IDEA-Research/GroundingDINO.git\n   cd GroundingDINO\n   git checkout feature/more_compact_inference_api\n   pip install -q -e .\n   ```\n\n2.",
        "index": 1
      },
      {
        "id": "2024-12-13-Grounding-DINO------Object-Detection_chunk_2",
        "text": "GroundingDINO\n   git checkout feature/more_compact_inference_api\n   pip install -q -e .\n   ```\n\n2. **Supervision 패키지 설치**:\n   ```bash\n   pip uninstall -y supervision\n   pip install -q supervision==0.6.0\n   ```\n\n### 3.3 Weights 및 Configuration 파일 준비\n\nGrounding DINO를 실행하기 위해 필요한 Weight 파일과 Configuration 파일을 설정합니다.\n\n```python\nimport os\n\nHOME = os.getcwd()\nCONFIG_PATH = os.path.join(HOME, \"GroundingDINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\")\nWEIGHTS_PATH = os.path.join(HOME, \"weights\", \"groundingdino_swint_ogc.pth\")\n\n# Weights 파일 다운로드\n!mkdir -p {HOME}/weights\n!wget -q -P {HOME}/weights https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n```\n\n---\n\n## 4.",
        "index": 2
      },
      {
        "id": "2024-12-13-Grounding-DINO------Object-Detection_chunk_3",
        "text": "A-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n```\n\n---\n\n## 4.",
        "index": 3
      },
      {
        "id": "2024-12-13-Grounding-DINO------Object-Detection_chunk_4",
        "text": "A-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n```\n\n---\n\n## 4.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-13-Gradio------Yolov7",
    "title": "Gradio를 활용한 Yolov7 모델 서빙 웹사이트 만들기",
    "path": "/2024/12/13/Gradio를-활용한-Yolov7-모델-서빙-웹사이트-만들기/",
    "categories": [
      "AI & CV",
      "Gradio를 활용한 웹 기반 서빙",
      "MLOps"
    ],
    "content": "# Gradio를 활용한 Yolov7 모델 서빙 웹페이지 만들기\n\nML 모델을 실험하고 공유하는 데 있어서 큰 어려움은 **모델을 테스트하기 위한 환경을 구축**하는 것입니다.   \nGradio를 사용하면 몇 줄의 Python 코드만으로 **웹 기반 데모**를 빠르게 생성할 수 있습니다.\n\n이 글에서는 **Yolov7 모델**을 Gradio를 활용해 모델을 테스트하는 환경을 만들겠습니다.  \n**이미지와 비디오를 입력받아 추론 결과를 반환**하는 **웹페이지**를 만들고, 모델 파일을 유연하게 관리하는 확장 기능도 추가해보겠습니다.\n\n## 시작하기 전\n\n다음 게시글에서는 Docker를 활용한 방법을 소개합니다.  \n만약, 로컬에 설치하는 것이 부담이 된다면, Docker를 활용한 방법을 추천드립니다.\n\n> Docker로 수행할 경우, pytorch 2.0.1버전과 cuda11.7버전이 설치된 이미지를 사용합니다.\n{: .prompt-tip }\n\n---\n\n## 1. Gradio 설치\n\n먼저 Gradio 라이브러리를 설치합니다.\n\n```bash\npip install gradio==3.50.2\n```\n\n> gradio 버전 업데이트로 인해 기존 기능이 동작하지 않습니다.\n> 이를 방지하고자 3.X버전 중 가장 최신 버전을 설치합니다.\n{: .prompt-warning }\n\n---\n\n## 2. Yolov7 모델 설치\n\nGradio에서 사용할 **Yolov7 모델**을 설치합니다.  \nYolov7을 GitHub에서 다운로드합니다.\n\n```bash\ngit clone https://github.com/WongKinYiu/yolov7\n```\n\n---\n\n## 3. 필요 라이브러리 설치\n\nYolov7을 실행하기 위해 필요한 라이브러리들을 설치합니다.\n\n### PyTorch 설치\n\nPyTorch 설치는 [공식 사이트](https://pytorch.org/get-started/locally/)를 참고합니다.  \n아래는 CUDA 11.8 기반의 PyTorch 설치 예제입니다.\n\n```bash\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n```\n\n### Yolov7 requirements 설치\n\n```bash\npip install -r requirements.txt\n```\n\n### OpenCV 설치\n\nGradio와 OpenCV를 함께 사용하기 위해 다음 명령어를 실행합니다.\n\n```bash\npip install opencv-python\n```\n\n---\n\n## 4. 기본 모델 서빙 코드 (main.py)\n\n먼저, Yolov7 모델을 불러와서 **이미지와 비디오 추론**을 진행하는 Gradio 기반 웹 앱을 작성합니다.\n\n### main.py\n\n```python\nimport cv2\nimport torch\nimport gradio as gr\nfrom PIL import Image\nimport atexit\nimport os\n\n# Load Yolov7 Model\nmodel = torch.hub.load('', source='local', model='yolov7', force_reload=True)\n\n# 이미지 처리 함수\ndef yolo_image(im):\n    if im is None:\n        return None\n    results = model(im)\n    results.render()\n    return Image.fromarray(results.imgs[0])\n\n# 비디오 처리 함수\ndef yolo_video(video):\n    if video is None:\n        return None\n\n    cap = cv2.VideoCapture(video)\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    tmp_output_video = 'tmp_output.mp4'\n    output_vw = cv2.VideoWriter(tmp_output_video, fourcc, fps, (width, height))\n\n    def delete_tmp_video():\n        if os.path.exists(tmp_output_video):\n            os.remove(tmp_output_video)\n\n    atexit.register(delete_tmp_video)\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        results = model(frame)\n        results.render()\n        output_vw.write(results.imgs[0])\n\n    cap.release()\n    output_vw.release()\n    return tmp_output_video\n\n# Gradio 인터페이스\niface = gr.Interface(\n    fn=lambda img, vid, conf: (yolo_image(img), yolo_video(vid)),\n    inputs=[\"image\", \"video\", gr.Slider(0, 1, 0.25, label=\"Confidence Threshold\")],\n    outputs=[\"image\", \"video\"],\n    title=\"Yolov7 Gradio Demo\",\n    description=\"이미지와 비디오에 Yolov7 모델을 적용합니다.\"\n)\n\nif __name__ == \"__main__\":\n    iface.launch(server_name=\"0.0.0.0\", server_port=12345)\n```\n![alt text](/assets/img/Gradio/image1.png)\n**실행 방법**:  \n```bash\npython main.py\n```\n\n실행 시 **yolov7.pt**를 자동으로 설치하고, 테스트할 수 있습니다.\n\n---\n\n## 5. 확장된 모델 서빙 UI (extend_main.py)\n\n이제 사용자가 **다양한 모델을 업로드**하고 **Dropdown**에서 선택할 수 있는 확장 기능을 추가해봅니다.\n\n### 주요 추가 기능\n\n1. **모델 업로드 및 삭제**: 새로운 모델을 업로드하거나, 삭제할 수 있습니다.  \n2. **Dropdown 모델 선택**: `weights` 폴더에 저장된 모델 파일 중 하나를 선택할 수 있습니다.  \n3. **실시간 Confidence Threshold 조정**: Slider를 통해 모델의 예측 신뢰도 조정이 가능합니다.\n4. **Inference Device 선택**: Inference할 Device로 CPU, cuda0, cuda1 등 선택할 수 있습니다.\n  \n우선, **4번 기능**을 추가하기 위해, `yolov7` 폴더에 있는 `hubconf.py`를 수정합니다.\n> 이 중, 모델을 load하는 `custom` 함수를 수정하기 위함\n\n\n### hubconf.py\n```python\n\"\"\"PyTorch Hub models\n\nUsage:\n    import torch\n    model = torch.hub.load('repo', 'model')\n\"\"\"\n\nfrom pathlib import Path\n\nimport torch\n\nfrom models.yolo import Model\nfrom utils.general import check_requirements, set_logging\nfrom utils.google_utils import attempt_download\nfrom utils.torch_utils import select_device\n\ndependencies = ['torch', 'yaml']\ncheck_requirements(Path(__file__).parent / 'requirements.txt', exclude=('pycocotools', 'thop'))\nset_logging()\n\n\ndef create(name, pretrained, channels, classes, autoshape):\n    \"\"\"Creates a specified model\n\n    Arguments:\n        name (str): name of model, i.e. 'yolov7'\n        pretrained (bool): load pretrained weights into the model\n        channels (int): number of input channels\n        classes (int): number of model classes\n\n    Returns:\n        pytorch model\n    \"\"\"\n    try:\n        cfg = list((Path(__file__).parent / 'cfg').rglob(f'{name}.yaml'))[0]  # model.yaml path\n        model = Model(cfg, channels, classes)\n        if pretrained:\n            fname = f'{name}.pt'  # checkpoint filename\n            attempt_download(fname)  # download if not found locally\n            ckpt = torch.load(fname, map_location=torch.device('cpu'))  # load\n            msd = model.state_dict()  # model state_dict\n            csd = ckpt['model'].float().state_dict()  # checkpoint state_dict as FP32\n            csd = {k: v for k, v in csd.items() if msd[k].shape == v.shape}  # filter\n            model.load_state_dict(csd, strict=False)  # load\n            if len(ckpt['model'].names) == classes:\n                model.names = ckpt['model'].names  # set class names attribute\n            if autoshape:\n                model = model.autoshape()  # for file/URI/PIL/cv2/np inputs and NMS\n        device = select_device('0' if torch.cuda.is_available() else 'cpu')  # default to GPU if available\n        return model.to(device)\n\n    except Exception as e:\n        s = 'Cache maybe be out of date, try force_reload=True.'\n        raise Exception(s) from e\n\n\ndef custom(path_or_model='path/to/model.pt', autoshape=True, device=None):\n    \"\"\"custom mode\n\n    Arguments (3 options):\n        path_or_model (str): 'path/to/model.pt'\n        path_or_model (dict): torch.load('path/to/model.pt')\n        path_or_model (nn.Module): torch.load('path/to/model.pt')['model']\n\n    Returns:\n        pytorch model\n    \"\"\"\n    model = torch.load(path_or_model, map_location=torch.device('cpu')) if isinstance(path_or_model, str) else path_or_model  # load checkpoint\n    if isinstance(model, dict):\n        model = model['ema' if model.get('ema') else 'model']  # load model\n\n    hub_model = Model(model.yaml).to(next(model.parameters()).device)  # create\n    hub_model.load_state_dict(model.float().state_dict())  # load state_dict\n    hub_model.names = model.names  # class names\n    if autoshape:\n        hub_model = hub_model.autoshape()  # for file/URI/PIL/cv2/np inputs and NMS\n    # device = select_device('0' if torch.cuda.is_available() else 'cpu')  # default to GPU if available\n    device = select_device(device)\n    return hub_model.to(device)\n\n\ndef yolov7(pretrained=True, channels=3, classes=80, autoshape=True):\n    return create('yolov7', pretrained, channels, classes, autoshape)\n\n\nif __name__ == '__main__':\n    model = custom(path_or_model='yolov7.pt')  # custom example\n    # model = create(name='yolov7', pretrained=True, channels=3, classes=80, autoshape=True)  # pretrained example\n\n    # Verify inference\n    import numpy as np\n    from PIL import Image\n\n    imgs = [np.zeros((640, 480, 3))]\n\n    results = model(imgs)  # batched inference\n    results.print()\n    results.save()\n```\n\n이제, 기능을 추가한 `main.py`를 작성하겠습니다.\n\n### extend_main.py\n```python\nimport cv2\nimport torch\nimport gradio as gr\nfrom PIL import Image\nimport os\nimport atexit\nimport shutil\nfrom hubconf import custom\n\n# Event Callback Function\ndef yolo_image(im):\n    if im is None:\n        return None\n    \n    model.conf = conf\n    results = model(im)\n    results.render()\n    \n    return Image.fromarray(results.imgs[0])\n# Event Callback Function\ndef yolo_video(video):\n    if video is None:\n        return None\n    \n    # YOLO process\n    def yolo(im):\n        results = model(im)\n        results.render()\n        \n        return results.imgs[0]\n    \n    # Delete tmp Video\n    def delete_output_video():\n        if os.path.exists(tmp_output_video):\n            os.remove(tmp_output_video)\n\n    atexit.register(delete_output_video)\n\n    # Open Video\n    cap = cv2.VideoCapture(video)\n\n    # VideoWriter setting\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n    fps = int(cap.get(cv2.CAP_PROP_FPS))\n    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n    tmp_output_video = 'tmp_processed_output.mp4'\n    output_vw = cv2.VideoWriter(tmp_output_video, fourcc, fps,(width, height))\n    \n    try:\n        while(cap.isOpened()):\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            model.conf = conf\n            result = yolo(frame)\n            output_vw.write(result)\n\n    except Exception as e:\n        print(\"Error Occured: \", str(e))\n        # Delete tmp video\n        delete_output_video()\n    \n    finally:\n        cap.release()\n        output_vw.release()\n        \n        return tmp_output_video\n\ndef slider_callback(value):\n    global conf\n    conf = value\n\ndef load_model(modeldropdown, devicedropdown):\n    global model, device\n    gr.Warning(\"Wait for Load Model\")\n    if torch.cuda.is_available() is not True and devicedropdown != \"cpu\":\n        return gr.Warning(\"CUDA를 사용할 수 없습니다.\")\n    \n    scrip_dir = os.path.dirname(os.path.abspath(__file__))\n    if modeldropdown is None:\n        return dropdown.update()\n    model_path = scrip_dir + \"/weights/\" + modeldropdown\n    model = custom(model_path, device=devicedropdown)\n    \n    \n    if devicedropdown != \"cpu\":\n        model.half()\n    \n    model.conf = conf\n\n    return gr.Info(f\"Device :{next(model.parameters()).device}\")\n\ndef upload_save(file):\n    \n    file_name = os.path.basename(file.name)\n    save_path = os.path.dirname(os.path.abspath(__file__)) + \"/weights/\" + file_name\n    try:\n        shutil.copy(file.name, save_path)\n    except Exception as e:\n        print(\"Error!!\", e)\n        return uploadbtn.update(label=\"Error Occured! Press F5\")\n\n\n    updated_list = [f for f in os.listdir(\"weights\") if os.path.isfile(os.path.join(\"weights\", f))]\n    return dropdown.update(choices=updated_list)\n\ndef delete_callback(file_):\n    \n    file_path = os.path.dirname(os.path.abspath(__file__)) + \"/weights/\" + file_\n    os.remove(file_path)\n\n\n    updated_list = [f for f in os.listdir(\"weights\") if os.path.isfile(os.path.join(\"weights\", f))]\n\n    return dropdown.update(choices=updated_list, value=None)\n\n# Initial Setting\nscrip_dir = os.path.dirname(os.path.abspath(__file__))\nos.chdir(scrip_dir)\nconf = 0.25\nmodel_list = [f for f in os.listdir(\"weights\") if os.path.isfile(os.path.join(\"weights\", f))]\nmodel = None\ndevice = None\n\n# Gradio Blocks Setting\nKnowgyuBlock = gr.Blocks(theme=\"Soft\", title=\"YOLOv7-Model_Test\")\nwith KnowgyuBlock:\n    gr.Markdown('''\n                # [Gyu] Object Detection Model Test\n                ### 사용법 :\n                - 모델 선택 → 이미지(혹은 동영상) 업로드 → 'Run' 버튼 클릭\n                - 'Upload model' 버튼을 통해 모델을 추가할 수 있습니다.\n                ''')\n\n    with gr.Tab(\"Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image(label=\"Result\")\n\n        with gr.Row():\n            slider_input1 = gr.Slider(minimum=0, maximum=1, value=0.25, label=\"Confidence Threshold\", \n                                    interactive=True, container=True)\n            image_button = gr.Button(\"Run\")\n            \n            \n    with gr.Tab(\"Video\"):\n        with gr.Row():\n            video_input = gr.Video()\n            video_output = gr.Video(label=\"Result\")\n\n        with gr.Row():\n            slider_input2 = gr.Slider(minimum=0, maximum=1, value=0.25, label=\"Confidence Threshold\",\n                                    interactive=True, container=True)\n            video_button = gr.Button(\"Run\")\n\n    with gr.Row():\n        with gr.Column():\n            dropdown = gr.Dropdown(label=\"Select Model\", choices=model_list, \n                                   container=True,interactive=True)\n            devicedropdown = gr.Dropdown(label=\"Select Device\", choices=[\"cpu\",\"0\",\"1\"], value=\"0\")\n        with gr.Column():\n            uploadbtn = gr.UploadButton(label=\"Upload model\", type='file'\n                                        , file_types=[\".pt\"])\n            deletebtn = gr.Button(value=\"Delete selected model\", interactive=True)\n            \n\n    ## Event Callback Functions ##\n    ##############################\n    slider_input1.change(fn = slider_callback, inputs=slider_input1)\n    slider_input2.change(fn = slider_callback, inputs=slider_input2)\n    dropdown.change(fn = load_model, inputs = [dropdown,devicedropdown])\n    devicedropdown.change(fn = load_model, inputs = [dropdown, devicedropdown])\n    uploadbtn.upload(fn = upload_save, inputs = uploadbtn, outputs=dropdown)\n    deletebtn.click(fn = delete_callback, inputs=dropdown, outputs=dropdown)\n\n    with torch.no_grad():\n        image_button.click(yolo_image,image_input,image_output)\n        video_button.click(yolo_video,video_input,video_output)\n    \n    \n\n\n\n\nif __name__ == \"__main__\":\n\n    KnowgyuBlock.queue(max_size=10)\n    KnowgyuBlock.launch(server_name=\"0.0.0.0\", server_port=9999, show_error=True, inbrowser=True)\n\n```\n![alt text](/assets/img/Gradio/image2.png)\n\n> 우측 상단을 보면, Device를 선택하고 그 결과를 확인할 수 있습니다.\n{: .prompt-tip }\n\n---\n\n## 6. 실행 및 결과\n\n1. **main.py**를 실행하면 기본 Gradio 웹 앱이 생성되어 이미지/비디오 추론이 가능합니다.  \n2. **extend_main.py**를 실행하면 사용자가 모델을 업로드하고 선택할 수 있는 확장된 UI가 실행됩니다.  \n\n> `main.py`에 기능을 추가한 코드가 `extend_main.py`입니다.\n\n**실행 예시**:  \n```bash\npython extend_main.py\n```\n\n---\n\n## 결론\n\n이 글에서는 **Yolov7 모델**을 Gradio를 활용해 웹페이지 형태로 서빙하는 방법을 소개했습니다.  \n기본 서빙부터 **모델 업로드, 선택, Confidence 조정**까지 확장된 기능을 구현함으로써 **실험과 배포**를 손쉽게 할 수 있습니다.  \n\n다음 게시글에서는 DockerFile을 작성하고, Docker compose로 웹페이지를 배포해보겠습니다.\n",
    "date": "2024-12-13",
    "tags": [
      "MLOps",
      "Yolo",
      "Gradio",
      "Docker"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-13-Gradio------Yolov7_chunk_0",
        "text": "Gradio를 활용한 Yolov7 모델 서빙 웹사이트 만들기\n\n# Gradio를 활용한 Yolov7 모델 서빙 웹페이지 만들기\n\nML 모델을 실험하고 공유하는 데 있어서 큰 어려움은 **모델을 테스트하기 위한 환경을 구축**하는 것입니다.   \nGradio를 사용하면 몇 줄의 Python 코드만으로 **웹 기반 데모**를 빠르게 생성할 수 있습니다.\n\n이 글에서는 **Yolov7 모델**을 Gradio를 활용해 모델을 테스트하는 환경을 만들겠습니다.  \n**이미지와 비디오를 입력받아 추론 결과를 반환**하는 **웹페이지**를 만들고, 모델 파일을 유연하게 관리하는 확장 기능도 추가해보겠습니다.\n\n## 시작하기 전\n\n다음 게시글에서는 Docker를 활용한 방법을 소개합니다.  \n만약, 로컬에 설치하는 것이 부담이 된다면, Docker를 활용한 방법을 추천드립니다.\n\n> Docker로 수행할 경우, pytorch 2.0.1버전과 cuda11.7버전이 설치된 이미지를 사용합니다.\n{: .prompt-tip }\n\n---\n\n## 1. Gradio 설치\n\n먼저 Gradio 라이브러리를 설치합니다.\n\n```bash\npip install gradio==3.50.2\n```\n\n> gradio 버전 업데이트로 인해 기존 기능이 동작하지 않습니다.\n> 이를 방지하고자 3.X버전 중 가장 최신 버전을 설치합니다.\n{: .prompt-warning }\n\n---\n\n## 2. Yolov7 모델 설치\n\nGradio에서 사용할 **Yolov7 모델**을 설치합니다.",
        "index": 0
      },
      {
        "id": "2024-12-13-Gradio------Yolov7_chunk_1",
        "text": "가장 최신 버전을 설치합니다.\n{: .prompt-warning }\n\n---\n\n## 2. Yolov7 모델 설치\n\nGradio에서 사용할 **Yolov7 모델**을 설치합니다.  \nYolov7을 GitHub에서 다운로드합니다.\n\n```bash\ngit clone https://github.com/WongKinYiu/yolov7\n```\n\n---\n\n## 3. 필요 라이브러리 설치\n\nYolov7을 실행하기 위해 필요한 라이브러리들을 설치합니다.\n\n### PyTorch 설치\n\nPyTorch 설치는 [공식 사이트](https://pytorch.org/get-started/locally/)를 참고합니다.  \n아래는 CUDA 11.8 기반의 PyTorch 설치 예제입니다.\n\n```bash\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n```\n\n### Yolov7 requirements 설치\n\n```bash\npip install -r requirements.txt\n```\n\n### OpenCV 설치\n\nGradio와 OpenCV를 함께 사용하기 위해 다음 명령어를 실행합니다.\n\n```bash\npip install opencv-python\n```\n\n---\n\n## 4.",
        "index": 1
      },
      {
        "id": "2024-12-13-Gradio------Yolov7_chunk_2",
        "text": "CV 설치\n\nGradio와 OpenCV를 함께 사용하기 위해 다음 명령어를 실행합니다.\n\n```bash\npip install opencv-python\n```\n\n---\n\n## 4.",
        "index": 2
      },
      {
        "id": "2024-12-13-Gradio------Yolov7_chunk_3",
        "text": "CV 설치\n\nGradio와 OpenCV를 함께 사용하기 위해 다음 명령어를 실행합니다.\n\n```bash\npip install opencv-python\n```\n\n---\n\n## 4.",
        "index": 3
      },
      {
        "id": "2024-12-13-Gradio------Yolov7_chunk_4",
        "text": "CV 설치\n\nGradio와 OpenCV를 함께 사용하기 위해 다음 명령어를 실행합니다.\n\n```bash\npip install opencv-python\n```\n\n---\n\n## 4.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-13-Gradio",
    "title": "Gradio 시작하기",
    "path": "/2024/12/13/Gradio/",
    "categories": [
      "AI & CV",
      "Gradio를 활용한 웹 기반 서빙",
      "MLOps"
    ],
    "content": "# Gradio\n\nGradio는 몇 줄의 Python 코드만으로 **웹 기반 데모**를 구현할 수 있는 강력하고 간단한 라이브러리입니다.\n\n예를 들어, **YOLO 모델**과 같은 객체 탐지 모델을 간단하게 웹사이트 형태로 배포하고 다른 사람들과 공유하는 것이 가능해집니다. 이를 통해 **모델 성능 검증, 사용자 테스트, 시연** 등의 과정을 직관적이고 손쉽게 진행할 수 있습니다.\n\n---\n\n## Gradio의 장점?\n\n머신러닝 프로젝트의 가장 큰 어려움 중 하나는 **모델을 실제 사용자와 공유하고 시연하는 과정**입니다.  \n이때 Gradio를 사용하면 다음과 같은 이점을 얻을 수 있습니다:\n\n1. **빠른 프로토타이핑**: 복잡한 웹 개발 과정 없이 몇 줄의 코드로 웹 인터페이스를 생성합니다.  \n2. **인터랙티브한 검증**: 다양한 입력값을 활용해 실시간으로 모델 결과를 확인할 수 있습니다.  \n3. **쉬운 배포와 공유**: 생성된 웹 앱 링크를 공유하면 누구나 브라우저에서 모델을 테스트할 수 있습니다.  \n4. **개발과 시연의 일관성**: 개발자는 Python 코드만 작성하면 되므로, 개발과 배포의 흐름이 끊기지 않습니다.  \n\n---\n\n## Gradio 설치\n\n```bash\npip install gradio\n```\n\n---\n\n## Gradio 실행 예시\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!!\"\n\niface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\niface.launch()\n```\n\n---\n\n## 커스터마이징 가능한 컴포넌트\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!!\"\n\niface = gr.Interface(fn=greet, \n                     inputs=gr.inputs.Textbox(lines=2, placeholder=\"이름을 입력하세요.\"),\n                     outputs=\"text\")\niface.launch()\n```\n\n---\n\n## 다중 입출력\n\n```python\nimport gradio as gr\n\ndef greet(name, is_morning, temperature):\n    salutation = \"Good morning\" if is_morning else \"Good evening\"\n    greeting = f\"{salutation} {name}. It is {temperature} degrees today\"\n    celsius = (temperature - 32) * 5 / 9\n    return greeting, round(celsius, 2)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"checkbox\", gr.Slider(0, 100)],\n    outputs=[\"text\", \"number\"],\n)\ndemo.launch()\n```\n\n---\n\n## 이미지 작업\n\nGradio는 **Image, DataFrame, Video, Label**과 같은 다양한 유형의 구성 요소를 지원합니다.  \n이미지를 변환하는 기능을 살펴보겠습니다.\n\n```python\nimport numpy as np\nimport gradio as gr\n\ndef sepia(input_img):\n    sepia_filter = np.array([\n        [0.393, 0.769, 0.189], \n        [0.349, 0.686, 0.168], \n        [0.272, 0.534, 0.131]\n    ])\n    sepia_img = input_img.dot(sepia_filter.T)\n    sepia_img /= sepia_img.max()\n    return sepia_img\n\ndemo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\ndemo.launch()\n```\n\n**입력 설명**: 함수의 입력 이미지는 Shape(너비, 높이, 3)의 **Numpy Array** 형태이며 마지막 차원은 RGB 값을 나타냅니다.\n\n---\n\n## 블록 클래스\n\nGradio는 **인터페이스 클래스** 외에도 더 높은 자유도를 제공하는 **블록** 클래스를 지원합니다.\n\n```python\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\nwith gr.Blocks() as demo:\n    name = gr.Textbox(label=\"Name\")\n    output = gr.Textbox(label=\"Output Box\")\n    greet_btn = gr.Button(\"Greet\")\n    greet_btn.click(fn=greet, inputs=name, outputs=output)\n\ndemo.launch()\n```\n\n- **블록**은 `with` 문을 사용해 정의되며, 이 안에 생성된 모든 구성 요소는 앱에 자동으로 추가됩니다.  \n- 버튼에 **클릭 이벤트**를 추가할 수 있으며, 입력/출력 구성 요소를 연결할 수 있습니다.\n\n---\n\n## 더 높은 자유도\n\nGradio는 **탭(Tab)**과 **아코디언(Accordion)**을 활용해 다양한 인터페이스를 구성할 수 있습니다.\n\n```python\nimport numpy as np\nimport gradio as gr\n\ndef flip_text(x):\n    return x[::-1]\n\ndef flip_image(x):\n    return np.fliplr(x)\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"Flip text or image files using this demo.\")\n    with gr.Tab(\"Flip Text\"):\n        text_input = gr.Textbox()\n        text_output = gr.Textbox()\n        text_button = gr.Button(\"Flip\")\n    with gr.Tab(\"Flip Image\"):\n        with gr.Row():\n            image_input = gr.Image()\n            image_output = gr.Image()\n        image_button = gr.Button(\"Flip\")\n\n    with gr.Accordion(\"Open for More!\"):\n        gr.Markdown(\"Look at me...\")\n\n    text_button.click(flip_text, inputs=text_input, outputs=text_output)\n    image_button.click(flip_image, inputs=image_input, outputs=image_output)\n\ndemo.launch()\n```\n\n---\n\n## Flagging\n\n출력 인터페이스 아래의 **Flag 버튼**을 통해 테스트 시 발견된 이슈를 기록할 수 있습니다.\n\n```python\niface = gr.Interface(fn=classify_image, inputs=\"image\", outputs=\"label\", flagging_dir=\"flagged_data\")\niface.launch()\n```\n\n- **`flagging_dir`**에 설정된 경로에 플래그된 데이터가 CSV 파일로 저장됩니다.\n\n---\n\n## 인터페이스 공유\n\n`launch()` 메서드에서 `share=True`를 설정하면 공개 링크가 자동으로 생성됩니다.\n\n```python\ngr.Interface(classify_image, \"image\", \"label\").launch(share=True)\n```\n\n- Colab 노트북에서는 **공유 링크**가 자동 생성됩니다.  \n- **`share=False`**(기본값): 로컬 링크만 생성되며 특정 사용자에게만 접근이 가능합니다.\n\n---\n\n## 인증 (Authentication)\n\n인증 페이지를 추가해 접근을 제한할 수 있습니다.\n\n```python\niface.launch(auth=[(\"username\", \"password\")])\n```\n\n---\n",
    "date": "2024-12-13",
    "tags": [
      "MLOps",
      "Yolo",
      "Gradio"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-13-Gradio_chunk_0",
        "text": "Gradio 시작하기\n\n# Gradio\n\nGradio는 몇 줄의 Python 코드만으로 **웹 기반 데모**를 구현할 수 있는 강력하고 간단한 라이브러리입니다.\n\n예를 들어, **YOLO 모델**과 같은 객체 탐지 모델을 간단하게 웹사이트 형태로 배포하고 다른 사람들과 공유하는 것이 가능해집니다. 이를 통해 **모델 성능 검증, 사용자 테스트, 시연** 등의 과정을 직관적이고 손쉽게 진행할 수 있습니다.\n\n---\n\n## Gradio의 장점?\n\n머신러닝 프로젝트의 가장 큰 어려움 중 하나는 **모델을 실제 사용자와 공유하고 시연하는 과정**입니다.  \n이때 Gradio를 사용하면 다음과 같은 이점을 얻을 수 있습니다:\n\n1. **빠른 프로토타이핑**: 복잡한 웹 개발 과정 없이 몇 줄의 코드로 웹 인터페이스를 생성합니다.  \n2. **인터랙티브한 검증**: 다양한 입력값을 활용해 실시간으로 모델 결과를 확인할 수 있습니다.  \n3. **쉬운 배포와 공유**: 생성된 웹 앱 링크를 공유하면 누구나 브라우저에서 모델을 테스트할 수 있습니다.  \n4. **개발과 시연의 일관성**: 개발자는 Python 코드만 작성하면 되므로, 개발과 배포의 흐름이 끊기지 않습니다.",
        "index": 0
      },
      {
        "id": "2024-12-13-Gradio_chunk_1",
        "text": "면 누구나 브라우저에서 모델을 테스트할 수 있습니다.  \n4. **개발과 시연의 일관성**: 개발자는 Python 코드만 작성하면 되므로, 개발과 배포의 흐름이 끊기지 않습니다.",
        "index": 1
      },
      {
        "id": "2024-12-13-Gradio_chunk_2",
        "text": "면 누구나 브라우저에서 모델을 테스트할 수 있습니다.  \n4. **개발과 시연의 일관성**: 개발자는 Python 코드만 작성하면 되므로, 개발과 배포의 흐름이 끊기지 않습니다.",
        "index": 2
      },
      {
        "id": "2024-12-13-Gradio_chunk_3",
        "text": "면 누구나 브라우저에서 모델을 테스트할 수 있습니다.  \n4. **개발과 시연의 일관성**: 개발자는 Python 코드만 작성하면 되므로, 개발과 배포의 흐름이 끊기지 않습니다.",
        "index": 3
      },
      {
        "id": "2024-12-13-Gradio_chunk_4",
        "text": "면 누구나 브라우저에서 모델을 테스트할 수 있습니다.  \n4. **개발과 시연의 일관성**: 개발자는 Python 코드만 작성하면 되므로, 개발과 배포의 흐름이 끊기지 않습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-13-Docker------Gradio-Yolov7",
    "title": "Docker를 이용해 Gradio Yolov7모델 서빙 웹사이트 만들기",
    "path": "/2024/12/13/Docker를-이용해-Gradio-Yolov7모델-서빙-웹사이트-만들기/",
    "categories": [
      "AI & CV",
      "Gradio를 활용한 웹 기반 서빙",
      "MLOps"
    ],
    "content": "# Docker를 활용한 Gradio 기반 YOLOv7 서빙 배포\n\n이전 글에서는 Gradio를 활용해 YOLOv7 모델을 웹페이지 형태로 서빙하는 방법을 알아보았습니다.  \n이번 글에서는 **Docker**를 활용해 환경을 패키징하고, 더 간편하게 배포하는 방법을 설명합니다.  \n\nDocker를 활용하면 **로컬 환경의 의존성 문제**를 해결할 수 있고, **GPU**와 같은 하드웨어 리소스도 손쉽게 설정할 수 있습니다.\n\n> 단, 이 게시글에서 사용하는 이미지의 경우 약 14GB 정도의 용량을 사용합니다.  \n> 만약, 로컬에 CUDA가 설치되어 있고, 용량이 부족한 환경에서는 잘 고려해보시길 바랍니다!\n{: .prompt-warning }\n\n---\n\n## 프로젝트 구조\n\n먼저 프로젝트의 기본 디렉토리 구조를 확인해봅시다.\n\n```plaintext\n├── Dockerfile\n├── README.md\n├── docker-compose.yml\n├── hubconf.py\n├── main.py\n├── models/\n├── requirements.txt\n└── utils/\n```\n### Github Repo\n[https://github.com/knowgyu/gradio-yolov7](https://github.com/knowgyu/gradio-yolov7)\n\n---\n\n## Dockerfile: 컨테이너 환경 설정\n\n**Dockerfile**은 컨테이너 이미지를 정의하는 파일입니다.  \nPyTorch와 CUDA를 기반으로 필요한 라이브러리와 Python 환경을 설정합니다.\n\n### Dockerfile 내용\n\n```dockerfile\nFROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel\n\n# 패키지 설치 및 기본 설정\nRUN apt-get update -y && apt-get install -y --no-install-recommends \\\n    vim \\\n    wget \\\n    curl \\\n    libglib2.0-0 \\\n    libgl1-mesa-glx \\  # OpenCV 의존성\n    libsm6 \\          \n    libxext6 \\        \n    libxrender1 \\     \n    python3-pip \\\n    language-pack-ko \\\n    && rm -rf /var/lib/apt/lists/*\n\n# 타임존 설정\nENV TZ=Asia/Seoul\nRUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime\n\n# Python 라이브러리 설치\nCOPY requirements.txt /tmp/\nRUN pip install --no-cache-dir -r /tmp/requirements.txt\n\n# 작업 디렉토리 설정\nWORKDIR /gradio\n\n# 컨테이너 시작 시 기본 명령어\nCMD [\"python\", \"main.py\"]\n```\n\n### 코드 설명\n1. **PyTorch 이미지**: `pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel`를 사용하여 GPU와 CUDA 환경을 설정합니다.  \n   - GPU가 필요 없다면 `pytorch/pytorch:2.0.1-cpu-py310` 이미지로 대체할 수 있습니다.  \n2. **필요 패키지 설치**: `libgl1-mesa-glx`와 같은 OpenCV 의존성 라이브러리를 설치합니다.  \n3. **Python 라이브러리**: `requirements.txt`에 명시된 패키지를 설치합니다.  \n4. **기본 작업 디렉토리**: `/gradio`를 설정하고, 이곳에서 `main.py`를 실행합니다.\n\n---\n\n## docker-compose.yml: 컨테이너 실행 설정\n\n**docker-compose.yml**은 Docker 컨테이너를 실행하고 설정을 관리하는 파일입니다.\n\n### docker-compose.yml 내용\n\n```yaml\nversion: \"3\"\n\nservices:\n  gradio_v1:\n    build: .  # 현재 디렉토리의 Dockerfile 사용\n    container_name: gradio_yolov7\n    runtime: nvidia  # GPU 사용 설정 (필요 없으면 제거 가능)\n    volumes:\n      - .:/gradio  # 로컬 폴더를 컨테이너와 공유\n    ports:\n      - \"9999:9999\"  # 호스트와 컨테이너의 포트를 매핑\n    tty: true\n    restart: always\n    command: python main.py  # 컨테이너 시작 시 실행할 명령어\n```\n\n### 코드 설명\n1. **GPU 설정**: `runtime: nvidia`를 통해 GPU를 사용할 수 있도록 설정합니다.  \n   - **CPU만 사용하려면** 이 옵션을 제거하면 됩니다.  \n2. **볼륨 마운트**: `- .:/gradio`를 통해 로컬 프로젝트 폴더를 컨테이너에 연결합니다.  \n3. **포트 매핑**: `9999:9999`를 통해 컨테이너의 Gradio 웹 서버에 접근할 수 있습니다.  \n   - 포트를 바꾸고 싶다면 `8080:9999`와 같이 수정합니다.  \n4. **재시작 설정**: `restart: always`는 컨테이너가 종료되더라도 자동으로 재시작합니다.\n\n---\n\n## requirements.txt: Python 라이브러리\n\n`requirements.txt`에는 Gradio와 YOLOv7 모델 실행에 필요한 패키지들이 나열되어 있습니다.\n\n```plaintext\ngradio==3.50.2\nopencv-python>=4.1.2\nscipy\nseaborn>=0.11.0\ntorch>=1.7.0\ntorchvision>=0.8.1\n```\n\n> PyTorch와 Gradio 버전이 맞지 않을 경우, 필요에 따라 버전을 조정할 수 있습니다.\n\n---\n\n## 실행 방법\n\n### 1. Docker 이미지 빌드\n다음 명령어를 통해 Docker 이미지를 빌드합니다.\n\n```bash\ndocker compose build\n```\n\n### 2. 컨테이너 실행\nDocker Compose를 통해 컨테이너를 실행합니다.\n\n```bash\ndocker compose up\n```\n\n### 3. 백그라운드 실행\n`-d` 옵션을 추가하면 백그라운드에서 실행됩니다.\n\n```bash\ndocker compose up -d\n```\n\n### 4. 컨테이너 종료\n실행 중인 컨테이너를 종료하려면 다음 명령어를 사용합니다.\n\n```bash\ndocker compose down\n```\n\n---\n\n## 시연 영상\n\n아래는 Docker를 활용해 YOLOv7 모델을 서빙하는 시연 영상입니다.\n\n<iframe width=\"840\" height=\"473\" src=\"https://www.youtube-nocookie.com/embed/87pI8rkKzoA?si=r-licJ3JNZrOPzb9\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n---\n\n## 결론\n\n이 글에서는 **Docker**를 활용해 Gradio 기반의 **YOLOv7 모델 서빙 환경**을 배포하는 방법을 설명했습니다.  \n- Dockerfile과 Compose를 사용해 **환경 설정과 실행을 자동화**할 수 있습니다.  \n- GPU/CPU에 따라 유연하게 설정을 변경할 수 있습니다.  \n",
    "date": "2024-12-13",
    "tags": [
      "MLOps",
      "Yolo",
      "Gradio",
      "Docker"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-13-Docker------Gradio-Yolov7_chunk_0",
        "text": "Docker를 이용해 Gradio Yolov7모델 서빙 웹사이트 만들기\n\n# Docker를 활용한 Gradio 기반 YOLOv7 서빙 배포\n\n이전 글에서는 Gradio를 활용해 YOLOv7 모델을 웹페이지 형태로 서빙하는 방법을 알아보았습니다.  \n이번 글에서는 **Docker**를 활용해 환경을 패키징하고, 더 간편하게 배포하는 방법을 설명합니다.  \n\nDocker를 활용하면 **로컬 환경의 의존성 문제**를 해결할 수 있고, **GPU**와 같은 하드웨어 리소스도 손쉽게 설정할 수 있습니다.\n\n> 단, 이 게시글에서 사용하는 이미지의 경우 약 14GB 정도의 용량을 사용합니다.  \n> 만약, 로컬에 CUDA가 설치되어 있고, 용량이 부족한 환경에서는 잘 고려해보시길 바랍니다!\n{: .prompt-warning }\n\n---\n\n## 프로젝트 구조\n\n먼저 프로젝트의 기본 디렉토리 구조를 확인해봅시다.\n\n```plaintext\n├── Dockerfile\n├── README.md\n├── docker-compose.yml\n├── hubconf.py\n├── main.py\n├── models/\n├── requirements.txt\n└── utils/\n```\n### Github Repo\n[https://github.com/knowgyu/gradio-yolov7](https://github.com/knowgyu/gradio-yolov7)\n\n---\n\n## Dockerfile: 컨테이너 환경 설정\n\n**Dockerfile**은 컨테이너 이미지를 정의하는 파일입니다.",
        "index": 0
      },
      {
        "id": "2024-12-13-Docker------Gradio-Yolov7_chunk_1",
        "text": "b.com/knowgyu/gradio-yolov7)\n\n---\n\n## Dockerfile: 컨테이너 환경 설정\n\n**Dockerfile**은 컨테이너 이미지를 정의하는 파일입니다.",
        "index": 1
      },
      {
        "id": "2024-12-13-Docker------Gradio-Yolov7_chunk_2",
        "text": "b.com/knowgyu/gradio-yolov7)\n\n---\n\n## Dockerfile: 컨테이너 환경 설정\n\n**Dockerfile**은 컨테이너 이미지를 정의하는 파일입니다.",
        "index": 2
      },
      {
        "id": "2024-12-13-Docker------Gradio-Yolov7_chunk_3",
        "text": "b.com/knowgyu/gradio-yolov7)\n\n---\n\n## Dockerfile: 컨테이너 환경 설정\n\n**Dockerfile**은 컨테이너 이미지를 정의하는 파일입니다.",
        "index": 3
      },
      {
        "id": "2024-12-13-Docker------Gradio-Yolov7_chunk_4",
        "text": "b.com/knowgyu/gradio-yolov7)\n\n---\n\n## Dockerfile: 컨테이너 환경 설정\n\n**Dockerfile**은 컨테이너 이미지를 정의하는 파일입니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-12",
    "title": "스택 자료구조",
    "path": "/2024/12/12/스택/",
    "categories": [
      "Computer Science",
      "Algorithm & Data structure",
      "Computer_Science/Algorithm_Theory"
    ],
    "content": "# 스택 개념\n\n스택의 어원은 **“쌓는다”**입니다.  \n스택은 **LIFO (Last In First Out, 후입선출)** 방식으로 동작하는 자료구조입니다.\n\n---\n\n# 스택의 정의\n\n스택은 **추상 자료형(ADT: Abstract Data Type)**으로 정의됩니다.  \n추상 자료형이란 **인터페이스만 존재하고, 구현은 정의되지 않은 자료형**을 의미합니다. 마치 설계도와 같습니다.\n\n**C++ STL**은 스택을 표준 라이브러리로 제공하여 편리하게 사용할 수 있습니다.\n\n---\n\n## 스택의 ADT\n\n스택을 정의하기 위해 **Push, Pop, isFull, isEmpty**와 같은 연산을 사용합니다.  \n또한, 스택에는 **Top**이라는 변수가 있어 **최근에 삽입된 데이터의 위치**를 기록합니다.\n\n| 구분     | 정의                       | 설명                                                             |\n| -------- | -------------------------- | ---------------------------------------------------------------- |\n| **연산** | `boolean isFull()`         | 스택에 들어있는 데이터의 개수가 `maxsize`인지 확인해 `bool` 반환 |\n|          | `boolean isEmpty()`        | 스택에 데이터가 하나도 없는지 확인해 `bool` 반환                 |\n|          | `void push(ItemType item)` | 스택에 데이터를 푸시                                             |\n|          | `ItemType pop()`           | 스택에서 최근에 푸시된 데이터를 팝하고 반환                      |\n| **상태** | `int top`                  | 스택의 최근 푸시된 데이터 위치를 기록                            |\n|          | `ItemType data[maxsize]`   | 스택 데이터를 관리하는 배열 (최대 `maxsize` 개)                  |\n\n---\n\n> 자료구조의 세부 동작을 이해하면 코딩 테스트뿐만 아니라 면접에도 큰 도움이 됩니다.  \n> 자료구조의 성능 및 특성을 파악하면 효율적인 알고리즘을 떠올릴 수 있습니다.  \n{: .prompt-tip }\n\n---\n\n## 스택 세부 동작\n\n### **스택에 데이터를 추가하는 상황 (push 연산)**\n\n`push(3)` 연산으로 데이터 `3`이 추가되는 과정:\n\n1. `isFull()`을 수행해 스택이 가득 차 있는지 확인합니다.  \n2. 스택이 가득 차지 않았다면, `top`을 1만큼 증가시킵니다.  \n   - 초기값: `-1 → 0`  \n3. `top`이 가리키는 위치에 데이터를 추가합니다.  \n   - 예: `data[0] = 3`\n\n### **스택에서 데이터를 인출하는 상황 (pop 연산)**\n\n`pop()` 연산으로 데이터를 인출하는 과정:\n\n1. `isEmpty()`를 수행해 스택이 비어 있는지 확인합니다.  \n2. 스택이 비어 있지 않다면, 데이터를 반환하고 `top`을 1만큼 감소시킵니다.  \n3. 데이터는 물리적으로 남아 있지만, `top`이 이동하므로 스택은 비어 있는 것으로 간주됩니다.\n\n> **참고**  \n> 데이터가 스택에서 삭제되더라도 메모리상에는 남아있을 수 있습니다.  \n> 하지만 `top`이 가리키는 위치가 바뀌므로 **스택은 비어 있다**고 해석됩니다.  \n{: .prompt-info }\n\n---\n\n## 스택 구현하기\n\n코딩 테스트에서는 **문제에 맞는 자료구조**를 빠르게 파악하는 것이 중요합니다.\n\n- 데이터를 **순서와 상관없이 저장**하고 임의 접근만 하면 된다면? → **배열**  \n- **최근 삽입한 데이터를 대상으로 연산**해야 한다면? → **스택**\n\n---\n\n### 예시 코드: C++ STL 스택 활용\n\n```cpp\n#include <iostream>\n#include <stack>\n\nusing namespace std;\n\nint main() {\n    stack<int> st;\n\n    // push(): 요소를 스택의 맨 위에 추가. 시간 복잡도 O(1)\n    st.push(10);\n    st.push(20);\n    st.push(30);\n\n    // 스택의 모든 요소 출력 및 제거\n    while (!st.empty()) { // 스택이 비어있지 않은 동안\n        cout << st.top() << \" \"; // 스택의 맨 위 요소 출력\n        st.pop();                // 출력된 요소를 스택에서 제거\n    }\n\n    // 출력값: 30 20 10\n    return 0;\n}\n```\n\n---\n\n### STL 스택의 주요 함수\n\n1. **`push(item)`**: 데이터를 스택에 추가합니다.  \n2. **`top()`**: 스택의 맨 위 데이터를 반환합니다.  \n3. **`pop()`**: 스택의 맨 위 데이터를 제거하지만 반환하지 않습니다.  \n4. **`empty()`**: 스택이 비어 있는지를 확인합니다.\n\n---\n\n> C++ STL의 `pop()` 함수는 데이터를 반환하지 않고 삭제만 수행합니다.  \n> 따라서 데이터를 확인하려면 `top()`을 먼저 사용해야 합니다.  \n{: .prompt-tip }\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-12-12",
    "tags": [
      "Algorithm",
      "DataStructure"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-12_chunk_0",
        "text": "스택 자료구조\n\n# 스택 개념\n\n스택의 어원은 **“쌓는다”**입니다.  \n스택은 **LIFO (Last In First Out, 후입선출)** 방식으로 동작하는 자료구조입니다.\n\n---\n\n# 스택의 정의\n\n스택은 **추상 자료형(ADT: Abstract Data Type)**으로 정의됩니다.  \n추상 자료형이란 **인터페이스만 존재하고, 구현은 정의되지 않은 자료형**을 의미합니다. 마치 설계도와 같습니다.\n\n**C++ STL**은 스택을 표준 라이브러리로 제공하여 편리하게 사용할 수 있습니다.\n\n---\n\n## 스택의 ADT\n\n스택을 정의하기 위해 **Push, Pop, isFull, isEmpty**와 같은 연산을 사용합니다.",
        "index": 0
      },
      {
        "id": "2024-12-12_chunk_1",
        "text": "로 제공하여 편리하게 사용할 수 있습니다.\n\n---\n\n## 스택의 ADT\n\n스택을 정의하기 위해 **Push, Pop, isFull, isEmpty**와 같은 연산을 사용합니다.",
        "index": 1
      },
      {
        "id": "2024-12-12_chunk_2",
        "text": "로 제공하여 편리하게 사용할 수 있습니다.\n\n---\n\n## 스택의 ADT\n\n스택을 정의하기 위해 **Push, Pop, isFull, isEmpty**와 같은 연산을 사용합니다.",
        "index": 2
      },
      {
        "id": "2024-12-12_chunk_3",
        "text": "로 제공하여 편리하게 사용할 수 있습니다.\n\n---\n\n## 스택의 ADT\n\n스택을 정의하기 위해 **Push, Pop, isFull, isEmpty**와 같은 연산을 사용합니다.",
        "index": 3
      },
      {
        "id": "2024-12-12_chunk_4",
        "text": "로 제공하여 편리하게 사용할 수 있습니다.\n\n---\n\n## 스택의 ADT\n\n스택을 정의하기 위해 **Push, Pop, isFull, isEmpty**와 같은 연산을 사용합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-12",
    "title": "배열 자료구조",
    "path": "/2024/12/12/배열/",
    "categories": [
      "Computer Science",
      "Algorithm & Data structure",
      "Computer_Science/Algorithm_Theory"
    ],
    "content": "# 배열 개념\n\n배열은 같은 타입의 원소를 효율적으로 관리할 수 있는 **기본 자료형**입니다.\n\n## 배열 선언\n\n`int a`와 비슷하게 `int a[10]` 과 같이 **배열의 크기**를 명시합니다.\n\n- **예시 코드**:\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n    int arr1[] = {1, 2, 3, 4, 5}; // 크기는 5로 자동 설정\n    int arr2[5] = {1, 2};         // 1, 2, 0, 0, 0\n    int arr3[5] = {};             // 0, 0, 0, 0, 0\n    int arr4[5];                  // 5개의 쓰레기값\n}\n```\n\n---\n\n## 배열과 차원\n\n배열은 2차원, 3차원 배열과 같이 다차원 배열을 확장해서 사용할 수 있습니다.  \n하지만 **컴퓨터 메모리 구조는 1차원**이므로, 다차원 배열도 실제로는 1차원 공간에 저장됩니다.\n\n### 배열의 접근 및 제어\n\n배열로 선언된 변수들은 **메모리의 연속된 공간**에 할당됩니다.  \n따라서 배열 원소 간 주소값은 **변수의 크기**만큼 차이가 발생합니다.\n\n- **예시 코드**:\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n    int intArray[3] = {1, 2, 3};\n    double doubleArray[3] = {1.1, 2.2, 3.3};\n    char charArray[3] = {'a', 'b', 'c'};\n    \n    // int는 4바이트 간격\n    cout << &intArray[0] << endl; // 0x...c0\n    cout << &intArray[1] << endl; // 0x...c4\n    cout << &intArray[2] << endl; // 0x...c8\n    \n    // double은 8바이트 간격\n    cout << &doubleArray[0] << endl; // 0x...b0\n    cout << &doubleArray[1] << endl; // 0x...b8\n    cout << &doubleArray[2] << endl; // 0x...c0\n    \n    // char은 1바이트 간격\n    cout << &charArray[0] << endl; // 0x...af\n    cout << &charArray[1] << endl; // 0x...b0\n    cout << &charArray[2] << endl; // 0x...b1\n}\n```\n\n---\n\n### 2차원 배열\n\n2차원 배열은 **1차원 배열을 확장한 형태**입니다.\n\n- **예시 코드**:\n{% raw %}\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n    int arr[3][4] = {{1, 2, 3, 4}, {5, 6, 7, 8}, {9, 10, 11, 12}};\n    \n    cout << arr[2][3] << endl; // 12\n    arr[2][3] = 15;\n    cout << arr[2][3] << endl; // 15\n}\n```\n{% endraw %}\n2차원 배열은 **행(row)**과 **열(column)**로 나타내지만, 본질적으로 **1차원 메모리 공간**에 저장됩니다.\n\n---\n\n# 배열의 효율성\n\n## 배열 연산의 시간 복잡도\n\n배열은 **임의 접근(Random Access)**이 가능하기 때문에 **모든 위치**에 있는 데이터에 한 번에 접근할 수 있습니다.  \n→ **시간 복잡도: O(1)**\n\n하지만 **삽입**과 **삭제**의 경우에는 위치에 따라 시간 복잡도가 다릅니다.\n\n- **맨 뒤에 삽입**: O(1)\n- **맨 앞에 삽입**: O(N)  \n  → 기존 데이터를 한 칸씩 뒤로 미는 작업이 필요\n- **중간에 삽입**: O(N)  \n  → 삽입 위치 뒤의 데이터 개수만큼 이동 작업 필요\n\n---\n\n## 배열 선택 시 고려할 점\n\n배열을 사용할 때 **효율성**을 고려해야 합니다:\n\n1. **자주 접근하고 읽어야 하는 경우**  \n   배열은 좋은 성능을 제공합니다.\n   \n2. **메모리 공간 확보**  \n   배열은 선언 시 메모리를 **연속적으로 할당**해야 합니다.  \n   따라서 충분한 메모리 공간이 확보되어야 합니다.\n\n3. **중간 삽입/삭제 여부**  \n   중간에 삽입/삭제가 많다면 배열보다 **연결 리스트**가 효율적일 수 있습니다.\n\n---\n\n> **참고**: 배열은 기본 자료구조로서 성능과 메모리 관리가 중요한 경우에 자주 사용됩니다.\n{: .prompt-info }\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-12-12",
    "tags": [
      "Algorithm",
      "DataStructure"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-12_chunk_0",
        "text": "배열 자료구조\n\n# 배열 개념\n\n배열은 같은 타입의 원소를 효율적으로 관리할 수 있는 **기본 자료형**입니다.\n\n## 배열 선언\n\n`int a`와 비슷하게 `int a[10]` 과 같이 **배열의 크기**를 명시합니다.\n\n- **예시 코드**:\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main() {\n    int arr1[] = {1, 2, 3, 4, 5}; // 크기는 5로 자동 설정\n    int arr2[5] = {1, 2};         // 1, 2, 0, 0, 0\n    int arr3[5] = {};             // 0, 0, 0, 0, 0\n    int arr4[5];                  // 5개의 쓰레기값\n}\n```\n\n---\n\n## 배열과 차원\n\n배열은 2차원, 3차원 배열과 같이 다차원 배열을 확장해서 사용할 수 있습니다.  \n하지만 **컴퓨터 메모리 구조는 1차원**이므로, 다차원 배열도 실제로는 1차원 공간에 저장됩니다.\n\n### 배열의 접근 및 제어\n\n배열로 선언된 변수들은 **메모리의 연속된 공간**에 할당됩니다.",
        "index": 0
      },
      {
        "id": "2024-12-12_chunk_1",
        "text": "모리 구조는 1차원**이므로, 다차원 배열도 실제로는 1차원 공간에 저장됩니다.\n\n### 배열의 접근 및 제어\n\n배열로 선언된 변수들은 **메모리의 연속된 공간**에 할당됩니다.",
        "index": 1
      },
      {
        "id": "2024-12-12_chunk_2",
        "text": "모리 구조는 1차원**이므로, 다차원 배열도 실제로는 1차원 공간에 저장됩니다.\n\n### 배열의 접근 및 제어\n\n배열로 선언된 변수들은 **메모리의 연속된 공간**에 할당됩니다.",
        "index": 2
      },
      {
        "id": "2024-12-12_chunk_3",
        "text": "모리 구조는 1차원**이므로, 다차원 배열도 실제로는 1차원 공간에 저장됩니다.\n\n### 배열의 접근 및 제어\n\n배열로 선언된 변수들은 **메모리의 연속된 공간**에 할당됩니다.",
        "index": 3
      },
      {
        "id": "2024-12-12_chunk_4",
        "text": "모리 구조는 1차원**이므로, 다차원 배열도 실제로는 1차원 공간에 저장됩니다.\n\n### 배열의 접근 및 제어\n\n배열로 선언된 변수들은 **메모리의 연속된 공간**에 할당됩니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-12",
    "title": "해시 자료구조",
    "path": "/2024/12/12/해시/",
    "categories": [
      "Computer Science",
      "Algorithm & Data structure",
      "Computer_Science/Algorithm_Theory"
    ],
    "content": "# 해시 개념\n\n해시는 데이터를 효율적으로 저장하고 탐색하기 위해 **해시 함수**를 사용해 데이터를 **키-값**으로 관리하는 자료구조입니다.  \n\n---\n\n## 해시의 기본 원리\n\n데이터를 탐색할 때 **순차 탐색**의 경우 최악의 상황에서 모든 데이터를 살펴야 하기 때문에 비효율적입니다.  \n하지만 **해시 함수**를 이용해 데이터가 저장될 위치(인덱스)를 미리 정하면 **O(1)**의 시간 복잡도로 데이터를 탐색할 수 있습니다.\n\n**해시(Hash)**: 키를 해시 함수로 변환해 나온 **해시값(인덱스)**에 데이터를 저장하는 자료구조입니다.\n\n---\n\n## 해시의 특징\n\n1. **단방향**으로 동작  \n   - 키를 통해 값을 찾을 수 있지만, 그 반대는 불가능합니다.  \n2. **탐색 속도 O(1)**  \n   - 해시 함수로 키를 해시값으로 변환하기 때문에 탐색 과정이 필요 없습니다.  \n3. **적절한 해시 함수가 중요**  \n   - 키를 인덱스로 변환하는 과정에서 충돌이 최소화되어야 합니다.\n\n---\n\n## 해시 테이블과 버킷\n\n- **해시 테이블**: 키와 값이 저장되는 데이터 공간입니다.  \n- **버킷**: 해시 테이블 내의 각 데이터 저장 공간입니다.\n\n---\n\n## 해시의 활용 분야\n\n해시는 **단방향 검색**과 **빠른 탐색**이 필요한 분야에 활용됩니다.  \n\n- **비밀번호 관리**  \n- **데이터베이스 인덱싱**  \n- **블록체인**  \n\n코딩 테스트에서도 **데이터 탐색**의 효율성이 중요한 경우 해시를 고려해야 합니다.\n\n---\n\n# 해시 함수\n\n해시 함수는 **키를 특정 범위 내의 값(해시값)**으로 변환하는 역할을 합니다.\n\n---\n\n## 해시 함수를 구현할 때 고려할 내용\n\n1. **해시값은 해시 테이블의 크기 내에서 결정되어야 합니다.**  \n   예: `N`개의 데이터를 저장하려면 해시값은 `0 ~ N-1` 범위여야 합니다.  \n\n2. **충돌(Collision)은 최소화해야 합니다.**  \n   - **충돌**: 서로 다른 키가 같은 해시값을 가지는 경우를 의미합니다.  \n   - 완벽한 해시 함수는 없지만, 충돌이 적게 발생하도록 설계해야 합니다.\n\n---\n\n## 자주 사용하는 해시 함수\n\n### 1. 나눗셈법 (Division Method)\n\n가장 단순하고 직관적인 방법입니다. 키를 소수로 나눈 나머지를 해시값으로 사용합니다.\n\n**공식**:  \n$$\nh(x) = x \\mod k\n$$\n\n- $$ x $$ : 키  \n- $$ k $$ : 소수 (해시 테이블 크기)  \n\n**소수를 사용하는 이유**:  \n소수가 아닌 값을 사용하면 특정 키에 대해 충돌이 많이 발생할 수 있습니다.\n\n---\n\n### 2. 곱셈법 (Multiplication Method)\n\n곱셈법은 큰 소수를 구해야 하는 나눗셈법의 단점을 보완합니다.\n\n**공식**:  \n$$\nh(x) = \\lfloor ((x \\cdot A) \\mod 1) \\cdot m \\rfloor\n$$\n\n- $$ m $$ : 해시 테이블 크기  \n- $$ A $$ : 상수 (황금비 \\( \\approx 0.6180339887 \\))  \n\n---\n\n### 3. 문자열 해싱\n\n문자열을 해싱하기 위해 **문자를 숫자로 변환**한 뒤 다항식을 활용합니다.\n\n**Polynomial Rolling Method**:  \n$$\n\\text{hash}(s) = (s[0] + s[1] \\cdot p + s[2] \\cdot p^2 + \\dots + s[n-1] \\cdot p^{n-1}) \\mod m\n$$\n\n- $$ p $$ : 31 (메르센 소수)  \n- $$ m $$ : 해시 테이블 크기  \n\n**오버플로우 방지**:  \n덧셈 연산 중간에 모듈러 연산을 수행합니다.  \n$$\n(a + b) \\% c = (a \\% c + b \\% c) \\% c\n$$\n\n---\n\n# 충돌 처리\n\n서로 다른 키가 같은 해시값을 가지면 **충돌**이 발생합니다. 이를 해결하기 위해 **체이닝**과 **개방 주소법**을 사용합니다.\n\n---\n\n## 체이닝 (Chaining)\n\n충돌이 발생하면 해당 버킷에 **링크드 리스트**를 사용해 데이터를 연결합니다.\n\n---\n\n## 개방 주소법 (Open Addressing)\n\n충돌 시 **빈 버킷**을 찾아 데이터를 저장합니다.\n\n### 선형 탐사 (Linear Probing)\n\n충돌이 발생하면 **일정 간격**으로 이동하며 빈 버킷을 찾습니다. 보통 간격은 1입니다.\n\n**공식**:  \n$$\nh(k, i) = (h(k) + i) \\mod m\n$$\n\n---\n\n### 이중 해싱 (Double Hashing)\n\n충돌이 발생하면 **두 번째 해시 함수**를 사용해 이동 간격을 결정합니다.\n\n**공식**:  \n$$\nh(k, i) = (h_1(k) + i \\cdot h_2(k)) \\mod m\n$$\n\n---\n\n# 핵심 정리\n\n1. **해시**는 키를 해시 함수로 변환해 데이터를 저장하고 빠르게 탐색하는 자료구조입니다.  \n2. **충돌 처리**는 체이닝과 개방 주소법(선형 탐사, 이중 해싱)으로 해결합니다.  \n3. 코딩 테스트에서는 **키와 값을 매핑**하는 과정이 해시 문제의 핵심입니다.\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-12-12",
    "tags": [
      "Algorithm",
      "DataStructure"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-12_chunk_0",
        "text": "해시 자료구조\n\n# 해시 개념\n\n해시는 데이터를 효율적으로 저장하고 탐색하기 위해 **해시 함수**를 사용해 데이터를 **키-값**으로 관리하는 자료구조입니다.  \n\n---\n\n## 해시의 기본 원리\n\n데이터를 탐색할 때 **순차 탐색**의 경우 최악의 상황에서 모든 데이터를 살펴야 하기 때문에 비효율적입니다.  \n하지만 **해시 함수**를 이용해 데이터가 저장될 위치(인덱스)를 미리 정하면 **O(1)**의 시간 복잡도로 데이터를 탐색할 수 있습니다.\n\n**해시(Hash)**: 키를 해시 함수로 변환해 나온 **해시값(인덱스)**에 데이터를 저장하는 자료구조입니다.\n\n---\n\n## 해시의 특징\n\n1. **단방향**으로 동작  \n   - 키를 통해 값을 찾을 수 있지만, 그 반대는 불가능합니다.  \n2. **탐색 속도 O(1)**  \n   - 해시 함수로 키를 해시값으로 변환하기 때문에 탐색 과정이 필요 없습니다.  \n3. **적절한 해시 함수가 중요**  \n   - 키를 인덱스로 변환하는 과정에서 충돌이 최소화되어야 합니다.\n\n---\n\n## 해시 테이블과 버킷\n\n- **해시 테이블**: 키와 값이 저장되는 데이터 공간입니다.  \n- **버킷**: 해시 테이블 내의 각 데이터 저장 공간입니다.\n\n---\n\n## 해시의 활용 분야\n\n해시는 **단방향 검색**과 **빠른 탐색**이 필요한 분야에 활용됩니다.",
        "index": 0
      },
      {
        "id": "2024-12-12_chunk_1",
        "text": "- **버킷**: 해시 테이블 내의 각 데이터 저장 공간입니다.\n\n---\n\n## 해시의 활용 분야\n\n해시는 **단방향 검색**과 **빠른 탐색**이 필요한 분야에 활용됩니다.  \n\n- **비밀번호 관리**  \n- **데이터베이스 인덱싱**  \n- **블록체인**  \n\n코딩 테스트에서도 **데이터 탐색**의 효율성이 중요한 경우 해시를 고려해야 합니다.\n\n---\n\n# 해시 함수\n\n해시 함수는 **키를 특정 범위 내의 값(해시값)**으로 변환하는 역할을 합니다.\n\n---\n\n## 해시 함수를 구현할 때 고려할 내용\n\n1. **해시값은 해시 테이블의 크기 내에서 결정되어야 합니다.**  \n   예: `N`개의 데이터를 저장하려면 해시값은 `0 ~ N-1` 범위여야 합니다.  \n\n2. **충돌(Collision)은 최소화해야 합니다.**  \n   - **충돌**: 서로 다른 키가 같은 해시값을 가지는 경우를 의미합니다.  \n   - 완벽한 해시 함수는 없지만, 충돌이 적게 발생하도록 설계해야 합니다.\n\n---\n\n## 자주 사용하는 해시 함수\n\n### 1. 나눗셈법 (Division Method)\n\n가장 단순하고 직관적인 방법입니다. 키를 소수로 나눈 나머지를 해시값으로 사용합니다.\n\n**공식**:  \n$$\nh(x) = x \\mod k\n$$\n\n- $$ x $$ : 키  \n- $$ k $$ : 소수 (해시 테이블 크기)  \n\n**소수를 사용하는 이유**:  \n소수가 아닌 값을 사용하면 특정 키에 대해 충돌이 많이 발생할 수 있습니다.\n\n---\n\n### 2.",
        "index": 1
      },
      {
        "id": "2024-12-12_chunk_2",
        "text": "k $$ : 소수 (해시 테이블 크기)  \n\n**소수를 사용하는 이유**:  \n소수가 아닌 값을 사용하면 특정 키에 대해 충돌이 많이 발생할 수 있습니다.\n\n---\n\n### 2. 곱셈법 (Multiplication Method)\n\n곱셈법은 큰 소수를 구해야 하는 나눗셈법의 단점을 보완합니다.\n\n**공식**:  \n$$\nh(x) = \\lfloor ((x \\cdot A) \\mod 1) \\cdot m \\rfloor\n$$\n\n- $$ m $$ : 해시 테이블 크기  \n- $$ A $$ : 상수 (황금비 \\( \\approx 0.6180339887 \\))  \n\n---\n\n### 3. 문자열 해싱\n\n문자열을 해싱하기 위해 **문자를 숫자로 변환**한 뒤 다항식을 활용합니다.\n\n**Polynomial Rolling Method**:  \n$$\n\\text{hash}(s) = (s[0] + s[1] \\cdot p + s[2] \\cdot p^2 + \\dots + s[n-1] \\cdot p^{n-1}) \\mod m\n$$\n\n- $$ p $$ : 31 (메르센 소수)  \n- $$ m $$ : 해시 테이블 크기  \n\n**오버플로우 방지**:  \n덧셈 연산 중간에 모듈러 연산을 수행합니다.  \n$$\n(a + b) \\% c = (a \\% c + b \\% c) \\% c\n$$\n\n---\n\n# 충돌 처리\n\n서로 다른 키가 같은 해시값을 가지면 **충돌**이 발생합니다.",
        "index": 2
      },
      {
        "id": "2024-12-12_chunk_3",
        "text": "다.  \n$$\n(a + b) \\% c = (a \\% c + b \\% c) \\% c\n$$\n\n---\n\n# 충돌 처리\n\n서로 다른 키가 같은 해시값을 가지면 **충돌**이 발생합니다. 이를 해결하기 위해 **체이닝**과 **개방 주소법**을 사용합니다.\n\n---\n\n## 체이닝 (Chaining)\n\n충돌이 발생하면 해당 버킷에 **링크드 리스트**를 사용해 데이터를 연결합니다.\n\n---\n\n## 개방 주소법 (Open Addressing)\n\n충돌 시 **빈 버킷**을 찾아 데이터를 저장합니다.\n\n### 선형 탐사 (Linear Probing)\n\n충돌이 발생하면 **일정 간격**으로 이동하며 빈 버킷을 찾습니다. 보통 간격은 1입니다.\n\n**공식**:  \n$$\nh(k, i) = (h(k) + i) \\mod m\n$$\n\n---\n\n### 이중 해싱 (Double Hashing)\n\n충돌이 발생하면 **두 번째 해시 함수**를 사용해 이동 간격을 결정합니다.\n\n**공식**:  \n$$\nh(k, i) = (h_1(k) + i \\cdot h_2(k)) \\mod m\n$$\n\n---\n\n# 핵심 정리\n\n1. **해시**는 키를 해시 함수로 변환해 데이터를 저장하고 빠르게 탐색하는 자료구조입니다.  \n2. **충돌 처리**는 체이닝과 개방 주소법(선형 탐사, 이중 해싱)으로 해결합니다.  \n3. 코딩 테스트에서는 **키와 값을 매핑**하는 과정이 해시 문제의 핵심입니다.\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }",
        "index": 3
      },
      {
        "id": "2024-12-12_chunk_4",
        "text": "핵심입니다.\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-12-C----STL",
    "title": "C++ 문법과 STL",
    "path": "/2024/12/12/C문법과-STL/",
    "categories": [
      "Computer Science",
      "Algorithm & Data structure",
      "Computer_Science/Algorithm_Theory"
    ],
    "content": "# 빌트인 데이터 타입\n\nC++의 **빌트인 데이터 타입**은 헤더 파일을 포함하지 않아도 사용할 수 있는 **내장 데이터 타입**입니다.  \n\n- **정수형**: `int`  \n- **부동소수형**: `float` 혹은 `double`  \n- **논리형**: `bool`  \n- **문자형**: `char`  \n- **배열**: `array`  \n\n---\n\n## 형 변환\n\nC++에서는 변수 선언과 동시에 타입이 정해집니다. 하지만 구현 중 타입 변경이 필요하면 **형 변환**을 사용해야 합니다.\n\n**예시 코드**:\n\n```cpp\n#include <iostream>\nusing namespace std;\n\nint main()\n{\n    int i = 65;\n    float f = 5.2f;\n\n    // 암시적 형 변환 (float로 변환됨)\n    double d = i + f;\n    cout << d << endl; // 70.2\n\n    // 명시적 형 변환\n    cout << static_cast<int>(d) << endl; // 70\n    cout << static_cast<char>(i) << endl; // 'A'\n\n    return 0;\n}\n```\n\n---\n\n## 문자열\n\nC++에서는 **문자열 자료형**을 제공하며, `string`을 사용하려면 `<string>` 헤더 파일을 포함해야 합니다.\n\n```cpp\n#include <iostream>\n#include <string>\nusing namespace std;\n\nint main() {\n    string str1;                        // 문자열 선언\n    string str2 = \"Hello, World!\";      // 문자열 초기화\n    string str3(str2);                  // 문자열 복사\n    string str4(str2, 0, 5);            // 부분 복사 \"Hello\"\n    string str5(10, '*');               // 반복된 문자로 초기화\n    cout << str5;                       // **********\n}\n```\n\n---\n\n### 문자열 찾기 (find)\n\n**find()** 메서드를 사용하면 문자열에서 특정 문자나 문자열을 찾을 수 있습니다.\n\n```cpp\n#include <iostream>\n#include <string>\nusing namespace std;\n\nint main() {\n    string str = \"Hello, C++ World!\";\n\n    size_t pos1 = str.find(\"Hello\"); // 0\n    size_t pos2 = str.find('C');     // 7\n    size_t pos3 = str.find('Z');     // string::npos 반환 (찾지 못함)\n\n    cout << pos1 << \" \" << pos2 << \" \" << pos3 << endl;\n}\n```\n\n---\n\n### 문자열 수정 (replace)\n\n**replace()** 메서드나 인덱스를 사용해 문자열을 수정할 수 있습니다.\n\n```cpp\n#include <iostream>\n#include <string>\nusing namespace std;\n\nint main() {\n    string str = \"APPLE\";\n    str += \" World!\";\n    cout << str << endl; // APPLE World!\n\n    str.replace(7, 4, \"Cold\"); // APPLE Cold!\n    cout << str << endl;\n\n    str.replace(2, 50, \"\"); // AP\n    cout << str << endl;\n}\n```\n\n---\n\n# STL (Standard Template Library)\n\n**STL**은 C++에서 제공하는 **템플릿 기반 표준 라이브러리**로, 다음 3가지 요소로 구성됩니다.\n\n- **컨테이너**: 데이터를 저장하는 객체 (예: 벡터, 맵, 셋 등)  \n- **알고리즘**: 정렬, 탐색 등 데이터를 다루는 함수  \n- **반복자**: 컨테이너 원소를 순회하는 도구  \n\n---\n\n## STL과 함께 사용하는 필수 문법\n\n### 1. 상수 레퍼런스\n\n**Call by Reference**를 사용하면 인수를 복사하는 비용을 줄이고, 값을 수정할 수 있습니다.\n\n```cpp\nvoid test(int& val) {\n    val = 10;\n}\n\nvoid test2(int val) {\n    val = 20;\n}\n\nint main() {\n    int val = 5;\n    cout << val << endl; // 5\n    test(val);\n    cout << val << endl; // 10\n    test2(val);\n    cout << val << endl; // 10 (Call by Value)\n\n    return 0;\n}\n```\n\n---\n\n### 2. auto 키워드\n\n**auto**는 변수의 타입을 자동으로 추론합니다.\n\n```cpp\nint main() {\n    auto num = 42;            // int로 추론\n    auto pi = 3.14159;        // double로 추론\n    auto greet = \"Hello!\";    // const char*로 추론\n    return 0;\n}\n```\n\n---\n\n### 3. 범위 기반 반복문\n\nC++11부터 제공되는 **범위 기반 for문**은 컨테이너 원소를 간단하게 순회합니다.\n\n```cpp\n#include <iostream>\n#include <vector>\nusing namespace std;\n\nint main() {\n    vector<int> vec = {1, 2, 3, 4, 5};\n    for (int num : vec) {\n        cout << num << \" \";\n    }\n    // 출력: 1 2 3 4 5\n}\n```\n\n---\n\n## 반복자 (Iterator)\n\n반복자는 컨테이너의 원소를 순회하고 접근할 수 있도록 돕는 도구입니다.\n\n### 순방향 반복자\n\n```cpp\n#include <iostream>\n#include <vector>\nusing namespace std;\n\nint main() {\n    vector<int> vec = {10, 20, 30, 40, 50};\n\n    for (auto it = vec.begin(); it != vec.end(); ++it) {\n        cout << *it << \" \"; // 출력: 10 20 30 40 50\n    }\n\n    return 0;\n}\n```\n\n### 역방향 반복자\n\n`rbegin()`과 `rend()`를 사용해 역방향으로 순회합니다.\n\n```cpp\n#include <iostream>\n#include <vector>\nusing namespace std;\n\nint main() {\n    vector<int> vec = {10, 20, 30, 40, 50};\n\n    for (auto it = vec.rbegin(); it != vec.rend(); ++it) {\n        cout << *it << \" \"; // 출력: 50 40 30 20 10\n    }\n\n    return 0;\n}\n```\n\n---\n\n# STL의 컨테이너\n\n## 벡터 (Vector)\n\n벡터는 동적 배열과 비슷하며 **임의 접근**이 가능합니다.\n\n### 선언과 초기화\n\n```cpp\n#include <vector>\nusing namespace std;\n\nint main() {\n    vector<int> v = {1, 2, 3, 4, 5};\n    vector<int> v2(5, 10); // 5개의 원소를 10으로 초기화\n    return 0;\n}\n```\n\n### 삽입과 삭제\n\n```cpp\n#include <vector>\nusing namespace std;\n\nint main() {\n    vector<int> v = {2, 3, 4};\n\n    v.push_back(5);         // {2, 3, 4, 5}\n    v.pop_back();           // {2, 3, 4}\n\n    v.insert(v.begin(), 1); // {1, 2, 3, 4}\n    v.erase(v.begin());     // {2, 3, 4}\n\n    return 0;\n}\n```\n\n---\n\n## 셋 (Set)\n\n셋은 **중복을 허용하지 않고 자동 정렬**되는 컨테이너입니다.\n\n```cpp\n#include <set>\nusing namespace std;\n\nint main() {\n    set<int> s = {3, 1, 2, 1, 5};\n\n    s.insert(4);  // {1, 2, 3, 4, 5}\n    s.erase(2);   // {1, 3, 4, 5}\n\n    for (int num : s) {\n        cout << num << \" \";\n    }\n    return 0;\n}\n```\n\n---\n\n## 맵 (Map)\n\n맵은 **키-값 쌍**으로 데이터를 저장합니다. 키를 기준으로 정렬됩니다.\n{% raw %}\n```cpp\n#include <map>\nusing namespace std;\n\nint main() {\n    map<string, int> myMap = {{\"apple\", 1}, {\"banana\", 2}};\n    myMap[\"cherry\"] = 3; // 삽입\n\n    for (const auto& pair : myMap) {\n        cout << pair.first << \": \" << pair.second << endl;\n    }\n    return 0;\n}\n```\n{% endraw %}\n---\n\n## 정렬되지 않은 셋과 맵\n\n`unordered_set`과 `unordered_map`은 **해시 기반**으로 동작하여 삽입, 삭제, 탐색의 시간 복잡도가 **O(1)**입니다.\n\n```cpp\n#include <unordered_set>\nusing namespace std;\n\nint main() {\n    unordered_set<int> uset = {1, 2, 3, 4, 5};\n    for (int num : uset) {\n        cout << num << \" \";\n    }\n    return 0;\n}\n```\n\n# STL의 알고리즘\n\n---\n\n## count() 함수로 횟수 세기  \n\n`count()` 함수는 **컨테이너 내 특정 값의 등장 횟수**를 셉니다.  \n- **시간 복잡도**: O(N)  \n\n**문법**:  \n`count(시작 반복자, 끝 반복자, 찾을 값)`  \n\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm> // count를 사용하기 위한 헤더\n\nusing namespace std;\n\nint main() {\n    vector<int> v = {1, 4, 3, 4, 5, 4, 5};\n\n    // 5라는 값이 몇 번 나타나는지 확인\n    int ret = count(v.begin(), v.end(), 5);\n\n    cout << ret << endl; // 출력: 2\n}\n```\n\n---\n\n## sort() 함수로 정렬하기\n\n`sort()` 함수는 컨테이너를 정렬하는 함수로 **시간 복잡도는 O(NlogN)** 입니다.  \n\n### **기본 정렬**  \n- **문법**: `sort(시작 반복자, 끝 반복자)`  \n- 기본적으로 **오름차순**으로 정렬됩니다.\n\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm> // sort를 사용하기 위한 헤더\n\nusing namespace std;\n\nint main() {\n    vector<int> v = {4, 2, 5, 3, 1};\n\n    sort(v.begin(), v.end());  // 오름차순 정렬\n    for (int num : v) cout << num << \" \"; // 출력: 1 2 3 4 5\n\n    sort(v.rbegin(), v.rend()); // 내림차순 정렬\n    for (int num : v) cout << num << \" \"; // 출력: 5 4 3 2 1\n}\n```\n\n### **비교 함수 사용하기**  \n커스텀 비교 함수로 정렬 기준을 설정할 수 있습니다.  \n\n{% raw %}\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nstruct Point {\n    int x, y;\n\n    Point(int x, int y) : x(x), y(y) {}\n};\n\nbool compare(const Point &a, const Point &b) {\n    if (a.x == b.x) return a.y < b.y; // x가 같으면 y 오름차순\n    return a.x < b.x; // x 오름차순\n}\n\nint main() {\n    vector<Point> points = {{3, 4}, {1, 2}, {3, 1}, {2, 5}};\n\n    sort(points.begin(), points.end(), compare);\n\n    for (const Point &p : points) {\n        cout << p.x << \" \" << p.y << endl;\n    }\n    // 출력: \n    // 1 2\n    // 2 5\n    // 3 1\n    // 3 4\n}\n```\n{% endraw %}\n---\n\n## next_permutation() 함수로 순열 생성하기\n\n`next_permutation()` 함수는 **사전 순**으로 모든 순열을 생성합니다.  \n- **시간 복잡도**: O(N × N!)  \n\n**주의**: 원소들을 **정렬한 후**에 사용해야 합니다.  \n\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint main() {\n    vector<int> v = {1, 2, 3};\n\n    do {\n        for (int i : v) cout << i << \" \";\n        cout << endl;\n    } while (next_permutation(v.begin(), v.end()));\n\n    return 0;\n}\n/* 출력:\n1 2 3\n1 3 2\n2 1 3\n2 3 1\n3 1 2\n3 2 1\n*/\n```\n\n---\n\n## unique() 함수로 중복 정리하기\n\n`unique()` 함수는 **연속된 중복 원소를 제거**하며, 중복되지 않은 원소들의 새로운 끝 반복자를 반환합니다.  \n- **시간 복잡도**: O(N)  \n\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint main() {\n    vector<int> v = {1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5};\n\n    auto newEnd = unique(v.begin(), v.end());\n\n    for (auto it = v.begin(); it != newEnd; ++it) cout << *it << \" \"; \n    // 출력: 1 2 3 4 5\n\n    cout << v.size() << endl; // 출력: 11\n    return 0;\n}\n```\n\n---\n\n## binary_search() 함수로 이진 탐색하기\n\n`binary_search()` 함수는 **이진 탐색**을 수행해 원소를 찾습니다.  \n- **시간 복잡도**: O(logN)  \n- **정렬된 컨테이너**에서만 사용할 수 있습니다.  \n\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint main() {\n    vector<int> v = {1, 2, 3, 4, 5};\n\n    cout << binary_search(v.begin(), v.end(), 3) << endl; // 출력: 1 (true)\n    cout << binary_search(v.begin(), v.end(), 7) << endl; // 출력: 0 (false)\n\n    return 0;\n}\n```\n\n---\n\n## max_element(), min_element() 함수로 최대, 최소 위치 구하기\n\n`max_element()`와 `min_element()`는 컨테이너에서 최대 또는 최소 원소의 **반복자**를 반환합니다.  \n- **시간 복잡도**: O(N)  \n\n**예시 코드**:  \n```cpp\n#include <iostream>\n#include <vector>\n#include <algorithm>\nusing namespace std;\n\nint main() {\n    vector<int> v = {1, 3, 5, 7, 2, 4, 6};\n\n    auto maxIt = max_element(v.begin(), v.end());\n    auto minIt = min_element(v.begin(), v.end());\n\n    cout << *maxIt << endl; // 출력: 7\n    cout << *minIt << endl; // 출력: 1\n\n    return 0;\n}\n```\n\n---\n\n# 함수 정의와 호출\n\n## 함수 정의  \nC++의 함수는 다음과 같은 형식으로 정의합니다:  \n`반환타입 함수명(매개변수)`  \n\n**예시 코드**:  \n```cpp\nint add(int a, int b) {\n    return a + b;\n}\n\nint main() {\n    int result = add(5, 10);\n    cout << result << endl; // 출력: 15\n    return 0;\n}\n```\n\n> C++을 활용해 알고리즘 문제를 푼다면, STL은 정말 잘 다루는게 중요합니다!  \n> 처음부터 모든 걸 외우려하기보단, 까먹을 때마다 계속 찾아보는 것을 추천드립니다.\n{: .prompt-tip }\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-12-12",
    "tags": [
      "Algorithm",
      "DataStructure"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-12-C----STL_chunk_0",
        "text": "C++ 문법과 STL\n\n# 빌트인 데이터 타입\n\nC++의 **빌트인 데이터 타입**은 헤더 파일을 포함하지 않아도 사용할 수 있는 **내장 데이터 타입**입니다.  \n\n- **정수형**: `int`  \n- **부동소수형**: `float` 혹은 `double`  \n- **논리형**: `bool`  \n- **문자형**: `char`  \n- **배열**: `array`  \n\n---\n\n## 형 변환\n\nC++에서는 변수 선언과 동시에 타입이 정해집니다.",
        "index": 0
      },
      {
        "id": "2024-12-12-C----STL_chunk_1",
        "text": "논리형**: `bool`  \n- **문자형**: `char`  \n- **배열**: `array`  \n\n---\n\n## 형 변환\n\nC++에서는 변수 선언과 동시에 타입이 정해집니다.",
        "index": 1
      },
      {
        "id": "2024-12-12-C----STL_chunk_2",
        "text": "논리형**: `bool`  \n- **문자형**: `char`  \n- **배열**: `array`  \n\n---\n\n## 형 변환\n\nC++에서는 변수 선언과 동시에 타입이 정해집니다.",
        "index": 2
      },
      {
        "id": "2024-12-12-C----STL_chunk_3",
        "text": "논리형**: `bool`  \n- **문자형**: `char`  \n- **배열**: `array`  \n\n---\n\n## 형 변환\n\nC++에서는 변수 선언과 동시에 타입이 정해집니다.",
        "index": 3
      },
      {
        "id": "2024-12-12-C----STL_chunk_4",
        "text": "논리형**: `bool`  \n- **문자형**: `char`  \n- **배열**: `array`  \n\n---\n\n## 형 변환\n\nC++에서는 변수 선언과 동시에 타입이 정해집니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-12",
    "title": "큐 자료구조",
    "path": "/2024/12/12/큐/",
    "categories": [
      "Computer Science",
      "Algorithm & Data structure",
      "Computer_Science/Algorithm_Theory"
    ],
    "content": "# 큐의 개념\n\n큐(queue)는 **\"줄을 서다\"**라는 뜻을 가지고 있으며, **FIFO (First In First Out, 선입선출)** 방식으로 동작하는 자료구조입니다.  \n\n스택과 마찬가지로 큐에 데이터를 **삽입**하는 연산을 `Push`, 꺼내는 연산을 `Pop`이라고 합니다.\n\n---\n\n## 큐의 ADT\n\n큐를 정의하기 위해 **isFull, isEmpty, push, pop** 등의 연산이 사용되며, **front**와 **rear**를 통해 데이터의 위치를 관리합니다.\n\n| 구분     | 정의                       | 설명                                                           |\n| -------- | -------------------------- | -------------------------------------------------------------- |\n| **연산** | `boolean isFull()`         | 큐에 들어있는 데이터의 개수가 `maxsize`인지 확인해 `bool` 반환 |\n|          | `boolean isEmpty()`        | 큐가 비어 있는지 확인해 `bool` 반환                            |\n|          | `void push(ItemType item)` | 큐에 데이터를 삽입                                             |\n|          | `ItemType pop()`           | 큐에서 가장 먼저 삽입된 데이터를 꺼내고 반환                   |\n| **상태** | `int front`                | 큐에서 마지막으로 **팝**한 데이터의 위치를 기록                |\n|          | `int rear`                 | 큐에서 최근에 **푸시**된 데이터의 위치를 기록                  |\n|          | `ItemType data[maxsize]`   | 큐의 데이터를 관리하는 배열 (최대 `maxsize` 개)                |\n\n---\n\n## 큐의 세부 동작\n\n### 큐에 데이터를 삽입할 때 (`push(3)`)\n\n1. `isFull()` 연산을 수행해 큐가 가득 찼는지 확인합니다.  \n2. 비어 있다면, `rear`를 1 증가시킵니다.  \n   - 초기값: `front = -1`, `rear = -1 → 0`  \n3. `rear`가 가리키는 위치에 데이터를 삽입합니다.  \n   - 예: `data[0] = 3`\n\n### 큐에서 데이터를 꺼낼 때 (`pop()`)\n\n1. `isEmpty()` 연산을 수행해 큐가 비어 있는지 확인합니다.  \n2. 비어 있지 않다면, `front`를 1 증가시킵니다.  \n3. `front`와 `rear`가 같아지면 큐는 비어 있는 상태로 처리됩니다.\n\n> **참고**  \n> 스택과 마찬가지로, **데이터를 물리적으로 삭제하지 않아도** 데이터를 관리할 수 있습니다.  \n> 실제 데이터는 배열에 남아 있지만, **front**와 **rear**가 가리키는 위치를 통해 삭제된 것처럼 처리됩니다.  \n{: .prompt-info }\n\n---\n\n### 큐에 데이터를 여러 번 푸시할 때\n\n- `push(5)` → `rear`를 1 증가시켜 데이터를 삽입합니다.  \n- 이후 6과 8을 푸시하면:  \n  - **front = 0, rear = 3** → `{ ~3~ , 5, 6, 8 }`  \n\n### 큐가 가득 찼을 때\n\n1. `rear`가 `maxsize - 1`에 도달하면 `isFull()`이 `True`를 반환합니다.  \n2. 데이터는 `{3, 5, 6, 8}`이지만, 큐가 **3개 데이터**만 관리 중입니다.\n\n> **문제점**  \n> 큐는 **한 방향**으로만 데이터가 이동하기 때문에 `front` 이전의 공간을 재활용하지 못해 **메모리 낭비**가 발생합니다.  \n\n---\n\n## 큐를 원형으로 개선하기\n\n위 문제를 해결하기 위해 **원형 큐(Circular Queue)**를 사용합니다.  \n- 원형 큐는 `front`와 `rear`가 **원형으로 순환**하면서 공간 낭비를 줄입니다.  \n- 구현은 복잡하지만, **메모리 효율성을 크게 향상**시킬 수 있습니다.\n\n> **팁**  \n> C++ STL의 큐는 내부적으로 메모리 관리를 제공하므로, **STL 큐**를 사용하는 것이 좋습니다.  \n{: .prompt-tip }\n\n---\n\n## 큐 구현하기\n\nC++ STL에서 제공하는 큐는 **O(1)** 시간 복잡도로 `push(), pop(), front(), empty()` 연산을 수행합니다.\n\n### 예시 코드: C++ STL 큐 활용\n\n```cpp\n#include <iostream>\n#include <queue>\n\nusing namespace std;\n\nint main() {\n    queue<int> q;\n\n    // 데이터 삽입\n    q.push(10);\n    q.push(20);\n    q.push(30);\n\n    // 큐의 맨 앞 요소 확인\n    cout << \"Front: \" << q.front() << endl; // 출력: 10\n\n    // 큐의 모든 요소 꺼내기\n    while (!q.empty()) {\n        cout << q.front() << \"을 큐에서 삭제했습니다.\" << endl;\n        q.pop();\n    } \n\n    // 큐가 비어있는지 확인\n    cout << (q.empty() ? \"Yes\" : \"No\"); // 출력: Yes\n\n    return 0;\n}\n```\n\n---\n\n### STL 큐의 주요 함수\n\n1. **`push(item)`**: 큐에 데이터를 삽입합니다.  \n2. **`front()`**: 큐의 맨 앞 데이터를 반환합니다.  \n3. **`pop()`**: 큐의 맨 앞 데이터를 삭제합니다.  \n4. **`empty()`**: 큐가 비어 있는지 확인합니다.  \n\n---\n\n> 자료구조의 세부 동작을 이해하고 문제에 맞는 자료구조를 선택하는게 좋습니다.  \n> 메모리 효율성을 위해 원형 큐와 같은 최적화된 형태도 고려하는 것이 좋습니다.  \n{: .prompt-tip }\n\n---\n---\n---\n> 위 내용은 박경록 저자님의 \"코딩 테스트 합격자 되기 (C++편)\" 을 읽고 공부한 것을 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-12-12",
    "tags": [
      "Algorithm",
      "DataStructure"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-12_chunk_0",
        "text": "큐 자료구조\n\n# 큐의 개념\n\n큐(queue)는 **\"줄을 서다\"**라는 뜻을 가지고 있으며, **FIFO (First In First Out, 선입선출)** 방식으로 동작하는 자료구조입니다.",
        "index": 0
      },
      {
        "id": "2024-12-12_chunk_1",
        "text": "# 큐의 개념\n\n큐(queue)는 **\"줄을 서다\"**라는 뜻을 가지고 있으며, **FIFO (First In First Out, 선입선출)** 방식으로 동작하는 자료구조입니다.",
        "index": 1
      },
      {
        "id": "2024-12-12_chunk_2",
        "text": "# 큐의 개념\n\n큐(queue)는 **\"줄을 서다\"**라는 뜻을 가지고 있으며, **FIFO (First In First Out, 선입선출)** 방식으로 동작하는 자료구조입니다.",
        "index": 2
      },
      {
        "id": "2024-12-12_chunk_3",
        "text": "# 큐의 개념\n\n큐(queue)는 **\"줄을 서다\"**라는 뜻을 가지고 있으며, **FIFO (First In First Out, 선입선출)** 방식으로 동작하는 자료구조입니다.",
        "index": 3
      },
      {
        "id": "2024-12-12_chunk_4",
        "text": "# 큐의 개념\n\n큐(queue)는 **\"줄을 서다\"**라는 뜻을 가지고 있으며, **FIFO (First In First Out, 선입선출)** 방식으로 동작하는 자료구조입니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-11-PID-Controller",
    "title": "PID Controller",
    "path": "/2024/12/11/PID-Controller/",
    "categories": [
      "Embedded System",
      "Control Engineering",
      "Embedded/Control"
    ],
    "content": "# ⭐ 고전제어 PID Control\n\n> **PID 제어는 매우 심플하지만 강력함!**  \n> 새로운 제어기와의 성능을 비교할 때 기준이 되는 제어기!\n{: .highlight}\n\n### PID는 플랜트 모델을 정확히 모르더라도 P, I, D gain값을 휴리스틱하게 변경하여 제어할 수 있음!\n\n> **보통 Ziegler-Nichols Method**를 통해 값을 정함.\n{: .prompt-info }\n---\n\n## 1. Concept of PID, Heuristic Tuning\n![alt text](/assets/img/control/pid1.png)\n> **제어는** 시스템의 상태를 원하는 목표치로 도달하게끔 만드는 과정.\n\n- **$x$**: 시스템의 상태  \n- **$x_d$**: 원하는 목표치  \n- **Plant**: 우리가 관심 있는 시스템 (드론, 로봇팔 등)\n\n<br><br>\n\n### **PID 제어의 개념**\n\n---\n\n1. **비례 제어 (Proportional Gain)**  \n   에러값에 비례해서 제어 값을 조정.\n\n   → 초반 에러가 클 경우 **빠른 시간 내에 에러를 줄이는 역할!!**\n\n   > 하지만, 에러가 줄더라도 에러에 비례해 제어하므로 **오버슈팅** 및 **잔류 에러** 발생 가능.\n   {: .highlight }\n\n\n2. **적분 제어 (Integral Gain)**  \n   비례 제어의 단점을 보완.  \n   에러의 적분값에 비례하여 시스템에 입력을 주어 **잔류 에러를 줄임**.\n\n   > 하지만, 갑작스러운 변화 혹은 에러가 누적되면 적분 값이 커져 시스템이 **발산**할 위험이 있음.  \n   → **Anti-windup 기법 사용**을 고려해야 함.\n   {: .highlight }\n\n\n3. **미분 제어 (Derivative Gain)**  \n   변화량에 비례한 입력을 줌으로써 안정성을 높임.\n\n   > 미분 값은 미래의 값을 알 수 없어 물리적으로 구현할 수 없음.  \n   대신 **현재 에러와 과거 에러**를 활용하여 미분 값을 계산.\n   {: .highlight }\n\n   \n짧은 샘플링 시간이나 갑작스러운 변화로 인해 튀는 현상을 방지하기 위해 **Low-pass Filter**를 사용.\n{: .prompt-tip }\n![alt text](/assets/img/control/pid2.png)\n\n### Ziegler-Nichols Method를 통한 PID 튜닝\n\n---\n\n### 모델 정보가 없을 때 사용할 수 있는 방법!  \n- $$K_p, T_i, T_d$$ 값을 계산할 수 있음.\n \n![alt text](/assets/img/control/pid3.png)\n\n만약 모터를 제어한다고 했을 때, 모터의 엔코더 값이 위의 그림과 같다면\n**P Gain** ($K_{cr}$): 진동이 발생하기 시작하는 P gain.  \n**진동 주기** ($P_{cr}$): 진동 주기의 시간.\n\n**아래의 표를 통해 PID 값 튜닝 가능**:  \n![alt text](/assets/img/control/pid4.png)\n\n> 하지만, Ziegler-Nichols Method는 항상 잘 동작하는 것은 아님.<br>\n> 성능과 외란 안정성을 고려해야 함.\n{: .prompt-warning }\n\n---\n\n## ⭐모델 기반 PID 튜닝\n\n### 고전 제어 vs 현대 제어\n\n---\n\n**칼만 필터 이후 두 제어 방식이 나뉘게 됨.**\n\n> **칼만 필터란?**  \n> 시스템 모델과 측정치를 결합하여 실제 상태를 추정하는 필터.\n{: .prompt-info }\n\n#### 고전 제어\n- 주파수 관점에서 **입출력 전달함수**를 기반으로 설계.\n- **SISO (Single Input Single Output)** 시스템에 적합.\n\n#### 현대 제어\n- 시간 관점에서 **상태 방정식**을 기반으로 설계.\n- **MIMO (Multi Input Multi Output)** 시스템 설계에 적합.\n\n\n### 플랜트 모델 찾기 (System Identification)\n---\nPID 제어를 설계하기 전, 다루고자 하는 플랜트를 정의해야 합니다.  \n아래는 모터의 간단한 방정식 예제입니다:\n\n#### 모터 방정식\n\n$$\nJ\\ddot{\\theta}(t) + B\\dot{\\theta}(t) = T(t)\n$$\n\n- **$J$**: 관성 모멘트 (Moment of Inertia)  \n- **$B$**: 점성 마찰 계수 (Viscous Friction)\n\n라플라스 변환을 통해 주파수 영역으로 변환:\n\\$$\nJ \\theta(s) s^2 + B \\theta(s) s = T(s)\n$$\n![alt text](/assets/img/control/pid5.png)\n![alt text](/assets/img/control/pid6.png)\n\n> 라플라스 식에서 전달함수를 구하면 P(s)를 위 이미지처럼 바꿀 수 있습니다.\n{: .prompt-tip }\n\n#### ex) J = 0.02 , b = 0.1 로 설정\n\nInput 은 desired trajectory인 위치 명령, Output은 모터가 움직인 각도\n\n시스템의 특성을 파악하기 좋은 방법으로\n\n**1) 루트 로커스(root locus) 와 2) 나이퀴스트(Nyquist)** \n\nroot loucs는 matlab이나 python의 python control 모듈에서 쉽게 확인 가능.\n\n`pip install control` 을 통해 쉽게 설치!\n\n\n## 4. Pole과 Zero의 특성\n\n---\n\nOpen loop 전달함수를 인수분해하여 Pole과 Zero를 구함:\n$$\nL(s) = C(s) P(s) = K \\frac{(s + z_1)(s + z_2) \\cdots (s + z_m)}{(s + p_1)(s + p_2) \\cdots (s + p_n)}\n$$\n\n### 설명:\n- $$ L(s) $$: Open loop 전달함수\n- $$ C(s) $$: 제어기 전달함수\n- $$ P(s) $$: 플랜트 전달함수\n- $$ K $$: Gain\n- $$ z_1, z_2, \\ldots, z_m $$: 시스템의 Zero\n- $$ p_1, p_2, \\ldots, p_n $$: 시스템의 Pole\n\n> **Pole**: 전달함수의 분모를 0으로 만드는 근.  \n> **Zero**: 전달함수의 분자를 0으로 만드는 근.\n\n> 시스템의 안정성은 **Pole의 위치**로 판단.  \n> Pole이 s-plane의 왼쪽에 위치할 때 안정적.\n{: .highlight}\n\n### 제어기 설계 시 포인트\n\n1. LHP (Left Half Plane)에 위치한 Pole은 안정성을 나타냄.\n2. 허수부가 클수록 시스템의 진동이 커짐.\n3. I Gain은 **루트 궤적을 오른쪽으로**, D Gain은 **왼쪽으로** 당기는 역할.\n",
    "date": "2024-12-11",
    "tags": [
      "Embedded System",
      "Control"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-11-PID-Controller_chunk_0",
        "text": "PID Controller\n\n# ⭐ 고전제어 PID Control\n\n> **PID 제어는 매우 심플하지만 강력함!**  \n> 새로운 제어기와의 성능을 비교할 때 기준이 되는 제어기!\n{: .highlight}\n\n### PID는 플랜트 모델을 정확히 모르더라도 P, I, D gain값을 휴리스틱하게 변경하여 제어할 수 있음!\n\n> **보통 Ziegler-Nichols Method**를 통해 값을 정함.\n{: .prompt-info }\n---\n\n## 1. Concept of PID, Heuristic Tuning\n![alt text](/assets/img/control/pid1.png)\n> **제어는** 시스템의 상태를 원하는 목표치로 도달하게끔 만드는 과정.\n\n- **$x$**: 시스템의 상태  \n- **$x_d$**: 원하는 목표치  \n- **Plant**: 우리가 관심 있는 시스템 (드론, 로봇팔 등)\n\n<br><br>\n\n### **PID 제어의 개념**\n\n---\n\n1. **비례 제어 (Proportional Gain)**  \n   에러값에 비례해서 제어 값을 조정.\n\n   → 초반 에러가 클 경우 **빠른 시간 내에 에러를 줄이는 역할!!**\n\n   > 하지만, 에러가 줄더라도 에러에 비례해 제어하므로 **오버슈팅** 및 **잔류 에러** 발생 가능.\n   {: .highlight }\n\n\n2. **적분 제어 (Integral Gain)**  \n   비례 제어의 단점을 보완.",
        "index": 0
      },
      {
        "id": "2024-12-11-PID-Controller_chunk_1",
        "text": "로 **오버슈팅** 및 **잔류 에러** 발생 가능.\n   {: .highlight }\n\n\n2. **적분 제어 (Integral Gain)**  \n   비례 제어의 단점을 보완.  \n   에러의 적분값에 비례하여 시스템에 입력을 주어 **잔류 에러를 줄임**.\n\n   > 하지만, 갑작스러운 변화 혹은 에러가 누적되면 적분 값이 커져 시스템이 **발산**할 위험이 있음.  \n   → **Anti-windup 기법 사용**을 고려해야 함.\n   {: .highlight }\n\n\n3. **미분 제어 (Derivative Gain)**  \n   변화량에 비례한 입력을 줌으로써 안정성을 높임.\n\n   > 미분 값은 미래의 값을 알 수 없어 물리적으로 구현할 수 없음.  \n   대신 **현재 에러와 과거 에러**를 활용하여 미분 값을 계산.\n   {: .highlight }\n\n   \n짧은 샘플링 시간이나 갑작스러운 변화로 인해 튀는 현상을 방지하기 위해 **Low-pass Filter**를 사용.\n{: .prompt-tip }\n![alt text](/assets/img/control/pid2.png)\n\n### Ziegler-Nichols Method를 통한 PID 튜닝\n\n---\n\n### 모델 정보가 없을 때 사용할 수 있는 방법!",
        "index": 1
      },
      {
        "id": "2024-12-11-PID-Controller_chunk_2",
        "text": "ets/img/control/pid2.png)\n\n### Ziegler-Nichols Method를 통한 PID 튜닝\n\n---\n\n### 모델 정보가 없을 때 사용할 수 있는 방법!  \n- $$K_p, T_i, T_d$$ 값을 계산할 수 있음.\n \n![alt text](/assets/img/control/pid3.png)\n\n만약 모터를 제어한다고 했을 때, 모터의 엔코더 값이 위의 그림과 같다면\n**P Gain** ($K_{cr}$): 진동이 발생하기 시작하는 P gain.",
        "index": 2
      },
      {
        "id": "2024-12-11-PID-Controller_chunk_3",
        "text": "ol/pid3.png)\n\n만약 모터를 제어한다고 했을 때, 모터의 엔코더 값이 위의 그림과 같다면\n**P Gain** ($K_{cr}$): 진동이 발생하기 시작하는 P gain.  \n**진동 주기** ($P_{cr}$): 진동 주기의 시간.\n\n**아래의 표를 통해 PID 값 튜닝 가능**:  \n![alt text](/assets/img/control/pid4.png)\n\n> 하지만, Ziegler-Nichols Method는 항상 잘 동작하는 것은 아님.<br>\n> 성능과 외란 안정성을 고려해야 함.\n{: .prompt-warning }\n\n---\n\n## ⭐모델 기반 PID 튜닝\n\n### 고전 제어 vs 현대 제어\n\n---\n\n**칼만 필터 이후 두 제어 방식이 나뉘게 됨.**\n\n> **칼만 필터란?**  \n> 시스템 모델과 측정치를 결합하여 실제 상태를 추정하는 필터.\n{: .prompt-info }\n\n#### 고전 제어\n- 주파수 관점에서 **입출력 전달함수**를 기반으로 설계.\n- **SISO (Single Input Single Output)** 시스템에 적합.\n\n#### 현대 제어\n- 시간 관점에서 **상태 방정식**을 기반으로 설계.\n- **MIMO (Multi Input Multi Output)** 시스템 설계에 적합.\n\n\n### 플랜트 모델 찾기 (System Identification)\n---\nPID 제어를 설계하기 전, 다루고자 하는 플랜트를 정의해야 합니다.",
        "index": 3
      },
      {
        "id": "2024-12-11-PID-Controller_chunk_4",
        "text": "t)** 시스템 설계에 적합.\n\n\n### 플랜트 모델 찾기 (System Identification)\n---\nPID 제어를 설계하기 전, 다루고자 하는 플랜트를 정의해야 합니다.  \n아래는 모터의 간단한 방정식 예제입니다:\n\n#### 모터 방정식\n\n$$\nJ\\ddot{\\theta}(t) + B\\dot{\\theta}(t) = T(t)\n$$\n\n- **$J$**: 관성 모멘트 (Moment of Inertia)  \n- **$B$**: 점성 마찰 계수 (Viscous Friction)\n\n라플라스 변환을 통해 주파수 영역으로 변환:\n\\$$\nJ \\theta(s) s^2 + B \\theta(s) s = T(s)\n$$\n![alt text](/assets/img/control/pid5.png)\n![alt text](/assets/img/control/pid6.png)\n\n> 라플라스 식에서 전달함수를 구하면 P(s)를 위 이미지처럼 바꿀 수 있습니다.\n{: .prompt-tip }\n\n#### ex) J = 0.02 , b = 0.1 로 설정\n\nInput 은 desired trajectory인 위치 명령, Output은 모터가 움직인 각도\n\n시스템의 특성을 파악하기 좋은 방법으로\n\n**1) 루트 로커스(root locus) 와 2) 나이퀴스트(Nyquist)** \n\nroot loucs는 matlab이나 python의 python control 모듈에서 쉽게 확인 가능.\n\n`pip install control` 을 통해 쉽게 설치!\n\n\n## 4.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-11",
    "title": "제어란?",
    "path": "/2024/12/11/제어란/",
    "categories": [
      "Embedded System",
      "Control Engineering",
      "Embedded/Control"
    ],
    "content": "# 제어란?\n\n---\n\n## Definition\n\n내가 가지고있는 시스템을 목표한 상태 변수로 이끄는 것!  \n시스템을 지배하는 **수학적 모델**과 입력을 수정하는 **제어 알고리즘**을 통해서.\n\n---\n\n## Controller $\\simeq$ Feed-back Controller !\n\nOpen loop의 경우 플랜트를 완벽하게 구해야 에러를 줄일 수 있음.  \n**→ 에러를 최소화하기 위해, 피드백 제어기를 사용해야 한다!**\n\n> ### 중요한 포인트!\n> 1. **플랜트의 수학적 모델을 어떻게 유도할 것인가?**\n>    - State-space Representation\n>    - Transfer function Representation\n>\n> 2. **시스템의 안정성과 성능을 어떻게 평가할 것인가?**\n>    - Stability: Pole-zero stability analysis\n>    - Performance: Bode plot\n{: .highlight }\n\n---\n\n# Plant Modeling\n\n---\n\n## 1. State Space Representation\n\n상태공간 표현식은 물리적 시스템의 수학적 모델입니다.  \n**인풋, 아웃풋, 상태변수간의 관계를 1계 미분 방정식으로 표현!**\n\n---\n\n### State-Space Equations\n\n$$\n\\dot{X}(k) = AX(k) + BU(k)\n$$\n\n$$\nY(k) = CX(k) + DU(k)\n$$\n\n1. **Calculate**:  \n   $$\n   \\dot{X}(k) = AX(k) + BU(k)\n   $$\n\n2. **Calculate**:  \n   $$\n   X(k+1) = X(k) + \\dot{X}(k) \\Delta t\n   $$\n\n   _(where $$\\Delta t$$ is the time gap between k and k+1.)_\n\n3. **Calculate**:  \n   $$\n   Y(k+1) = CX(k+1) + DU(k)\n   $$\n\n---\n\n#### Description\n\n상태공간 모델을 이용하면, 제어 입력 $$ U(k) $$가 주어졌을 때, 시스템의 상태 $$ X(k) $$를 시간에 따라 시뮬레이션할 수 있습니다.  \n이를 통해 시스템의 출력 $$ Y(k) $$ 또한 시간 흐름에 따라 계산할 수 있습니다.\n\n---\n\n#### 추가 변수 설명\n\n- **State Variables**:  \n  $$\n  X(k), \\dot{X}(k)\n  $$\n\n- **Input**:  \n  $$\n  U(k)\n  $$\n\n- **Output**:  \n  $$\n  Y(k)\n  $$\n\n행렬 $$ A, B, C, D $$는 시스템 동역학을 정의하며, 이 값들이 상수일 경우 해당 시스템은 **선형 시간 불변(LTI)** 시스템으로 간주됩니다.\n\n---\n\n## 2. Transfer Function\n\n전달함수는 수학적 모델.  \n인풋, 아웃풋을 주파수 영역 s (=jw)로 표현합니다. (**LTI System**)\n\n---\n\n### State-space model to Transfer Function model\n\n$$\nP(s) = C(sI-A)^{-1}B+D\n$$\n\n---\n\n## 3. PID Controller\n\nPID제어기와 관련해선 [여기를 참고](#)하세요.\n\n---\n\n### PID = Proportional Integrate Derivative\n\n> **P Control**  \n> &emsp;&emsp;&emsp;&emsp; $$T(t) = Pe_z(t)$$\n{: .prompt-info }\n\n**P gain tuning (응답속도 Term):**  \n응답성과 관련.  \n너무 커지면 overshoot과 진동을 야기.  \n→ **D gain**을 통해 해결.\n\n---\n\n> **PD Control**  \n> &emsp;&emsp;&emsp;&emsp; $$T(t) = Pe_z(t)+D {de_z(t)\\over dt}$$\n{: .prompt-info }\n\n**D gain tuning (안정성 Term):**  \novershoot과 진동 억제.  \n하지만 시스템의 delay를 야기.  \n고주파 노이즈를 미분하기 때문에 D gain이 크면 노이즈에 취약.  \n→ D는 과도하게 증가시키지 말고, P를 줄이는 방향으로 해결.\n\n---\n\n> **PID Control** ⭐  \n> &emsp;&emsp;&emsp;&emsp; $$T(t) = Pe_z(t) + I\\int e_z(t)dt + D{de_z(t)\\over dt}$$\n{: .prompt-info }\n\n**I gain tuning (SSE Term):**  \nsteady-state error → 0.  \n빠르게 에러를 수렴시키지만 안정성을 떨어뜨릴 가능성이 있음.  \n→ I는 **마지막 옵션**으로 최소한으로 사용.\n\n---\n\n## 4. System Analysis\n\n---\n\n### Stability\n\n- **RHP Pole**이 하나라도 있다면 시스템은 **UNSTABLE**.\n- 허수 축에 폴이 있다면 시스템은 **MARGINALLY STABLE** (동일한 진폭으로 진동).\n- 모든 Pole이 LHP에 있다면 시스템은 **STABLE**.\n- Pole이 실수축에서 멀어질수록 진동이 커짐.\n\n---\n\n> **RHP zero undershoot**  \n> 만약 RHP Zero가 하나라도 있다면, 시스템은 **Undershoot**라는 응답을 보임.  \n> 이는 **초기 응답 시 목표 방향과 반대로 가는 현상!**\n\n---\n\n### Performance\n\n⭐ **Bode Plot** (가로축: Frequency, 세로축: Magnitude and Phase)\n\n- 안정한 시스템에서 **Magnitude**가 더 중요. 이는 성능과 높은 연관성을 가짐.  \n- 대부분의 제어 문제에서 **낮은 주파수 영역**에서의 응답이 중요.  \n- High frequency에서 Magnitude가 충분히 작지 않다면, 센서의 노이즈와 의도치 않은 진동에 영향을 받음.\n\n---\n",
    "date": "2024-12-11",
    "tags": [
      "Embedded System",
      "Control"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-11_chunk_0",
        "text": "제어란?\n\n# 제어란?\n\n---\n\n## Definition\n\n내가 가지고있는 시스템을 목표한 상태 변수로 이끄는 것!  \n시스템을 지배하는 **수학적 모델**과 입력을 수정하는 **제어 알고리즘**을 통해서.\n\n---\n\n## Controller $\\simeq$ Feed-back Controller !\n\nOpen loop의 경우 플랜트를 완벽하게 구해야 에러를 줄일 수 있음.  \n**→ 에러를 최소화하기 위해, 피드백 제어기를 사용해야 한다!**\n\n> ### 중요한 포인트!\n> 1. **플랜트의 수학적 모델을 어떻게 유도할 것인가?**\n>    - State-space Representation\n>    - Transfer function Representation\n>\n> 2. **시스템의 안정성과 성능을 어떻게 평가할 것인가?**\n>    - Stability: Pole-zero stability analysis\n>    - Performance: Bode plot\n{: .highlight }\n\n---\n\n# Plant Modeling\n\n---\n\n## 1. State Space Representation\n\n상태공간 표현식은 물리적 시스템의 수학적 모델입니다.  \n**인풋, 아웃풋, 상태변수간의 관계를 1계 미분 방정식으로 표현!**\n\n---\n\n### State-Space Equations\n\n$$\n\\dot{X}(k) = AX(k) + BU(k)\n$$\n\n$$\nY(k) = CX(k) + DU(k)\n$$\n\n1.",
        "index": 0
      },
      {
        "id": "2024-12-11_chunk_1",
        "text": "*\n\n---\n\n### State-Space Equations\n\n$$\n\\dot{X}(k) = AX(k) + BU(k)\n$$\n\n$$\nY(k) = CX(k) + DU(k)\n$$\n\n1. **Calculate**:  \n   $$\n   \\dot{X}(k) = AX(k) + BU(k)\n   $$\n\n2. **Calculate**:  \n   $$\n   X(k+1) = X(k) + \\dot{X}(k) \\Delta t\n   $$\n\n   _(where $$\\Delta t$$ is the time gap between k and k+1.)_\n\n3. **Calculate**:  \n   $$\n   Y(k+1) = CX(k+1) + DU(k)\n   $$\n\n---\n\n#### Description\n\n상태공간 모델을 이용하면, 제어 입력 $$ U(k) $$가 주어졌을 때, 시스템의 상태 $$ X(k) $$를 시간에 따라 시뮬레이션할 수 있습니다.  \n이를 통해 시스템의 출력 $$ Y(k) $$ 또한 시간 흐름에 따라 계산할 수 있습니다.\n\n---\n\n#### 추가 변수 설명\n\n- **State Variables**:  \n  $$\n  X(k), \\dot{X}(k)\n  $$\n\n- **Input**:  \n  $$\n  U(k)\n  $$\n\n- **Output**:  \n  $$\n  Y(k)\n  $$\n\n행렬 $$ A, B, C, D $$는 시스템 동역학을 정의하며, 이 값들이 상수일 경우 해당 시스템은 **선형 시간 불변(LTI)** 시스템으로 간주됩니다.\n\n---\n\n## 2. Transfer Function\n\n전달함수는 수학적 모델.",
        "index": 1
      },
      {
        "id": "2024-12-11_chunk_2",
        "text": "며, 이 값들이 상수일 경우 해당 시스템은 **선형 시간 불변(LTI)** 시스템으로 간주됩니다.\n\n---\n\n## 2. Transfer Function\n\n전달함수는 수학적 모델.  \n인풋, 아웃풋을 주파수 영역 s (=jw)로 표현합니다. (**LTI System**)\n\n---\n\n### State-space model to Transfer Function model\n\n$$\nP(s) = C(sI-A)^{-1}B+D\n$$\n\n---\n\n## 3. PID Controller\n\nPID제어기와 관련해선 [여기를 참고](#)하세요.\n\n---\n\n### PID = Proportional Integrate Derivative\n\n> **P Control**  \n> &emsp;&emsp;&emsp;&emsp; $$T(t) = Pe_z(t)$$\n{: .prompt-info }\n\n**P gain tuning (응답속도 Term):**  \n응답성과 관련.  \n너무 커지면 overshoot과 진동을 야기.  \n→ **D gain**을 통해 해결.\n\n---\n\n> **PD Control**  \n> &emsp;&emsp;&emsp;&emsp; $$T(t) = Pe_z(t)+D {de_z(t)\\over dt}$$\n{: .prompt-info }\n\n**D gain tuning (안정성 Term):**  \novershoot과 진동 억제.  \n하지만 시스템의 delay를 야기.  \n고주파 노이즈를 미분하기 때문에 D gain이 크면 노이즈에 취약.",
        "index": 2
      },
      {
        "id": "2024-12-11_chunk_3",
        "text": "ing (안정성 Term):**  \novershoot과 진동 억제.  \n하지만 시스템의 delay를 야기.  \n고주파 노이즈를 미분하기 때문에 D gain이 크면 노이즈에 취약.  \n→ D는 과도하게 증가시키지 말고, P를 줄이는 방향으로 해결.\n\n---\n\n> **PID Control** ⭐  \n> &emsp;&emsp;&emsp;&emsp; $$T(t) = Pe_z(t) + I\\int e_z(t)dt + D{de_z(t)\\over dt}$$\n{: .prompt-info }\n\n**I gain tuning (SSE Term):**  \nsteady-state error → 0.  \n빠르게 에러를 수렴시키지만 안정성을 떨어뜨릴 가능성이 있음.  \n→ I는 **마지막 옵션**으로 최소한으로 사용.\n\n---\n\n## 4. System Analysis\n\n---\n\n### Stability\n\n- **RHP Pole**이 하나라도 있다면 시스템은 **UNSTABLE**.\n- 허수 축에 폴이 있다면 시스템은 **MARGINALLY STABLE** (동일한 진폭으로 진동).\n- 모든 Pole이 LHP에 있다면 시스템은 **STABLE**.\n- Pole이 실수축에서 멀어질수록 진동이 커짐.\n\n---\n\n> **RHP zero undershoot**  \n> 만약 RHP Zero가 하나라도 있다면, 시스템은 **Undershoot**라는 응답을 보임.",
        "index": 3
      },
      {
        "id": "2024-12-11_chunk_4",
        "text": "수록 진동이 커짐.\n\n---\n\n> **RHP zero undershoot**  \n> 만약 RHP Zero가 하나라도 있다면, 시스템은 **Undershoot**라는 응답을 보임.  \n> 이는 **초기 응답 시 목표 방향과 반대로 가는 현상!**\n\n---\n\n### Performance\n\n⭐ **Bode Plot** (가로축: Frequency, 세로축: Magnitude and Phase)\n\n- 안정한 시스템에서 **Magnitude**가 더 중요. 이는 성능과 높은 연관성을 가짐.  \n- 대부분의 제어 문제에서 **낮은 주파수 영역**에서의 응답이 중요.  \n- High frequency에서 Magnitude가 충분히 작지 않다면, 센서의 노이즈와 의도치 않은 진동에 영향을 받음.\n\n---",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-10-Aruco--------------RC",
    "title": "Aruco 마커를 활용한 자율주행 RC카",
    "path": "/2024/12/10/Aruco-마커를-활용한-자율주행-RC카/",
    "categories": [
      "Embedded System",
      "Project",
      "Embedded"
    ],
    "content": "## Aruco 마커를 활용한 자율주행 RC카\n\n이 글은 **라즈베리파이 4**와 **Renesas FPB-RA6E1 보드**를 활용해 Aruco 마커를 탐지하고 자율주행 RC카를 제어하는 프로젝트의 내용을 다룹니다. 프로젝트는 크게 라즈베리파이에서의 비전 처리와 Renesas 보드에서의 하드웨어 제어로 구성됩니다.\n\n### Flow Chart\n프로젝트 시작 전, 간단한 제어 흐름은 아래와 같이 생각했습니다.\n![Flow Chart](/assets/img/rccar/img1.png){: .center}\n\n### ArUco 마커를 선택한 이유\n스마트홈 혹은 스마트팩토리 등 실내 환경에서 사용할 경우, GPS 신호를 정확하게 받아올 수 없기에 현재 위치를 알아내는 것에 어려움이 있습니다.\n\n이를 위해 LiDAR 센서 혹은 RGB-D 카메라를 활용한 SLAM 기술이 있습니다.\n\n하지만, ArUco마커를 활용한다면 위 센서들보단 저렴한 RGB카메라만으로 현재 위치를 알아낼 수 있어 이를 활용한 프로젝트를 진행합니다.\n> 물론, ArUco 마커를 사용한다면 제한된 환경에서만 적용 가능할 것이라 생각됩니다.\n{: .prompt-info }\n\n\n---\n\n### Raspberry Pi: 웹 서버, Aruco 탐지 및 모터 컨트롤\n\n#### 1. Flask 기반 웹 서버\n\nRaspberry Pi에서 Flask를 사용하여 웹 서버를 구동합니다. 이 서버는 RC카의 상태를 모니터링하고 제어할 수 있는 UI를 제공합니다. 주요 코드는 다음과 같습니다:\n\n```python\nfrom flask import Flask, request, jsonify\nfrom motor_controller import MotorController\n\napp = Flask(__name__)\nmotor_controller = MotorController()\n\n@app.route(\"/control\", methods=[\"POST\"])\ndef control():\n    action = request.json.get(\"action\")\n    if action == \"forward\":\n        motor_controller.move_forward()\n    elif action == \"left\":\n        motor_controller.turn_left()\n    elif action == \"right\":\n        motor_controller.turn_right()\n    elif action == \"stop\":\n        motor_controller.stop()\n    return jsonify({\"status\": \"success\"})\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=5000)\n```\n\n위 코드에서 `/control` 엔드포인트는 JSON 데이터를 통해 RC카의 동작을 제어합니다.\n\n#### 2. Aruco 마커 탐지를 위한 영상 처리\n\nOpenCV를 활용하여 카메라로부터 입력받은 영상에서 Aruco 마커를 탐지합니다. 탐지된 마커의 ID에 따라 RC카의 동작을 결정합니다:\n\n```python\nimport cv2\nimport numpy as np\nfrom motor_controller import MotorController\n\nclass ArucoDetector:\n    def __init__(self, motor_controller):\n        self.aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n        self.aruco_params = cv2.aruco.DetectorParameters_create()\n        self.motor_controller = motor_controller\n\n    def process_frame(self, frame):\n        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n        corners, ids, _ = cv2.aruco.detectMarkers(\n            gray, self.aruco_dict, parameters=self.aruco_params\n        )\n        if ids is not None:\n            for marker_id, corner in zip(ids, corners):\n                print(f\"Detected Marker: {marker_id}\")\n                self.motor_controller.adjust_to_marker(marker_id[0], corner)\n```\n\n#### 3. UART를 통한 명령 전송\n\n탐지된 결과에 따라 RC카를 제어하기 위해 Renesas 보드로 명령을 UART로 전송합니다:\n\n```python\nimport serial\n\nclass MotorController:\n    def __init__(self):\n        self.uart = serial.Serial(\"/dev/ttyAMA0\", baudrate=115200, timeout=1)\n\n    def move_forward(self):\n        self.uart.write(b\"FW\\n\")\n        print(\"Moving Forward\")\n\n    def turn_left(self):\n        self.uart.write(b\"LE\\n\")\n        print(\"Turning Left\")\n\n    def turn_right(self):\n        self.uart.write(b\"RI\\n\")\n        print(\"Turning Right\")\n\n    def stop(self):\n        self.uart.write(b\"ST\\n\")\n        print(\"Stopping\")\n```\n\n이 코드는 UART를 통해 명령을 전송하며, Renesas 보드에서 이를 수신해 모터 제어에 활용합니다.\n> print문은 디버깅을 위해 작성되어있음\n{: .prompt-tip }\n\n---\n\n### Renesas 보드: 명령 처리 및 하드웨어 제어\n\nRenesas FPB-RA6E1 보드는 Raspberry Pi로부터 전달받은 UART 명령을 기반으로 모터를 제어합니다. 명령은 하드웨어 추상화 레이어를 통해 모터 제어로 변환됩니다.\n\n#### 1. `motorhat.h`에서 레지스터 정의 및 API 설계\n\n`motorhat.h`는 모터햇의 레지스터를 코드로 추상화하는 부분과 API 선언이 작성되어 있습니다.\n\n```c\n#ifndef MOTORHAT_H_\n#define MOTORHAT_H_\n#include \"hal_data.h\"\n#define CENTER 320 //\n\nuint8_t __MODE1              = 0x00;\nuint8_t __MODE2              = 0x01;\nuint8_t __SUBADR1            = 0x02;\nuint8_t __SUBADR2            = 0x03;\nuint8_t __SUBADR3            = 0x04;\nuint8_t __PRESCALE           = 0xFE;\n...\n```\n\n- **레지스터 정의**: `__MODE1`은 초기화 모드를 설정하며, `__PRESCALE`은 PWM 주파수를 설정합니다.\n\nAPI 선언은 아래와 같으며 `motorhat.c`에 구현합니다.\n\n```c\nvoid iic_callback(i2c_master_callback_args_t *p_args);\nuint8_t read_byte_data(uint8_t reg);\nvoid write_byte_data(int reg, int val);\nvoid setPWM(int channel, int on, int off);\nvoid Forward();\nvoid Backward();\n...\n```\n\n---\n\n#### 2. 주요 함수 구현 (`motorhat.c`)\n\n##### 1. I2C 콜백 및 데이터 읽기\n\n```c\nvoid iic_callback(i2c_master_callback_args_t *p_args)\n{\n    g_iic_callback_event = p_args->event;\n}\n\nuint8_t read_byte_data(uint8_t reg)\n{\n    uint8_t buf;\n    R_IIC_MASTER_Write(&g_i2c_master0_ctrl, &reg, 1, true);\n    R_BSP_SoftwareDelay(50, BSP_DELAY_UNITS_MILLISECONDS);\n    while (g_iic_callback_event != I2C_MASTER_EVENT_TX_COMPLETE);\n    R_IIC_MASTER_Read(&g_i2c_master0_ctrl, &buf, 1, false);\n    while (g_iic_callback_event != I2C_MASTER_EVENT_RX_COMPLETE);\n    return buf;\n}\n```\n\n- `iic_callback`: I2C 통신 완료 시 호출됩니다.\n- `read_byte_data`: 특정 레지스터에서 데이터를 읽어옵니다.\n\n##### 2. PWM 설정 함수\n\n```c\nvoid setPWM(int channel, int on, int off)\n{\n    write8(__LED0_ON_L + 4 * channel, on & 0xFF);\n    write8(__LED0_ON_H + 4 * channel, on >> 8);\n    write8(__LED0_OFF_L + 4 * channel, off & 0xFF);\n    write8(__LED0_OFF_H + 4 * channel, off >> 8);\n}\n```\n\n- 특정 채널에서 PWM 신호를 생성합니다. `on` 및 `off` 값은 신호의 시작 및 끝을 정의합니다.\n\n##### 3. 동작 제어 함수\n\n```c\nvoid Forward()\n{\n    setPin(IN2pin, 0);\n    setPin(IN1pin, 1);\n}\n\nvoid Left(int *current_angle, int angle)\n{\n    if (angle > 125) angle = 125;\n    *current_angle = CENTER - angle;\n    setPWM(0, 0, *current_angle);\n}\n\nvoid Right(int *current_angle, int angle)\n{\n    if (angle > 125) angle = 125;\n    *current_angle = CENTER + angle;\n    setPWM(0, 0, *current_angle);\n}\n```\n\n- **`Forward()`**: 전진 동작을 수행합니다.\n- **`Left()` 및 `Right()`**: 각도를 기반으로 RC카를 회전시킵니다.\n\n---\n\n### 하드웨어 다이어그램\n\n![HW Diagram](/assets/img/rccar/img2.png){: .center}\n\n### 라즈베리파이 코드 모듈\n![Code Diagram](/assets/img/rccar/img3.png){: .center}\n\n---\n\n## 결론 및 시연영상\n<iframe width=\"840\" height=\"476\" src=\"https://www.youtube.com/embed/sx9A7bn4dmM?si=dJHsMTD-1YUI3VY7\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n<br>\n\n라즈베리파이에서 ArUco마커를 인식하고, 명령어를 Renesas보드로 보내 정상적으로 RC카를 제어할 수 있었습니다.\n\n현재 코드는 ArUco마커의 ID 만을 활용해 좌회전 혹은 정지 명령어를 생성하기에 단순한 기능만 적용되어 있습니다. \n하지만, 마커의 pose estimation을 활용한다면 더욱 활용성 높게 사용할 수 있을 것이라 기대합니다.\n\n### Github Repo\n프로젝트에 활용한 코드는 아래 링크에서 참고\n[https://github.com/knowgyu/Renesas-RPi4-Rccar](https://github.com/knowgyu/Renesas-RPi4-Rccar)\n",
    "date": "2024-12-10",
    "tags": [
      "Embedded System",
      "RC-car",
      "PJT",
      "Raspberry",
      "Renesas"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-10-Aruco--------------RC_chunk_0",
        "text": "Aruco 마커를 활용한 자율주행 RC카\n\n## Aruco 마커를 활용한 자율주행 RC카\n\n이 글은 **라즈베리파이 4**와 **Renesas FPB-RA6E1 보드**를 활용해 Aruco 마커를 탐지하고 자율주행 RC카를 제어하는 프로젝트의 내용을 다룹니다. 프로젝트는 크게 라즈베리파이에서의 비전 처리와 Renesas 보드에서의 하드웨어 제어로 구성됩니다.\n\n### Flow Chart\n프로젝트 시작 전, 간단한 제어 흐름은 아래와 같이 생각했습니다.\n![Flow Chart](/assets/img/rccar/img1.png){: .center}\n\n### ArUco 마커를 선택한 이유\n스마트홈 혹은 스마트팩토리 등 실내 환경에서 사용할 경우, GPS 신호를 정확하게 받아올 수 없기에 현재 위치를 알아내는 것에 어려움이 있습니다.\n\n이를 위해 LiDAR 센서 혹은 RGB-D 카메라를 활용한 SLAM 기술이 있습니다.\n\n하지만, ArUco마커를 활용한다면 위 센서들보단 저렴한 RGB카메라만으로 현재 위치를 알아낼 수 있어 이를 활용한 프로젝트를 진행합니다.\n> 물론, ArUco 마커를 사용한다면 제한된 환경에서만 적용 가능할 것이라 생각됩니다.\n{: .prompt-info }\n\n\n---\n\n### Raspberry Pi: 웹 서버, Aruco 탐지 및 모터 컨트롤\n\n#### 1. Flask 기반 웹 서버\n\nRaspberry Pi에서 Flask를 사용하여 웹 서버를 구동합니다. 이 서버는 RC카의 상태를 모니터링하고 제어할 수 있는 UI를 제공합니다.",
        "index": 0
      },
      {
        "id": "2024-12-10-Aruco--------------RC_chunk_1",
        "text": "1. Flask 기반 웹 서버\n\nRaspberry Pi에서 Flask를 사용하여 웹 서버를 구동합니다. 이 서버는 RC카의 상태를 모니터링하고 제어할 수 있는 UI를 제공합니다.",
        "index": 1
      },
      {
        "id": "2024-12-10-Aruco--------------RC_chunk_2",
        "text": "1. Flask 기반 웹 서버\n\nRaspberry Pi에서 Flask를 사용하여 웹 서버를 구동합니다. 이 서버는 RC카의 상태를 모니터링하고 제어할 수 있는 UI를 제공합니다.",
        "index": 2
      },
      {
        "id": "2024-12-10-Aruco--------------RC_chunk_3",
        "text": "1. Flask 기반 웹 서버\n\nRaspberry Pi에서 Flask를 사용하여 웹 서버를 구동합니다. 이 서버는 RC카의 상태를 모니터링하고 제어할 수 있는 UI를 제공합니다.",
        "index": 3
      },
      {
        "id": "2024-12-10-Aruco--------------RC_chunk_4",
        "text": "1. Flask 기반 웹 서버\n\nRaspberry Pi에서 Flask를 사용하여 웹 서버를 구동합니다. 이 서버는 RC카의 상태를 모니터링하고 제어할 수 있는 UI를 제공합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-12-05",
    "title": "당구공 경로 생성기",
    "path": "/2024/12/05/당구공-경로-생성-프로젝트/",
    "categories": [
      "AI & CV",
      "Computer Vision",
      "Project",
      "Computer_Vision"
    ],
    "content": "## 개요\n**OpenCV**를 사용하여 비디오 파일에서 **당구공의 경로를 추적**하고 시각화하는 프로그램입니다. <br>\n\n**아래는 세계 당구 선수권 대회 중계에서 경로를 생성하는 예시 영상입니다.**\n![산체스](/assets/img/cv/bil1.gif){: .center}\n<br>\n\n**실제 프로그램 동작 영상**\n\n![내꺼](/assets/img/cv/bil2.gif){: .center}\n\n\n하지만, 실제 환경에서는 이처럼 버드아이뷰로 영상을 획득하지 못하는 상황을 고려해야 합니다.\n![실제영상](/assets/img/cv/bil3.gif){: .center}\n<br>\n이를 위해 perspective transform을 적용합니다.\n\n---\n\n## 프로젝트 설명\n주어진 비디오 파일에서 **노란색과 흰색 당구공**을 찾아 **경로를 추적**합니다. 사용자는 **마우스 클릭**을 통해 비디오의 4개 모서리를 지정하면 Perspective 변환을 적용해 비디오를 정사각형 형태로 투영합니다.\n\n### 주요 기능\n1. **마우스 이벤트**를 통해 비디오의 네 꼭짓점 수집\n2. **Perspective 변환**을 통한 비디오 투영\n3. **색상 및 원형성**을 기반으로 당구공 탐지\n4. 공의 궤적을 실시간으로 시각화\n\n---\n\n## 코드 분석 및 설명\n\n### 1. 공 경로 시각화 함수\n공의 경로를 추적하기 위해 좌표 리스트를 받아 **선(Line)**을 그려주는 함수입니다.\n\n```python\ndef draw_ball_location(img_color, locations, t_color):\n    for i in range(len(locations) - 1):\n        if locations[0] is None or locations[1] is None:\n            continue\n        cv2.line(img_color, tuple(locations[i]), tuple(locations[i + 1]), t_color, 2)\n    return img_color\n```\n\n---\n\n### 2. 마우스 이벤트 핸들러\n사용자의 **마우스 클릭 이벤트**를 처리하여 비디오의 꼭짓점을 수집합니다.\n\n```python\ndef handle_mouse_events(event, x, y, flags, params):\n    global point_list, pts_cnt, frame\n    if event == cv2.EVENT_LBUTTONDOWN:\n        print(f\"({x}, {y})\")\n        point_list.append((x, y))\n        pts_cnt += 1\n        cv2.circle(frame, (x, y), 7, (0, 0, 255), -1)\n        cv2.imshow('original', frame)\n```\n\n---\n\n### 3. Perspective 변환\n선택된 꼭짓점을 기준으로 비디오를 **투영 변환**합니다.\n\n```python\ndef get_perspective_transform(points):\n    sm = points.sum(axis=1)\n    diff = np.diff(points, axis=1)\n\n    topLeft = points[np.argmin(sm)]\n    bottomRight = points[np.argmax(sm)]\n    topRight = points[np.argmin(diff)]\n    bottomLeft = points[np.argmax(diff)]\n\n    pts1 = np.float32([topLeft, topRight, bottomRight, bottomLeft])\n    w1 = abs(bottomRight[0] - bottomLeft[0])\n    w2 = abs(topRight[0] - topLeft[0])\n    h1 = abs(topRight[1] - bottomRight[1])\n    h2 = abs(topLeft[1] - bottomLeft[1])\n    width, height = max(w1, w2), max(h1, h2)\n    pts2 = np.float32([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]])\n\n    return cv2.getPerspectiveTransform(pts1, pts2), (int(width), int(height))\n```\n\n---\n\n### 4. 비디오 프레임 처리 및 공 탐지\n공의 **색상과 원형성**을 기준으로 흰색 및 노란색 공을 탐지합니다.\n\n```python\ndef process_frame(frame, M, width, height, list_whiteball_location, list_yellowball_location):\n    frame = cv2.warpPerspective(frame, M, (width, height))\n    img_blur = cv2.GaussianBlur(frame, (7, 7), 0)\n    img_gray = cv2.cvtColor(img_blur, cv2.COLOR_BGR2GRAY)\n    _, img_bin = cv2.threshold(img_gray, 160, 255, cv2.THRESH_BINARY)\n    img_bin = cv2.morphologyEx(img_bin, cv2.MORPH_DILATE, np.ones((5, 5), np.uint8))\n    contours, _ = cv2.findContours(img_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n    for cnt in contours:\n        mmt = cv2.moments(cnt)\n        if mmt['m00'] == 0: continue\n        area = mmt['m00']\n        if area < 450 or area > 700: continue\n\n        cx, cy = int(mmt['m10'] / area), int(mmt['m01'] / area)\n        perimeter = cv2.arcLength(cnt, True)\n        circular = 4 * pi * area / (perimeter * perimeter)\n        color = frame[cy, cx]\n\n        if color.min() > 225 and circular > 0.85:  # 흰공\n            list_whiteball_location.append((cx, cy))\n            draw_ball_location(frame, list_whiteball_location, (255, 255, 255))\n        elif color.min() < 70 and circular > 0.72:  # 노란공\n            list_yellowball_location.append((cx, cy))\n            draw_ball_location(frame, list_yellowball_location, (0, 255, 255))\n\n    return frame, img_bin\n```\n\n---\n\n## 실행 방법\n\n### 명령어\n터미널에서 다음 명령어로 실행합니다.\n\n```bash\npython script.py <video_path>\n```\n\n프로그램 실행 후, 당구대의 네 꼭지점을 클릭하면 원근 보정 후 트래킹 영상이 실행됩니다.\n\n\n### 예시\n```bash\npython script.py sample_video.mp4\n```\n\n\n\n---\n\n## 실행 영상 및 정리\n이 프로그램은 OpenCV를 활용하여 비디오에서 **당구공을 탐지**하고 경로를 시각화하는 프로젝트입니다. \n\n트래킹을 위한 Mean Shift, CAM Shift와 배경제거 알고리즘 MOG를 활용해 테스트를 진행해 보았지만, 이처럼 직접 당구공을 Object Detection한 후 경로를 생성하는 것이 가장 성능이 좋았습니다.\n\n> 조명과 당구공의 빛 반사로 인해 픽셀값이 명확하지 않아 발생하는 문제라 생각합니다.\n> 특히, 나사지가 균일한 파란색이 아닌, 조명으로 인해 하얗게 보이는 부분이 있기에 이런 문제가 발생한다고 판단하여, 직접 Circularity를 계산해 공을 추적하는 것으로 작성했습니다.\n{: .prompt-info }\n\n아래 영상에서 순서대로 CAM Shift, Mean Shift 알고리즘을 적용한 결과, 그리고 MOG2 배경제거 알고리즘을 이용해 공을 추적한 결과, 그리고 글에 작성한 코드로 실행한 결과로 이뤄져 있습니다.\n\n### 시연 영상1\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/xCMkWAt3ssk?si=ZxfUjpT3rGuryMhO\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n### 시연 영상2\n\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/oh3lbJkI3fk?si=gZLVEL68i9iZqdpq\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n\n## 코드 레포\n[https://github.com/knowgyu/Billiard-Tracking](https://github.com/knowgyu/Billiard-Tracking)\n\nCAM Shift와 Mean Shift 코드는 위 저장소에서 확인할 수 있습니다.\n",
    "date": "2024-12-05",
    "tags": [
      "OpenCV",
      "영상 처리",
      "PJT",
      "Object Detection"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-12-05_chunk_0",
        "text": "당구공 경로 생성기\n\n## 개요\n**OpenCV**를 사용하여 비디오 파일에서 **당구공의 경로를 추적**하고 시각화하는 프로그램입니다. <br>\n\n**아래는 세계 당구 선수권 대회 중계에서 경로를 생성하는 예시 영상입니다.**\n![산체스](/assets/img/cv/bil1.gif){: .center}\n<br>\n\n**실제 프로그램 동작 영상**\n\n![내꺼](/assets/img/cv/bil2.gif){: .center}\n\n\n하지만, 실제 환경에서는 이처럼 버드아이뷰로 영상을 획득하지 못하는 상황을 고려해야 합니다.\n![실제영상](/assets/img/cv/bil3.gif){: .center}\n<br>\n이를 위해 perspective transform을 적용합니다.\n\n---\n\n## 프로젝트 설명\n주어진 비디오 파일에서 **노란색과 흰색 당구공**을 찾아 **경로를 추적**합니다. 사용자는 **마우스 클릭**을 통해 비디오의 4개 모서리를 지정하면 Perspective 변환을 적용해 비디오를 정사각형 형태로 투영합니다.\n\n### 주요 기능\n1. **마우스 이벤트**를 통해 비디오의 네 꼭짓점 수집\n2. **Perspective 변환**을 통한 비디오 투영\n3. **색상 및 원형성**을 기반으로 당구공 탐지\n4. 공의 궤적을 실시간으로 시각화\n\n---\n\n## 코드 분석 및 설명\n\n### 1.",
        "index": 0
      },
      {
        "id": "2024-12-05_chunk_1",
        "text": "ective 변환**을 통한 비디오 투영\n3. **색상 및 원형성**을 기반으로 당구공 탐지\n4. 공의 궤적을 실시간으로 시각화\n\n---\n\n## 코드 분석 및 설명\n\n### 1. 공 경로 시각화 함수\n공의 경로를 추적하기 위해 좌표 리스트를 받아 **선(Line)**을 그려주는 함수입니다.\n\n```python\ndef draw_ball_location(img_color, locations, t_color):\n    for i in range(len(locations) - 1):\n        if locations[0] is None or locations[1] is None:\n            continue\n        cv2.line(img_color, tuple(locations[i]), tuple(locations[i + 1]), t_color, 2)\n    return img_color\n```\n\n---\n\n### 2.",
        "index": 1
      },
      {
        "id": "2024-12-05_chunk_2",
        "text": "or, tuple(locations[i]), tuple(locations[i + 1]), t_color, 2)\n    return img_color\n```\n\n---\n\n### 2. 마우스 이벤트 핸들러\n사용자의 **마우스 클릭 이벤트**를 처리하여 비디오의 꼭짓점을 수집합니다.\n\n```python\ndef handle_mouse_events(event, x, y, flags, params):\n    global point_list, pts_cnt, frame\n    if event == cv2.EVENT_LBUTTONDOWN:\n        print(f\"({x}, {y})\")\n        point_list.append((x, y))\n        pts_cnt += 1\n        cv2.circle(frame, (x, y), 7, (0, 0, 255), -1)\n        cv2.imshow('original', frame)\n```\n\n---\n\n### 3.",
        "index": 2
      },
      {
        "id": "2024-12-05_chunk_3",
        "text": "v2.circle(frame, (x, y), 7, (0, 0, 255), -1)\n        cv2.imshow('original', frame)\n```\n\n---\n\n### 3.",
        "index": 3
      },
      {
        "id": "2024-12-05_chunk_4",
        "text": "v2.circle(frame, (x, y), 7, (0, 0, 255), -1)\n        cv2.imshow('original', frame)\n```\n\n---\n\n### 3.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-10",
    "title": "[RTOS개발] 10장 컨텍스트 스위칭",
    "path": "/2024/11/05/10장-컨텍스트-스위칭/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 컨텍스트 스위칭에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81](https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81)\n{: .prompt-tip }\n\nTest 코드 수정버전 :\n> [https://github.com/navilera/Navilos/commit/273b96189c6adf8f402f02f9f5ee103589492256](https://github.com/navilera/Navilos/commit/273b96189c6adf8f402f02f9f5ee103589492256)\n{: .prompt-tip }\n\n## 서론\n***\n컨텍스트 스위칭이란 이름 그대로 컨텍스트를 전환한다는 것입니다.\n\n현재 태스크 컨텍스트를 태스크의 스택에 저장되어 있습니다.\n\n그러므로 컨텍스트 스위칭은 아래와 같은 과정으로 진행됩니다.\n\n1. 현재 동작하고 있는 태스크의 컨텍스트를 현재 스택에 백업\n2. 다음에 동작할 태스크 컨트롤 블록을 스케줄러에서 받아오기\n3. 2에서 받은 태스크 컨트롤 블럭에서 스택 포인터 읽기\n4. 3에서 읽은 태스크의 스택에서 컨텍스트를 읽어서 ARM 코어에 복구\n5. 다음에 동작할 태스크의 직전 프로그램 실행 위치로 이동.<br>\n  (이러면 이제 현재 동작하고 있는 태스크가 됨)\n\n이를 코드로 옮기면 아래와 같습니다.\n\n### `kernel/task.c` 스케줄러 함수\n\n```c\nstatic KernelTcb_t* sCurrent_tcb;\nstatic KernelTcb_t* sNext_tcb;\n...\n...\n  ...\nvoid Kernel_task_scheduler(void)\n{\n  sCurrent_tcb = &sTask_list[sCurrent_tcb_index];\n  sNext_tcb = Scheduler_round_robin_algorithm();\n\n  Kernel_task_context_switching();\n}\n```\n\n`sCurrent_tcb` 는 현재 동작 중인 태스크 컨트롤 블록의 포인터입니다.\n\n`sNext_tcb`는 라운드 로빈 알고리즘이 선택한 다음에 동작할 TCB의 포인터입니다.\n\n이 두 포인터를 확보한 후, 11번째 줄에서 컨텍스트 스위칭 함수를 호출합니다.\n\n### 컨텍스트 스위칭 함수\n\n```c\n__attribute__ ((naked)) void Kernel_task_context_switching(void)\n{\n\t__asm__ (\"B Save_context\");\n\t__asm__ (\"B Restore_context\");\n}\n```\n\n### `__attribute__ ((naked))`\n\n: GCC 컴파일러의 어트리뷰트 기능인데, 어트리뷰트를 naked라고 설정하면 컴파일러가 함수를 컴파일할 때 자동으로 만드는 스택 백업, 복구, 리턴 관련 **어셈블리어가 전혀 생성되지 않고** 내부에 코딩한 코드 자체만 남습니다.\n\n위 함수를 역어셈블해서 보면 아래와 같습니다.\n\n```bash\n0000021c <Kernel_task_context_switching>:\n 21c:  ea000000    b    224 <Save_context>\n 220:  ea000006    b    240 <Restore_context>\n```\n\n위처럼 인라인 어셈블리로 코딩한 두 줄이 그대로 컴파일되고 다른 코드는 없습니다.\n\n어트리뷰트 기능을 사용하지 않으면 아래와 같은 역어셈블 결과가 나옵니다.\n\n```bash\n0000021c <Kernel_task_context_switching>:\n 21c:  e52db004    push {fp}    ; (str fp, [sp, #-4]!)\n 220:  528db000    add  fp, sp, #0\n 224:  ea000000    b    238 <Save_context>\n 228:  ea000006    b    254 <Restore_context>\n 22c:  e24bd000    sub  sp, fp, #0\n 230:  e49db004    pop  {fp}    ; (ldr fp. [sp], #4)\n 234:  e12fff1e    bx   lr\n```\n\n> C 언어 코드 파일에서 코딩한 내용의 앞뒤로 스택을 확보하는 코드와 리턴하는 코드가 추가됨.\n{: .prompt-info }\n\nNavilos는 컨텍스트를 스택에 백업하고 스택에 복구할 것이므로 컨텍스트 스위칭할 때 되도록 스택을 그대로 유지하는 것이 좋습니다.\n\n→ `__attribute__ ((naked))` 기능을 사용\n\n![image.png](/assets/img/OS/os1001.png)\n\n위 그림은 Navilos의 컨텍스트 스위칭 과정을 설명하는 그림입니다.\n\nTask#1이 현재 동작 중인 태스크입니다. Task#2가 다음 동작할 태스크입니다.\n\nTask#1의 현재 스택 포인터에 그대로 현재 컨텍스트를 백업합니다.\n\n**✨스택 포인터만 따로 저장하는 이유**<br>\n: 커널이 스택 포인터의 위치를 쉽게 가져올 수 있어야 스택에서 컨텍스트를 복구할 수 있다.\n\nTask#2의 TCB에서 스택 포인터 값을 읽습니다. 그리고 범용 레지스터 SP에 그 값을 씁니다.\n\n그러면 ARM 코어에서는 스택 포인터가 바로 바뀝니다.\n\n그 상태에서 스택 관련 어셈블리 명령을 사용해서 컨텍스트를 복구합니다.\n\n컨텍스트를 복구하면서 자연스럽게 스택 포인터를 Task#2가 컨텍스트 스위칭을 하기 직전의 정상적인 스택 포인터 위치로 복구합니다.\n\nNavilos의 컨텍스트 스위칭은 엄밀하게 말하면 윈도우나 리룩스의 프로세스 전환하는 컨텍스트 스위칭보다는 한 프로세스 안에서 쓰레드(thread) 간에 전환을 하는 모습에 더 가깝습니다.\n\n\n## 컨텍스트 백업하기\n***\n컨텍스트는 현재 동작 중인 태스크의 스택에 직접 백업하니다.\n\n따라서 앞서 정의한 컨텍스트 자료 구조에 따라 스택 명령어의 순서를 맞춰야 합니다.\n\n```c\ntypedef struct KernelTaskContext_t\n{\n\tuint32_t spsr;\n\tuint32_t r0_r12 [13];\n\tuint32_t pc;\n} KernelTaskContext_t;\n```\n\n`spsr`, `r0_r12` , `pc` 순서입니다.\n\n스택은 메모리 주소가 큰 값에서 작은 값으로 진행하기에, 이 구조체에 맞춰 컨텍스트를 백업할 땐 `pc`, `r0_r12` , `spsr` 순서로 백업해야 의도한 자료 구조에 맞게 값이 저장됩니다.\n\n### 컨텍스트 백업 코드\n\n```c\nstatic __attribute__ ((naked)) void Save_context(void)\n{\n  // save current task context into the current task stack\n  __asm__ (\"PUSH {lr}\");\n  __asm__ (\"PUSH {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12}\");\n  __asm__ (\"MRS   r0, cpsr\");\n  __asm__ (\"PUSH {r0}\");\n  // save current task stack pointer into the current TCB\n  __asm__ (\"LDR   r0, =sCurrent_tcb\");\n  __asm__ (\"LDR   r0, [r0]\");\n  __asm__ (\"STMIA r0!, {sp}\");\n}\n```\n\n**4번째 줄**에서 LR을 스택에 푸시합니다. → `pc` 멤버 변수 저장\n\n나중에 태스크가 다시 스케줄링을 받았을 때 복귀하는 위치는 `pc` 멤버 변수가 저장하고 있고, 이 위치는 `Kernel_task_context_switching()` 함수의 리턴 주소입니다.\n\n그러므로 `pc` 멤버 변수에 현재 컨텍스트의 LR값을 그대로 저장하는 것입니다.\n\n**5번째 줄**이 범용 레지스터인 R0부터 R12까지 스택에 푸시하는 코드입니다.\n\n여기까지 진행하며 현재 R0부터 R12에 다른 값을 덮어 쓰지 않았으므로 이 값은 스위칭 함수를 호출하기 **전 값이 유지**되고 있습니다.\n\n→ 어트리뷰트 ((naked)) 지시어를 사용하는 이유\n\n**6,7번째 줄**이 CPSR을 `KernelTaskContext_t` 의 `spsr` 멤버 변수 위치에 저장하는 코드입니다.\n\n프로그램 상태 레지스터는 직접 메모리에 저장할 수 없으니 R0를 사용합니다.\n\n**9번째 줄**은 현재 동작 중인 TCB의 포인터 변수를 읽는 코드입니다.\n\n**10번째 줄**에서 포인터에 저장된 값을 읽습니다.\n\n포인터에 저장된 값이 주솟값이므로 `r0`로 TCB의 온전한 메모리 위치를 읽습니다.\n\n**11번째 줄**은 10번째 줄에서 읽은 값을 베이스 메모리 주소로 해서 SP를 저장하는 코드입니다.\n\n9~11번째 줄을 C언어로 표현하면\n\n```c\nsCurrent_tcb->sp = ARM_코어_SP_레지스터값;\n// 혹은\n(uint32_t)(*sCurrent_tcb) = ARM_코어_SP_레지스터값;\n```\n\n> TCB 구조체의 첫 번째 멤버 변수가 `sp` 이므로 포인터 값을 읽어 사용할 수 있습니다.\n두 번째 멤버 변수일 경우 4바이트를 더해야 하나, 추가 작업을 없애기 위해 첫 번째 멤버 변수로 사용합니다.\n{: .prompt-tip }\n\n## 컨텍스트 복구하기\n***\n컨텍스트를 복구하는 작업은 백업하는 작업의 역순입니다.\n\n### 컨텍스트 복구 코드\n\n```c\nstatic __attribute__ ((naked)) void Restore_context(void)\n{\n  // restore next task stack pointer from the next TCB\n  __asm__ (\"LDR   r0, =sNext_tcb\");\n  __asm__ (\"LDR   r0, [r0]\");\n  __asm__ (\"LDMIA r0!, {sp}\");\n  // restore next task context from the next task stack\n  __asm__ (\"POP  {r0}\");\n  __asm__ (\"MSR   cpsr, r0\");\n  __asm__ (\"POP  {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12}\");\n  __asm__ (\"POP  {pc}\");\n}\n\n```\n\n형태가 `Save_context()` 함수와 동일하며, 동작만 역순일 뿐입니다.\n\n- `sNext_tcb` 에서 스택 포인터 값 읽어오기\n\n4~6번째 줄이 TCB의 `sp` 멤버 변수의 값을 읽어 ARM 코어의 SP에 쓰는 작업입니다.\n\n- CSPR 복구\n\n8,9번째 줄이 스택에 저장된 `cpsr` 값을 꺼내 ARM코어의 CPSR에 쓰는 작업입니다.\n\n백업 시 PUSH 명령을 사용하고 복구할 땐 POP 명령을 사용합니다.\n\n- 범용 레지스터 복구\n\n10번째 줄이 R0 ~ R12 범용 레지스터를 복구하는 코드입니다.\n\n이 시점 이후로는 R0 ~ R12 값을 변경하면 복구에 실패하게 됩니다.\n\n그래서 11번째 줄에서 스택 값을 꺼내 PC에 저장하면서 태스크 코드로 점프합니다.\n\n11번째 줄이 실행되는 순간 ARM코어는 컨텍스트 백업 전 코드 위치로 PC를 옮기고 실행을 이어서 합니다. \n\n## yield 만들기\n***\n스케줄러와 컨텍스트 스위칭이 있으면 태스크를 전환할 수 있습니다.\n\n**스케줄러와 컨텍스트 스위칭을 합쳐 스케줄링(scheduling)**이라 합니다.\n\n### 시분할 시스템\n\n정기적으로 발생하는 타이머 인터럽트에 연동해 스케줄링하고\n\n각 태스크가 일정한 시간만 동작하고 다음 태스크로 전환되는 시스템\n\nex) 100ms마다 스케줄링을 하도록 설정하면 태스크들은 각각 100ms씩 동작하고 다음 태스크로.\n\n### 선점형 멀티태스킹 시스템\n\n태스크가 명시적으로 스케줄링을 요청하지 않았는데 커널이 강제로 스케줄링하는 시스템\n\n### 비선점형 멀티태스킹 시스템\n\n반대로 태스크가 명시적으로 스케줄링을 요청하지 않으면 커널이 스케줄링하지 않는 시스템\n\n> **일반적으로 시분할 시스템은 거의 선점형 멀티태스킹 시스템!**\n{: .prompt-tip }\n\nNavilos 프로젝트에선 시분할이 아닌 비선점형 스케줄링을 사용\n\n→ 스케줄링하려면 태스크가 명시적으로 커널에 스케줄링을 요청해야 함\n\n→ 태스크가 CPU 자원을 다음 태스크에 양보한다는 의미로 해석 가능\n\n→ `yield()` 함수 작성해야 한다!\n\n### `yield()` 함수 작성하기\n\n커널 API를 별도로 만들어 외부에서 사용\n\n`kernel/Kernel.c` 와 `kernel/Kernel.h` 파일 만들기\n\n### `kernel/Kernel.h` yield 커널 API 정의\n\n```c\n#ifndef KERNEL_KERNEL_H_\n#define KERNEL_KERNEL_H_\n\n#include \"task.h\"\n\nvoid Kernel_yield(void);\n\n#endif /* KERNEL_KERNEL_H_ */\n```\n\n### `kernel/Kernel.c` yield 커널 API 구현\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n\n#include \"Kernel.h\"\n\nvoid Kernel_yield(void)\n{\n\tKernel_task_scheduler();\n}\n```\n\n구현은 매우 간단하게 `Kernel_task_scheduler()` 함수를 호출하면 됩니다. \n\n태스크가 더 이상 할 일이 없을 때 `Kernel_yield()` 함수를 호출\n\n→ 즉시 스케줄러를 호출해 다음에 동작할 태스크를 선정합니다.\n\n→ 컨텍스트 스위칭 수행\n\n→ `Kernel_yield()` 함수를 호출한 태스크의 컨텍스트를 백업하고 스케줄러가 선정한 태스크의 스택 포인터를 복구\n\n→ 스택 포인터로부터 컨텍스트 복구\n\n→ 다음 동작할 코드의 위치는 태스크의 `Kernel_yield()`의 리턴 코드 직전\n\n→ 즉, 스케줄링 직후로 돌아와서 다음 태스크가 CPU를 사용\n\n## 커널 시작하기\n***\n앞 장에서 커널에 태스크를 세 개 생성했습니다(더미 태스크).\n\n이제 스케줄러도 있고 컨텍스트 스위칭도 있으니 커널을 시작해 태스크 세 개를 동작시킬 수 있습니다.\n\n하지만, 처음 커널을 시작할 때 스케줄러를 그냥 실행하면 **태스크가 동작하지 않습니다.**\n\n→ 커널을 **시작할 땐 현재 동작 중인 태스크가 없기 때문**!\n\n**즉, 최초로 스케줄러를 실행할 때는 컨텍스트 백업을 하지 않아야 합니다.**\n\n최초 스케줄링 시 컨텍스트 복구만 하면 됩니다.\n\n최초 스케줄링이니까 스케줄러를 거치지 말고 그냥 0번 TCB를 복구 대상으로 삼습니다.\n\n커널 소스 코드에 있는 TCB 인덱스를 저장하고 있는 정적 전역 변수의 초기 값을 바로 사용합니다.\n\n### `kernel/task.c` 첫 번째 스케줄링만 처리하는 코드\n\n```c\nstatic KernelTcb_t  sTask_list[MAX_TASK_NUM];\nstatic KernelTcb_t* sCurrent_tcb;\nstatic KernelTcb_t* sNext_tcb;\nstatic uint32_t     sAllocated_tcb_index;\nstatic uint32_t     sCurrent_tcb_index;\n...\n...\n...\nvoid Kernel_task_init(void)\n{\n    sAllocated_tcb_index = 0;\n    sCurrent_tcb_index = 0;\n    for(uint32_t i = 0 ; i < MAX_TASK_NUM ; i++)\n    {\n        sTask_list[i].stack_base = (uint8_t*)(TASK_STACK_START + (i * USR_TASK_STA    CK_SIZE));\n        sTask_list[i].sp = (uint32_t)sTask_list[i].stack_base + USR_TASK_STACK_SIZ    E - 4;\n        sTask_list[i].sp -= sizeof(KernelTaskContext_t);\n        KernelTaskContext_t* ctx = (KernelTaskContext_t*)sTask_list[i].sp;\n        ctx->pc = 0;\n        ctx->spsr = ARM_MODE_BIT_SYS;\n    }\n}\nvoid Kernel_task_start(void)\n{\n    sNext_tcb = &sTask_list[sCurrent_tcb_index];\n    Restore_context();\n}\n\n```\n\n5번째 줄은 현재 실행 중인 태스크의 TCB 인덱스를 저장하고 있는 정적 전역 변수를 선언합니다.\n\n이 변수를 12번째 줄에서 0으로 초기화합니다.\n\n그리고 26~30번째 줄은 커널이 시작할 때 최초 한 번만 호출하는 함수입니다.\n\n**이전에 말했듯 0번 TCB를 다음 태스크로 선정하고, 컨텍스트 복구만 실행합니다.(백업없이)**\n\n이제, `Kernel_task_start()` 함수를 커널 API인 `Kernel_start()` 함수에 연결하고 `main()`에서 호출해 실행해 보겠습니다.\n\n### `kernel/Kernel.h` `Kernel_start()` 함수를 추가\n\n```c\n#ifndef KERNEL_KERNEL_H_\n#define KERNEL_KERNEL_H_\n\n#include \"task.h\"\n\n**void Kernel_start(void);**\nvoid Kernel_yield(void);\n\n#endif /* KERNEL_KERNEL_H_ */\n```\n\n앞으로 추가할 커널 관련 초기화 함수를 `Kernel_start()` 함수에 모아서 한번에 실행할 계획입니다.\n\n`Kernel_start()` 함수에서 커널 초기화를 담당하는 것입니다.\n\n### `kernel/Kernel.c` 최초의 `Kernel_start()` 함수\n\n```c\nvoid Kernel_start(void)\n{\n\tKernel_task_start();\n}\n```\n\n`Kernel_start()` 함수를 호출하는 코드를 `main()` 함수에 추가하고 QEMU를 실행해 보겠습니다.\n\n### `boot/Main.c` `main()` 함수에서 커널 시작하기\n\n```c\nstatic void Kernel_init(void)\n{\n    uint32_t taskId;\n\n    Kernel_task_init();\n\n    taskId = Kernel_task_create(User_task0);\n\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task0 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task1);\n\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task1 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task2);\n\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task2 creation fail\\n\");\n    }\n\n    Kernel_start();\n}\n```\n\n여기에 더불어 사용자 새트크가 제대로 스택을 할당받았는지 확인해 보는 코드를 추가해 정상적으로 동작하는지 확인하겠습니다.\n\n아무 이름으로나 로컬 변수를 하나 선언하고 `debug_printf()`로 변수의 주소 값을 출력합니다.\n\n### 사용자 태스크의 스택 주소를 확인하는 코드\n\n```c\nvoid User_task0(void)\n{\n  uint32_t local = 0;\n\n  while(true)\n  {\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n    Kernel_yield();\n  }\n}\n\nvoid User_task1(void)\n{\n  uint32_t local = 0;\n\n  while(true)\n  {\n    debug_printf(\"User Task #1 SP=0x%x\\n\", &local);\n    Kernel_yield();\n  }\n}\n\nvoid User_task2(void)\n{\n  uint32_t local = 0;\n\n  while(true)\n  {\n    debug_printf(\"User Task #2 SP=0x%x\\n\", &local);\n    Kernel_yield();\n  }\n}\n\n```\n\n세 태스크 모두 `local` 이름으로 로컬 변수를 선언하고 해당 변수의 주소 값을 출력하는 코드가 이어집니다.\n\n의도한 대로 동작한다면 세 태스크의 로컬 변수 주소(스택 주소)가 출력될 것입니다.\n\n```bash\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os1002.png)\n\n각 태스크의 스택 주소 차이가 0x10 0000이므로 간격이 딱 1MB씩입니다.\n\n일단 스택 간격은 의도한대로 잘 할당되었습니다.\n\n그리고, `include/MemoryMap.h` 파일에서 `TASK_STACK_START` 의 값을 0x80 0000으로 작성했습니다.\n\n이 값이 Task#0의 스택 베이스 주소입니다.\n\n스택 포인터에는 스택 공간의 최댓값을 할당합니다.\n\n그리고 태스크 스택 간 4바이트 간격을 패딩으로 설계했습니다.\n\n→ TCB 초기화 후 할당된 스택 포인터의 초기 값은 0x8F FFFC입니다.\n\n여기에 컴파일러가 사용하는 스택이 몇 개 되고 그다음에 로컬 변수가 스택에 잡히므로\n\n0x8F FFF0으로 출력된 것입니다.\n\n## 요약\n***\n이 장에서는 컨텍스트 스위칭을 만들었습니다.\n\n일반적으로 쉽게 이해할 수 있는 함수 호출-리턴이 아닌\n\n강제로 컨텍스트를 백업-리스토어하는 것이라 어려웠을 것입니다.\n\n다음 장에서는 이벤트를 구현해 일단 태스크 간 간단한 신호부터 주고받아 보겠습니다.\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-10_chunk_0",
        "text": "[RTOS개발] 10장 컨텍스트 스위칭\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 컨텍스트 스위칭에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81](https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81)\n{: .prompt-tip }\n\nTest 코드 수정버전 :\n> [https://github.com/navilera/Navilos/commit/273b96189c6adf8f402f02f9f5ee103589492256](https://github.com/navilera/Navilos/commit/273b96189c6adf8f402f02f9f5ee103589492256)\n{: .prompt-tip }\n\n## 서론\n***\n컨텍스트 스위칭이란 이름 그대로 컨텍스트를 전환한다는 것입니다.\n\n현재 태스크 컨텍스트를 태스크의 스택에 저장되어 있습니다.\n\n그러므로 컨텍스트 스위칭은 아래와 같은 과정으로 진행됩니다.\n\n1. 현재 동작하고 있는 태스크의 컨텍스트를 현재 스택에 백업\n2. 다음에 동작할 태스크 컨트롤 블록을 스케줄러에서 받아오기\n3. 2에서 받은 태스크 컨트롤 블럭에서 스택 포인터 읽기\n4.",
        "index": 0
      },
      {
        "id": "2024-11-05-10_chunk_1",
        "text": "동작하고 있는 태스크의 컨텍스트를 현재 스택에 백업\n2. 다음에 동작할 태스크 컨트롤 블록을 스케줄러에서 받아오기\n3. 2에서 받은 태스크 컨트롤 블럭에서 스택 포인터 읽기\n4. 3에서 읽은 태스크의 스택에서 컨텍스트를 읽어서 ARM 코어에 복구\n5.",
        "index": 1
      },
      {
        "id": "2024-11-05-10_chunk_2",
        "text": "스크 컨트롤 블록을 스케줄러에서 받아오기\n3. 2에서 받은 태스크 컨트롤 블럭에서 스택 포인터 읽기\n4. 3에서 읽은 태스크의 스택에서 컨텍스트를 읽어서 ARM 코어에 복구\n5.",
        "index": 2
      },
      {
        "id": "2024-11-05-10_chunk_3",
        "text": "스크 컨트롤 블록을 스케줄러에서 받아오기\n3. 2에서 받은 태스크 컨트롤 블럭에서 스택 포인터 읽기\n4. 3에서 읽은 태스크의 스택에서 컨텍스트를 읽어서 ARM 코어에 복구\n5.",
        "index": 3
      },
      {
        "id": "2024-11-05-10_chunk_4",
        "text": "스크 컨트롤 블록을 스케줄러에서 받아오기\n3. 2에서 받은 태스크 컨트롤 블럭에서 스택 포인터 읽기\n4. 3에서 읽은 태스크의 스택에서 컨텍스트를 읽어서 ARM 코어에 복구\n5.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-12",
    "title": "[RTOS개발] 12장 메시징",
    "path": "/2024/11/05/12장-메시징/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 메시징에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/208f196acb2eb8a03a69a56e85b6f56c824290c$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic0](https://github.com/navilera/Navilos/tree/208f196acb2eb8a03a69a56e85b6f56c824290c0)\n{: .prompt-tip }\n\n## 서론\n***\n이벤트는 많은 정보를 보내고 받을 수 없습니다. \n\n이전 페이지에서 Uart 인터럽트와 이벤트를 연결했지만, 키보드 입력이 발생했다는 것만 알 뿐, 어떤 문자가 입력되었는지는 알 수 없습니다.\n\n어떤 문자가 입력되었는지 알기 위해선 추가적으로 정보를 보내야 하는데, 이러한 기능을 하는 것이 **메시징** 입니다.\n\n## 메시지 큐\n***\n메시징 기능의 설계는 큐로 합니다.\n\n가장 일반적이고 효율적이기에 큐 자료구조를 사용하며, 메시지를 큐로 관리하기에 **메시지 큐**라고 부르기도 합니다.\n\n큐를 구현하는 방법에는 **링크드 리스트** 혹은 **배열**이 있습니다.\n\n임베디드 시스템에서는 동적 할당을 피하기 위해 주로 배열을 이용하며, 본 페이지에서도 배열을 이용해 구현하겠습니다.\n\n### `kernel/msg.h` 메시지 큐 선언\n\n```c\n#ifndef KERNEL_MSG_H_\n#define KERNEL_MSG_H_\n\n#define MSG_Q_SIZE_BYTE     512\n\ntypedef enum KernelMsgQ_t\n{\n    KernelMsgQ_Task0,\n    KernelMsgQ_Task1,\n    KernelMsgQ_Task2,\n\n    KernelMsgQ_Num\n} KernelMsgQ_t;\n\ntypedef struct KernelCirQ_t\n{\n    uint32_t front;\n    uint32_t rear;\n    uint8_t  Queue[MSG_Q_SIZE_BYTE];\n} KernelCirQ_t;\n\nvoid Kernel_msgQ_init(void);\nbool Kernel_msgQ_is_empty(KernelMsgQ_t Qname);\nbool Kernel_msgQ_is_full(KernelMsgQ_t Qname);\nbool Kernel_msgQ_enqueue(KernelMsgQ_t Qname, uint8_t data);\nbool Kernel_msgQ_dequeue(KernelMsgQ_t Qname, uint8_t* out_data);\n\n#endif /* KERNEL_MSG_H_ */\n\n```\n\n우선 기본적으로 512바이트짜리 메시지 큐 세 개를 사용합니다.\n\n이 개수는 시스템의 요구사항에 따라 변경될 수 있으며, \n\n우선 본 교재에서는 각 태스크마다 한 개씩 메시지 큐를 배정하기로 했습니다.\n\n### `kernel/msg.c` 메시지 큐 구현\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n#include \"stdlib.h\"\n\n#include \"msg.h\"\n\nKernelCirQ_t sMsgQ[KernelMsgQ_Num];\n\nvoid Kernel_msgQ_init(void)\n{\n    for (uint32_t i = 0 ; i < KernelMsgQ_Num ; i++)\n    {\n        memclr(sMsgQ[i].Queue, MSG_Q_SIZE_BYTE);\n    }\n}\n\nbool Kernel_msgQ_is_empty(KernelMsgQ_t Qname)\n{\n    if (Qname >= KernelMsgQ_Num)\n    {\n        return false;\n    }\n\n    if (sMsgQ[Qname].front == sMsgQ[Qname].rear)\n    {\n        return true;\n    }\n\n    return false;\n}\n\nbool Kernel_msgQ_is_full(KernelMsgQ_t Qname)\n{\n    if (Qname >= KernelMsgQ_Num)\n    {\n        return false;\n    }\n\n    if (((sMsgQ[Qname].rear + 1) % MSG_Q_SIZE_BYTE) == sMsgQ[Qname].front)\n    {\n        return true;\n    }\n\n    return false;\n}\n\nbool Kernel_msgQ_enqueue(KernelMsgQ_t Qname, uint8_t data)\n{\n    if (Kernel_msgQ_is_full(Qname))\n    {\n        return false;\n    }\n    sMsgQ[Qname].rear++;\n    sMsgQ[Qname].rear %= MSG_Q_SIZE_BYTE;\n\n    uint32_t idx = sMsgQ[Qname].rear;\n    sMsgQ[Qname].Queue[idx] = data;\n\n    return true;\n}\n\nbool Kernel_msgQ_dequeue(KernelMsgQ_t Qname, uint8_t* out_data)\n{\n    if (Kernel_msgQ_is_empty(Qname))\n    {\n        return false;\n    }\n\n    sMsgQ[Qname].front++;\n    sMsgQ[Qname].front %= MSG_Q_SIZE_BYTE;\n\n    uint32_t idx = sMsgQ[Qname].front;\n    *out_data = sMsgQ[Qname].Queue[idx];\n\n    return true;\n}\n\n```\n\n- `init()` 메시지 큐를 0으로 초기화합니다.\n- `is_empty()` 메시지 큐가 비어있으면 `true`를 리턴합니다.\n- `is_full()` 메시지 큐가 꽉 차있으면 `true` 를 리턴합니다.\n- `enqueue()` 메시지 큐에 `data` 를 넣습니다.\n- `dequeue()` 메시지 큐에서 데이터를 `out_data` 로 뽑아냅니다.\n\n이렇게해서 메시지 큐 구현은 끝났습니다.\n\n앞서 태스크나 이벤트와 마찬가지로 커널 API로 조금 더 활용성을 높게 만들어 보겠습니다.\n\n### `kernel/Kernel.c` 메시지 보내기 및 받기 API 추가\n\n```c\nbool Kernel_send_msg(KernelMsgQ_t Qname, void* data, uint32_t count)\n{\n    uint8_t* d = (uint8_t*)data;\n\n    for (uint32_t i = 0 ; i < count ; i++)\n    {\n        if (false == Kernel_msgQ_enqueue(Qname, *d))\n        {\n            for (uint32_t j = 0 ; j < i ; j++)\n            {\n                uint8_t rollback;\n                Kernel_msgQ_dequeue(Qname, &rollback);\n            }\n            return false;\n        }\n        d++;\n    }\n\n    return true;\n}\n\nuint32_t Kernel_recv_msg(KernelMsgQ_t Qname, void* out_data, uint32_t count)\n{\n    uint8_t* d = (uint8_t*)out_data;\n\n    for (uint32_t i = 0 ; i < count ; i++)\n    {\n        if (false == Kernel_msgQ_dequeue(Qname, d))\n        {\n            return i;\n        }\n        d++;\n    }\n\n    return count;\n}\n\n```\n\n`send_msg()` 함수와 `recv_msg()` 함수 모두 메시지를 보내고 받는 함수입니다.\n\n단, 중간에 예외 처리를 추가했습니다.\n\n- `send_msg()`\n    \n    : 데이터를 큐에 넣는 중 큐가 꽉 차버리는 상태에 대한 예외 처리\n    \n    → 일부만 들어간 불완전한 데이터를 다시 빼내야 메시지 큐의 무결성을 보장!\n    \n- `recv_msg()`\n    \n    : 데이터를 메시지 큐에서 읽는 도중 더 읽을 것이 없는 상태에 대한 예외 처리\n    \n    → 10바이트를 읽는 중 메시지 큐에 7바이트 밖에 없었다면, 함수를 한번 더 호출해 3바이트를 추가로 읽기 위함.\n    \n\n여기까지 해서 커널의 메시징 관련 기능을 모두 구현했습니다.\n\n## 태스크 간 데이터 전달\n***\n메시징 기능 적당한 예제를 만들어 테스트 해보겠습니다.\n\nUART 인터럽트 핸들러에서 이벤트와 함께 들어온 입력 값을 메시지 큐로 보내겠습니다.\n\n### `/hal/rvpb/Uart.c` UART 인터럽트 핸들러 수정\n\n```c\nstatic void interrupt_handler(void)\n{\n    uint8_t ch = Hal_uart_get_char();\n    Hal_uart_put_char(ch);\n\n    Kernel_send_msg(KernelMsgQ_Task0, &ch, 1); // Added\n    Kernel_send_events(KernelEventFlag_UartIn|KernelEventFlag_CmdIn);\n\n    if (ch == 'X')\n    {\n        Kernel_send_events(KernelEventFlag_CmdOut);\n    }\n}\n```\n\nTask0용으로 만든 메시지 큐에 UART 입력으로 받은 값을 전달합니다.\n\n그리고, UartIn 이벤트를 보냅니다.\n\n이제 태스크0에서 메시지 처리하는 코드를 작성하겠습니다.\n\n### `boot/Main.c` Task0에서 메시지 처리\n\n```c\nvoid User_task0(void)\n{\n    uint32_t local = 0;\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n\n    uint8_t  cmdBuf[16];\n    uint32_t cmdBufIdx = 0;\n    uint8_t  uartch = 0;\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_UartIn | KernelEventFlag_CmdOut);\n        switch(handle_event)\n        {\n        case KernelEventFlag_UartIn:\n            Kernel_recv_msg(KernelMsgQ_Task0, &uartch, 1);\n            if (uartch == '\\r')\n            {\n                cmdBuf[cmdBufIdx] = '\\0';\n\n                while(true)\n                {\n                    Kernel_send_events(KernelEventFlag_CmdIn);\n                    if (false == Kernel_send_msg(KernelMsgQ_Task1, &cmdBufIdx, 1))\n                    {\n                        Kernel_yield();\n                    }\n                    else if (false == Kernel_send_msg(KernelMsgQ_Task1, cmdBuf, cmdBufIdx))\n                    {\n                        uint8_t rollback;\n                        Kernel_recv_msg(KernelMsgQ_Task1, &rollback, 1);\n                        Kernel_yield();\n                    }\n                    else\n                    {\n                        break;\n                    }\n                }\n\n                cmdBufIdx = 0;\n            }\n            else\n            {\n                cmdBuf[cmdBufIdx] = uartch;\n                cmdBufIdx++;\n                cmdBufIdx %= 16;\n            }\n            break;\n        case KernelEventFlag_CmdOut:\n            debug_printf(\"\\nCmdOut Event by Task0\\n\");\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\n```\n\n우선, `Main.c`의 `Kernel_init()`함수에서 `Kernel_msgQ_init()` 을 호출해 메시지 큐를 초기화합니다.\n\n이후, `Task0`에선 UART 인터럽트 핸들러에서 이벤트가 오면 메시지 큐에서 1바이트를 읽어 내부 버퍼에 읽은 값을 계속 쌓아둡니다.\n\n그러다가 엔터 키(’\\r’)가 입력되면 지금까지 버퍼에 쌓아 두었던 값을 Task1의 메시지 큐에 넣고 `CmdIn` 이벤트를 보냅니다.\n\n`cmdBuf`는 16바이트짜리 로컬 배열에 순서대로 쌓아두기에, 오버플로가 되지 않도록 16으로 나눈 나머지 값을 인덱스로 활용합니다.\n\n또한, `Task1`이 받지 못하는 상황에 대해서 예외 처리를 추가합니다.\n\n### `boot/Main.c` Task1에서 메시지 처리\n\n```c\nvoid User_task1(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #1 SP=0x%x\\n\", &local);\n\n    uint8_t cmdlen = 0;\n    uint8_t cmd[16] = {0};\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_CmdIn)    ;\n        switch(handle_event)\n        {\n        case KernelEventFlag_CmdIn:\n            memclr(cmd, 16);\n            Kernel_recv_msg(KernelMsgQ_Task1, &cmdlen, 1);\n            Kernel_recv_msg(KernelMsgQ_Task1, cmd, cmdlen);\n            debug_printf(\"\\nRecv Cmd: %s\\n\", cmd);\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\n```\n\nTask0에서 데이터의 길이를 먼저 보내고 그다음에 데이터를 보냈습니다.\n\n그래서 우선 cmdlen 변수에 길이를 읽은 후, `cmdlen` 변수의 값 길이만큼 메시지를 읽어 cmd 로컬 배열에 저장하고, `debuf_printf()`함수를 이용해 출력합니다.\n\n> `memclr` 함수를 사용하고 있습니다. `lib` 폴더의 `stdlib.c`와 `stdlib.h`에 새롭게 정의해 사용해야 합니다.\n\n또한, `Kernel.h`에 `msg.h` 헤더파일과 API 함수를 선언해줘야 합니다.\n{: .prompt-tip }\n\n이제 정상적으로 동작하는지 테스트해보겠습니다.\n\n```bash\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os1201.png)\n\n엔터를 눌렀을 때, 정상적으로 `abcdef`가 출력되는 것은 확인했지만,\n\n엔터를 누르지 않았을 때도 `Recv Cmd:`가 출력되고 있습니다.\n\n> `hal/rvpb/Uart.c` 의 인터럽트 핸들러에서 `CmdIn` 이벤트를 같이 보내고 있어서 발생하는 문제입니다.\n>\n>`UartIn` 이벤트만 발생하도록 설정하면 해결됩니다.\n{: .prompt-tip }\n\n조금 더 편한 디버깅을 위해 코드를 아래와 같이 수정하겠습니다.\n\n### `boot/Main.c`\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n\n#include \"HalUart.h\"\n#include \"HalInterrupt.h\"\n#include \"HalTimer.h\"\n\n#include \"stdio.h\"\n#include \"stdlib.h\"\n\n#include \"Kernel.h\"\n\nstatic void Hw_init(void);\nstatic void Kernel_init(void);\n\nstatic void Printf_test(void);\nstatic void Timer_test(void);\n\nvoid User_task0(void);\nvoid User_task1(void);\nvoid User_task2(void);\n\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n    Hal_uart_put_char('\\n');\n\n    putstr(\"Hello World!\\n\");\n\n    Printf_test();\n    Timer_test();\n\n    Kernel_init();\n\n    while(true);\n}\n\nstatic void Hw_init(void)\n{\n    Hal_interrupt_init();\n    Hal_uart_init();\n    Hal_timer_init();\n}\n\nstatic void Kernel_init(void)\n{\n    uint32_t taskId;\n\n    Kernel_task_init();\n    Kernel_event_flag_init();\n    Kernel_msgQ_init();\n\n    taskId = Kernel_task_create(User_task0);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task0 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task1);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task1 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task2);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task2 creation fail\\n\");\n    }\n\n    Kernel_start();\n}\n\nstatic void Printf_test(void)\n{\n    char* str = \"printf pointer test\";\n    char* nullptr = 0;\n    uint32_t i = 5;\n    uint32_t* sysctrl0 = (uint32_t*)0x10001000;\n\n    debug_printf(\"%s\\n\", \"Hello printf\");\n    debug_printf(\"output string pointer: %s\\n\", str);\n    debug_printf(\"%s is null pointer, %u number\\n\", nullptr, 10);\n    debug_printf(\"%u = 5\\n\", i);\n    debug_printf(\"dec=%u hex=%x\\n\", 0xff, 0xff);\n    debug_printf(\"print zero %u\\n\", 0);\n    debug_printf(\"SYSCTRL0 %x\\n\", *sysctrl0);\n}\n\nstatic void Timer_test(void)\n{\n    for(uint32_t i = 0; i < 5 ; i++)\n    {\n        debug_printf(\"current count : %u\\n\", Hal_timer_get_1ms_counter());\n        delay(1000);\n    }\n}\n\nvoid User_task0(void)\n{\n    uint32_t local = 0;\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n\n    uint8_t  cmdBuf[16];\n    uint32_t cmdBufIdx = 0;\n    uint8_t  uartch = 0;\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_UartIn|KernelEventFlag_CmdOut);\n        switch(handle_event)\n        {\n        case KernelEventFlag_UartIn:\n            Kernel_recv_msg(KernelMsgQ_Task0, &uartch, 1);\n            if (uartch == '\\r')\n            {\n                cmdBuf[cmdBufIdx] = '\\0';\n\n                Kernel_send_msg(KernelMsgQ_Task1, &cmdBufIdx, 1);\n                Kernel_send_msg(KernelMsgQ_Task1, cmdBuf, cmdBufIdx);\n                Kernel_send_events(KernelEventFlag_CmdIn);\n\n                cmdBufIdx = 0;\n            }\n            else\n            {\n                cmdBuf[cmdBufIdx] = uartch;\n                cmdBufIdx++;\n                cmdBufIdx %= 16;\n            }\n            break;\n        case KernelEventFlag_CmdOut:\n            debug_printf(\"\\nCmdOut Event by Task0\\n\");\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\nvoid User_task1(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #1 SP=0x%x\\n\", &local);\n\n    uint8_t cmdlen = 0;\n    uint8_t cmd[16] = {0};\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_CmdIn);\n        switch(handle_event)\n        {\n        case KernelEventFlag_CmdIn:\n            memclr(cmd, 16);\n            Kernel_recv_msg(KernelMsgQ_Task1, &cmdlen, 1);\n            Kernel_recv_msg(KernelMsgQ_Task1, cmd, cmdlen);\n            debug_printf(\"\\nRecv Cmd: %s\\n\", cmd);\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\nvoid User_task2(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #2 SP=0x%x\\n\", &local);\n\n    while(true)\n    {\n        Kernel_yield();\n    }\n}\n```\n\n### `kernel/msg.c`\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n#include \"stdlib.h\"\n\n#include \"msg.h\"\n\nKernelCirQ_t sMsgQ[KernelMsgQ_Num];\n\nvoid Kernel_msgQ_init(void)\n{\n    for (uint32_t i = 0 ; i < KernelMsgQ_Num ; i++)\n    {\n        sMsgQ[i].front = 0;\n        sMsgQ[i].rear = 0;\n        memclr(sMsgQ[i].Queue, MSG_Q_SIZE_BYTE);\n    }\n}\n\nbool Kernel_msgQ_is_empty(KernelMsgQ_t Qname)\n{\n    if (Qname >= KernelMsgQ_Num)\n    {\n        return false;\n    }\n\n    if (sMsgQ[Qname].front == sMsgQ[Qname].rear)\n    {\n        return true;\n    }\n\n    return false;\n}\n\nbool Kernel_msgQ_is_full(KernelMsgQ_t Qname)\n{\n    if (Qname >= KernelMsgQ_Num)\n    {\n        return false;\n    }\n\n    if (((sMsgQ[Qname].rear + 1) % MSG_Q_SIZE_BYTE) == sMsgQ[Qname].front)\n    {\n        return true;\n    }\n\n    return false;\n}\n\nbool Kernel_msgQ_enqueue(KernelMsgQ_t Qname, uint8_t data)\n{\n    if (Qname >= KernelMsgQ_Num)\n    {\n        return false;\n    }\n\n    if (Kernel_msgQ_is_full(Qname))\n    {\n        return false;\n    }\n    sMsgQ[Qname].rear++;\n    sMsgQ[Qname].rear %= MSG_Q_SIZE_BYTE;\n\n    uint32_t idx = sMsgQ[Qname].rear;\n    sMsgQ[Qname].Queue[idx] = data;\n\n    return true;\n}\n\nbool Kernel_msgQ_dequeue(KernelMsgQ_t Qname, uint8_t* out_data)\n{\n    if (Qname >= KernelMsgQ_Num)\n    {\n        return false;\n    }\n\n    if (Kernel_msgQ_is_empty(Qname))\n    {\n        return false;\n    }\n\n    sMsgQ[Qname].front++;\n    sMsgQ[Qname].front %= MSG_Q_SIZE_BYTE;\n\n    uint32_t idx = sMsgQ[Qname].front;\n    *out_data = sMsgQ[Qname].Queue[idx];\n\n    return true;\n}\n```\n\n이제, 다시 동작을 확인해보겠습니다.\n\n```bash\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os1202.png)\n\n원하는대로 동작하는 것을 확인할 수 있습니다.\n\n## 요약\n***\n이 장에서는 큐 자료구조를 활용해 메시징 기능을 만들었습니다.\n\n태스크나 인터럽트 간 데이터를 전달하고 싶을 때는 큐에 데이터를 넣고 꺼내기만 하면 됩니다.\n\n이벤트와 조합해 필요한 정보를 어떤 태스크가 보내고 받는지를 제어합니다.\n\n매우 유용한 기능이니 개념을 잘 이해해 두는 것이 좋습니다.\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-12_chunk_0",
        "text": "[RTOS개발] 12장 메시징\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 메시징에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/208f196acb2eb8a03a69a56e85b6f56c824290c$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic0](https://github.com/navilera/Navilos/tree/208f196acb2eb8a03a69a56e85b6f56c824290c0)\n{: .prompt-tip }\n\n## 서론\n***\n이벤트는 많은 정보를 보내고 받을 수 없습니다.",
        "index": 0
      },
      {
        "id": "2024-11-05-12_chunk_1",
        "text": "ee/208f196acb2eb8a03a69a56e85b6f56c824290c0)\n{: .prompt-tip }\n\n## 서론\n***\n이벤트는 많은 정보를 보내고 받을 수 없습니다.",
        "index": 1
      },
      {
        "id": "2024-11-05-12_chunk_2",
        "text": "ee/208f196acb2eb8a03a69a56e85b6f56c824290c0)\n{: .prompt-tip }\n\n## 서론\n***\n이벤트는 많은 정보를 보내고 받을 수 없습니다.",
        "index": 2
      },
      {
        "id": "2024-11-05-12_chunk_3",
        "text": "ee/208f196acb2eb8a03a69a56e85b6f56c824290c0)\n{: .prompt-tip }\n\n## 서론\n***\n이벤트는 많은 정보를 보내고 받을 수 없습니다.",
        "index": 3
      },
      {
        "id": "2024-11-05-12_chunk_4",
        "text": "ee/208f196acb2eb8a03a69a56e85b6f56c824290c0)\n{: .prompt-tip }\n\n## 서론\n***\n이벤트는 많은 정보를 보내고 받을 수 없습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-9",
    "title": "[RTOS개발] 9장 스케줄러",
    "path": "/2024/11/05/9장-스케줄러/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 9장. 스케줄러\n\n날짜: 2024년 10월 15일\n상태: 완료\n생성 일시: 2024년 10월 1일 오후 8:57\n최종 편집 일시: 2024년 10월 18일 오후 5:40\n\n본 페이지는 스케줄러를 만들겠습니다.\n\n> [https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81](https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81)\n{: .prompt-tip }\n\n## 서론\n***\n스케줄러란 지금 실행 중인 태스크 다음에 어떤 태스크를 실행할 지 골라주는 기능을 합니다.\n\n스케줄러를 얼마나 효율적으로 만드느냐에 따라 RTOS의 성능이 좌우될 정도로 중요합니다.\n\n## 간단한 스케줄러\n***\n먼저 가장 간단한 스케줄러를 만들겠습니다.\n\n현재 실행 중인 태스크 컨트롤 블록의 **바로 다음** 태스크 컨트롤 블록을 선택하겠습니다.\n\n만약, 현재 실행 중인 태스크 컨트롤 블록의 배열 인덱스가 1이라면, 그 다음에는 2를 실행합니다.\n\n다른 추가 계산 없이 그냥 인덱스를 계속 증가시키며 대상을 선택하는 알고리즘을 **라운드 로빈(Round Robin) 알고리즘**이라 합니다.\n\n> 인덱스가 계속 증가하는 것이 아닌, 정해진 최댓값에 이르면 다시 0이 됩니다. → Round\n{: .prompt-tip }\n\n스케줄러 역시 태스크 관련 작업이므로 `kernel/task.c`에 작성하겠습니다.\n\n### `kernel/task.c` 라운드 로빈 알고리즘\n\n```c\nstatic uint32_t     sCurrent_tcb_index;\nstatic KernelTcb_t* Scheduler_round_robin_algorithm(void);\n...\n...\n...\nstatic KernelTcb_t* Scheduler_round_robin_algorithm(void)\n{\n  sCurrent_tcb_index++;\n  sCurrent_tcb_index %= sAllocated_tcb_index;\n\n  return &sTask_list[sCurrent_tcb_index];\n}\n```\n\n`sCurrent_tcb_index` 라는 새로운 변수를 만듭니다.\n\n이 변수에 현재 실행 중인 태스크의 태스크 컨텍스트 블록 인덱스를 저장합니다.\n\n현재 인덱스를 증가시켜 나머지 연산을 이용해 최댓값을 넘지않도록 한 후, 배열을 읽어 다음에 동작할 태스크 컨트롤 블록을 리턴합니다.\n\n구현은 이걸로 끝이며, 이렇게 만든 알고리즘 코드를 컨텍스트 스위칭에 적용하면 됩니다.\n\n## 우선순위 스케줄러\n***\n> 이 책에서는 우선순위 스케줄러를 만들지 않습니다.\nQEMU의 제약으로 적당한 테스트 케이스를 만들기 어렵기 때문입니다.\n{: .prompt-info }\n\n**우선순위 스케줄러**란 태스크 우선순위가 있어 스케줄러가 낮은 우선순위 태크스를 높은 우선순위 태스크가 동작하는 동안 다음에 동작할 태스크로 선택하지 않는 것을 말합니다.\n\n(즉, 현재 태스크의 우선순위보다 낮은 태스크는 선택하지 않음)\n\n이를 구현하려면 태스크 컨트롤 블록에 우선순위를 부여해야 합니다.\n\n간단하게 태스크 컨트롤 블록에 멤버 변수를 하나 추가하는 것으로 우선순위를 부여하겠습니다.\n\n```c\ntypedef struct KernelTcb_t\n{\n\tuint32_t sp;\n\tuint8_t* stack_base;\n\tuint32_t priority; // 우선순위를 태스크 컨트롤 블록에 추가\n}\n```\n\n이제 이 확장된 자료 구조를 사용하는 코드로 변경합니다.\n\n```c\nuint32_t Kernel_task_create(KernelTaskFunc_t startFunc, uint32_t priority)\n{\n\tKernelTcb_t* new_tcb = &sTask_list[sAllocated_tcb_index++];\n\t\n\tif (sAllocated_tcb_index > MAX_TASK_NUM)\n\t{\n\t\treturn NOT_ENOUGH_TASK_NUM;\n\t}\n\t\n\tnew_tcb->priority = priority;    // 우선순위를 TCB에 등록\n\t\n\tKernelTaskContext_t* ctx = (KernelTaskContext_t*)new_tcb->sp;\n\tctx->pc = (uint32_t)startFunc;\n\t\n\treturn (sAllocated_tcb_index - 1);\n}\n```\n\n위와 같은 코드로 태스크 생성(등록) 함수의 기능을 확장합니다.\n\n우선순위를 파라미터로 받고 받은 우선순위를 그대로 TCB에 저장합니다.\n\n아래 코드와 같은 형태로 우선순위 스케줄러의 스케줄링 알고리즘을 작성할 수 있습니다.\n\n### 우선순위 스케줄러의 스케줄링 알고리즘\n\n```c\nstatic KernelTcb_t* Scheduler_priority_algorithm(void)\n{\n\tfor(uint32_t i = 0 ; i < sAllocated_tcb_index ; i++)\n\t{\n\t\tKernelTcb_t* pNextTcb = &sTask_list[i];\n\t\tif (pNextTcb != sCurrent)\n\t\t\t{\n\t\t\t\tif (pNextTcb->priority <= sCurrent->priority)\n\t\t\t\t{\n\t\t\t\t\treturn pNextTcb;\n\t\t\t\t}\n\t\t\t}\n\t}\n  return sCurrent_tcb;    // 현재보다 우선순위가 높은 태스크가 없을 경우 현재 태스크 실행\n}\n```\n\n> 작은 숫자의 우선순위가 큰 숫자의 우선순위보다 높은 우선순위라고 간주\n{: .prompt-info }\n\n## 요약\n***\n이 장에서는 스케줄러를 만들었습니다. 스케줄러는 여러 알고리즘으로 구현할 수 있습니다.\n\n가장 기본적인 라운드 로빈 스케줄러를 만들었습니다.\n\n다음 장에서 컨텍스트 스위칭을 구현해 커널이 태스크를 여러 개 실행하도록 하겠습니다.\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-9_chunk_0",
        "text": "[RTOS개발] 9장 스케줄러\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 9장.",
        "index": 0
      },
      {
        "id": "2024-11-05-9_chunk_1",
        "text": ".w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 9장. 스케줄러\n\n날짜: 2024년 10월 15일\n상태: 완료\n생성 일시: 2024년 10월 1일 오후 8:57\n최종 편집 일시: 2024년 10월 18일 오후 5:40\n\n본 페이지는 스케줄러를 만들겠습니다.\n\n> [https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81](https://github.com/navilera/Navilos/tree/f02ff6b92d2a356f85c76a60a12ef6ea73fdbd81)\n{: .prompt-tip }\n\n## 서론\n***\n스케줄러란 지금 실행 중인 태스크 다음에 어떤 태스크를 실행할 지 골라주는 기능을 합니다.\n\n스케줄러를 얼마나 효율적으로 만드느냐에 따라 RTOS의 성능이 좌우될 정도로 중요합니다.\n\n## 간단한 스케줄러\n***\n먼저 가장 간단한 스케줄러를 만들겠습니다.\n\n현재 실행 중인 태스크 컨트롤 블록의 **바로 다음** 태스크 컨트롤 블록을 선택하겠습니다.\n\n만약, 현재 실행 중인 태스크 컨트롤 블록의 배열 인덱스가 1이라면, 그 다음에는 2를 실행합니다.\n\n다른 추가 계산 없이 그냥 인덱스를 계속 증가시키며 대상을 선택하는 알고리즘을 **라운드 로빈(Round Robin) 알고리즘**이라 합니다.\n\n> 인덱스가 계속 증가하는 것이 아닌, 정해진 최댓값에 이르면 다시 0이 됩니다.",
        "index": 1
      },
      {
        "id": "2024-11-05-9_chunk_2",
        "text": "며 대상을 선택하는 알고리즘을 **라운드 로빈(Round Robin) 알고리즘**이라 합니다.\n\n> 인덱스가 계속 증가하는 것이 아닌, 정해진 최댓값에 이르면 다시 0이 됩니다.",
        "index": 2
      },
      {
        "id": "2024-11-05-9_chunk_3",
        "text": "며 대상을 선택하는 알고리즘을 **라운드 로빈(Round Robin) 알고리즘**이라 합니다.\n\n> 인덱스가 계속 증가하는 것이 아닌, 정해진 최댓값에 이르면 다시 0이 됩니다.",
        "index": 3
      },
      {
        "id": "2024-11-05-9_chunk_4",
        "text": "며 대상을 선택하는 알고리즘을 **라운드 로빈(Round Robin) 알고리즘**이라 합니다.\n\n> 인덱스가 계속 증가하는 것이 아닌, 정해진 최댓값에 이르면 다시 0이 됩니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-14",
    "title": "[RTOS개발] 14장 끝!",
    "path": "/2024/11/05/14장-끝!/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n아무것도 없는 상태에서 `MOV R0, R1` 이라는 의미 없는 코드에서\n\n부트 로더\n\n-> 인터럽트 처리로 키보드 입력 받기\n\n-> 타이머 하드웨어로 시간을 다루고\n\n-> 태스크와 스케줄러, 컨텍스트 스위칭을 만들어 RTOS다운 기능을 만들고\n\n-> 메시지와 동기화 기능으로 멀티코어 환경에 필수적인 기능을 만들었습니다.\n\n## 펌웨어\n\nRTOS도 기본적으로 펌웨어입니다.\n\n펌웨어는 플랫폼과 하드웨어를 알아야 제대로 만들 수 있습니다.\n\n→ ARM 아키텍처에 대한 공부 필요!!\n\n## 마치며\n\n이 책에서 배운 것들\n\n- 개발 환경 설정\n- 컴파일러에 대한 이해\n- 링커에 대한 이해\n- 부트로더에 대한 이해\n- 레지스터 사용에 대한 이해\n- 인터럽트 처리\n- 메모리 관리\n- 주변장치 제어\n- 멀티코어 동기화\n- 멀티코어 간 메시지 처리\n\n끝! \n\n## 교재 공부 후기\n한 달이라는 짧은 시간동안 밀도있게 공부했는데, 매우 유익했습니다.\n\n단순 OS에 대한 지식뿐만 아니라, 기본적인 코드를 읽는 능력과 프로그램을 이해하고, 설계하는 역량이 키워졌습니다.\n\n임베디드 개발자를 희망하는 학부생 혹은 취업준비생이라면 꼭 교재를 구매하여 처음부터 끝까지 읽어보고, 직접 따라해보시길 권장드립니다.\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-14_chunk_0",
        "text": "[RTOS개발] 14장 끝!\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n아무것도 없는 상태에서 `MOV R0, R1` 이라는 의미 없는 코드에서\n\n부트 로더\n\n-> 인터럽트 처리로 키보드 입력 받기\n\n-> 타이머 하드웨어로 시간을 다루고\n\n-> 태스크와 스케줄러, 컨텍스트 스위칭을 만들어 RTOS다운 기능을 만들고\n\n-> 메시지와 동기화 기능으로 멀티코어 환경에 필수적인 기능을 만들었습니다.\n\n## 펌웨어\n\nRTOS도 기본적으로 펌웨어입니다.\n\n펌웨어는 플랫폼과 하드웨어를 알아야 제대로 만들 수 있습니다.\n\n→ ARM 아키텍처에 대한 공부 필요!!\n\n## 마치며\n\n이 책에서 배운 것들\n\n- 개발 환경 설정\n- 컴파일러에 대한 이해\n- 링커에 대한 이해\n- 부트로더에 대한 이해\n- 레지스터 사용에 대한 이해\n- 인터럽트 처리\n- 메모리 관리\n- 주변장치 제어\n- 멀티코어 동기화\n- 멀티코어 간 메시지 처리\n\n끝!",
        "index": 0
      },
      {
        "id": "2024-11-05-14_chunk_1",
        "text": "커에 대한 이해\n- 부트로더에 대한 이해\n- 레지스터 사용에 대한 이해\n- 인터럽트 처리\n- 메모리 관리\n- 주변장치 제어\n- 멀티코어 동기화\n- 멀티코어 간 메시지 처리\n\n끝! \n\n## 교재 공부 후기\n한 달이라는 짧은 시간동안 밀도있게 공부했는데, 매우 유익했습니다.\n\n단순 OS에 대한 지식뿐만 아니라, 기본적인 코드를 읽는 능력과 프로그램을 이해하고, 설계하는 역량이 키워졌습니다.\n\n임베디드 개발자를 희망하는 학부생 혹은 취업준비생이라면 꼭 교재를 구매하여 처음부터 끝까지 읽어보고, 직접 따라해보시길 권장드립니다.\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 1
      },
      {
        "id": "2024-11-05-14_chunk_2",
        "text": "/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 2
      },
      {
        "id": "2024-11-05-14_chunk_3",
        "text": "/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 3
      },
      {
        "id": "2024-11-05-14_chunk_4",
        "text": "/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-13",
    "title": "[RTOS개발] 13장 동기화",
    "path": "/2024/11/05/13장-동기화/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 동기화에 대해 다룹니다.\n\n>[https://github.com/navilera/Navilos/tree/49dcd06dabad43674c2a2df22c6b567f4777240a](https://github.com/navilera/Navilos/tree/49dcd06dabad43674c2a2df22c6b567f4777240a)\n{: .prompt-tip }\n\n## 서론\n***\n우선, Navilos 프로젝트에선 비선점형 스케줄링인데다가 명시적으로 `Kernel_yield()`를 호출해야 하는 싱글코어 환경이기에 동기화 문제가 발생하지 않습니다.\n\n하지만, 동기화는 운영체제에서 매우 중요한 부분이기에 꼭 배워두는 것이 좋습니다.\n\n### 동기화(synchronization)\n\n운영체제에서 어떤 작업을 아토믹 오퍼레이션(atmoic operatiron)으로 만들어 준다는 의미입니다.\n\n**어떤 작업이 아토믹하다 = 해당 작업이 끝날 때까지 컨텍스트 스위칭이 발생하지 않는다**\n\n(컨텍스트 스위칭뿐만 아니라 다른 코어가 해당 동작에 끼어들지 않아야 함)\n\n### 크리티컬 섹션(critical section)\n\n어떤 작업이 아토믹하게 구현되어야만 한다면 해당 작업을 크리티컬 섹션이라 합니다.\n\n> 즉, 동기화란 어떤 작업이 크리티컬 섹션이라 판단되었을 경우, 해당 크리티컬 섹션을 아토믹 오퍼레이션으로 만들어 주는 것을 말합니다.\n{: .prompt-tip }\n\n동기화를 구현하는 알고리즘은 크게 세마포어, 뮤텍스, 스핀락이 있습니다.\n\n## 세마포어(Semaphore)\n***\n세마포어의 의사 코드(pseudo code)는 아래와 같습니다.\n\n```c\nTest(S)\n{\n\twhile S<=0; // 대기\n\tS--;\n}\n\nRelease(S)\n{\n\tS++;\n}\n```\n\n아주 간단하게 두 가지 함수만으로 구현할 수 있습니다.\n\n- `Test()`\n    \n    : 이름 그대로 크리티컬 섹션에 진입 가능한지 확인하는 함수입니다.\n    \n    혹은, 세마포어를 잠글 수 있는지(lock) 확인한다는 의미도 가지고 있습니다.\n    \n- `Release()`\n    \n    : 크리티컬 섹션을 나갈 때 호출해 세마포어를 놓아주는(release) 함수입니다.\n    \n    혹은, 세마포어의 잠금을 푸는(unlock) 한다는 의미도 가지고 있습니다.\n    \n\n>잠금과 잠금의 해제!\n{: .prompt-tip }\n\n우선, 세마포어를 구현해보겠습니다.\n\n### `kernel/synch.h` 세마포어 구현\n\n```c\n#ifndef KERNEL_SYNCH_H_\n#define KERNEL_SYNCH_H_\n\nvoid Kernel_sem_init(int32_t max);\nbool Kernel_sem_test(void);\nvoid Kernel_sem_release(void);\n\n#endif /* KERNEL_SYNCH_H_ */\n```\n\n### `kernel/synch.c` 세마포어 구현\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n\n#include \"synch.h\"\n\n#define DEF_SEM_MAX 8\n\nstatic int32_t sSemMax;\nstatic int32_t sSem;\n\nvoid Kernel_sem_init(int32_t max)\n{\n    sSemMax = (max <= 0) ? DEF_SEM_MAX : max;\n    sSem = sSemMax;\n}\n\nbool Kernel_sem_test(void)\n{\n    if (sSem <= 0)\n    {\n        return false;\n    }\n\n    sSem--;\n\n    return true;\n}\n\nvoid Kernel_sem_release(void)\n{\n    if (sSem >= sSemMax)\n    {\n        sSem = sSemMax;\n    }\n\n    sSem++;\n}\n\n```\n\n- `init()`\n    \n    : 세마포어의 초기화 함수인데, max 파라미터로 세마포어의 최댓값을 받습니다.\n    \n    ex) max == 1이면 크리티컬 섹션에는 컨텍스트가 딱 한 개만 진입할 수 있습니다.\n    \n    → 바이너리 세마포어\n    \n    위 코드에서는 DEF_SEM_MAX을 8로 정의했고, max가 0이하 혹은 8이상의 수가 들어오면 최댓값인 8로 지정하는 코드입니다.\n    \n- `sem_test()`\n    \n    : 세마포어를 잠글 수 없으면 `false` 리턴\n    \n\n세마포어는 커널 API를 통해 사용합니다. 그래서 `Kernel.c`에 추가해 구현하면 됩니다.\n\n### `kernel/Kernel.c` 세마포어용 커널 API\n\n```c\nvoid Kernel_lock_sem(void)\n{\n  while(false == Kernel_sem_test())\n  {\n    Kernel_yield();\n  }\n}\n\nvoid Kernel_unlock_sem(void)\n{\n  Kernel_sem_release();\n}\n```\n\n`while` 무한 루프를 대기하는 기능을 Navilos에선 `Kernel_yield()` 함수를 호출해 스케줄링을 하는 것으로 구현했습니다.\n\n이렇게 해야 해당 크리티컬 섹션의 잠금을 소유하고 있는 다른 태스크로 컨텍스트가 넘어가서 세마포어의 잠금을 풀어줄 수 있기 때문입니다.\n\n>즉, `Kernel_sem_test()`가 `false`라는 것은 잠글 수 없는 상태라는 것은 접근할 수 없는 상태임을 말합니다.\n{: .prompt-tip }\n\n따라서 `Kernel_yield()` 함수를 호출해 잠금을 해제할 수 있는 태스크로 컨텍스트를 넘겨 세마포어의 잠금을 풀어줄 수 있도록 해야합니다.\n{: .prompt-tip }\n\n**QEMU의 RealViewPB는 싱글코어 에뮬레이터입니다.**\n\n게다가 Navilos는 비선점형 스케줄러인데다가 커널이 강제로 스케줄링하는게 아니라, 태스크가 `Kernel_yield()` 함수를 호출해야 스케줄링이 동작하므로 동기화 문제가 발생하는 코드를 만드는 것이 더 어렵습니다.\n\n**따라서 동작 테스트 코드는 작성하지 않겠습니다.**\n\n## 뮤텍스(mutex)\n***\n또 다른 동기화 알고리즘으로 뮤텍스가 있습니다. 뮤텍스는 바이너리 세마포어의 일종입니다.\n\n여기서 특별한 점이 있는데, 그것은 소유의 개념입니다.\n\n세마포어는 잠금에 대한 소유 개념이 없으므로 누가 잠근 세마포어이든 누구나 잠금을 풀 수 있습니다. 그러나 뮤텍스는 소유의 개념이 있습니다.\n\n### 소유\n\n소유의 개념이 있다는 것은 뮤텍스를 잠근 태스크만이 뮤텍스의 잠금을 풀 수 있다는 말입니다.\n\n다시 말해 **뮤텍스는 바이너리 세마포어에 소유의 개념을 더한 동기화 알고리즘이라 볼 수 있습니다.**\n\nex) 화장실 키, 잠금장치 예시\n\n뮤텍스 파일을 새로 생성하지 않고, 기존의 파일에 추가해 구현하겠습니다.\n\n### `kernel/synch.h` 뮤텍스 함수 선언 추가\n\n```c\n#ifndef KERNEL_SYNCH_H_\n#define KERNEL_SYNCH_H_\n\ntypedef struct KernelMutex_t\n{\n  uint32_t owner;\n  bool lock;\n} KernelMutex_t;\n\nvoid Kernel_sem_init(int32_t max);\nbool Kernel_sem_test(void);\nvoid Kernel_sem_release(void);\n\nvoid Kernel_mutex_init(void);\nbool Kernel_mutex_lock(uint32_t owner);\nbool Kernel_mutex_unlock(uint32_t owner);\n\n#endif /* KERNEL_SYNCH_H_ */\n```\n\n중요한 부분은 뮤텍스는 세마포어와 달리 별도의 자료구조가 필요합니다.\n\n구조체의 내용을 보면 `owner`변수와 `lock`변수 두 개가 선언되어있습니다.\n\n**뮤텍스는 소유자와 잠김을 표시하는 변수를 추상화한 구조체입니다.**\n\n### `kernel/synch.c` 뮤텍스 구현 코드\n\n```c\n...\n 11 KernelMutext_t sMutex;\n...\n...\n...\nvoid Kernel_mutex_init(void)\n{\n    sMutex.owner = 0;\n    sMutex.lock = false;\n}\n\nbool Kernel_mutex_lock(uint32_t owner)\n{\n    if (sMutex.lock)\n    {\n        return false;\n    }\n\n    sMutex.owner = owner;\n    sMutex.lock = true;\n\n    return true;\n}\n\nbool Kernel_mutex_unlock(uint32_t owner)\n{\n    if (owner == sMutex.owner)\n    {\n        sMutex.lock = false;\n        return true;\n    }\n\n    return false;\n}\n```\n\n뮤텍스 자료 구조를 전역 변수로 만들어 커널 뮤텍스를 제어합니다.\n\n단순한 구현을 위해 그냥 변수로 선언했는데, 필요에 따라 배열로 만들어 여러 개 사용할 수 있습니다.\n\n이전의 설명과 동일하게 구현되었습니다.\n\n- `lock(uint32_t owner)`\n    \n    : 뮤텍스가 이미 잠겨있다면 `false`를 리턴합니다.\n    \n    잠겨있지 않다면 소유자를 등록하고 lock을 true로 만들어 잠그고 `true`를 리턴합니다.\n    \n- `unlock(uint32_t owner)`\n    \n    : 뮤텍스 전역 변수에 저장된 `owner`와 비교해 소유자일 때만 잠금을 해제할 수 있습니다.\n    \n\n이제 세마포어와 동일하게 커널 API를 만들어 보도록 하겠습니다.\n\n### `kernel/Kernel.c` 뮤텍스 커널 API\n\n```c\nvoid Kernel_lock_mutex(void)\n{\n    while(true)\n    {\n        uint32_t current_task_id = Kernel_task_get_current_task_id();\n        if (false == Kernel_mutex_lock(current_task_id))\n        {\n            Kernel_yield();\n        }\n        else\n        {\n            break;\n        }\n    }\n}\n\nvoid Kernel_unlock_mutex(void)\n{\n    uint32_t current_task_id = Kernel_task_get_current_task_id();\n    if (false == Kernel_mutex_unlock(current_task_id))\n    {\n        Kernel_yield();\n    }\n}\n```\n\n뮤텍스의 커널 API가 세마포어와 다른 점은 뮤텍스의 소유자를 뮤텍스 함수에 알려주는 작업입니다.\n\n이를 위해, 소유자인 태스크 ID를 리턴하는 함수를 추가로 작성해야 합니다.\n\n### `kernel/task.c` 현재 동작 중인 태스크 ID를 받는 함수\n\n```c\nuint32_t Kernel_task_get_current_task_id(void)\n{\n\treturn sCurrent_tcb_index;\n}\n```\n\n이렇게 하면 뮤텍스 구현은 끝났습니다.\n\n세마포어와 동일하게 동작 테스트는 진행하지 않습니다.\n\n## 스핀락(spin lock)\n***\n스핀락은 바쁜 대기(busy waiting) 개념의 크리티컬 섹션 보호 기능입니다.\n\n### 바쁜 대기(busy waiting)\n\n스케줄링을 하지 않고 CPU를 점유한 상태, 즉 CPU가 여전히 바쁜 상태에서 락이 풀리는 것을 대기한다는 말입니다.\n\n> 스케줄링을 하지 않고 짧은 시간 동안 CPU를 점유하면서 잠금이 풀리는 것을 기다린다는 아이디어이므로 멀티코어 환경에서 유용하게 쓰이기도 합니다.\n{: .prompt-tip }\n\n실제 스핀락 구현은 바쁜 대기 자체가 완전히 아토믹해야 하기 때문에 배타적 메모리 연산을 지원하는 어셈블리어 명령으로 구현되지만, 이 책에서는 개념 설명이 우선이기에 C 언어 코드로 의사 코드를 작성합니다.\n\n### 스핀락 의사 코드\n\n```c\nstatic bool sSpinLock = false;\n\nvoid spin_lock(void)\n{\n\twhile (sSpinLock); // 대기\n\tsSpinLock = true;  // 잠금\n}\n\nvoid spin_unlock(void)\n{\n\tsSpinLock = false; // 해제\n}\n```\n\n스핀락 변수가 불타입이라 바이너리 세마포어와 같은 동작을 합니다.\n\n그리고 대기할 때 스케줄러를 호출하지 않고 그냥 while문에서 CPU를 점유한 채로 대기합니다.\n\n→ 다른 코어에서 동작 중인 스핀락을 잠갔던 태스크가 `spin_unlock()` 함수를 호출하면 공유 변수인 `sSpinLock` 변수를 `false`로 바꿔 while문에 대기가 풀리면서 크리티컬 섹션에 진입하게 됩니다.\n\nQEMU는 싱글 코어 에뮬레이터이기에 테스트 케이스를 작성할 수 없기에, 이 또한 진행하지 않습니다.\n\n## 요약\n***\n이 장에서는 동기화 기능을 만들었습니다.\n\nNavilos는 싱글코어 환경이라 동기화 문제가 발생하지 않았지만, 동기화는 중요한 개념이기에 알아둬야 합니다.\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-13_chunk_0",
        "text": "[RTOS개발] 13장 동기화\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 동기화에 대해 다룹니다.\n\n>[https://github.com/navilera/Navilos/tree/49dcd06dabad43674c2a2df22c6b567f4777240a](https://github.com/navilera/Navilos/tree/49dcd06dabad43674c2a2df22c6b567f4777240a)\n{: .prompt-tip }\n\n## 서론\n***\n우선, Navilos 프로젝트에선 비선점형 스케줄링인데다가 명시적으로 `Kernel_yield()`를 호출해야 하는 싱글코어 환경이기에 동기화 문제가 발생하지 않습니다.\n\n하지만, 동기화는 운영체제에서 매우 중요한 부분이기에 꼭 배워두는 것이 좋습니다.\n\n### 동기화(synchronization)\n\n운영체제에서 어떤 작업을 아토믹 오퍼레이션(atmoic operatiron)으로 만들어 준다는 의미입니다.\n\n**어떤 작업이 아토믹하다 = 해당 작업이 끝날 때까지 컨텍스트 스위칭이 발생하지 않는다**\n\n(컨텍스트 스위칭뿐만 아니라 다른 코어가 해당 동작에 끼어들지 않아야 함)\n\n### 크리티컬 섹션(critical section)\n\n어떤 작업이 아토믹하게 구현되어야만 한다면 해당 작업을 크리티컬 섹션이라 합니다.\n\n> 즉, 동기화란 어떤 작업이 크리티컬 섹션이라",
        "index": 0
      },
      {
        "id": "2024-11-05-13_chunk_1",
        "text": "크리티컬 섹션(critical section)\n\n어떤 작업이 아토믹하게 구현되어야만 한다면 해당 작업을 크리티컬 섹션이라 합니다.\n\n> 즉, 동기화란 어떤 작업이 크리티컬 섹션이라 판단되었을 경우, 해당 크리티컬 섹션을 아토믹 오퍼레이션으로 만들어 주는 것을 말합니다.\n{: .prompt-tip }\n\n동기화를 구현하는 알고리즘은 크게 세마포어, 뮤텍스, 스핀락이 있습니다.\n\n## 세마포어(Semaphore)\n***\n세마포어의 의사 코드(pseudo code)는 아래와 같습니다.\n\n```c\nTest(S)\n{\n\twhile S<=0; // 대기\n\tS--;\n}\n\nRelease(S)\n{\n\tS++;\n}\n```\n\n아주 간단하게 두 가지 함수만으로 구현할 수 있습니다.\n\n- `Test()`\n    \n    : 이름 그대로 크리티컬 섹션에 진입 가능한지 확인하는 함수입니다.\n    \n    혹은, 세마포어를 잠글 수 있는지(lock) 확인한다는 의미도 가지고 있습니다.\n    \n- `Release()`\n    \n    : 크리티컬 섹션을 나갈 때 호출해 세마포어를 놓아주는(release) 함수입니다.\n    \n    혹은, 세마포어의 잠금을 푸는(unlock) 한다는 의미도 가지고 있습니다.\n    \n\n>잠금과 잠금의 해제!\n{: .prompt-tip }\n\n우선, 세마포어를 구현해보겠습니다.\n\n### `kernel/synch.h` 세마포어 구현\n\n```c\n#ifndef KERNEL_SYNCH_H_\n#define KERNEL_SYNCH_H_\n\nvoid Kernel_sem_init(int32_t max);\nbool Kernel_",
        "index": 1
      },
      {
        "id": "2024-11-05-13_chunk_2",
        "text": "``c\n#ifndef KERNEL_SYNCH_H_\n#define KERNEL_SYNCH_H_\n\nvoid Kernel_sem_init(int32_t max);\nbool Kernel_sem_test(void);\nvoid Kernel_sem_release(void);\n\n#endif /* KERNEL_SYNCH_H_ */\n```\n\n### `kernel/synch.c` 세마포어 구현\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n\n#include \"synch.h\"\n\n#define DEF_SEM_MAX 8\n\nstatic int32_t sSemMax;\nstatic int32_t sSem;\n\nvoid Kernel_sem_init(int32_t max)\n{\n    sSemMax = (max <= 0) ?",
        "index": 2
      },
      {
        "id": "2024-11-05-13_chunk_3",
        "text": "t32_t sSemMax;\nstatic int32_t sSem;\n\nvoid Kernel_sem_init(int32_t max)\n{\n    sSemMax = (max <= 0) ? DEF_SEM_MAX : max;\n    sSem = sSemMax;\n}\n\nbool Kernel_sem_test(void)\n{\n    if (sSem <= 0)\n    {\n        return false;\n    }\n\n    sSem--;\n\n    return true;\n}\n\nvoid Kernel_sem_release(void)\n{\n    if (sSem >= sSemMax)\n    {\n        sSem = sSemMax;\n    }\n\n    sSem++;\n}\n\n```\n\n- `init()`\n    \n    : 세마포어의 초기화 함수인데, max 파라미터로 세마포어의 최댓값을 받습니다.\n    \n    ex) max == 1이면 크리티컬 섹션에는 컨텍스트가 딱 한 개만 진입할 수 있습니다.\n    \n    → 바이너리 세마포어\n    \n    위 코드에서는 DEF_SEM_MAX을 8로 정의했고, max가 0이하 혹은 8이상의 수가 들어오면 최댓값인 8로 지정하는 코드입니다.\n    \n- `sem_test()`\n    \n    : 세마포어를 잠글 수 없으면 `false` 리턴\n    \n\n세마포어는 커널 API를 통해 사용합니다.",
        "index": 3
      },
      {
        "id": "2024-11-05-13_chunk_4",
        "text": "지정하는 코드입니다.\n    \n- `sem_test()`\n    \n    : 세마포어를 잠글 수 없으면 `false` 리턴\n    \n\n세마포어는 커널 API를 통해 사용합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-8",
    "title": "[RTOS개발] 8장 태스크",
    "path": "/2024/11/05/8장-태스크/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 작성한 함수를 이용해 태스크를 구현하겠습니다.\n\n> [https://github.com/navilera/Navilos/tree/e9b04bb60da9b282ec2761e5036a1aa9a6d2be68](https://github.com/navilera/Navilos/tree/e9b04bb60da9b282ec2761e5036a1aa9a6d2be68)\n{: .prompt-tip }\n\n## 서론\n***\n\nRTOS를 만들기 위해선 **임베디드 시스템**과 **펌웨어**에 대한 기본적인 지식이 필요하므로\n\n아무것도 없는 맨바닥에서 **펌웨어가 어떻게 만들어지는지** 설명했습니다.\n\n그 과정에서 RTOS를 만드는 데 필요한 몇 가지 라이브러리 함수를 만들었습니다.\n\n이 함수들을 이용해서 이제 RTOS를 만들어 보겠습니다.\n\n### 운영체제(RTOS 포함)\n\n> 태스크를 관리하여 사용자가 하고 싶은 것을 할 수 있도록 도와주는 것!\n\n## 태스크 컨트롤 블록(task control block)\n***\n개별 태스크 자체를 추상화하는 자료 구조를 말합니다.\n\n태스크는 운영체제에서 동작하는 프로그램 그 자체입니다. \n\n여러가지 태스크를 사용하고 전환(switching)하더라도 프로그램의 흐름에 어떤 문제도 생기면 안 됩니다.\n\n이것을 보장하기 위해 **태스크 컨트롤 블록**은 현재 진행 중인 **프로그램의 현재 상태 정보(context)**를 기록하고 있어야 합니다.\n\n컨텍스트 말고도 정보를 더 추가할 수 있는데, 대표적인 것은 **태스크의 이름**입니다.\n\n없어도 상관없지만 태스크의 이름 정보를 가지고 있으면 실행 중인 태스크의 정보를 표시해 주는 별도의 기능을 구현하는 데 사용할 수 있습니다.\n\n태스크 컨트롤 블록 구현은 RTOS 커널을 만드는 첫 번째 작업입니다.\n\nkernel이라는 디렉터리를 새로 만들고 두 가지 파일을 만들겠습니다.\n\n### `kernel/task.h` 태스크 컨트롤 블록과 관련 함수 정의\n\n```c\n#ifndef KERNEL_TASK_H_\n#define KERNEL_TASK_H_\n\n#include \"MemoryMap.h\"\n\n#define NOT_ENOUGH_TASK_NUM 0xFFFFFFFF\n\n#define USR_TASK_STACK_SIZE     0x100000\n#define MAX_TASK_NUM            (TASK_STACK_SIZE / USR_TASK_STACK_SIZE)\n\ntypedef struct KernelTaskContext_t\n{\n  uint32_t spsr;\n  uint32_t r0_r12[13];\n  uint32_t pc;\n} KernelTaskContext_t;\n\ntypedef struct KernelTcb_t\n{\n  uint32_t sp;\n  uint8_t* stack_base;\n} KernelTcb_t;\n\ntypedef void (*KernelTaskFunc_t)(void);\n\nvoid Kernel_task_init(void);\nuint32_t Kernel_task_create(KernelTaskFunc_t startFunc);\n\n#endif /* KERNEL_TASK_H_ */\n```\n\nQEMU는 메모리가 넉넉하기에 개별 태스크를 1MB로 모두 동등하게 사용하고 있습니다.\n\n우선, 이전 페이지에서 태스크 스택용으로 64MB를 할당해 놓았고 각각의 태스크가 동일하게 1MB씩 스택을 쓸 수 있으므로 Navilos는 태스크를 최대 64개까지 사용할 수 있습니다.\n\n26, 27번째 줄에 선언한 `init()` 함수와 `create()` 함수는 각각 커널의 태스크 관련 기능을 초기화하는 함수와 커널에 태스크를 생성(등록)하는 함수입니다.\n\n11~22번째 줄의 **두 구조체가 태스크 컨트롤 블록**입니다.\n\n`KernelTaskContext_t` 는 **컨텍스트를 추상화한 자료 구조**입니다.\n\n**ARM의 프로그램 상태 레지스터와 범용 레지스터를 백업할 수 있는 영역**이 있습니다.\n\n이 영역을 **구조체로 확보**해 놓은 것이며, 이것이 바로 **컨텍스트의 실체**입니다.\n\n그리고 `KernelTcb_t`에는 스택 관련 정보만 저장하고 있습니다.\n\n- `sp`는 범용 레지스터에 있는 스택 포인터\n- `stack_base` 멤버 변수는 컨텍스트에 포함되지 않는 부가 데이터라고 볼 수 있습니다.(개별 태스크의 스택 베이스 주소 저장용)\n\n테스크 컨텍스트는 결국 레지스터와 스택 포인터의 값입니다.\n\n스택 포인터도 레지스터의 일부이므로 태스크 컨텍스트를 전환한다는 것\n\n→ 코어의 레지스터의 값을 다른 태스크의 것으로 바꾼다는 것.\n\n## 태스크 컨트롤 블록 초기화\n***\n이제 실제 메모리에 태스크 컨트롤 블록 인스턴스를 만들고 기본값을 할당하는 코드를 작성하겠습니다.\n\n### `kernel/task.c` 태스크 컨트롤 블록 초기화 코드\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n#include \"ARMv7AR.h\"\n#include \"task.h\"\n\nstatic KernelTcb_t  sTask_list[MAX_TASK_NUM];\nstatic uint32_t     sAllocated_tcb_index;\n\nvoid Kernel_task_init(void)\n{\n  sAllocated_tcb_index = 0;\n\n  for(uint32_t i = 0 ; i < MAX_TASK_NUM ; i++)\n  {\n    sTask_list[i].stack_base = (uint8_t*)(TASK_STACK_START + (i * SR_TASK_STACK_S    IZE));\n    sTask_list[i].sp = (uint32_t)sTask_list[i].stack_base + USR_TASK_STACK_SIZE -     4;\n\n    sTask_list[i].sp -= sizeof(KernelTaskContext_t);\n    KernelTaskContext_t* ctx = (KernelTaskContext_t*)sTask_list[i].sp;\n    ctx->pc = 0;\n    ctx->spsr = ARM_MODE_BIT_SYS;\n  }\n}\n\nuint32_t Kernel_task_create(KernelTaskFunc_t startFunc)\n{\n  return NOT_ENOUGH_TASK_NUM;\n}\n```\n\n7번째 줄에서 태스크 컨트롤 블록을 64개 배열로 선언했습니다.\n\n메모리에 태스크 컨트롤 블록용으로 자리를 잡아 놓은 것입니다.\n\n동적 메모리 할당을 피하기 위해 일종의 객체 풀(object pool)로 잡은 것!\n\n8번째 줄의 `sAllocated_tcb_index` 변수는 생성한 태스크 컨트롤 블록 인덱스를 저장하는 변수\n\n태스크를 몇 개까지 생성했는지 이 변수 값을 보고 추적 가능합니다.\n\n초기화 시 이 변수값을 0으로 초기화합니다.(배열 인덱스로 사용하기에)\n\n14~23번째 줄은 태스크 컨트롤 블록 배열을 모두 순회하며 초기화하는 코드입니다.\n\nNavilos는 태스크의 컨텍스트를 태스크 컨트롤 블록이 아니라 해당 태스크의 스택에 저장합니다.\n\n**태스크의 컨텍스트를 어디에 저장하느냐는 개발자의 설계에 따라 달라지는 것!**\n\n위 코드에서 초기화 한 태스크 스택 구조를 그림으로 나타내면 아래와 같습니다.\n\n![image.png](/assets/img/OS/os701.png)\n\n⬆️**태스크 스택 구조**\n\n> 4바이트는 태스크 간의 경계를 표시하고자 패딩했습니다\n\n스택 포인터가 태스크 컨텍스트 다음에 위치합니다.\n\n하지만, 앞으로 설명할 컨텍스트 스위칭 작업에 의해 태스크 컨텍스트는 모두 레지스터로 복사\n\n→ 스택 포인터는 태스크 컨텍스트가 없는 위치로 이동\n\n그래서 동작 중인 태스크의 스택에는 태스크 컨텍스트가 존재하지 않습니다.\n\n## 태스크 생성\n***\n이어서 `Kernel_task_create()` 함수를 작성하겠습니다.\n\n이 함수는 태스크로 동작할 함수를 태스크 컨트롤 블록에 등록합니다.\n\n그리고 태스크 컨트롤 블록을 커널에 만듭니다.\n\n### `kernel/task.c` 태스크 생성\n\n```c\n uint32_t Kernel_task_create(KernelTaskFunc_t startFunc)\n {\n   KernelTcb_t* new_tcb = &sTask_list[sAllocated_tcb_index++];\n\n   if (sAllocated_tcb_index > MAX_TASK_NUM)\n   {\n     return NOT_ENOUGH_TASK_NUM;\n   }\n\n   KernelTaskContext_t* ctx = (KernelTaskContext_t*)new_tcb->sp;\n   ctx->pc = (uint32_t)startFunc;\n\n   return (sAllocated_tcb_index - 1);\n }\n```\n\n3번째 줄이 태스크 리스트에서 사용하지 않은 태스크 컨트롤 블록 객체를 하나 가져오는 코드입니다.\n\n5~8번째 줄은 에러 검사 코드입니다.\n\n10번째 줄은 **현재 스택에 저장된 컨텍스트 메모리 주소 포인터를 가져옵니다.**\n\n11번째 줄은 **파라미터로 넘어오는 함수의 시작 주소를 PC에 넣어줍니다.**\n\n태스크를 동작하려면 스케줄러와 컨텍스트 스위칭까지 다 만들어야하기에, 아직 태스크를 동작시켜 볼 순 없습니다.\n\n보통 전체 시스템을 각 **기능별로 나눠** 개발하고 해당 기능을 실행하는 **태스크 함수를 대표로 하나** 만듭니다.\n\n그리고 펌웨어가 시작될 때 RTOS를 **초기화하는 코드**에서 **개별적으로 태스크를 등록**합니다.\n\n예를 들어, 네트워크를 처리하는 기능을 구현하는 소스 파일들은 별도의 디렉토리에 있고,\n\n그중 한 소스 파일에 태스크 함수가 있는 것!\n\n마찬가지로 화면 출력 기능이라면 해당 기능을 구현하는 소스 파일들은 별도의 디렉터리에 모여있고, 그중 하나에 대표 태스크 함수가 있는 식입니다.\n\n하지만 지금은 그런 것이 없기에 일단 `Main.c`파일에 더미 태스크 함수를 만들고 커널에 등록하도록 합니다.\n\n### `boot/Main.c` 태스크 등록\n\n```c\n...\nvoid User_task0(void);\nvoid User_task1(void);\nvoid User_task2(void);\n...\nstatic void Kernel_init(void)\n{\n    uint32_t taskId;\n\n    taskId = Kernel_task_create(User_task0);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task0 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task1);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task1 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task2);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task2 creation fail\\n\");\n    }\n}\n...\nvoid User_task0(void)\n{\n    debug_printf(\"User Task #0\\n\");\n\n    while(true);\n}\n\nvoid User_task1(void)\n{\n    debug_printf(\"User Task #1\\n\");\n\n    while(true);\n}\n\nvoid User_task2(void)\n{\n    debug_printf(\"User Task #2\\n\");\n\n    while(true);\n}\n```\n\n더미 태스크 함수를 3개 등록하는 코드를 작성했습니다.\n\n`taskId = Kernel_task_create(User_task1)`\n: 함수 포인터를 파라미터로 넘깁니다. 해당 함수 포인터는 태스크 컨트롤 블록의 PC에 저장됩니다.\n\n  그러면 나중에 컨텍스트 스위칭 시 ARM의 PC 레지스터에 태스크 컨트롤 블록의 PC값이 저장됩니다.\n\n  Navilos의 태스크 관리 설계에는 태스크의 종료를 보장하는 기능이 없기에, 즉 태스크는 종료되면 안 되기에, while 무한 루프로 한번 시작된 태스크는 계속 실행 중이어야 합니다.\n\n## 요약\n***\n이 장에서는 태스크 컨트롤 블록 자료 구조를 설계하고 구현했습니다.\n\n그리고 태스크 컨트롤 블록에 함수 포인터를 연결해 함수를 태스크로 만들었습니다.\n\n각 태스크 함수는 그냥 C 언어 함수와 같이 생겼지만, 각 태스크 함수는 스택 주소와 레지스터를 독립적으로 가지고 있습니다.\n\n→ 기능적으로 완전히 독립된 프로세스\n\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-8_chunk_0",
        "text": "[RTOS개발] 8장 태스크\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 작성한 함수를 이용해 태스크를 구현하겠습니다.\n\n> [https://github.com/navilera/Navilos/tree/e9b04bb60da9b282ec2761e5036a1aa9a6d2be68](https://github.com/navilera/Navilos/tree/e9b04bb60da9b282ec2761e5036a1aa9a6d2be68)\n{: .prompt-tip }\n\n## 서론\n***\n\nRTOS를 만들기 위해선 **임베디드 시스템**과 **펌웨어**에 대한 기본적인 지식이 필요하므로\n\n아무것도 없는 맨바닥에서 **펌웨어가 어떻게 만들어지는지** 설명했습니다.\n\n그 과정에서 RTOS를 만드는 데 필요한 몇 가지 라이브러리 함수를 만들었습니다.\n\n이 함수들을 이용해서 이제 RTOS를 만들어 보겠습니다.\n\n### 운영체제(RTOS 포함)\n\n> 태스크를 관리하여 사용자가 하고 싶은 것을 할 수 있도록 도와주는 것!\n\n## 태스크 컨트롤 블록(task control block)\n***\n개별 태스크 자체를 추상화하는 자료 구조를 말합니다.\n\n태스크는 운영체제에서 동작하는 프로그램 그 자체입니다.",
        "index": 0
      },
      {
        "id": "2024-11-05-8_chunk_1",
        "text": "## 태스크 컨트롤 블록(task control block)\n***\n개별 태스크 자체를 추상화하는 자료 구조를 말합니다.\n\n태스크는 운영체제에서 동작하는 프로그램 그 자체입니다.",
        "index": 1
      },
      {
        "id": "2024-11-05-8_chunk_2",
        "text": "## 태스크 컨트롤 블록(task control block)\n***\n개별 태스크 자체를 추상화하는 자료 구조를 말합니다.\n\n태스크는 운영체제에서 동작하는 프로그램 그 자체입니다.",
        "index": 2
      },
      {
        "id": "2024-11-05-8_chunk_3",
        "text": "## 태스크 컨트롤 블록(task control block)\n***\n개별 태스크 자체를 추상화하는 자료 구조를 말합니다.\n\n태스크는 운영체제에서 동작하는 프로그램 그 자체입니다.",
        "index": 3
      },
      {
        "id": "2024-11-05-8_chunk_4",
        "text": "## 태스크 컨트롤 블록(task control block)\n***\n개별 태스크 자체를 추상화하는 자료 구조를 말합니다.\n\n태스크는 운영체제에서 동작하는 프로그램 그 자체입니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-7",
    "title": "[RTOS개발] 7장 타이머",
    "path": "/2024/11/05/7장-타이머/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 타이머 하드웨어에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/fcd6a32a91d5d4053fbcd7b7e8689f77c74c2989](https://github.com/navilera/Navilos/tree/fcd6a32a91d5d4053fbcd7b7e8689f77c74c2989)\n{: .prompt-tip }\n\n## 서론\n***\n일반적으로 타이머는 목표 카운트 레지스터와 측정 카운트 레지스터를 조합해 활용합니다.\n\nRealViewPB는 SP804라는 타이머 하드웨어를 가지고 있습니다.\n\n이 타이머는 측정 카운터가 감소하며 목표 카운트 값과 같아지면 인터럽트를 발생시키는 형식으로 동작합니다.\n\n우리의 목표는 일정 시간 간격으로 타이머 인터럽트를 발생시켜 얼마만큼 시간이 지났는지 알아내는 것입니다.\n\n이것을 알아낼 수 있으면 `delay()` 와 같은 함수를 구현할 수 있습니다.\n\n\n## 타이머 하드웨어 초기화\n***\n새로운 하드웨어를 추가하는 첫 작업은 해당 하드웨어의 레지스터를 구조체로 추상화하여 hal에 추가하는 작업입니다.\n\n### `hal/rvpb/Timer.h` SP804 하드웨어의 레지스터\n\n```c\n#ifndef HAL_RVPB_TIMER_H_\n#define HAL_RVPB_TIMER_H_\n\ntypedef union TimerXControl_t\n{\n    uint32_t all;\n    struct {\n        uint32_t OneShot:1;     //0\n        uint32_t TimerSize:1;   //1\n        uint32_t TimerPre:2;    //3:2\n        uint32_t Reserved0:1;   //4\n        uint32_t IntEnable:1;   //5\n        uint32_t TimerMode:1;   //6\n        uint32_t TimerEn:1;     //7\n        uint32_t Reserved1:24;  //31:8\n    } bits;\n} TimerXControl_t;\n\ntypedef union TimerXRIS_t\n{\n    uint32_t all;\n    struct {\n        uint32_t TimerXRIS:1;   //0\n        uint32_t Reserved:31;   //31:1\n    } bits;\n} TimerXRIS_t;\n\ntypedef union TimerXMIS_t\n{\n    uint32_t all;\n    struct {\n        uint32_t TimerXMIS:1;   //0\n        uint32_t Reserved:31;   //31:1\n    } bits;\n} TimerXMIS_t;\n\ntypedef struct Timer_t\n{\n    uint32_t        timerxload;     // 0x00\n    uint32_t        timerxvalue;    // 0x04\n    TimerXControl_t timerxcontrol;  // 0x08\n    uint32_t        timerxintclr;   // 0x0C\n    TimerXRIS_t     timerxris;      // 0x10\n    TimerXMIS_t     timerxmis;      // 0x14\n    uint32_t        timerxbgload;   // 0x18\n} Timer_t;\n\n#define TIMER_CPU_BASE  0x10011000\n#define TIMER_INTERRUPT 36\n\n#define TIMER_FREERUNNING   0\n#define TIMER_PERIOIC       1\n\n#define TIMER_16BIT_COUNTER 0\n#define TIMER_32BIT_COUNTER 1\n\n#define TIMER_10HZ_INTERVAL       (32768 * 4)\n\n#endif /* HAL_RVPB_TIMER_H_ */\n```\n\n`Timer_t` 타입의 구조체를 보면 레지스터 7개가 정의되어 있습니다.\n\n- `timerxload` : 카운터의 목표 값을 지정하는 레지스터\n- `timerxvalue` : 감소하는 레지스터\n- `timerxcontorl` : 타이머 하드웨어의 속성을 설정하는 레지스터\n- `timerxintclr` : 인터럽트 처리가 완료되었음을 타이머 하드웨어에 알려주는 레지스터\n- 나머지 3개는 현재 사용하지 않음.\n\n`TimerXContorl_t` 는 타이머 하드웨어의 속성을 설정합니다.\n\n`OneShot` = 1이면 타이머 인터럽트가 한 번 발생하고 타이머가 바로 꺼집니다.\n\n다시 켜려면 수동으로 레지스터를 설정해야 합니다.\n\n48번째 줄의 `TIMER_CPU_BASE`는 타이머 하드웨어 레지스터가 할당되어있는 메모리 주소입니다.\n\nRealViewPB의 데이터시트를 보면 0x1001 1000에 타이머 0과 1이 할당되어 있습니다.\n\n레지스터 헤더 파일을 만들었으니 이제 초기화 코드를 작성하겠습니다.\n\nUART와 마찬가지로 `hal/HalTimer.h` 파일을 만들어 공용 인터페이스 API를 확장하고 그것에 맞춰 구현 코드를 작성하겠습니다.\n\n### `hal/HalTimer.h` 공용 인터페이스 API\n\n```c\n#ifndef HAL_HALTIMER_H_\n#define HAL_HALTIMER_H_\n\nvoid    Hal_timer_init(void);\n\n#endif /* HAL_HALTIMER_H_ */\n```\n\n우선 타이머를 초기화하는 `Hal_timer_init` 함수만 선언했습니다.\n\n개발을 진행하는 과정에서 하나씩 추가해 가겠습니다.\n\nUART나 GIC와 마찬가지로 공용 API를 구현하는 하드웨어 의존적인 코드를 `hal/rvpb/Timer.c`에 작성합니다.\n\n### `hal/rvpb/Timer.c` 타이머 HAL 구현\n\n```c\n#include \"stdint.h\"\n#include \"Timer.h\"\n#include \"HalTimer.h\"\n#include \"HalInterrupt.h\"\n\nextern volatile Timer_t* Timer;\nstatic void interrupt_handler(void);\nstatic uint32_t internal_1ms_counter;\n\nvoid Hal_timer_init(void)\n{\n    // inerface reset\n    Timer->timerxcontrol.bits.TimerEn = 0;\n    Timer->timerxcontrol.bits.TimerMode = 0;\n    Timer->timerxcontrol.bits.OneShot = 0;\n    Timer->timerxcontrol.bits.TimerSize = 0;\n    Timer->timerxcontrol.bits.TimerPre = 0;\n    Timer->timerxcontrol.bits.IntEnable = 1;\n    Timer->timerxload = 0;\n    Timer->timerxvalue = 0xFFFFFFFF;\n\n    // set periodic mode\n    Timer->timerxcontrol.bits.TimerMode = TIMER_PERIOIC;\n    Timer->timerxcontrol.bits.TimerSize = TIMER_32BIT_COUNTER;\n    Timer->timerxcontrol.bits.OneShot = 0;\n    Timer->timerxcontrol.bits.TimerPre = 0;\n    Timer->timerxcontrol.bits.IntEnable = 1;\n    uint32_t interval = TIMER_10HZ_INTERVAL / 1000;\n    Timer->timerxload = interval;\n    Timer->timerxcontrol.bits.TimerEn = 1;\n    internal_1ms_counter = 0;\n    // Register Timer interrupt handler\n    \n    Hal_interrupt_enable(TIMER_INTERRUPT);\n    Hal_interrupt_register_handler(interrupt_handler, TIMER_INTERRUPT);\n}\nuint32_t Hal_timer_get_1ms_counter(void)\n{\n    return internal_1ms_counter;\n}\n// 인터럽트 핸들러\nstatic void interrupt_handler(void)\n{\n    internal_1ms_counter++;\n    Timer->timerxintclr = 1;\n}\n\n```\n\n우선 `init` 함수부터 살펴보겠습니다.\n(SP804 데이터시트에서 해당 절차를 그대로 코드로 옮긴 것)\n\n1. 타이머를 끕니다.(TimerEn = 0)\n2. 프리-러닝 모드로 설정해 놓습니다.(TimerMode = 0, OneShot = 0)\n3. 16비트 카운터 모드로 설정합니다.(TimerSize = 0)\n4. 프리스케일러 분주(divider)는 1로 설정합니다.(TimerPre = 0)\n5. 인터럽트를 켭니다.(IntEnable = 1)\n6. 로드 레지스터를 켭니다.\n7. 카운터 레지스터는 0xFFFF FFFF로 설정합니다.\n\n인터페이스 초기화 코드 이후에 나오는 코드는 \n\n피리오딕 모드로 1ms 간격으로 인터럽트를 발생하게 타이머를 설정하는 코드입니다.\n\n가장 중요한 코드는 31번째 줄입니다.\n\n```c\n    uint32_t interval = TIMER_10HZ_INTERVAL / 100;\n```\n\n이 interval 변수의 값이 로드 레지스터로 들어갑니다. 따라서 이 값이 타이머 인터럽트의 발생 간격을 지정하는 것입니다.\n\n```c\n#define TIMER_1MZ_INTERVAL (1024*1024)\nTIMER_1MZ_INTERVAL / 1000;\n```\n\n위 두 줄을 이해해야 왜 간격을 1밀리초로 지정했는지 알 수 있습니다.\n\nRealViewPB는 **타이머 클럭 소스(clock source)로 1MHz 클럭**을 받거나 **32.768kHz짜리 크리스탈 오실레이터를 클럭**으로 쓸 수 있습니다.\n\nQEMU의 RealView-PB는 타이머의 클럭으로 1MHz를 쓴다는 것을 알 수 있습니다.\n\n기준 클럭이 1MHz인 것을 알았으니 이제 타이머의 로드 레지스터에 값을 어떻게 설정해야 하는지 찾아보겠습니다. \n\n`PL804` 의 데이터시트에 공식이 있습니다.\n\n$$\nTimerXLoad = {\nInterval * TIMCLK_{FREQ}\\over{TIMCLKENX_{DIV} * PRESCALE_{DIV}}}\n$$\n\nTIMCLKENX = 1이고 PRESCALE = 1이므로 분모는 신경쓰지 않아도 됩니다.\n\n그러므로 클럭값 자체가 로드 레지스터의 값이 되며, TIMCLK = 1024 x 1024(1M)이기에 1024*1024가 로드 레지스터의 값이 됩니다.\n\n공식대로라면 1M인 1048576을 설정하면 타이머 인터럽트가 1초마다 한 번씩 발생하게 됩니다.\n\n우리가 원하는 것은 1ms 이므로 숫자를 1000으로 나눠줍니다.\n\n그래서 1048576 / 1000을 로드 레지스터에 설정하는 것입니다.\n\n\n<br>\n\n\n\n43~48번째 코드는 **인터럽트 핸들러**입니다.\n\n앞서 작성한 코드가 제대로 동작한다면 이 핸들러는 1ms 마다 실행될 것이므로 `internal_1ms_counter` 변수 값은 1밀리초마다 1씩 증가하게 됩니다.\n\n값을 증가했다면 `Timer->timerxintclr = 1;` 로 인터럽트를 클리어해야 합니다.\n\n그렇지 않으면 하드웨어가 인터럽트 신호를 계속 GIC에 보내 원하는 동작을 하지 않게 됩니다.\n\n## 타이머 카운터 오버플로\n***\n임베디드 시스템에 전원이 들어오면 숫자가 증가하기 시작해 전원이 꺼질 때까지 계속 증가합니다.\n\n여기서 고려해야 할 점은 이 변수의 크기가 32비트이기에 최대 크기까지 증가하고 나면 다시 변수의 값이 0이 된다는 점입니다.(오버플로우)\n\n→ 0xFFFF FFFF = 4294967초 -> 최댓값\n\n그러므로 시스템을 50일 정도 계속 켜 놓으면 50일이 다 지나기 전에 타이머 카운터는 오버플로우를 일으켜 0이 될 것입니다.\n\n## `delay()` 함수\n***\n이번에는 가장 간단한 형태의 시간 지연 함수인 `delay()` 함수를 만들어 보겠습니다.\n\n`stdlib.h` 파일을 `lib` 디렉토리 밑에 생성합니다. \n\n`delay()` 함수와 같은 유틸리티 관련 함수를 `stdlib.h`에 정의하겠습니다.\n\n### `lib/stdlib.h` `delay()` 함수 선언\n\n```c\n#ifndef LIB_STDLIB_H_\n#define LIB_STDLIB_H_\n\nvoid delay(uint32_t ms);\n\n#endif /* LIB_STDLIB_H_ */\n```\n\n- 밀리초를 파라미터로 받습니다.\n\n이어서 함수 본체를 작성하겠습니다.\n\n`delay()` 함수는 타이머 카운터 변수의 값을 이용합니다. \n\n타이머 카운터 변수는 로컬 전역 변수이므로 다른 파일에서 값을 이용하려면\n\n- 글로벌 전역 변수로 바꾸기\n- 값을 읽을 수 있는 인터페이스 함수를 만들기\n\n본 교재에서는 2번 방법을 선호합니다.\n\n타이머 공용 인터페이스에 타이머 카운터 변수의 값을 읽을 수 있는 인터페이스 함수를 선언합니다.\n\n### `hal/HalTimer.h` 공용 인터페이스API 추가\n\n```c\n#ifndef HAL_HALTIMER_H_\n#define HAL_HALTIMER_H_\n\nvoid     Hal_timer_init(void);\nuint32_t Hal_timer_get_1ms_counter(void); // 추가\n\n#endif /* HAL_HALTIMER_H_ */\n```\n\n그리고 타이머 카운터 변수의 값을 리턴하는 함수 본체를 작성합니다.\n\n### `hal/rvpb/Timer.c`에 추가\n\n```c\nuint32_t Hal_timer_get_1ms_counter(void)\n{\n\t\treturn internal_1ms_counter;\n}\n```\n\n이제 이 함수를 이용해서 `delay()` 함수의 본체를 만들겠습니다.\n\n### `lib/stdlib.c` `delay()` 함수 본체\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n#include \"HalTimer.h\"\n\nvoid delay(uint32_t ms)\n{\n\tuint32_t goal = Hal_timer_get_1ms_counter() + ms;\n\n\twhile(goal != Hal_timer_get_1ms_counter());\n}\n```\n\n`delay()` 함수를 통해 100ms의 시간 지연을 구현하고 싶다면, 함수가 호출된 순간의 타이머 카운터 값, 예시로 100이라면 타이머 카운터의 값이 200이 될 때까지 기다리면 되는 것입니다.\n\n\n이제 `delay()` 함수를 테스트하는 코드를 작성해 제대로 동작하는지 확인해보겠습니다.\n\n### `boot/Main.c` `delay()` 함수 테스트 코드\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n\n#include \"HalUart.h\"\n#include \"HalInterrupt.h\"\n#include \"HalTimer.h\"\n\n#include \"stdio.h\"\n#include \"stdlib.h\"\n\nstatic void Hw_init(void);\n\nstatic void Printf_test(void);\nstatic void Timer_test(void);\n\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n    Hal_uart_put_char('\\n');\n\n    putstr(\"Hello World!\\n\");\n\n    Printf_test();\n    Timer_test();\n\n    while(true);\n}\n\nstatic void Hw_init(void)\n{\n    Hal_interrupt_init();\n    Hal_uart_init();\n    Hal_timer_init();\n}\n\nstatic void Printf_test(void)\n{\n    char* str = \"printf pointer test\";\n    char* nullptr = 0;\n    uint32_t i = 5;\n    uint32_t* sysctrl0 = (uint32_t*)0x10001000;\n\n    debug_printf(\"%s\\n\", \"Hello printf\");\n    debug_printf(\"output string pointer: %s\\n\", str);\n    debug_printf(\"%s is null pointer, %u number\\n\", nullptr, 10);\n    debug_printf(\"%u = 5\\n\", i);\n    debug_printf(\"dec=%u hex=%x\\n\", 0xff, 0xff);\n    debug_printf(\"print zero %u\\n\", 0);\n    debug_printf(\"SYSCTRL0 %x\\n\", *sysctrl0);\n}\n\nstatic void Timer_test(void)\n{\n    while(true)\n    {\n        debug_printf(\"current count : %u\\n\", Hal_timer_get_1ms_counter());\n        delay(1000);\n    }\n}\n```\n\n![image.png](/assets/img/OS/os601.png)\n\n무한 루프를 돌면서 1초를 대기하고 타이머 카운터 변수의 값을 UART로 출력하는 코드입니다.\n\n제대로 동작한다면 1초마다 한 번씩 메시지가 화면에 출력되어야 합니다.\n\n```bash\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\nQEMU는 실물 하드웨어가 아니므로 타이머 같은 값이 정확히 동작하지 않습니다.\n\n대략 1초마다 나오면 맞다고 보고 나중에 실제 하드웨어로 옮길 때 값을 조정하는 식으로 개발합니다.\n\n## 요약\n***\n이 장에서는 타이머 하드웨어를 제어하는 방법을 공부했습니다.\n\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-7_chunk_0",
        "text": "[RTOS개발] 7장 타이머\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 타이머 하드웨어에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/fcd6a32a91d5d4053fbcd7b7e8689f77c74c2989](https://github.com/navilera/Navilos/tree/fcd6a32a91d5d4053fbcd7b7e8689f77c74c2989)\n{: .prompt-tip }\n\n## 서론\n***\n일반적으로 타이머는 목표 카운트 레지스터와 측정 카운트 레지스터를 조합해 활용합니다.\n\nRealViewPB는 SP804라는 타이머 하드웨어를 가지고 있습니다.\n\n이 타이머는 측정 카운터가 감소하며 목표 카운트 값과 같아지면 인터럽트를 발생시키는 형식으로 동작합니다.\n\n우리의 목표는 일정 시간 간격으로 타이머 인터럽트를 발생시켜 얼마만큼 시간이 지났는지 알아내는 것입니다.\n\n이것을 알아낼 수 있으면 `delay()` 와 같은 함수를 구현할 수 있습니다.\n\n\n## 타이머 하드웨어 초기화\n***\n새로운 하드웨어를 추가하는 첫 작업은 해당 하드웨어의 레지스터를 구조체로 추상화하여 hal에 추가하는 작업입니다.\n\n### `hal/rvpb/Timer.h` SP804 하드웨어의 레지스터\n\n```c\n#ifndef HAL_RVPB_TIMER_H_\n#define HAL",
        "index": 0
      },
      {
        "id": "2024-11-05-7_chunk_1",
        "text": "al에 추가하는 작업입니다.\n\n### `hal/rvpb/Timer.h` SP804 하드웨어의 레지스터\n\n```c\n#ifndef HAL_RVPB_TIMER_H_\n#define HAL_RVPB_TIMER_H_\n\ntypedef union TimerXControl_t\n{\n    uint32_t all;\n    struct {\n        uint32_t OneShot:1;     //0\n        uint32_t TimerSize:1;   //1\n        uint32_t TimerPre:2;    //3:2\n        uint32_t Reserved0:1;   //4\n        uint32_t IntEnable:1;   //5\n        uint32_t TimerMode:1;   //6\n        uint32_t TimerEn:1;     //7\n        uint32_t Reserved1:24;  //31:8\n    } bits;\n} TimerXControl_t;\n\ntypedef union TimerXRIS_t\n{\n    uint32_t all;\n    struct {\n        uint32_t TimerXRIS:1;   //0\n        uint32_t Reserved:31;   //31:1\n    } bits;\n} TimerXRIS_t;\n\ntypedef union TimerXMIS_t\n{\n    uint32_t all;\n    struct {\n        uint32_t TimerXMIS:1;   //0\n        uint32_t Reserved:31;   //31:1",
        "index": 1
      },
      {
        "id": "2024-11-05-7_chunk_2",
        "text": "nt32_t all;\n    struct {\n        uint32_t TimerXMIS:1;   //0\n        uint32_t Reserved:31;   //31:1\n    } bits;\n} TimerXMIS_t;\n\ntypedef struct Timer_t\n{\n    uint32_t        timerxload;     // 0x00\n    uint32_t        timerxvalue;    // 0x04\n    TimerXControl_t timerxcontrol;  // 0x08\n    uint32_t        timerxintclr;   // 0x0C\n    TimerXRIS_t     timerxris;      // 0x10\n    TimerXMIS_t     timerxmis;      // 0x14\n    uint32_t        timerxbgload;   // 0x18\n} Timer_t;\n\n#define TIMER_CPU_BASE  0x10011000\n#define TIMER_INTERRUPT 36\n\n#define TIMER_FREERUNNING   0\n#define TIMER_PERIOIC       1\n\n#define TIMER_16BIT_COUNTER 0\n#define TIMER_32BIT_COUNTER 1\n\n#define TIMER_10HZ_INTERVAL       (32768 * 4)\n\n#endif /* HAL_RVPB_TIMER_H_ */\n```\n\n`Timer_t` 타입의 구조체를 보면 레지스터 7개가 정의되어 있습니다.\n\n- `timerxload` :",
        "index": 2
      },
      {
        "id": "2024-11-05-7_chunk_3",
        "text": "4)\n\n#endif /* HAL_RVPB_TIMER_H_ */\n```\n\n`Timer_t` 타입의 구조체를 보면 레지스터 7개가 정의되어 있습니다.\n\n- `timerxload` : 카운터의 목표 값을 지정하는 레지스터\n- `timerxvalue` : 감소하는 레지스터\n- `timerxcontorl` : 타이머 하드웨어의 속성을 설정하는 레지스터\n- `timerxintclr` : 인터럽트 처리가 완료되었음을 타이머 하드웨어에 알려주는 레지스터\n- 나머지 3개는 현재 사용하지 않음.\n\n`TimerXContorl_t` 는 타이머 하드웨어의 속성을 설정합니다.\n\n`OneShot` = 1이면 타이머 인터럽트가 한 번 발생하고 타이머가 바로 꺼집니다.\n\n다시 켜려면 수동으로 레지스터를 설정해야 합니다.\n\n48번째 줄의 `TIMER_CPU_BASE`는 타이머 하드웨어 레지스터가 할당되어있는 메모리 주소입니다.\n\nRealViewPB의 데이터시트를 보면 0x1001 1000에 타이머 0과 1이 할당되어 있습니다.\n\n레지스터 헤더 파일을 만들었으니 이제 초기화 코드를 작성하겠습니다.\n\nUART와 마찬가지로 `hal/HalTimer.h` 파일을 만들어 공용 인터페이스 API를 확장하고 그것에 맞춰 구현 코드를 작성하겠습니다.\n\n### `hal/HalTimer.h` 공용 인터페이스 API\n\n```c\n#ifndef HAL_HALTIMER_H_\n#define HAL_HALTIMER_H_\n\nvoid    Hal_timer_init(void);\n\n#endif /* HAL_HALTIMER_H_ */\n```\n\n우선 타이머를 초기화하는 `Ha",
        "index": 3
      },
      {
        "id": "2024-11-05-7_chunk_4",
        "text": "HAL_HALTIMER_H_\n\nvoid    Hal_timer_init(void);\n\n#endif /* HAL_HALTIMER_H_ */\n```\n\n우선 타이머를 초기화하는 `Hal_timer_init` 함수만 선언했습니다.\n\n개발을 진행하는 과정에서 하나씩 추가해 가겠습니다.\n\nUART나 GIC와 마찬가지로 공용 API를 구현하는 하드웨어 의존적인 코드를 `hal/rvpb/Timer.c`에 작성합니다.\n\n### `hal/rvpb/Timer.c` 타이머 HAL 구현\n\n```c\n#include \"stdint.h\"\n#include \"Timer.h\"\n#include \"HalTimer.h\"\n#include \"HalInterrupt.h\"\n\nextern volatile Timer_t* Timer;\nstatic void interrupt_handler(void);\nstatic uint32_t internal_1ms_counter;\n\nvoid Hal_timer_init(void)\n{\n    // inerface reset\n    Timer->timerxcontrol.bits.TimerEn = 0;\n    Timer->timerxcontrol.bits.TimerMode = 0;\n    Timer->timerxcontrol.bits.OneShot = 0;\n    Timer->timerxcontrol.bits.TimerSize = 0;\n    Timer->timerxcontrol.bits.TimerPre = 0;\n    Timer->timerxcontrol.bits.IntEnable = 1;\n    Timer->timerxloa",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-6",
    "title": "[RTOS개발] 6장 인터럽트",
    "path": "/2024/11/05/6장-인터럽트/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 인터럽트에 대해 다룹니다.\n\n> <https://github.com/navilera/Navilos/tree/05714c85573612856085724e7a15383f1c6f41b8>\n{:. prompt-tip }\n\n## 서론\n***\n인터럽트를 처리하려면 우선 인터럽트 컨트롤러를 어떻게 사용해야 하는지 알아야 합니다.\n\n그 다음, 인터럽트 컨트롤러를 초기화하고 사용하는 코드를 작성해야 합니다.\n\n인터럽트 컨트롤러 관련 코드를 다 작성했으면 실제 인터럽트를 발생시키는 하드웨어와 인터럽트 컨트롤러를 연결해야 합니다.\n\n현재 사용하는 UART에 인터럽트를 연결해보겠습니다.\n\n- UART 하드웨어와 인터럽트 컨트롤러 연결\n- UART 하드웨어가 인터럽트 컨트롤러로 인터럽트 신호 보냄\n- 인터럽트 컨트롤러는 ARM 코어로 인터럽트를 보냄\n- 펌웨어에서 마스크를 끄면 코어가 자동으로 익셉션 핸들러(펌웨어)를 호출\n- 익셉션 핸들러를 작성\n- 익셉션 핸들러에서 적절한 인터럽트 핸들러를 호출하면 인터럽트 처리 완료\n\n### 무한 루프 `main()` 함수\n\n```c\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n    Hal_uart_put_char('\\n');\n\n    putstr(\"Hello World!\\n\");\n\n    Printf_test();\n\n    while(true); // 추가\n}\n```\n\n이번 챕터의 목표는 펌웨어는 무한 루프를 돌고 있지만 키보드 입력에는 반응하게 만드는 것입니다.\n\n## 인터럽트 컨트롤러\n***\nRealViewPB에는 GIC(Generic Interrupt Controller)라는 이름의 인터럽트 컨트롤러 하드웨어가 있습니다.\n\n가장 먼저 할 일은 GIC의 레지스터 구조체를 만드는 일입니다. <br>\nGIC는 RealViewPB에 포함된 인터럽트 컨트롤러이므로 `hal/rvpb` 디렉터리에 PL011과 같은 레벨로 레지스터 구조체를 작성해 넣어야 합니다.\n\n### `hal/rvpb/Interrupt.h` 파일\n\n```c\n/*\n * Interrupt.h\n *\n *  Created on: Sep 21, 2018\n *      Author: maanu\n */\n\n#ifndef HAL_RVPB_INTERRUPT_H_\n#define HAL_RVPB_INTERRUPT_H_\n\ntypedef union CpuControl_t\n{\n    uint32_t all;\n    struct {\n        uint32_t Enable:1;          // 0\n        uint32_t reserved:31;\n    } bits;\n} CpuControl_t;\n\ntypedef union PriorityMask_t\n{\n    uint32_t all;\n    struct {\n        uint32_t Reserved:4;        // 3:0\n        uint32_t Prioritymask:4;    // 7:4\n        uint32_t reserved:24;\n    } bits;\n} PriorityMask_t;\n\ntypedef union BinaryPoint_t\n{\n    uint32_t all;\n    struct {\n        uint32_t Binarypoint:3;     // 2:0\n        uint32_t reserved:29;\n    } bits;\n} BinaryPoint_t;\n\ntypedef union InterruptAck_t\n{\n    uint32_t all;\n    struct {\n        uint32_t InterruptID:10;    // 9:0\n        uint32_t CPUsourceID:3;     // 12:10\n        uint32_t reserved:19;\n    } bits;\n} InterruptAck_t;\n\ntypedef union EndOfInterrupt_t\n{\n    uint32_t all;\n    struct {\n        uint32_t InterruptID:10;    // 9:0\n        uint32_t CPUsourceID:3;     // 12:10\n        uint32_t reserved:19;\n    } bits;\n} EndOfInterrupt_t;\n\ntypedef union RunningInterrupt_t\n{\n    uint32_t all;\n    struct {\n        uint32_t Reserved:4;        // 3:0\n        uint32_t Priority:4;        // 7:4\n        uint32_t reserved:24;\n    } bits;\n} RunningInterrupt_t;\n\ntypedef union HighestPendInter_t\n{\n    uint32_t all;\n    struct {\n        uint32_t InterruptID:10;    // 9:0\n        uint32_t CPUsourceID:3;     // 12:10\n        uint32_t reserved:19;\n    } bits;\n} HighestPendInter_t;\n\ntypedef union DistributorCtrl_t\n{\n    uint32_t all;\n    struct {\n        uint32_t Enable:1;          // 0\n        uint32_t reserved:31;\n    } bits;\n} DistributorCtrl_t;\n\ntypedef union ControllerType_t\n{\n    uint32_t all;\n    struct {\n        uint32_t IDlinesnumber:5;   // 4:0\n        uint32_t CPUnumber:3;       // 7:5\n        uint32_t reserved:24;\n    } bits;\n} ControllerType_t;\n\ntypedef struct GicCput_t\n{\n    CpuControl_t       cpucontrol;        //0x000\n    PriorityMask_t     prioritymask;      //0x004\n    BinaryPoint_t      binarypoint;       //0x008\n    InterruptAck_t     interruptack;      //0x00C\n    EndOfInterrupt_t   endofinterrupt;    //0x010\n    RunningInterrupt_t runninginterrupt;  //0x014\n    HighestPendInter_t highestpendinter;  //0x018\n} GicCput_t;\n\ntypedef struct GicDist_t\n{\n    DistributorCtrl_t   distributorctrl;    //0x000\n    ControllerType_t    controllertype;     //0x004\n    uint32_t            reserved0[62];      //0x008-0x0FC\n    uint32_t            reserved1;          //0x100\n    uint32_t            setenable1;         //0x104\n    uint32_t            setenable2;         //0x108\n    uint32_t            reserved2[29];      //0x10C-0x17C\n    uint32_t            reserved3;          //0x180\n    uint32_t            clearenable1;       //0x184\n    uint32_t            clearenable2;       //0x188\n} GicDist_t;\n\n#define GIC_CPU_BASE  0x1E000000  //CPU interface\n#define GIC_DIST_BASE 0x1E001000  //distributor\n\n#define GIC_PRIORITY_MASK_NONE  0xF\n\n#define GIC_IRQ_START           32\n#define GIC_IRQ_END             95\n\n#endif /* HAL_RVPB_INTERRUPT_H_ */\n```\n\nGIC는 크게 두 그룹으로 구분합니다.\n\n하나는 CPU Interface registers이고, 다른 하나는 Distributor registers입니다.\n\n\n레지스터 구조체를 선언했고 레지스터의 베이스 주소도 알고 있으므로 UART때와 마찬가지로 실제 인스턴스를 선언하기 위해 `hal/rvpb/Regs.c` 파일을 수정하겠습니다.\n\n### `Regs.c` 파일 수정\n\n```c\n#include \"stdint.h\"\n#include \"Uart.h\"\n#include \"Interrupt.h\"  // Added\n\nvolatile PL011_t*   Uart    = (PL011_t*)UART_BASE_ADDRESS0;\nvolatile GicCput_t* GicCpu  = (GicCput_t*)GIC_CPU_BASE; // Added\nvolatile GicDist_t* GicDist = (GicDist_t*)GIC_DIST_BASE; // Added\n```\n\n이제 구조체 포인터로 GIC의 레지스터를 제어할 수 있는 인스턴스가 생겼습니다.\n\n이 인스턴스로 GIC를 제어합니다.\n\n레지스터 구조체도 만들었고 제어 인스턴스도 만들었으니 이제 공용 API를 설계합니다.\n\n### `hal/HalInterrupt.h` 파일\n\n```c\n#ifndef HAL_HALINTERRUPT_H_\n#define HAL_HALINTERRUPT_H_\n\n#define INTERRUPT_HANDLER_NUM 255\n\ntypedef void (*InterHdlr_fptr)(void);\n\nvoid Hal_interrupt_init(void);\nvoid Hal_interrupt_enable(uint32_t interrupt_num);\nvoid Hal_interrupt_disable(uint32_t interrupt_num);\nvoid Hal_interrupt_register_handler(InterHdlr_fptr handler, uint32_t interrupt_num);\nvoid Hal_interrupt_run_handler(void);\n\n#endif /* HAL_HALINTERRUPT_H_ */\n```\n\n초기화 함수, 활성화 함수, 비활성화 함수, 핸들러 등록 함수, 핸들러 호출 함수 입니다.\n\n활성화 함수와 비활성화 함수는 파라미터로 인터럽트 번호를 받습니다.\n\n대부분 임베디드 시스템은 인터럽트를 한 개 이상 처리하므로 인터럽트를 각각 구분하는 번호를 부여했습니다.\n\n핸들러 등록과 핸들러 호출 함수는 개별 인터럽트별로 따로 연결해야 하는 인터럽트 핸들러를 등록하고 실행하는 역할을 합니다.\n\nARM은 모든 인터럽트를 IRQ나 FIQ 핸들러로 처리하므로 IRQ나 FIQ 핸들러에서 개변 인터럽트의 핸들러를 구분해야 합니다.\n\n그럼 이제 함수를 직접 구현해 보겠습니다.\n\n### `hal/rvpb/Interrupt.c` 파일\n\n```c\n#include \"stdint.h\"\n#include \"memio.h\"\n#include \"Interrupt.h\"\n#include \"HalInterrupt.h\"\n#include \"armcpu.h\"\n\n// 제어 인스턴스의 extern 선언\nextern volatile GicCput_t* GicCpu;\nextern volatile GicDist_t* GicDist;\n\n// HalInterrupt.h에 INTERRUPT_HANDLER_NUM가 255로 정의되어 있음.\nstatic InterHdlr_fptr sHandlers[INTERRUPT_HANDLER_NUM];\n\nvoid Hal_interrupt_init(void)\n{\n    GicCpu->cpucontrol.bits.Enable = 1; // 레지스터에서 인터럽트 컨트롤러 켜기\n    GicCpu->prioritymask.bits.Prioritymask = GIC_PRIORITY_MASK_NONE; // 0xF설정. 아래 설명 참고\n    GicDist->distributorctrl.bits.Enable = 1; // 레지스터에서 인터럽트 컨트롤러 켜기\n\n    for (uint32_t i = 0 ; i < INTERRUPT_HANDLER_NUM ; i++)\n    {\n        sHandlers[i] = NULL;\n    }\n\n    enable_irq(); // ARM의 cspr을 제어해 코어 수준의 IRQ 켜기\n}\n\nvoid Hal_interrupt_enable(uint32_t interrupt_num)\n{\n    if ((interrupt_num < GIC_IRQ_START) || (GIC_IRQ_END < interrupt_num))\n    {\n        return;\n    }\n\n    uint32_t bit_num = interrupt_num - GIC_IRQ_START;\n\n    if (bit_num < GIC_IRQ_START)\n    {\n        SET_BIT(GicDist->setenable1, bit_num); // 매크로 함수 (p,n)입력 ((p) |= (1 << (n)))\n    }\n    else\n    {\n        bit_num -= GIC_IRQ_START;\n        SET_BIT(GicDist->setenable2, bit_num);\n    }\n}\n\nvoid Hal_interrupt_disable(uint32_t interrupt_num)\n{\n    if ((interrupt_num < GIC_IRQ_START) || (GIC_IRQ_END < interrupt_num))\n    {\n        return;\n    }\n\n    uint32_t bit_num = interrupt_num - GIC_IRQ_START;\n\n    if (bit_num < GIC_IRQ_START)\n    {\n        CLR_BIT(GicDist->setenable1, bit_num); // 매크로 함수 (p,n)입력 ((p) &= ~(1 << (n)))\n    }\n    else\n    {\n        bit_num -= GIC_IRQ_START;\n        CLR_BIT(GicDist->setenable2, bit_num);\n    }\n}\n\nvoid Hal_interrupt_register_handler(InterHdlr_fptr handler, uint32_t interrupt_num)\n{\n    sHandlers[interrupt_num] = handler; // 사전 정의한 sHandlers 배열에 함수 포인터를 저장\n}\n\nvoid Hal_interrupt_run_handler(void)\n{\n\t\t// Interrupt acknowledge 레지스터에서 값을 읽어옴. 인터럽트 IRQ ID 번호\n    uint32_t interrupt_num = GicCpu->interruptack.bits.InterruptID;\n\n\t\t// 에러 처리\n    if (sHandlers[interrupt_num] != NULL)\n    {\n        sHandlers[interrupt_num]();\n    }\n\n\t\t// 처리가 끝났다는 것을 알려줘야함. End of interrupt 레지스터에 IRQ ID 쓰기\n    GicCpu->endofinterrupt.bits.InterruptID = interrupt_num;\n}\n```\n\n\n`include/memio.h` 에 아래와 같이 만듭니다.\n\n```c\n#ifndef INCLUDE_MEMIO_H_\n#define INCLUDE_MEMIO_H_\n\n#define SET_BIT(p,n) ((p) |=  (1 << (n)))\n#define CLR_BIT(p,n) ((p) &= ~(1 << (n)))\n\n#endif /* INCLUDE_MEMIO_H_ */\n```\n\n# 백링크걸기(부록 A.1 cspr의 IRQ 마스크)\n\ncspr의 IRQ 마스크를 끄는 코드에 대해 설명하겠습니다.\n\n### `lib/armcpu.h`\n\n```c\n#ifndef LIB_ARMCPU_H_\n#define LIB_ARMCPU_H_\n\nvoid enable_irq(void);\nvoid enable_fiq(void);\nvoid disable_irq(void);\nvoid disable_fiq(void);\n\n#endif /* LIB_ARMCPU_H_ */\n```\n\nIRQ와 FIQ를 켜고 끄는 함수 4개가 선언되어 있습니다.\n\ncspr을 제어하려면 어셈블리어를 사용할 수밖에 없습니다.\n\n~~GCC가 아닌 ARMCC는 컴파일러의 빌트인 변수로 cspr에 접근할 수 있음~~\n\n1. `Entry.S` 처럼 어셈블리어 소스 파일을 만들어 완전히 어셈블리어로 작성하는 방법\n2. C언어 소스 파일을 만들고 C언어 함수 속 인라인 어셈블리어를 사용하는 방버\n\n어떤 방법이든 상관없으나, 본 페이지에서는 2번 방법을 사용하겠습니다\n\n### `lib/armcpu.c`\n\n```c\n#include \"armcpu.h\"\n\nvoid enable_irq(void)\n{\n    __asm__ (\"PUSH {r0, r1}\");\n    __asm__ (\"MRS  r0, cpsr\");\n    __asm__ (\"BIC  r1, r0, #0x80\");\n    __asm__ (\"MSR  cpsr, r1\");\n    __asm__ (\"POP {r0, r1}\");\n}\n\nvoid enable_fiq(void)\n{\n    __asm__ (\"PUSH {r0, r1}\");\n    __asm__ (\"MRS  r0, cpsr\");\n    __asm__ (\"BIC  r1, r0, #0x40\");\n    __asm__ (\"MSR  cpsr, r1\");\n    __asm__ (\"POP {r0, r1}\");\n}\n\nvoid disable_irq(void)\n{\n    __asm__ (\"PUSH {r0, r1}\");\n    __asm__ (\"MRS  r0, cpsr\");\n    __asm__ (\"ORR  r1, r0, #0x80\");\n    __asm__ (\"MSR  cpsr, r1\");\n    __asm__ (\"POP {r0, r1}\");\n}\n\nvoid disable_fiq(void)\n{\n    __asm__ (\"PUSH {r0, r1}\");\n    __asm__ (\"MRS  r0, cpsr\");\n    __asm__ (\"ORR  r1, r0, #0x40\");\n    __asm__ (\"MSR  cpsr, r1\");\n    __asm__ (\"POP {r0, r1}\");\n}\n```\n\n> 인라인 어셈블리어를 사용할 때의 장점은 스택에 레지스터를 백업 및 복구하는 코드와 리턴처리하는 코드를 컴파일러가 자동으로 만듭니다!\n{: .prompt-tip }\n\n## UART 입력과 인터럽트 연결\n***\n이제 GIC를 설정하는 작업은 마무리했습니다.\n\n그런데, GIC만 설정해선 실제로 인터럽트를 활용할 수 없습니다.\n\n→ 인터럽트를 발생시키는 **하드웨어와 연결되어 있지 않기** 때문!\n\n가장 먼저 작업하는 하드웨어는 **UART**입니다.\n\n가장 대표적이고 많이 쓰이는 것은 **입력 인터럽트**입니다.\n\n먼저 하드웨어 의존적인 UART 코드가 있는 Uart.c 파일의 init함수를 수정합니다.\n\n### `Uart.c` 파일의 `Hal_uart_init()` 함수 수정\n\n```c\n#include \"stdint.h\"\n#include \"Uart.h\"\n#include \"HalUart.h\"\n#include \"HalInterrupt.h\"\n\nextern volatile PL011_t* Uart;\n\nstatic void interrupt_handler(void);\n\nvoid Hal_uart_init(void)\n{\n    // Enable UART\n    Uart->uartcr.bits.UARTEN = 0;\n    Uart->uartcr.bits.TXE = 1;\n    Uart->uartcr.bits.RXE = 1;\n    Uart->uartcr.bits.UARTEN = 1;\n\n    // Enable input interrupt\n    Uart->uartimsc.bits.RXIM = 1;\n\n    // Register UART interrupt handler\n    Hal_interrupt_enable(UART_INTERRUPT0); // 인터럽트 API 호출\n    Hal_interrupt_register_handler(interrupt_handler, UART_INTERRUPT0); // API 호출\n}\n```\n\n### UART 입력 인터럽트 핸들러\n\n```c\nstatic void interrupt_handler(void)\n{\n\tuint8_t ch = Hal_uart_get_char();\n\tHal_uart_put_char(ch);\n}\n```\n\nUART 입력이 발생하면 위 `interrupt_handler` 함수를 코어가 자동으로 실행합니다.<br>\n(에코 동작)\n\n이제 인터럽트와 UART가 연결되었으므로 초기화 순서를 맞춰줘야 합니다.\n\n다시 Main.c 파일에서 하드웨어 초기화 코드를 수정합니다.\n\n### 하드웨어 초기화 코드 수정\n\n```c\nstatic void Hw_init(void)\n{\n\tHal_interrupt_init(); // 추가\n\tHal_uart_init();\n}\n```\n\n> 순서 매우 중요!\n{: .prompt-tip }\n\n인터럽트 컨트롤러를 초기화하는 `Hal_interrupt_init()` 함수를 UART 초기화 함수보다 먼저 호출해야 합니다.<br>\n  → `Hal_uart_init()`함수 내부에서 인터럽트 관련 함수를 호출하기에 그 전에 초기화해야 정상적으로 동작합니다.\n\n## IRQ 익셉션 벡터 연결\n***\n지금까지 한 작업을 정리하면 아래와 같습니다.\n\n- `main()` 함수를 무한 루프로 변경\n- 인터럽트 컨트롤러 초기화\n- cspr의 IRQ 마스크를 해제\n- UART 인터럽트 핸들러를 인터럽트 컨트롤러에 등록\n- 인터럽트 컨트롤러와 UART 하드웨어 초기화 순서 조정\n\n-> 인터럽트가 발생하면 인터럽트 컨트롤러는 이 인터럽트를 접수해 ARM 코어로 바로 전달합니다.\n\nARM은 FIQ와 IRQ라는 두 종류의 인터럽트가 있는데, 본 교재에서는 IRQ만 사용합니다.\n\n1. ARM 코어는 인터럽트를 받으면 IRQ 익셉션을 발생\n2. 동작 모드를 IRQ 모드로 바꾸기\n3. 동시에 익셉션 벡터 테이블의 IRQ 익셉션 벡터로 점프\n\n즉, 인터럽트 종류가 무엇이든 일단 익셉션 벡터 테이블의 **IRQ 익셉션 핸들러**가 무조건 실행됩니다.\n\n즉, 남은 작업은 익셉션 벡터 테이블의 IRQ 익셉션 벡터와 인터럽트 컨트롤러의 인터럽트 핸들러를 연결하는 작업입니다.\n\n먼저 익셉션 핸들러부터 만들겠습니다.\n\n### `boot/Handler.c` Exception Handler\n\n```c\n#include \"stdbool.h\"\n#include \"stdint.h\"\n#include \"HalInterrupt.h\"\n\n __attribute__ ((interrupt (\"IRQ\"))) void Irq_Handler(void)\n{\n    Hal_interrupt_run_handler();\n}\n\n __attribute__ ((interrupt (\"FIQ\"))) void Fiq_Handler(void)\n{\n    while(true);\n}\n```\n\n우선, 익셉션 핸들러 함수를 선언하는 방법을 보겠습니다.\n\n`__attribute__` 는 GCC의 컴파일러 확장 기능을 사용하겠다는 지시어입니다.\n\n이 중 `__attribute__((interrupt(\"IRQ\"))`는 ARM용 GCC의 전용 확장 기능입니다.\n\nIRQ와 FIQ의 핸들러에 진입하는 코드와 나가는 코드를 자동으로 만들어 줍니다.\n\n(리턴 주소를 컴파일러가 자동으로 만들어 줌)\n\n만약 이 기능을 사용하지 않는다면, ARM의 구조상 IRQ 익셉션 핸들러를 수행하고 제대로 된 위치로 복귀하지 못하고 펌웨어가 오동작하게 됩니다.\n\n익셉션 핸들러를 만들었으니 이제 간단하게 익셉션 벡터 테이블에서 함수 이름으로 연결합니다.\n\n### `Entry.S` 의 익셉션 벡터 테이블에서 IRQ와 FIQ 익셉션 핸들러 연결\n\n```c\n#include \"ARMv7AR.h\"\n#include \"MemoryMap.h\"\n\n.text\n    .code 32\n\n    .global vector_start\n    .global vector_end\n\n    vector_start:\n        LDR PC, reset_handler_addr\n        LDR PC, undef_handler_addr\n        LDR PC, svc_handler_addr\n        LDR PC, pftch_abt_handler_addr\n        LDR PC, data_abt_handler_addr\n        B   .\n        LDR PC, irq_handler_addr\n        LDR PC, fiq_handler_addr\n\n        reset_handler_addr:     .word reset_handler\n        undef_handler_addr:     .word dummy_handler\n        svc_handler_addr:       .word dummy_handler\n        pftch_abt_handler_addr: .word dummy_handler\n        data_abt_handler_addr:  .word dummy_handler\n        irq_handler_addr:       .word Irq_Handler\n        fiq_handler_addr:       .word Fiq_Handler\n    vector_end:\n...\n```\n\n기존 더미핸들러로 연결하던 코드를 인터럽트 핸들러 함수로 연결하도록 수정했습니다.\n\n이제 빌드하고 테스트해보겠습니다.\n\n```c\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os501.png)\n\n잘 동작합니다. `main()`함수가 무한 루프로 막혀있어 키보드로 반응이 없던 상태에서\n\n인터럽트를 연결하고 키보드 입력을 인터럽트로 전달하여 반응하는 모습을 눈으로 볼 수 있습니다.\n\n> 디렉토리를 새로 만들지 않았으므로 Makefile은 수정하지 않아도 됩니다.\n\n</aside>\n\n## 요악\n***\n이 장에서는 인터럽트 컨트롤러를 사용해 키보드 입력을 받았습니다.\n\n인터럽트로 키보드 입력을 받기에 펌웨어가 입력을 대기하기 위해 멈춰있을 필요가 없습니다.\n\n이번 장에서는 UART 하드웨어를 다뤄봤습니다.\n\n다음 장에서는 또 다른 하드웨어인 타이머를 다뤄 시간을 제어하도록 하겠습니다.\n\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-6_chunk_0",
        "text": "[RTOS개발] 6장 인터럽트\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지는 인터럽트에 대해 다룹니다.\n\n> <https://github.com/navilera/Navilos/tree/05714c85573612856085724e7a15383f1c6f41b8>\n{:.",
        "index": 0
      },
      {
        "id": "2024-11-05-6_chunk_1",
        "text": "대해 다룹니다.\n\n> <https://github.com/navilera/Navilos/tree/05714c85573612856085724e7a15383f1c6f41b8>\n{:.",
        "index": 1
      },
      {
        "id": "2024-11-05-6_chunk_2",
        "text": "대해 다룹니다.\n\n> <https://github.com/navilera/Navilos/tree/05714c85573612856085724e7a15383f1c6f41b8>\n{:.",
        "index": 2
      },
      {
        "id": "2024-11-05-6_chunk_3",
        "text": "대해 다룹니다.\n\n> <https://github.com/navilera/Navilos/tree/05714c85573612856085724e7a15383f1c6f41b8>\n{:.",
        "index": 3
      },
      {
        "id": "2024-11-05-6_chunk_4",
        "text": "대해 다룹니다.\n\n> <https://github.com/navilera/Navilos/tree/05714c85573612856085724e7a15383f1c6f41b8>\n{:.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-5--UART",
    "title": "[RTOS개발] 5장 UART",
    "path": "/2024/11/05/5장-UART/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지에선 UART 하드웨어 입출력에 대해 다룹니다.\n\n<https://github.com/navilera/Navilos/tree/c484d81dbc1e7cbc8651b2f9ac1993ea215c09ea>\n\n## UART 출력하기\n***\nUART \n: Universal Asynchronous Receiver/Transmitter의 약자로 범용 비동기화 송수신기\n\n가장 먼저 UART를 작업하는 이유는 UART를 보통 콘솔 입출력용으로 사용하기 때문!\n\nUART를 사용하기 위해 가장 먼저 해야 할 일은 UART 하드웨어의 레지스터를 코드로 만드는 것!\n\n\n데이터 시트 링크\n: <https://developer.arm.com/documentation/ddi0183/g/programmers-model/summary-of-registers?lang=en>\n\n\nUART의 가장 기본적인 기능인 입력과 출력만을 사용할 것!\n\n![image.png](/assets/img/OS/os400.png)\n\n레지스터에 대한 설명은 위 링크를 참고\n\n오프셋이 0x00인 UARTDR에 대해서 간략하게 설명하겠습니다.\n\n[https://developer.arm.com/documentation/ddi0183/g/programmers-model/register-descriptions/data-register--uartdr?lang=en](https://developer.arm.com/documentation/ddi0183/g/programmers-model/register-descriptions/data-register--uartdr?lang=en)\n\nUARTDR은 데이터 레지스터입니다.\n\n![image.png](/assets/img/OS/os401.png)\n\n위 그림을 보면 0번부터 7번 비트까지 8비트는 입출력 데이터가 사용하는 레지스터.\n\n한 번에 8비트, 즉 1바이트씩 통신할수 있는 하드웨어 입니다.\n\n8번부터 11번까지는 종류별로 정의된 에러입니다. 프레임 에러, 패리티 에러, 브레이크 에러, 오버런 에러라 이름이 붙어있습니다. 설명에 부합하는 에러 발생 시 해당 비트의 값이 1로!\n\n**코드로 옮기는 방법??**\n\n1. C언어 매크로 이용\n2. 구조체 이용\n\n### 1. C언어 매크로를 이용해 레지스터 코드로 옮기기\n\n```bash\n#define UART_BASE_ADDR    0x10009000\n#define UARTDR_OFFSET     0x00\n#define UARTDR_DATA       (0)\n#define UARTDR_FE         (8)\n#define UARTDR_PE         (9)\n#define UARTDR_BE         (10)\n#define UARTDR_OE         (11)\n...\n...\n...\n#define UARTCR_OFFSET     0x30\n```\n\n데이터시트를 보면 RealViewPB에서 UART의 기본주소는 0x1000 9000입니다.\n\n위처럼 매크로를 정의했다면, 아래와 같이 사용할 수 있습니다.\n\n```c\nuint32_t *uartdr = (uint32_t*)(UART_BASE_ADDR + UARTDR_OFFSET);\n*uartdr = (data) << UARTDR_DATA;\nbool fe = (bool)((*uartdr >> UARTDR_FE) & 0x1);\nbool pe = (bool)((*uartdr >> UARTDR_PE) & 0x1);\n...\n```\n\n시프트 연산자를 사용하는 코드는 항상 반복되므로 공용 매크로를 만들어 사용하는 것이 일반적입니다.\n\n### 2. 구조체를 이용해 레지스터 코드로 옮기기\n\n```c\ntypedef union UARTDR_t\n{\n    uint32_t all;\n    struct {\n        uint32_t DATA:8;    // 7:0\n        uint32_t FE:1;      // 8\n        uint32_t PE:1;      // 9\n        uint32_t BE:1;      // 10\n        uint32_t OE:1;      // 11\n        uint32_t reserved:20;\n    } bits;\n} UARTDR_t;\n\ntypedef union UARTRSR_t\n{\n    uint32_t all;\n    struct {\n        uint32_t FE:1;      // 0\n        uint32_t PE:1;      // 1\n        uint32_t BE:1;      // 2\n        uint32_t OE:1;      // 3\n        uint32_t reserved:28;\n    } bits;\n} UARTRSR_t;\n\n...\n```\n\n형태는 다르지만 기본적인 개념은 매크로와 같습니다.\n\n이렇게 작성한다면, 아래와 같이 사용할 수 있습니다.\n\n```c\ntypedef struct PL011_t{\n  UARTDR_T uartdr;\n  ...\n  UARTCR_T uartcr;\n  ...\n}\n\nPL011_t* Uart = (PL011_t*)UART_BASE_ADDR;\n\nUart->uartdr.DATA = data & 0xFF;\nif (Uart->uart.FE || Uart->uart.PE || ...) {\n  // 예외 처리 코드\n}\n```\n\n1번 C언어 매크로와 2번 구조체 두 방법 모두 상관없습니다.\n\n그럼 RealViewPB의 UART하드웨어의 레지스터를 코드로 만들어서 아래와 같이 소스 코드 트리에 추가하겠습니다.\n\n![image.png](/assets/img/OS/os402.png)\n\n메모리 주소로 접근 가능한 레지스터를 구조체로 추상화하여 작성했습니다.\n\n다음으로 UART 하드웨어를 제어할 수 있는 변수를 선언합니다.\n\n`hal/rvpb` 위치에 `Regs.c` 를 만들어 레지스터를 선언해 모아 놓을 예정입니다.\n\n### `Regs.c`\n\n```c\n#include \"stdint.h\"\n#include \"Uart.h\"\n\nvolatile PL011_t* Uart = (PL011_t*)UART_BASE_ADDRESS0;\n```\n\n으로도 초기화하는 하드웨어가 추가될 때마다 해당 하드웨어의 레지스터 구조체와 베이스 주소를 연결해 추가할 것입니다.\n\n### UART 공용 인터페이스\n\n앞서 알아본 PL011은 RealViewPB의 UART입니다.\n\n다른 플랫폼은 다른 종류의 UART 하드웨어를 가지고 있을 것입니다.\n\n이들 각자의 레지스터와 접근 변수는 앞에서 설명한 방법대로 만들 수 있으며,\n\n개별 하드웨어는 각자의 방식으로 동작하더라도 이를 사용하는 코드는 공용 인터페이스를 통해 같은 방식으로 사용할 수 있어야 합니다.\n\n즉, 일종의 디바이스 드라이버 같은 것이 필요한 셈입니다.\n\n\n펌웨어에서는 적당한 수준의 범용성을 만족하면 되기에, 공용 인터페이스 API만 정의해놓고 해당 API를 각자의 하드웨어가 구현하는 식으로 범용성을 구현합니다.\n\n<br>\n공용 인터페이스 혹은 API의 설계를 HAL이라 한다!\n\n### _HAL(Hardware Abstraction Layer)_\n\n첫 작업으로 UART 공용 HAL 인터페이스를 정의하겠습니다.\n\n파일명은 `HalUart.h`입니다. 파일의 위치는 `hal/`입니다.\n\n### `HalUart.h` UART 공용 인터페이스 선언\n\n```c\n#ifndef HAL_HALUART_H_\n#define HAL_HALUART_H_\n\nvoid Hal_uart_init(void);\nvoid Hal_uart_put_char(uint8_t ch);\n\n#endif /* HAL_HALUART_H_ */\n```\n\nUART를 초기화하고 가장 먼저 테스트하는 것은 출력입니다.\n\nUART 하드웨어를 초기화하는 함수와 UART로 알파벳 한 글자를 보내 터미널에 알파벳 한 글자를 출력하는 함수입니다.\n\n> 이렇게 `HalUart.h`를 구현해놓은 후, RealViewPB에서 사용할 땐 `hal/rvpb/Uart.c`를 컴파일 목록에 넣고, 만약 타깃이 라즈베리파이 보드라면 `hal/rasppi/Uart.c`를 컴파일 목록에 넣어 사용할 수 있습니다.\n>\n>이렇게 여러 플랫폼을 지원 가능하게끔 디자인해야합니다.\n{: .prompt-tip }\n\n### UART 공용 인터페이스 구현\n\n지금까지 UART 공용 인터페이스 API를 설계했습니다. \n\n다음은 해당 API를 만족하는 코드를 구현하겠습니다.\n\n새로운 C언어 소스 파일을 추가하겠습니다.\n\n### `hal/rvpb/Uart.c` UART 공용 인터페이스 구현\n\n```c\n#include \"stdint.h\"\n#include \"Uart.h\"\n#include \"HalUart.h\"\n\nextern volatile PL011_t* Uart;\n\nvoid Hal_uart_init(void)\n{\n    // Enable UART\n    Uart->uartcr.bits.UARTEN = 0;\n    Uart->uartcr.bits.TXE = 1;\n    Uart->uartcr.bits.RXE = 1;\n    Uart->uartcr.bits.UARTEN = 1;\n}\n\nvoid Hal_uart_put_char(uint8_t ch)\n{\n    while(Uart->uartfr.bits.TXFF);\n    Uart->uartdr.all = (ch & 0xFF);\n}\n```\n\n7~14번째 줄의 초기화 함수는 UART 하드웨어를 초기화하는 코드입니다.\n\n`put_char` 는 알파벳 한 글자를 UART를 통해서 출력하는 코드입니다.\n\n18번째 줄 `while(Uart->uartfr.bits.TXFF);`는 UART하드웨어의 출력 버퍼가 0이 될 때까지 기다리는 코드입니다. 출력 버퍼가 0이라는 말은 출력 버퍼가 비었다는 뜻입니다.\n\n19번째 줄 `Uart->uartdr.all = (ch & 0xFF);`은 데이터 레지스터를 통해서 알파벳 한 글자를 출력 버퍼로 보내는 코드입니다. \n\n\n정상 동작하게 된다면 이 코드가 실행되는 순간 UART를 통해서 데이터가 호스트로 전송됩니다.\n\n### UART를 초기화하고 시험 출력해보기\n\n이제 지금까지 만든 UART 관련 코드를 `main()`에서 호출하면 됩니다.\n\n`Main.c`에 아래와 같이 코드를 추가합니다.\n\n### `Main.c` 함수에서 UART를 초기화하고 알파벳 출력하기\n\n```c\n#include \"stdint.h\"\n\n#include \"HalUart.h\"\n\nstatic void Hw_init(void);\n\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n}\n\nstatic void Hw_init(void)\n{\n    Hal_uart_init();\n}\n```\n\n이제, 코드를 실행시키기 전, 디렉토리와 추가된 파일들이 있으니 Makefile을 수정해야 합니다.\n\n### `Makefile` HAL을 포함해 빌드 가능하도록 수정\n\n```makefile\nARCH = armv7-a\nMCPU = cortex-a8\n\nTARGET = rvpb\n\nCC = arm-none-eabi-gcc\nAS = arm-none-eabi-as\nLD = arm-none-eabi-ld\nOC = arm-none-eabi-objcopy\n\nLINKER_SCRIPT = ./navilos.ld\nMAP_FILE = build/navilos.map\n\nASM_SRCS = $(wildcard boot/*.S)\nASM_OBJS = $(patsubst boot/%.S, build/%.os, $(ASM_SRCS))\n\nVPATH = boot \\\n        hal/$(TARGET)\n\nC_SRCS  = $(notdir $(wildcard boot/*.c))\nC_SRCS += $(notdir $(wildcard hal/$(TARGET)/*.c))\nC_OBJS = $(patsubst %.c, build/%.o, $(C_SRCS))\n\nINC_DIRS  = -I include \t\t\t\\\n            -I hal\t   \t\t\t\\\n            -I hal/$(TARGET)\n\nCFLAGS = -c -g -std=c11\n\nnavilos = build/navilos.axf\nnavilos_bin = build/navilos.bin\n\n.PHONY: all clean run debug gdb\n\nall: $(navilos)\n\nclean:\n\t@rm -fr build\n\nrun: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -nographic\n\ndebug: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -S -gdb tcp::1234,ipv4\n\ngdb:\n\tarm-none-eabi-gdb\n\n$(navilos): $(ASM_OBJS) $(C_OBJS) $(LINKER_SCRIPT)\n\t$(LD) -n -T $(LINKER_SCRIPT) -o $(navilos) $(ASM_OBJS) $(C_OBJS) -Map=$(MAP_FILE)\n\t$(OC) -O binary $(navilos) $(navilos_bin)\n\nbuild/%.os: %.S\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) $(INC_DIRS) $(CFLAGS) -o $@ $<\n\nbuild/%.o: %.c\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) $(INC_DIRS) $(CFLAGS) -o $@ $<\n\n```\n\n41번째 줄에서 `-nographic`옵션을 통해 GUI를 출력하지 않고, 시리얼 포트 입출력을 현재 호스트의 콘솔과 연결했습니다.\n\n\n> 즉, UART 입출력이 리눅스 터미널과 연결된다는 것입니다.\n\n```bash\n$ make run\n```\n\n![image.png](/assets/img/OS/os403.png)\n\n성공적으로 N이 출력된 것을 확인할 수 있습니다!\n\n> 위 코드 실행 후 QEMU와 리눅스 터미널의 입력이 연결되어 Ctrl+C로 QEMU를 종료할 수 없습니다. `ps -ef | grep qemu` 등으로 `kill` 명령어를 이용해 종료합니다.\n{: .prompt-tip }\n\n## Hello World!\n***\n우리가 지금 만들고있는 펌웨어에서는 `printf()` 함수조차 만들어 써야 합니다.\n\n`printf()`함수를 만들기 전, 기초 작업으로 문자열 출력을 해보겠습니다.\n\n**여기서 고려해야할 것은 “소프트웨어의 계층”입니다.**\n\n문자를 한 개 출력하는 함수는 **UART 하드웨어에 직접 접근**해야 구현 가능합니다.\n\n하지만, 문자열을 출력하는 함수는 UART 하드웨어를 직접 건드리는 작업이 **아닙니다**.\n\n→ UART 하드웨어에 직접 접근하는 **함수를 호출하는 함수**\n\n`lib` 디렉토리를 만들고 `stdio.c`와 `stdio.h`라는 두 파일을 생성합니다.\n\n- `stdio.h`\n\n```c\n#ifndef LIB_STDIO_H_\n#define LIB_STDIO_H_\n\nuint32_t putstr(const char* s);\n\n#endif /* LIB_STDIO_H_ */\n```\n\n- `stdio.c`\n\n```c\n#include \"stdint.h\"\n#include \"HalUart.h\"\n#include \"stdio.h\"\nuint32_t putstr(const char* s)\n{\n    uint32_t c = 0;\n    while(*s)\n    {\n        Hal_uart_put_char(*s++);\n        c++;\n    }\n    return c;\n}\n\n```\n\n7번째 줄에서 선언한 변수 c로 문자열의 길이를 카운트합니다.\n\n8번째 줄처럼 while문을 사용하면 s 포인터의 값이 0이 될 때 while 루프를 종료합니다.\n\n(문자열 종료 시 NULL == 0)\n\n문자열이 종료될 때까지 출력 후, 전체 출력한 글자 수를 반환합니다.\n\n이제 `main()` 함수에 추가하고 디렉터리를 추가했으니, Makefile을 수정하겠습니다\n\n- `Makefile`\n\n```makefile\nARCH = armv7-a\nMCPU = cortex-a8\n\nTARGET = rvpb\n\nCC = arm-none-eabi-gcc\nAS = arm-none-eabi-as\nLD = arm-none-eabi-ld\nOC = arm-none-eabi-objcopy\n\nLINKER_SCRIPT = ./navilos.ld\nMAP_FILE = build/navilos.map\n\nASM_SRCS = $(wildcard boot/*.S)\nASM_OBJS = $(patsubst boot/%.S, build/%.os, $(ASM_SRCS))\n\nVPATH = boot \t\t\t\\\n        hal/$(TARGET)\t\\\n        lib\n\nC_SRCS  = $(notdir $(wildcard boot/*.c))\nC_SRCS += $(notdir $(wildcard hal/$(TARGET)/*.c))\nC_SRCS += $(notdir $(wildcard lib/*.c))\nC_OBJS = $(patsubst %.c, build/%.o, $(C_SRCS))\n\nINC_DIRS  = -I include \t\t\t\\\n            -I hal\t   \t\t\t\\\n            -I hal/$(TARGET)\t\\\n            -I lib\n\nCFLAGS = -c -g -std=c11\n\nnavilos = build/navilos.axf\nnavilos_bin = build/navilos.bin\n\n.PHONY: all clean run debug gdb\n\nall: $(navilos)\n\nclean:\n\t@rm -fr build\n\nrun: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -nographic\n\ndebug: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -S -gdb tcp::1234,ipv4\n\ngdb:\n\tarm-none-eabi-gdb\n\n$(navilos): $(ASM_OBJS) $(C_OBJS) $(LINKER_SCRIPT)\n\t$(LD) -n -T $(LINKER_SCRIPT) -o $(navilos) $(ASM_OBJS) $(C_OBJS) -Map=$(MAP_FILE)\n\t$(OC) -O binary $(navilos) $(navilos_bin)\n\nbuild/%.os: %.S\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) $(INC_DIRS) $(CFLAGS) -o $@ $<\n\nbuild/%.o: %.c\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) $(INC_DIRS) $(CFLAGS) -o $@ $<\n\n```\n\n### “Hello World”를 출력하는 `main()` 함수\n\n```c\n#include \"stdint.h\"\n#include \"HalUart.h\"\n\n#include \"stdio.h\"\n\nstatic void Hw_init(void);\n\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n    Hal_uart_put_char('\\n');\n\n    putstr(\"Hello World!\\n\");\n}\n\nstatic void Hw_init(void)\n{\n    Hal_uart_init();\n}\n```\n\n이제, 빌드하고 실행해보겠습니다\n\n![image.png](/assets/img/OS/os404.png)\n\nN을 백 개 출력한 후 한 줄을 개행하고 “Hello World!”라는 문자열을 잘 출력했습니다.\n\n**문자열 출력에 성공했습니다!**\n\n## UART로 입력 받기\n***\n출력을 만들었으니 UART 입력을 구현해보겠습니다.\n\nUART 출력을 할 땐 먼저 보내기 버퍼가 비어있는지 확인한 다음, 비어 있으면 데이터 레지스터를 통해 데이터를 보내기 버퍼로 보냈습니다.\n\n그러면 하드웨어가 알아서 나머지 작업을 처리해 주고 하드웨어와 연결된 콘솔에 데이터가 나타납니다.\n\n입력은 출력의 반대로 하면 됩니다. 입력은 반대로 받기 버퍼가 채워져 있는지 확인한 다음, 받기 버퍼에 데이터가 있으면 데이터 레지스터를 통해 데이터를 하나 읽어오면 됩니다.\n\n데이터는 콘솔과 하드웨어를 통해서 전달되어 레지스터에서 펌웨어가 읽어가기만을 기다리고 있을 것입니다.\n\n### `Hal_uart_get_char()` 함수\n\n```c\nuint8_t Hal_uart_get_char(void)\n{\n    uint32_t data;\n\n    while(Uart->uartfr.bits.RXFE);\n\n    data = Uart->uartdr.all;\n\n    // Check for an error flag\n    if (data & 0xFFFFFF00)\n    {\n        // Clear the error\n        Uart->uartrsr.all = 0xFF;\n        return 0;\n    }\n\n    return (uint8_t)(data & 0xFF);\n}\n```\n\n레지스터에 접근하는 횟수를 줄이기 위해 `data = Uart->uartdr.all` 을 이용해 한 번만 접근하도록 최적화 한 코드입니다.\n\n그럼 이제, 동작하는지 확인하기 위해 main함수에 추가하고 테스트하겠습니다.\n\n### UART 입력을 받는 `main()` 함수\n\n```c\n#include \"stdint.h\"\n#include \"HalUart.h\"\n\n#include \"stdio.h\"\n\nstatic void Hw_init(void);\n\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n    Hal_uart_put_char('\\n');\n\n    putstr(\"Hello World!\\n\");\n\n    i = 100;\n    while(i--)\n    {\n        uint8_t ch = Hal_uart_get_char();\n        Hal_uart_put_char(ch);\n    }\n}\n\nstatic void Hw_init(void)\n{\n    Hal_uart_init();\n}\n```\n\n그럼 이제 테스트해보겠습니다.\n\n```bash\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os405.png)\n\n`Annyung Sesang!` 을 입력했습니다. 성공적으로 키보드 입력이 터미널에 나타나는 것을 확인할 수 있습니다!\n\n## printf 만들기\n***\n그냥 문자열을 출력하는 것과 `printf` 함수의 차이점은 포맷을 지정할 수 있다는 것!\n\n포맷\n: `%s` `%c` `%x` 등 데이터를 출력하는 형식을 지정할 수 있다\n\n\n펌웨어는 그 많은 기능이 다 필요하지 않기에, 필요한 기능만 최소로 구현하겠습니다.\n\n이제 `printf` 함수를 구현할 것인데, 함수 이름은 `debug_printf()`\n\n> `printf()` 라는 이름을 그대로 사용하지 않은 것은 GCC를 포함한 많은 컴파일러가 별다른 옵션을 주지 않는 한 최적화 과정에서 `puts()` 함수로 바꿔버리기 때문!\n{: .prompt-tip }\n\n### `debug_printf()` 의 선언 (`stdio.h`)\n\n```c\n#ifndef LIB_STDIO_H_\n#define LIB_STDIO_H_\n\nuint32_t putstr(cosnt char* s);\nuint32_t debug_printf(const char* format, ...);\n#endif /* LIB_STDIO_H_ */\n```\n\n`stdio.h` 에 `debug_printf()` 함수의 프로토타입을 선언합니다.\n\n마지막 파라미터인 점 세 개(…)는 C 언어 문법으로 가변 인자 지정입니다.\n\n### `debug_printf()` 의 구현 (`stdio.c`)\n\n```c\nuint32_t debug_printf(const char* format, ...)\n{\n    va_list args;\n    va_start(args, format);\n    vsprintf(printf_buf, format, args);\n    va_end(args);\n    return putstr(printf_buf);\n}\n```\n\n실제 포맷을 처리하는 코드는 `vsprintf()` 함수에서 구현할 것입니다.\n\n그리고 가변 인자를 처리하는 `va_list,va_start,va_end`가 있는데, 헤더 파일을 새로 만들어 추가하겠습니다.\n\n전통적으로 C언어는 가변인자를 처리하는 데 `stdarg.h` 에 있는 `va_start, va_end, va_arg` 매크로와 `va_list` 라는 자료형을 사용합니다.\n\n이는 표준 라이브러리가 아닌 **컴파일러의 빌트인 함수로 지원합니다.**\n\n→ 컴파일러마다 이름이 조금씩 다르기에 재정의하여 사용하겠습니다.\n\n### `stdarg.h` 코드\n\n```c\n#ifndef INCLUDE_STDARG_H_\n#define INCLUDE_STDARG_H_\n\ntypedef __builtin_va_list va_list;\n\n#define va_start(v,l)   __builtin_va_start(v,l)\n#define va_end(v)       __builtin_va_end(v)\n#define va_arg(v,l)     __builtin_va_arg(v,l)\n\n#endif /* INCLUDE_STDARG_H_ */\n```\n\n> GCC 표준 라이브러리의 `stdarg.h` 에서 필요한 부분만 사용합니다.\n\n이제 `vsprintf()` 함수를 만들어야 합니다. 이 함수는 가변 인자의 정보를 담고 있는 `va_list` 타입의 파라미터를 받아서 처리합니다.\n\n우선, 함수를 선언하겠습니다.\n\n### `vsprintf()` 함수 선언 (`stdio.h`)\n\n```c\n#ifndef LIB_STDIO_H_\n#define LIB_STDIO_H_\n\n#include \"stdarg.h\"\n\nuint32_t putstr(cosnt char* s);\nuint32_t debug_printf(const char* format, ...);\nuint32_t vsprintf(char* buf, const char* format, va_list arg);\n\n#endif /* LIB_STDIO_H_ */\n```\n\n`va_list` 와 같은 자료형을 사용하기 위해 이전에 만든 `stdarg.h` 파일을 포함합니다.\n\n그리고, `vsprintf()` 함수는 마지막 파라미터로 `va_list`타입의 `arg` 포인터를 받습니다.\n\n### `vsprintf()` 함수 구현\n\n```c\nuint32_t vsprintf(char* buf, const char* format, va_list arg)\n{\n    uint32_t c = 0;\n\n    char     ch;\n    char*    str;\n    uint32_t uint;\n    uint32_t hex;\n\n    for (uint32_t i = 0 ; format[i] ; i++)\n    {\n        if (format[i] == '%')\n        {\n            i++;\n            switch(format[i])\n            {\n            case 'c':\n                ch = (char)va_arg(arg, int32_t);\n                buf[c++] = ch;\n                break;\n            case 's':\n                str = (char*)va_arg(arg, char*);\n                if (str == NULL)\n                {\n                    str = \"(null)\";\n                }\n                while(*str)\n                {\n                    buf[c++] = (*str++);\n                }\n                break;\n            case 'u':\n                uint = (uint32_t)va_arg(arg, uint32_t);\n                c += utoa(&buf[c], uint, utoa_dec);\n                break;\n            case 'x':\n                hex = (uint32_t)va_arg(arg, uint32_t);\n                c += utoa(&buf[c], hex, utoa_hex);\n                break;\n            }\n        }\n        else\n        {\n            buf[c++] = format[i];\n        }\n    }\n\n    if (c >= PRINTF_BUF_LEN)\n    {\n        buf[0] = '\\0';\n        return 0;\n    }\n\n    buf[c] = '\\0';\n    return c;\n}\n```\n\n지원하는 형식은 `%s, %c, %u, %x` 입니다.\n\n만약, 기능을 추가하고 싶다면 `switch-case` 문에 코드를 추가하면 됩니다.\n\n%c와 %s는 구현하는 방법이 쉬우니 넘어가고, %u와 %x에 대해 보겠습니다.\n\n%u와 %x는 기본적으로 같은 코드로 구현되며, `utoa` 함수가 핵심 기능을 합니다.\n\n### `utoa()` 함수 선언\n\n```c\n#ifndef LIB_STDIO_H_\n#define LIB_STDIO_H_\n\n#include \"stdarg.h\"\n\ntypedef enum utoa_t\n{\n    utoa_dec = 10,\n    utoa_hex = 16,\n} utoa_t;\n\nuint32_t putstr(const char* s);\nuint32_t debug_printf(const char* format, ...);\nuint32_t vsprintf(char* buf, const char* format, va_list arg);\nuint32_t utoa(char* buf, uint32_t val, utoa_t base);\n\n#endif /* LIB_STDIO_H_ */\n```\n\n```c\nuint32_t utoa(char* buf, uint32_t val, utoa_t base);\n```\n\n`char* buf` : `utoa()` 함수는 문자열을 리턴해야하므로 `buf` 를 리턴 포인터로 사용\n\n`uint32_t val` : 문자열로 바꿀 원본 숫자 데이터\n\n`uint32_t base` : 10진수로 표현할지 16진수로 표현할지 결정하는 옵션\n\n`utoa_dec`과 `utoa_hex`는 10과 16으로 열거형의 값을 설정했습니다.\n\n### `utoa()` 함수 구현\n\n```c\nuint32_t utoa(char* buf, uint32_t val, utoa_t base)\n{\n    const char asciibase = 'a';\n\n    uint32_t c = 0;\n    int32_t idx = 0;\n    char     tmp[11];   // It is enough for 32 bit int\n\n    do {\n        uint32_t t = val % (uint32_t)base;\n        if (t >= 10)\n        {\n            t += asciibase - '0' - 10;\n        }\n        tmp[idx] = (t + '0');\n        val /= base;\n        idx++;\n    } while(val);\n\n    // reverse\n    idx--;\n    while (idx >= 0)\n    {\n        buf[c++] = tmp[idx];\n        idx--;\n    }\n\n    return c;\n}\n```\n\n우선 값이 10진수인 경우 do-while문에서 `if (t>=10)`에 진입하지 않습니다.\n\n이 경우 숫자 0을 아스키코드 ‘0’으로 만드는 것이기에, `(t + '0')` 과 같이 표현합니다.\n\n16진수로 표현할 경우, 정수 11은 b로 변환되어야 합니다.\n\n단, 10을 빼주는 이유는 16진수에서 a,b,c,d,e,f는 10이상일 때 등장하기에 그만큼 빼줍니다.\n\n하지만, 위 코드에선 `t += asciibase - '0' - 10;`으로 되어있는데, 여기서 ‘0’을 빼주는 이유는 조건문 다음의 코드 `tmp[idx] = (t+'0');` 에서 ‘0’을 더하기에 이를 상쇄하고자 추가했습니다.\n\n이제 print함수를 다 만들었으니, 테스트 해보겠습니다.\n\n### `stdio.c` 완성본\n\n```c\n#include \"stdint.h\"\n#include \"HalUart.h\"\n#include \"stdio.h\"\n\n#define PRINTF_BUF_LEN  1024\n\nstatic char printf_buf[PRINTF_BUF_LEN];   // 1KB\n\nuint32_t putstr(const char* s)\n{\n    uint32_t c = 0;\n    while(*s)\n    {\n        Hal_uart_put_char(*s++);\n        c++;\n    }\n    return c;\n}\n\nuint32_t debug_printf(const char* format, ...)\n{\n    va_list args;\n    va_start(args, format);\n    vsprintf(printf_buf, format, args);\n    va_end(args);\n\n    return putstr(printf_buf);\n}\n\nuint32_t vsprintf(char* buf, const char* format, va_list arg)\n{\n    uint32_t c = 0;\n\n    char     ch;\n    char*    str;\n    uint32_t uint;\n    uint32_t hex;\n\n    for (uint32_t i = 0 ; format[i] ; i++)\n    {\n        if (format[i] == '%')\n        {\n            i++;\n            switch(format[i])\n            {\n            case 'c':\n                ch = (char)va_arg(arg, int32_t);\n                buf[c++] = ch;\n                break;\n            case 's':\n                str = (char*)va_arg(arg, char*);\n                if (str == NULL)\n                {\n                    str = \"(null)\";\n                }\n                while(*str)\n                {\n                    buf[c++] = (*str++);\n                }\n                break;\n            case 'u':\n                uint = (uint32_t)va_arg(arg, uint32_t);\n                c += utoa(&buf[c], uint, utoa_dec);\n                break;\n            case 'x':\n                hex = (uint32_t)va_arg(arg, uint32_t);\n                c += utoa(&buf[c], hex, utoa_hex);\n                break;\n            }\n        }\n        else\n        {\n            buf[c++] = format[i];\n        }\n    }\n\n    if (c >= PRINTF_BUF_LEN)\n    {\n        buf[0] = '\\0';\n        return 0;\n    }\n\n    buf[c] = '\\0';\n    return c;\n}\n\nuint32_t utoa(char* buf, uint32_t val, utoa_t base)\n{\n    const char asciibase = 'a';\n\n    uint32_t c = 0;\n    int32_t idx = 0;\n    char     tmp[11];   // It is enough for 32 bit int\n\n    do {\n        uint32_t t = val % (uint32_t)base;\n        if (t >= 10)\n        {\n            t += asciibase - '0' - 10;\n        }\n        tmp[idx] = (t + '0');\n        val /= base;\n        idx++;\n    } while(val);\n\n    // reverse\n    idx--;\n    while (idx >= 0)\n    {\n        buf[c++] = tmp[idx];\n        idx--;\n    }\n\n    return c;\n}\n\n```\n\n### `stdint.h` 수정사항\n\n문자열 출력 시 NULL을 처리해야 하기에 아래와 같이 추가합니다.\n\n```c\n/* Copyright (C) 1997-2016 Free Software Foundation, Inc.\n   This file is part of the GNU C Library. */\n...\n#define NULL    ((void*)0)  // 추가\n\n#endif /* stdint.h */\n```\n\n### `debug_printf()` 함수가 추가된 `main()` 함수\n\n```c\n#include \"stdint.h\"\n#include \"HalUart.h\"\n\n#include \"stdio.h\"\n\nstatic void Hw_init(void);\nstatic void Printf_test(void);\n\nvoid main(void)\n{\n    Hw_init();\n\n    uint32_t i = 100;\n    while(i--)\n    {\n        Hal_uart_put_char('N');\n    }\n    Hal_uart_put_char('\\n');\n\n    putstr(\"Hello World!\\n\");\n\n    Printf_test();\n\n    i = 100;\n    while(i--)\n    {\n        uint8_t ch = Hal_uart_get_char();\n        Hal_uart_put_char(ch);\n    }\n}\n\nstatic void Hw_init(void)\n{\n    Hal_uart_init();\n}\n\nstatic void Printf_test(void)\n{\n    char* str = \"printf pointer test\";\n    char* nullptr = 0;\n    uint32_t i = 5;\n\n    debug_printf(\"%s\\n\", \"Hello printf\");\n    debug_printf(\"output string pointer: %s\\n\", str);\n    debug_printf(\"%s is null pointer, %u number\\n\", nullptr, 10);\n    debug_printf(\"%u = 5\\n\", i);\n    debug_printf(\"dec=%u hex=%x\\n\", 0xff, 0xff);\n}\n```\n\n이제, 빌드를...",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-5--UART_chunk_0",
        "text": "[RTOS개발] 5장 UART\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지에선 UART 하드웨어 입출력에 대해 다룹니다.\n\n<https://github.com/navilera/Navilos/tree/c484d81dbc1e7cbc8651b2f9ac1993ea215c09ea>\n\n## UART 출력하기\n***\nUART \n: Universal Asynchronous Receiver/Transmitter의 약자로 범용 비동기화 송수신기\n\n가장 먼저 UART를 작업하는 이유는 UART를 보통 콘솔 입출력용으로 사용하기 때문!\n\nUART를 사용하기 위해 가장 먼저 해야 할 일은 UART 하드웨어의 레지스터를 코드로 만드는 것!\n\n\n데이터 시트 링크\n: <https://developer.arm.com/documentation/ddi0183/g/programmers-model/summary-of-registers?lang=en>\n\n\nUART의 가장 기본적인 기능인 입력과 출력만을 사용할 것!\n\n![image.png](/assets/img/OS/os400.png)\n\n레지스터에 대한 설명은 위 링크를 참고\n\n오프셋이 0x00인 UARTDR에 대해서 간략하게 설명하겠습니다.\n\n[https://developer.arm.com/documentation/ddi0183/g/programmers-model/register-descrip",
        "index": 0
      },
      {
        "id": "2024-11-05-5--UART_chunk_1",
        "text": "간략하게 설명하겠습니다.\n\n[https://developer.arm.com/documentation/ddi0183/g/programmers-model/register-descriptions/data-register--uartdr?lang=en](https://developer.arm.com/documentation/ddi0183/g/programmers-model/register-descriptions/data-register--uartdr?lang=en)\n\nUARTDR은 데이터 레지스터입니다.\n\n![image.png](/assets/img/OS/os401.png)\n\n위 그림을 보면 0번부터 7번 비트까지 8비트는 입출력 데이터가 사용하는 레지스터.\n\n한 번에 8비트, 즉 1바이트씩 통신할수 있는 하드웨어 입니다.\n\n8번부터 11번까지는 종류별로 정의된 에러입니다. 프레임 에러, 패리티 에러, 브레이크 에러, 오버런 에러라 이름이 붙어있습니다. 설명에 부합하는 에러 발생 시 해당 비트의 값이 1로!\n\n**코드로 옮기는 방법??**\n\n1. C언어 매크로 이용\n2. 구조체 이용\n\n### 1.",
        "index": 1
      },
      {
        "id": "2024-11-05-5--UART_chunk_2",
        "text": "런 에러라 이름이 붙어있습니다. 설명에 부합하는 에러 발생 시 해당 비트의 값이 1로!\n\n**코드로 옮기는 방법??**\n\n1. C언어 매크로 이용\n2. 구조체 이용\n\n### 1. C언어 매크로를 이용해 레지스터 코드로 옮기기\n\n```bash\n#define UART_BASE_ADDR    0x10009000\n#define UARTDR_OFFSET     0x00\n#define UARTDR_DATA       (0)\n#define UARTDR_FE         (8)\n#define UARTDR_PE         (9)\n#define UARTDR_BE         (10)\n#define UARTDR_OE         (11)\n...\n...\n...\n#define UARTCR_OFFSET     0x30\n```\n\n데이터시트를 보면 RealViewPB에서 UART의 기본주소는 0x1000 9000입니다.\n\n위처럼 매크로를 정의했다면, 아래와 같이 사용할 수 있습니다.\n\n```c\nuint32_t *uartdr = (uint32_t*)(UART_BASE_ADDR + UARTDR_OFFSET);\n*uartdr = (data) << UARTDR_DATA;\nbool fe = (bool)((*uartdr >> UARTDR_FE) & 0x1);\nbool pe = (bool)((*uartdr >> UARTDR_PE) & 0x1);\n...\n```\n\n시프트 연산자를 사용하는 코드는 항상 반복되므로 공용 매크로를 만들어 사용하는 것이 일반적입니다.\n\n### 2.",
        "index": 2
      },
      {
        "id": "2024-11-05-5--UART_chunk_3",
        "text": "artdr >> UARTDR_PE) & 0x1);\n...\n```\n\n시프트 연산자를 사용하는 코드는 항상 반복되므로 공용 매크로를 만들어 사용하는 것이 일반적입니다.\n\n### 2.",
        "index": 3
      },
      {
        "id": "2024-11-05-5--UART_chunk_4",
        "text": "artdr >> UARTDR_PE) & 0x1);\n...\n```\n\n시프트 연산자를 사용하는 코드는 항상 반복되므로 공용 매크로를 만들어 사용하는 것이 일반적입니다.\n\n### 2.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-05-11",
    "title": "[RTOS개발] 11장 이벤트",
    "path": "/2024/11/05/11장-이벤트/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 11장. 이벤트\n\n본 페이지는 이벤트에 대해 다룹니다.\n\n> [https://github.com/navilera/Navilos/tree/df3716b9ca32fa0bd6635436d48f7f814948be0d](https://github.com/navilera/Navilos/tree/df3716b9ca32fa0bd6635436d48f7f814948be0d)\n{: .prompt-tip }\n\n## 서론\n***\n만약 임베디드 시스템에 있는 버튼을 누르면\n\n→ 컨트롤러에서 전기 신호 인식\n\n→ 물리적 전기 신호를 소프트웨어적 인터럽트로 처리\n\n→ ARM이라면 IRQ 혹은 FIQ가 발생\n\n→ IRQ나 FIQ의 핸들러에서 인터럽트 컨트롤러의 레지스터를 읽어 인터럽트 종류 확인\n\n→ 인터럽트 핸들러에서 버튼이 눌렸을 때의 처리\n\n현재 RTOS 커널이 태스크를 관리하고 있기에 좀 더 유연하게 동작하려면 인터럽트 핸들러의 구체적인 기능을 태스크로 옮기는 것이 더 좋습니다.\n\n**→ 인터럽트와 태스크 간의 연결 매체가 필요한데 이때 사용하는 것이 이벤트!**\n\n## 이벤트 플래그\n***\n이벤트는 개발자가 정한 어떤 값으로 전달됩니다.\n\n마치 해당 비트 위치에 있는 깃발을 올렸다 내렸다를 표시하는 것과 같아 **이벤트 플래그**라 부릅니다.\n\n![image.png](/assets/img/OS/os1101.png)\n\n위 그림을 보면 1번 비트와 31번 비트에 플래그가 올라가 있습니다.\n\n이것을 2진수로 표현하면 10000… …10 입니다.\n\n16진수로 표현하면 0x8000 0002입니다.\n\n→ 0x8000 0000과 0x0000 0002에 해당하는 이벤트 두 개가 현재 발생해 처리 대기 중(penind)이라는 뜻입니다.\n\n이것을 처리하는 커널의 기능을 만들겠습니다.\n\n`kernel` 디렉터리에 `event.h`와 `event.c` 파일 두 개를 만들겠습니다.\n\n`event.h` 에는 이벤트 플래그를 처리하는 함수와 이벤트 플래그 자체를 선언해 놓을 것입니다.\n\n`event.c` 에는 이벤트 플래그 데이터를 처리하는 코드가 들어갑니다.\n\n### `kernel/event.h`\n\n```c\n#ifndef KERNEL_EVENT_H_\n#define KERNEL_EVENT_H_\n\ntypedef enum KernelEventFlag_t\n{\n    KernelEventFlag_UartIn      = 0x00000001,\n    KernelEventFlag_Reserved01  = 0x00000002,\n    KernelEventFlag_Reserved02  = 0x00000004,\n    KernelEventFlag_Reserved03  = 0x00000008,\n    KernelEventFlag_Reserved04  = 0x00000010,\n    KernelEventFlag_Reserved05  = 0x00000020,\n    KernelEventFlag_Reserved06  = 0x00000040,\n    KernelEventFlag_Reserved07  = 0x00000080,\n    KernelEventFlag_Reserved08  = 0x00000100,\n    KernelEventFlag_Reserved09  = 0x00000200,\n    KernelEventFlag_Reserved10  = 0x00000400,\n    KernelEventFlag_Reserved11  = 0x00000800,\n    KernelEventFlag_Reserved12  = 0x00001000,\n    KernelEventFlag_Reserved13  = 0x00002000,\n    KernelEventFlag_Reserved14  = 0x00004000,\n    KernelEventFlag_Reserved15  = 0x00008000,\n    KernelEventFlag_Reserved16  = 0x00010000,\n    KernelEventFlag_Reserved17  = 0x00020000,\n    KernelEventFlag_Reserved18  = 0x00040000,\n    KernelEventFlag_Reserved19  = 0x00080000,\n    KernelEventFlag_Reserved20  = 0x00100000,\n    KernelEventFlag_Reserved21  = 0x00200000,\n    KernelEventFlag_Reserved22  = 0x00400000,\n    KernelEventFlag_Reserved23  = 0x00800000,\n    KernelEventFlag_Reserved24  = 0x01000000,\n    KernelEventFlag_Reserved25  = 0x02000000,\n    KernelEventFlag_Reserved26  = 0x04000000,\n    KernelEventFlag_Reserved27  = 0x08000000,\n    KernelEventFlag_Reserved28  = 0x10000000,\n    KernelEventFlag_Reserved29  = 0x20000000,\n    KernelEventFlag_Reserved30  = 0x40000000,\n    KernelEventFlag_Reserved31  = 0x80000000,\n\n    KernelEventFlag_Empty       = 0x00000000,\n} KernelEventFlag_t;\n\nvoid Kernel_event_flag_set(KernelEventFlag_t event);\nvoid Kernel_event_flag_clear(KernelEventFlag_t event);\nbool Kernel_event_flag_check(KernelEventFlag_t event);\n\n#endif /* KERNEL_EVENT_H_ */\n```\n\n대부분 이벤트 플래그 선언입니다.\n\n아직 이벤트 플래그와 이벤트 처리 기능 자체를 구현하는 단계이기에\n\n이벤트를 추가하지 않고 6번째 줄에 `UartIn`만 선언해 놨습니다.\n\n32비트 변수 한 개로는 이벤트 플래그 32개를 표시할 수 있기에, 37번째 줄까지 이벤트 플래그 자리 32개를 예약해 놨습니다.\n\n일단 지금은 이벤트 플래그는 최대 32개만 지원하는 것으로 기능을 한정합니다.\n\n### `kernel/event.c`\n\n```c\n#include \"stdint.h\"\n#include \"stdbool.h\"\n\n#include \"stdio.h\"\n#include \"event.h\"\n\nstatic uint32_t sEventFlag;\n\nvoid Kernel_event_flag_init(void)\n{\n    sEventFlag = 0;\n}\n\nvoid Kernel_event_flag_set(KernelEventFlag_t event)\n{\n    sEventFlag |= (uint32_t)event;\n}\n\nvoid Kernel_event_flag_clear(KernelEventFlag_t event)\n{\n    sEventFlag &= ~((uint32_t)event);\n}\n\nbool Kernel_event_flag_check(KernelEventFlag_t event)\n{\n    if (sEventFlag & (uint32_t)event)\n    {\n        Kernel_event_flag_clear(event);\n        return true;\n    }\n    return false;\n}\n```\n\n7번째 줄의 `sEventFlag`는 이벤트 플래그 32개 기록하고 있으며 태스크에 전달하는 역할을 하는 커널 자료 구조입니다.\n\n태스크 관련 함수와 마찬가지로 태스크에서는 커널 API를 통해 이벤트를 처리하게 하고 싶습니다.\n\n→ `Kernel.c` 와 `Kernel.h` 에 함수를 추가합니다.\n\n### `kernel/Kernel.c` 이벤트 관련 커널 API 추가\n\n```c\nvoid Kernel_send_events(uint32_t event_list)\n{\n  for (uint32_t i = 0 ; i < 32 ; i++)\n  {\n    if ((event_list >> i) & 1)\n    {\n      KernelEventFlag_t sending_event = KernelEventFlag_Empty;\n      sending_event = (KernelEventFlag_t)SET_BIT(sending_event, i);\n      Kernel_event_flag_set(sending_event);\n    }\n  }\n}\n\nKernelEventFlag_t Kernel_wait_events(uint32_t waiting_list)\n{\n  for (uint32_t i = 0 ; i < 32 ; i++)\n  {\n    if ((waiting_list >> i) & 1)\n    {\n      KernelEventFlag_t waiting_event = KernelEventFlag_Empty;\n      waiting_event = (KernelEventFlag_t)SET_BIT(waiting_event, i);\n\n      if (Kernel_event_flag_check(waiting_event))\n      {\n        return waiting_event;\n      }\n    }\n  }\n\n  return KernelEventFlag_Empty;\n}\n\n```\n\n`Kernel_send_events()` 함수는 이벤트를 전달하는 함수입니다.\n\n일단 이벤트를 보내고 누군가 알아서 처리하라고 내버려 두는, “이벤트를 보낸다”에 충실한 함수!\n\n→ 다른 코드와 커플링을 최소화할 수 있음.\n\n`Kernel_wait_events()` 함수는 이벤트를 기다리는 함수입니다.\n\n그냥 어디선가 날아온 이벤트를 처리하는 것입니다.\n\n여기서, 이 함수의 파라미터가 구조체가 아닌 `uint32_t` 인데, 이 덕분에 이벤트를 한번에 여러 개 보내고 받을 수 있습니다.\n\nex) 1,2,3,4번 이벤트를 한번에 보내고 싶을 경우, API를 4번 호출하는 게 아닌, 비트맵을 이용해 한번에 보낼 수 있다. `Kernel_send_events(event1|event2|event3|event4)`\n\n이렇게 보낼 때는 한번에 보낼 수 있으며, 받는 쪽에서는 보내는 함수와 커플링되어 있지 않기에, 각각의 이벤트를 태스크별로 나눠서 처리할 수 있습니다.\n\n```c\nTask#1\nKernel_wait_events(event1|event3)\n\nTask#2\nKernel_wait_events(event2)\n\nTask#3\nKernel_wait_events(event4)\n```\n\n이렇게해서 Navilos에서 이벤트를 처리하는 코드는 모두 구현했습니다.\n\n## 인터럽트와 이벤트\n***\n이벤트는 인터럽트와 엮어 사용하는 것이 일반적입니다.\n\nQEMU라는 에뮬레이터 환경의 제약 때문에 이용할 수 있는 인터럽트가 별로 없습니다.\n\n지금까지 구현한 인터럽트는 타이머와 UART인데, 이전에 구현한 UART를 사용하겠습니다.\n\nUART 인터럽트 핸들러에서 UART 입력 인터럽트가 발생하면 UART 하드웨어에서 입력된 글자를 받아 다시 그대로 UART로 출력했습니다.\n\n이 기능을 태스크의 이벤트 핸들러로 옮기겠습니다.\n\n우선, 이벤트를 발생시켜 태스크의 이벤트 핸들러가 동작하는 것을 확인하겠습니다.\n\n### `hal/rvpb/Uart.c` UART 인터럽트 핸들러 수정\n\n```c\n...\n...\nstatic void interrupt_handler(void)\n{\n    uint8_t ch = Hal_uart_get_char();\n    Hal_uart_put_char(ch);\n    \n    Kernel_send_events(KernelEventFlag_UartIn); // 추가\n}\n```\n\n이미 구현했던 인터럽트 핸들러 함수에 8번째 줄처럼 **이벤트 플래그를 커널로 보냅니다.**\n\n이렇게 코드를 한 줄 추가함으로써 인터럽트와 이벤트의 연결을 완료했습니다.\n\n태스크에서 이벤트를 받아 처리하는 코드를 넣고 시험해보겠습니다.\n\n### `boot/Main.c` 이벤트 처리 테스트\n\n```c\nstatic void Kernel_init(void)\n{\n    uint32_t taskId;\n\n    Kernel_task_init();\n    Kernel_event_flag_init(); // 추가\n\n    taskId = Kernel_task_create(User_task0);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task0 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task1);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task1 creation fail\\n\");\n    }\n\n    taskId = Kernel_task_create(User_task2);\n    if (NOT_ENOUGH_TASK_NUM == taskId)\n    {\n        putstr(\"Task2 creation fail\\n\");\n    }\n\n    Kernel_start();\n}\n\nvoid User_task0(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_UartIn);\n        switch(handle_event)\n        {\n        case KernelEventFlag_UartIn:\n            debug_printf(\"\\nEvent handled\\n\");\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\n```\n\n- `Kernel_init()` 함수에 이벤트 플래그의 초기화 함수를 호출하는 부분 추가\n- 39번째 줄에 `Kernel_wait_events()` 커널 API 사용\n- 기다리는 이벤트는 `KernelEventFlag_UartIn` 이벤트\n\n원하는 동작은 QEMU를 실행하고 키보드를 입력하기 전까지는 아무런 반응이 없어야 함.\n\n키보드 자판을 누르면 해당 자판의 글자가 출력되며 “Event handled”라는 문장이 출력되어야 함.\n\n```c\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n- 자판 입력 시\n\n![image.png](/assets/img/OS/os1102.png)\n\n원하는 대로 잘 동작하는 것을 확인할 수 있습니다.\n\n## 사용자 정의 이벤트\n***\n이벤트를 꼭 인터럽트와 연관지어 사용할 필요는 없습니다.\n\n필요에 따라 사용하지 않는 이벤트 플래그 하나에 이름을 줘서 태스크에서 태스크로 이벤트를 보낼 수도 있습니다.\n\n> 이 특징이 인터럽트와 이벤트의 차이!\n\n인터럽트 핸들러에서 인터럽트의 발생 소식을 태스크로 전달하기 위해 이벤트를 이용한 것이지, 이벤트 ≠ 인터럽트 !!\n{: .prompt-tip }\n\n이번에는 이벤트 플래그를 하나 만들어서 이 이벤트 플래그를 Task0에서 보내 Task1에서 받아보겠습니다.\n\n```c\n\ntypedef enum KernelEventFlag_t\n{\n    KernelEventFlag_UartIn      = 0x00000001,\n    KernelEventFlag_CmdIn       = 0x00000002,\n    KernelEventFlag_Reserved02  = 0x00000004,\n...\n```\n\n`Reservec01`로 예약되어있던 이벤트 플래그에 `CmdIn` 이라는 이름을 붙였습니다.\n\n그리고 아래와 같이 Task0함수와 Task1함수를 수정합니다.\n\n### `boot/Main.c` Task0과 Task1 함수 수정\n\n```c\nvoid User_task0(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_UartIn);\n        switch(handle_event)\n        {\n        case KernelEventFlag_UartIn:\n            debug_printf(\"\\nEvent handled\\n\");\n            Kernel_send_events(KernelEventFlag_CmdIn);\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\nvoid User_task1(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #1 SP=0x%x\\n\", &local);\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_CmdIn);\n        switch(handle_event)\n        {\n        case KernelEventFlag_CmdIn:\n            debug_printf(\"\\nEvent handled by Task1\\n\");\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\n```\n\n즉, 키보드 자판을 입력하면 `UartIn` 이벤트가 발생하고, 이를 `Task0`에서 처리합니다.\n\n`Task0`에서 해당 이벤트를 처리하며 `CmdIn` 이벤트를 보내고, `Task1`에서 이 이벤트를 받아 처리합니다.\n\n동작 테스트를 해보겠습니다.\n\n```c\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os1103.png)\n\n의도한대로 동작하는 것을 확인할 수 있습니다.\n\n## 여러 이벤트 플래그를 동시에 보내고 처리하기\n***\n이벤트 플래그 설계 시 비트맵을 사용한 가장 큰 이유는 이벤트 플래그를 **동시에 여러 개** 보내고 받을 수 있게끔 코딩할 수 있게 하기 위함입니다.\n\n현재 2개의 이벤트 플래그를 사용하는데, 하나 더 추가해 3개를 만들겠습니다.\n\n```c\n\ntypedef enum KernelEventFlag_t\n{\n    KernelEventFlag_UartIn      = 0x00000001,\n    KernelEventFlag_CmdIn       = 0x00000002,\n    KernelEventFlag_CmdOut      = 0x00000004,\n...\n```\n\n그리고 인터럽트 핸들러를 수정해 동시에 이벤트를 여러 개 보내보겠습니다.\n\n### `hal/rvpb/Uart.c` 동시에 이벤트 여러 개를 보내도록 UART 핸들러 수정\n\n```c\nstatic void interrupt_handler(void)\n{\n    uint8_t ch = Hal_uart_get_char();\n    Hal_uart_put_char(ch);\n\n    Kernel_send_events(KernelEventFlag_UartIn|KernelEventFlag_CmdIn);\n\n    if (ch == 'X')\n    {\n        Kernel_send_events(KernelEventFlag_CmtOut);\n    }\n}\n```\n\n비트 `OR` 연산을 이용해 이벤트 플래그 두 개를 동시에 보냅니다.\n\n추가로 `X` 입력 시 `CmdOut` 이벤트를 발생하는 코드를 추가했습니다.\n\n이제 `Main.c` 파일을 수정해 이벤트를 여러개 받도록 하겠습니다.\n\n### `boot/Main.c` 이벤트를 여러 개 받아 처리하는 Task0\n\n```c\nvoid User_task0(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n\n    while(true)\n    {\n        KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_UartIn|KernelEventFlag_CmdOut);\n\n        switch(handle_event)\n        {\n        case KernelEventFlag_UartIn:\n            debug_printf(\"\\nEvent handled\\n\");\n            Kernel_send_events(KernelEventFlag_CmdIn);\n            break;\n        case KernelEventFlag_CmdOut:\n            debug_printf(\"\\nCmdOut Event by Task0\\n\");\n            break;\n        }\n        Kernel_yield();\n    }\n}\n\n```\n\n비트맵으로 `UartIn` 과 `CmdOut` 을 설정했습니다. 이렇게 하면 비트맵으로 설정한 두 이벤트 중 하나가 커널에 대기 중일 때 해당 이벤트 값을 `wait_events` 함수가 리턴합니다.\n\n> 물론 이벤트 두 개를 동시에 처리하지는 않습니다.\n> \n\n이제 동작을 확인해보겠습니다.\n\n```c\n$ qemu-system-arm -M realview-pb-a8 -kernel build/navilos.axf -nographic\n```\n\n![image.png](/assets/img/OS/os1104.png)\n\nX가 아닌 다른 문자가 입력되면, `UartIn`과 `CmdIn` 이벤트를 보내 각각 처리했습니다.\n\n그리고, `X` 를 누르면 `UartIn`에 대한 응답, `CmdIn`에 대한 응답, `CmdOut` 에 대한 응답이 출력됩니다.\n\n그런데, `Task0`에서는 `UartIn`과 `CmdOut`을 모두 처리하지 않고, `Task1`이 처리한 후 처리합니다.\n\n즉, 한 번에 이벤트를 처리하고 있지 않습니다.\n\n> `while`과 `Kernel_wait_events()`  및 `Kernel_yield()` 의 호출 위치 때문!\n> \n\n아래와 같이 코드를 수정하면 해당 태스크가 처리할 이벤트가 없을 때까지 모든 이벤트를 다 처리하고 `Kernel_yield()` 를 호출합니다.\n\n```c\nvoid User_task0(void)\n{\n    uint32_t local = 0;\n\n    debug_printf(\"User Task #0 SP=0x%x\\n\", &local);\n\n    while(true)\n    {\n        bool pendingEvent = true;\n\n        while(pendingEvent)\n        {\n            KernelEventFlag_t handle_event = Kernel_wait_events(KernelEventFlag_UartIn | KernelEventFlag_CmdOut);\n            switch(handle_event)\n            {\n            case KernelEventFlag_UartIn:\n                debug_printf(\"\\nEvent handled\\n\");\n                Kernel_send_events(KernelEventFlag_CmdIn);\n                break;\n            case KernelEventFlag_CmdOut:\n                debug_printf(\"\\nCmdOut Event by Task0\\n\");\n                break;\n            default:\n                pendingEvent = false;\n                break;\n            }\n        }\n        Kernel_yield();\n    }\n}\n\n```\n\n![image.png](/assets/img/OS/os1105.png)\n\n이처럼 `Task0`에서 모든 이벤트를 처리하고 `Task1` 의 이벤트가 처리됩니다.\n\n어떤 것이 더 좋다고 할 수는 없으며, RTOS가 동작하는 시스템의 요구사항에 따라 코드를 다르게 작성해야 할 뿐입니다.\n\n## 요약\n***\n이 장에서는 이벤트 기능을 만들었습니다. 이벤트 플래그를 비트맵으로 만들어 각 태스크가 이벤트를 보내고 받도록 했습니다.\n\n이벤트는 태스크 간 정보 전달뿐 아니라 인터럽트 핸들러에서 태스크로 정보를 전달할 때도 유용하게 쓸 수 있습니다.\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n\n",
    "date": "2024-11-05",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-05-11_chunk_0",
        "text": "[RTOS개발] 11장 이벤트\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 11장.",
        "index": 0
      },
      {
        "id": "2024-11-05-11_chunk_1",
        "text": ".w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 11장.",
        "index": 1
      },
      {
        "id": "2024-11-05-11_chunk_2",
        "text": ".w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 11장.",
        "index": 2
      },
      {
        "id": "2024-11-05-11_chunk_3",
        "text": ".w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 11장.",
        "index": 3
      },
      {
        "id": "2024-11-05-11_chunk_4",
        "text": ".w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 11장.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-04-2",
    "title": "[RTOS개발] 2장 개발환경 구성하기",
    "path": "/2024/11/04/2장-개발환경-구성하기/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 본 페이지에선 개발 환경 구성에 대해 다룹니다\n***\n\n## 서론\n***\n개발 환경을 리눅스로 구성하는 것을 추천합니다. 우분투 리눅스나 민트 리눅스와 같은 배포판을 사용할 수 있습니다. 윈도우를 사용하는 경우에는 가상 머신이나 WSL을 통해 설치할 수 있습니다.\n\n## 컴파일러 설치하기\n***\n임베디드 시스템에서 동작하는 펌웨어를 만들기 위해서는 해당 임베디드 시스템에 맞는 컴파일러가 필요합니다. 우리의 목표는 ARM에서 동작하는 펌웨어를 만드는 것이므로 ARM용 컴파일러를 설치해야 합니다.\n\n### 크로스 컴파일러\n크로스 컴파일러는 컴파일을 실행하는 환경과 컴파일된 결과물이 실행될 환경이 다른 경우 사용됩니다. 이 교재에서는 크로스 컴파일러로 GCC를 사용합니다. 상용으로 판매되는 ARMCC도 있지만, 비용이 비싸기 때문에 GCC를 선택합니다. GCC는 다양한 종류가 있으며, 펌웨어 용도로는 `gcc-arm-none-eabi`를 사용합니다.\n\n```bash\n$ sudo apt install gcc-arm-none-eabi -y\n```\n![Untitled](/assets/img/OS/os101.png)\n\n설치 후 버전을 확인하여 컴파일러가 정상적으로 설치되었는지 확인합니다.\n\n```bash\n$ arm-none-eabi-gcc -v\n```\n![Untitled](/assets/img/OS/os102.png)\n\n## QEMU 설치하기\n***\nQEMU는 x86, ARM 등 여러 환경을 가상 머신으로 사용할 수 있는 에뮬레이터입니다. ARM 개발 보드를 구매하지 않고도 QEMU를 이용해 개발 환경을 구축할 수 있습니다.\n\n### QEMU 설치\nQEMU를 설치하려면 다음 명령어를 사용합니다.\n\n```bash\n$ sudo apt install qemu-system-arm -y\n```\n![Untitled](/assets/img/OS/os103.png)\n\n설치 후 버전을 확인하여 QEMU가 정상적으로 설치되었는지 확인합니다.\n\n```bash\n$ qemu-system-arm --version\n```\n![Untitled](/assets/img/OS/os104.png)\n\n## 지원하는 머신 목록 확인\n***\nQEMU에서 지원하는 ARM 시스템 목록을 확인하려면 다음 명령어를 사용합니다.\n\n```bash\n$ qemu-system-arm -M ?\n```\n![Untitled](/assets/img/OS/os105.png)\n\n\n출력된 목록에서 원하는 머신을 선택해 개발을 진행할 수 있습니다. 본 교재에서는 데이터시트를 쉽게 구할 수 있는 `realview-pb-a8`을 사용합니다.\n\n```bash\nrealview-pb-a8       ARM RealView Platform Baseboard for Cortex-A8\n```\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n",
    "date": "2024-11-04",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-04-2_chunk_0",
        "text": "[RTOS개발] 2장 개발환경 구성하기\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n# 본 페이지에선 개발 환경 구성에 대해 다룹니다\n***\n\n## 서론\n***\n개발 환경을 리눅스로 구성하는 것을 추천합니다. 우분투 리눅스나 민트 리눅스와 같은 배포판을 사용할 수 있습니다. 윈도우를 사용하는 경우에는 가상 머신이나 WSL을 통해 설치할 수 있습니다.\n\n## 컴파일러 설치하기\n***\n임베디드 시스템에서 동작하는 펌웨어를 만들기 위해서는 해당 임베디드 시스템에 맞는 컴파일러가 필요합니다. 우리의 목표는 ARM에서 동작하는 펌웨어를 만드는 것이므로 ARM용 컴파일러를 설치해야 합니다.\n\n### 크로스 컴파일러\n크로스 컴파일러는 컴파일을 실행하는 환경과 컴파일된 결과물이 실행될 환경이 다른 경우 사용됩니다. 이 교재에서는 크로스 컴파일러로 GCC를 사용합니다. 상용으로 판매되는 ARMCC도 있지만, 비용이 비싸기 때문에 GCC를 선택합니다.",
        "index": 0
      },
      {
        "id": "2024-11-04-2_chunk_1",
        "text": "물이 실행될 환경이 다른 경우 사용됩니다. 이 교재에서는 크로스 컴파일러로 GCC를 사용합니다. 상용으로 판매되는 ARMCC도 있지만, 비용이 비싸기 때문에 GCC를 선택합니다. GCC는 다양한 종류가 있으며, 펌웨어 용도로는 `gcc-arm-none-eabi`를 사용합니다.\n\n```bash\n$ sudo apt install gcc-arm-none-eabi -y\n```\n![Untitled](/assets/img/OS/os101.png)\n\n설치 후 버전을 확인하여 컴파일러가 정상적으로 설치되었는지 확인합니다.\n\n```bash\n$ arm-none-eabi-gcc -v\n```\n![Untitled](/assets/img/OS/os102.png)\n\n## QEMU 설치하기\n***\nQEMU는 x86, ARM 등 여러 환경을 가상 머신으로 사용할 수 있는 에뮬레이터입니다.",
        "index": 1
      },
      {
        "id": "2024-11-04-2_chunk_2",
        "text": "led](/assets/img/OS/os102.png)\n\n## QEMU 설치하기\n***\nQEMU는 x86, ARM 등 여러 환경을 가상 머신으로 사용할 수 있는 에뮬레이터입니다. ARM 개발 보드를 구매하지 않고도 QEMU를 이용해 개발 환경을 구축할 수 있습니다.\n\n### QEMU 설치\nQEMU를 설치하려면 다음 명령어를 사용합니다.\n\n```bash\n$ sudo apt install qemu-system-arm -y\n```\n![Untitled](/assets/img/OS/os103.png)\n\n설치 후 버전을 확인하여 QEMU가 정상적으로 설치되었는지 확인합니다.\n\n```bash\n$ qemu-system-arm --version\n```\n![Untitled](/assets/img/OS/os104.png)\n\n## 지원하는 머신 목록 확인\n***\nQEMU에서 지원하는 ARM 시스템 목록을 확인하려면 다음 명령어를 사용합니다.\n\n```bash\n$ qemu-system-arm -M ?\n```\n![Untitled](/assets/img/OS/os105.png)\n\n\n출력된 목록에서 원하는 머신을 선택해 개발을 진행할 수 있습니다.",
        "index": 2
      },
      {
        "id": "2024-11-04-2_chunk_3",
        "text": "mu-system-arm -M ?\n```\n![Untitled](/assets/img/OS/os105.png)\n\n\n출력된 목록에서 원하는 머신을 선택해 개발을 진행할 수 있습니다. 본 교재에서는 데이터시트를 쉽게 구할 수 있는 `realview-pb-a8`을 사용합니다.\n\n```bash\nrealview-pb-a8       ARM RealView Platform Baseboard for Cortex-A8\n```\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 3
      },
      {
        "id": "2024-11-04-2_chunk_4",
        "text": "m/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-04-4",
    "title": "[RTOS개발] 4장 부팅하기",
    "path": "/2024/11/04/4장-부팅하기/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n본 장에서는 시스템의 전원이 켜진 후 초기화 작업을 완료하고 대기 상태(idle)에 도달하는 **부팅 과정**에 대해 다룹니다.\n\n## 서론 📚\n\n***\n\n컴퓨터를 켰을 때 운영체제의 화면이나 바탕화면이 나타나는 과정을 일반적으로 **부팅**이라고 합니다. 💻\n\n펌웨어 관점에서 부팅은 특정한 규칙이 정해져 있지 않지만, 시스템 전원이 켜진 후 모든 초기화 작업을 완료하고 펌웨어가 대기 상태에 도달할 때까지의 과정을 의미합니다. 또한, ARM 코어가 리셋 익셉션 핸들러를 모두 처리한 후, 본격적으로 C 언어 코드로 전환되기 직전의 상태도 부팅 과정에 포함됩니다.\n\n## 메모리 설계 🧠\n\n***\n\n실행 파일은 메모리를 크게 세 가지 영역으로 나눠 사용합니다.\n\n1. **text 영역:** 코드가 위치하며 변경이 불가능합니다.\n2. **data 영역:** 초기화된 전역 변수가 저장됩니다.\n3. **bss 영역:** 초기화되지 않은 전역 변수가 저장됩니다. 빌드된 바이너리 파일에는 심벌과 크기 정보만 포함됩니다.\n\n이제 **text**, **data**, **bss** 영역을 어떻게 배치할지 고민해야 합니다.\n\n- **임베디드 시스템의 메모리 유형에 따른 배치 전략:**\n  \n  - **빠른 메모리:** **text 영역** 및 일부 성능에 민감한 **data 영역**을 배치합니다.\n  - **용량 큰 메모리:** 나머지 **data 영역**과 **bss 영역**을 배치합니다.\n\n하지만, **QEMU**는 이러한 메모리 구분이 없으므로 순차적으로 배치하겠습니다.\n\n### Text 영역의 크기 설정 📏\n\n리눅스 같은 거대한 운영체제를 사용하지 않기에, RTOS를 사용하는 펌웨어는 많아야 수십 KB 정도면 충분합니다.\n\n본 프로젝트에서는 넉넉하게 **1MB**를 할당하겠습니다.\n\n익셉션 벡터 테이블을 **text 영역**에 포함시킬 것이므로, 시작 주소는 `0x0000 0000`이며, **1MB**이기에 끝 주소는 `0x000F FFFF`입니다.\n\n### Data 영역과 BSS 영역의 크기 설정 📐\n\n데이터의 성격에 따라 데이터를 할당해야 합니다.\n\n- **데이터의 형태:** 동작 모드별 스택, 테스크 스택, 전역 변수, 동적 메모리 할당 영역\n- **데이터의 속성:** 성능 중시 데이터, 큰 공간이 필요한 데이터, 공유 데이터\n\n> - USR, SYS(2MB) : 0x0010 0000 ~ 0x002F FFFF  \n> - SVC(1MB) : 0X0030 0000 ~ 0X003F FFFF  \n> - IRQ(1MB) …  \n> - FIQ(1MB) …  \n> - ABT(1MB) …  \n> - UND(1MB) …\n{: .prompt-info }\n\n개별 동작 모드마다 각 **1MB**씩 할당했습니다. USR과 SYS 모드는 메모리 공간과 레지스터를 모두 공유하기에 하나로 묶어 **2MB**를 할당했습니다.\n\nRTOS를 개발할 것이기에 RTOS 위에서 동작할 **테스크(Task) 스택 영역**도 고려해야 합니다. 테스크마다 각 **1MB**씩 할당할 계획이므로 총 **64MB**를 배정하겠습니다.\n\n→ 본 프로젝트의 RTOS는 최대 **64개**의 테스크를 지원하게 됩니다.\n\n- **메모리 설계**\n\n![메모리 설계](/assets/img/OS/os301.png)\n\n## 익셉션 벡터 테이블 만들기 🛠️\n\n***\n\n설계를 완료한 후, **익셉션 핸들러**를 코드로 구현하겠습니다.\n\n### 익셉션 벡터 테이블 초기 코드 `Entry.S` 📄\n\n```bash\n.text\n\t.code 32\n\n\t.global vector_start\n\t.global vector_end\n\n\tvector_start:\n\t\tLDR\t\tPC, reset_handler_addr\n\t\tLDR\t\tPC, undef_handler_addr\n\t\tLDR\t\tPC, svc_handler_addr\n\t\tLDR\t\tPC, pftch_abt_handler_addr\n\t\tLDR\t\tPC, data_abt_handler_addr\n\t\tB\t\t.\n\t\tLDR\t\tPC, irq_handler_addr\n\t\tLDR\t\tPC, fiq_handler_addr\n\n\t\treset_handler_addr: \t.word reset_handler\n\t\tundef_handler_addr: \t.word dummy_handler\n\t\tsvc_handler_addr: \t\t.word dummy_handler\n\t\tpftch_abt_handler_addr: .word dummy_handler\n\t\tdata_abt_handler_addr:  .word dummy_handler\n\t\tirq_handler_addr:\t\t.word dummy_handler\n\t\tfiq_handler_addr:\t\t.word dummy_handler\n\tvector_end:\n\n\treset_handler:\n\t\tLDR\t\tR0, =0x10000000\n\t\tLDR\t\tR1, [R0]\n\n\tdummy_handler:\n\t\tB .\n.end\n```\n\n> 붙여넣기 시 vi 명령어로 `:set paste` 후 붙여넣으면 들여쓰기 오류를 방지할 수 있습니다.\n{: .prompt-info }\n\n우선, 각 핸들러로 점프하는 코드만 작성하고, 핸들러는 작성하지 않았습니다.\n\n리셋 익셉션 핸들러에는 `SYS_ID`를 읽는 코드가 있으므로, 3장에서와 같이 `R0`과 `R1`에 값이 있는지 확인하고, 코드를 이어서 작성하겠습니다.\n\n```bash\n$ make debug\n...\n$ make gdb\n...\n(gdb) target remote:1234\n(gdb) continue\n\n^C  # 무한루프를 돌고 있으므로, Ctrl + C를 이용해 빠져나옵니다.\n(gdb) i r\n```\n\n![디버깅 이미지](/assets/img/OS/os302.png)\n\n이전 3.5절에서 확인한 결과와 같습니다.\n\n## 익셉션 핸들러 만들기 🔧\n\n***\n\n핸들러를 작성하기 전에, **익셉션 핸들러**와 **뱅크드 레지스터**에 대한 ARM 아키텍처의 개념을 숙지하는 것이 좋습니다.\n\n가장 먼저 작성할 핸들러는 **리셋 익셉션 핸들러**입니다. 이 핸들러는 메모리 맵을 설정하고, 동작 모드별 스택 주소를 **SP 레지스터**에 할당합니다. 모든 스택 설정이 완료되면 C 언어의 `main()` 함수로 진입하여 **C 언어로 임베디드 시스템을 제어**할 수 있습니다.\n\nARM은 총 **7개의 동작 모드**가 있으며, USR과 SYS 모드는 레지스터를 공유하여 **6개의 SP 레지스터**가 제공됩니다.\n\n### 스택 만들기 🧩\n\n이전 절에서 설계한 메모리 맵을 C 언어 코드로 구현합니다.\n\n### 스택 주소를 정의 `MemoryMap.h` 📁\n\n```bash\n#define INST_ADDR_START     0\n#define USRSYS_STACK_START  0x00100000\n#define SVC_STACK_START     0x00300000\n#define IRQ_STACK_START     0x00400000\n#define FIQ_STACK_START     0x00500000\n#define ABT_STACK_START     0x00600000\n#define UND_STACK_START     0x00700000\n#define TASK_STACK_START    0x00800000\n#define GLOBAL_ADDR_START   0x04800000\n#define DALLOC_ADDR_START   0x04900000\n\n#define INST_MEM_SIZE       (USRSYS_STACK_START - INST_ADDR_START)\n#define USRSYS_STACK_SIZE   (SVC_STACK_START - USRSYS_STACK_START)\n#define SVC_STACK_SIZE      (IRQ_STACK_START - SVC_STACK_START)\n#define IRQ_STACK_SIZE      (FIQ_STACK_START - IRQ_STACK_START)\n#define FIQ_STACK_SIZE      (ABT_STACK_START - FIQ_STACK_START)\n#define ABT_STACK_SIZE      (UND_STACK_START - ABT_STACK_START)\n#define UND_STACK_SIZE      (TASK_STACK_START - UND_STACK_START)\n#define TASK_STACK_SIZE     (GLOBAL_ADDR_START - TASK_STACK_START)\n#define DALLOC_MEM_SIZE     (55 * 1024 * 1024)\n\n#define USRSYS_STACK_TOP    (USRSYS_STACK_START + USRSYS_STACK_SIZE - 4)\n#define SVC_STACK_TOP       (SVC_STACK_START + SVC_STACK_SIZE - 4)\n#define IRQ_STACK_TOP       (IRQ_STACK_START + IRQ_STACK_SIZE - 4)\n#define FIQ_STACK_TOP       (FIQ_STACK_START + FIQ_STACK_SIZE - 4)\n#define ABT_STACK_TOP       (ABT_STACK_START + ABT_STACK_SIZE - 4)\n#define UND_STACK_TOP       (UND_STACK_START + UND_STACK_SIZE - 4)\n```\n\n위 코드는 C 언어 헤더 파일이지만, GCC로 컴파일하면 `Entry.S` 어셈블리어 파일에서도 사용할 수 있습니다.\n\n그리고, ARM의 `cspr`에 값을 설정해 동작 모드를 변경할 수 있는 값을 정의한 헤더 파일을 만들겠습니다.\n\n### 동작 모드 전환 값 `ARMv7AR.h` 🔄\n\n```bash\n/* PSR Mode Bit Values */\n#define ARM_MODE_BIT_USR 0x10\n#define ARM_MODE_BIT_FIQ 0x11\n#define ARM_MODE_BIT_IRQ 0x12\n#define ARM_MODE_BIT_SVC 0x13\n#define ARM_MODE_BIT_ABT 0x17\n#define ARM_MODE_BIT_UND 0x1B\n#define ARM_MODE_BIT_SYS 0x1F\n#define ARM_MODE_BIT_MON 0x16\n```\n\n헤더 파일을 어셈블리어 코드에 포함시킵니다.\n\n### 동작 모드 스택 초기화 리셋 익셉션 핸들러 `Entry.S` 📝\n\n```bash\n#include \"ARMv7AR.h\"\n#include \"MemoryMap.h\"\n\n.text\n    .code 32\n\n    .global vector_start\n    .global vector_end\n\n    vector_start:\n        LDR PC, reset_handler_addr\n        LDR PC, undef_handler_addr\n        LDR PC, svc_handler_addr\n        LDR PC, pftch_abt_handler_addr\n        LDR PC, data_abt_handler_addr\n        B   .\n        LDR PC, irq_handler_addr\n        LDR PC, fiq_handler_addr\n\n        reset_handler_addr:     .word reset_handler\n        undef_handler_addr:     .word dummy_handler\n        svc_handler_addr:       .word dummy_handler\n        pftch_abt_handler_addr: .word dummy_handler\n        data_abt_handler_addr:  .word dummy_handler\n        irq_handler_addr:       .word dummy_handler\n        fiq_handler_addr:       .word dummy_handler\n    vector_end:\n\n    reset_handler:\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_SVC\n        MSR cpsr, r1\n        LDR sp, =SVC_STACK_TOP\n\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_IRQ\n        MSR cpsr, r1\n        LDR sp, =IRQ_STACK_TOP\n\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_FIQ\n        MSR cpsr, r1\n        LDR sp, =FIQ_STACK_TOP\n\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_ABT\n        MSR cpsr, r1\n        LDR sp, =ABT_STACK_TOP\n\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_UND\n        MSR cpsr, r1\n        LDR sp, =UND_STACK_TOP\n\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_SYS\n        MSR cpsr, r1\n        LDR sp, =USRSYS_STACK_TOP\n\n    dummy_handler:\n        B .\n.end\n```\n\n> 헤더 파일의 위치를 어셈블러에 알려주지 않으면 심벌 정의 오류가 발생할 수 있습니다.\n{: .prompt-info }\n\n### Makefile 수정 🛠️\n\n헤더 파일 경로를 지정하여 컴파일 오류를 방지합니다.\n\n```bash\nARCH = armv7-a\nMCPU = cortex-a8\n\nCC = arm-none-eabi-gcc\nAS = arm-none-eabi-as\nLD = arm-none-eabi-ld\nOC = arm-none-eabi-objcopy\n\nLINKER_SCRIPT = ./navilos.ld\n\nASM_SRCS = $(wildcard boot/*.S)\nASM_OBJS = $(patsubst boot/%.S, build/%.o, $(ASM_SRCS))\n\nINC_DIRS = include # 헤더파일이 있는 디렉토리를 지정\n\nnavilos = build/navilos.axf\nnavilos_bin = build/navilos.bin\n\n.PHONY: all clean run debug gdb\n\nall: $(navilos)\n\nclean:\n\t@rm -fr build\n\t\nrun: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos)\n\t\ndebug: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -S -gdb tcp::1234,ipv4\n\t\ngdb:\n\tgdb-multiarch $(navilos)\n\t\n$(navilos): $(ASM_OBJS) $(LINKER_SCRIPT)\n\t$(LD) -n -T $(LINKER_SCRIPT) -o $(navilos) $(ASM_OBJS)\n\t$(OC) -O binary $(navilos) $(navilos_bin)\n\t\nbuild/%.o: boot/%.S\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) -I $(INC_DIRS) -c -g -o $@ $< # -I 옵션으로 추가하고, $(AS)를 $(CC)로 수정\n```\n\n> `#define`은 전처리기에 의해 처리되는데, `arm-none-eabi-as`는 어셈블러일 뿐 전처리를 지원하지 않기에, 전처리까지 진행하려면 `gcc`를 사용해야 합니다. <br>→ `$(AS)`에서 `$(CC)`로 수정\n{: .prompt-info }\n\n`$(CC)`로 수정하여 GCC를 사용함으로써, `-c` 옵션을 추가해 오브젝트 파일을 생성하도록 지시합니다.\n\n### 스택 확인하기 🧐\n\n빌드를 완료했으니, 이제 스택이 제대로 초기화되었는지 확인해 보겠습니다.\n\n변수나 레지스터의 값을 출력할 수 없으므로, **gdb**를 이용해 확인합니다.\n\n```bash\n(gdb) target remote:1234\n.\n(gdb) s\n.\n(gdb) s\n.\n(gdb) s\n.\n(gdb) s\n.\n(gdb) s\n.\n(gdb) s\n.\n(gdb) i r\nr0             0x400001d3          1073742291\nr1             0x400001d3          1073742291\nr2             0x0                 0\nr3             0x0                 0\n...\n```\n\n![스택 확인 이미지](/assets/img/OS/os303.png)\n\n34번째 줄까지 실행되면 첫 번째 SVC 동작 모드 스택이 설정됩니다.\n\n이전 SVC 모드 스택은 `0x0030 0000 ~ 0x003F FFFF`까지의 메모리 주소 영역을 가집니다.\n\n또한, 스택과 스택 경계 사이에 **4바이트**를 비워두도록 크기를 설정했으므로, 스택 포인터에 저장되어야 할 값은 `0x003F FFFC`입니다.\n\n위 이미지를 보면 `sp 0x3f fffc`라는 출력이 보입니다. 나머지 값들도 확인해보면, 값이 제대로 설정되었음을 알 수 있습니다.\n\n> SYS 동작 모드를 가장 마지막에 설정했습니다. 스택 설정을 완료하면 RTOS로 진입하게 되는데, RTOS와 펌웨어의 기본 동작 모드가 SYS이기에, 추가 설정 없이 SYS 모드로 작업할 수 있습니다.\n{: .prompt-info }\n\n## 메인으로 진입하기 🎯\n\n***\n\nC 언어의 시작 지점은 일반적으로 `main()` 함수입니다. 컴파일러가 기본적으로 `main()`을 사용하기 때문에, 이를 유지하는 것이 좋습니다.\n\n### 메인 함수로 점프하는 코드 추가 `Entry.S` 🔄\n\n```bash\n...(생략)\n        MRS r0, cpsr\n        BIC r1, r0, #0x1F\n        ORR r1, r1, #ARM_MODE_BIT_SYS\n        MSR cpsr, r1\n        LDR sp, =USRSYS_STACK_TOP\n                \n                BL main     # 이거 추가\n```\n\n이 한 줄로 어셈블리어 코드에서 C 언어 코드로 전환됩니다.\n\n이제, `boot/Main.c` 파일을 만들고 간단한 코드를 작성해보겠습니다.\n\n### Main.c 파일 초기 코드 🖥️\n\n```bash\n#include \"stdint.h\"\n\nvoid main(void){\n\tuint32_t* dummyAddr = (uint32_t*)(1024*1024*100);\n\t*dummyAddr = sizeof(long);\n}\n```\n\n어셈블리어 코드에서 브랜치 명령(`BL`)으로 점프를 하려면, 점프 대상 레이블이 동일 파일에 있어야 합니다.\n\n다른 파일에 있다면 링커가 접근할 수 있도록 레이블을 `.global`로 선언해야 합니다.\n\n**컴파일러**는 C 언어 함수 이름을 링커가 자동으로 접근할 수 있는 전역 심벌로 만듭니다.\n\n> 전역 심벌은 어셈블리어에서 `.global`이고, C 언어에서는 `extern`으로 선언된 이름입니다.  \n> \n> 반대로 어셈블리어에서 `.global`로 선언한 이름은 C 언어에서 함수 호출로 진입할 수 있습니다.\n{: .prompt-info }\n\n위 `Main.c` 파일은 **100MB 메모리 주소 영역(0x640 0000)**에 의미 없는 값을 쓰는 동작을 수행합니다.\n\n위 코드에서는 `long` 타입의 크기인 **4**를 메모리에 저장합니다. 32비트 ARM 머신이므로 숫자 **4**가 메모리에 저장되어야 합니다.\n\n### C 언어 파일을 컴파일하기 위한 Makefile 📄\n\n```bash\nARCH = armv7-a\nMCPU = cortex-a8\n\nCC = arm-none-eabi-gcc\nAS = arm-none-eabi-as\nLD = arm-none-eabi-ld\nOC = arm-none-eabi-objcopy\n\nLINKER_SCRIPT = ./navilos.ld\nMAP_FILE = build/navilos.map\n\nASM_SRCS = $(wildcard boot/*.S)\nASM_OBJS = $(patsubst boot/%.S, build/%.os, $(ASM_SRCS))\n\nC_SRCS = $(wildcard boot/*.c)\nC_OBJS = $(patsubst boot/%.c, build/%.o, $(C_SRCS))\n\nINC_DIRS  = -I include\n\nnavilos = build/navilos.axf\nnavilos_bin = build/navilos.bin\n\n.PHONY: all clean run debug gdb\n\nall: $(navilos)\n\nclean:\n\t@rm -fr build\n\t\nrun: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos)\n\t\ndebug: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -S -gdb tcp::1234,ipv4\n\t\ngdb:\n\tgdb-multiarch $(navilos)\n\t\n$(navilos): $(ASM_OBJS) $(C_OBJS) $(LINKER_SCRIPT)\n\t$(LD) -n -T $(LINKER_SCRIPT) -o $(navilos) $(ASM_OBJS) $(C_OBJS) -Map=$(MAP_FILE)\n\t$(OC) -O binary $(navilos) $(navilos_bin)\n\t\nbuild/%.os: boot/%.S\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) $(INC_DIRS) -c -g -o $@ $<\n\t\nbuild/%.o: boot/%.c\n\tmkdir -p $(shell dirname $@)\n\t$(CC) -march=$(ARCH) -mcpu=$(MCPU) $(INC_DIRS) -c -g -o $@ $<\n```\n\n먼저 **10번째 줄**에서 map 파일 이름을 지정했습니다. (`map` 파일은 링커가 생성하는 파일입니다.)\n\nC 언어 소스코드와 오브젝트 파일을 변수로 지정한 후, 링커에 파라미터로 전달합니다.\n\n마지막 `build/%.o`에서 C 언어 파일을 컴파일해 오브젝트 파일을 생성하는 매크로를 작성했습니다.\n\n### 💡 `stdint.h` 파일 추가 필요 📄\n\n```c\n/* stdint.h 내용 (생략) */\n```\n\n빌드 후 **gdb**로 **100MB 위치(0x640 0000)**의 메모리 값을 확인합니다.\n\n![메모리 값 확인 이미지](/assets/img/OS/os305.png)\n\n`x/8wx 메모리 주소` 명령어로 메모리 값을 확인한 결과, **4**가 정상적으로 저장된 것을 확인할 수 있습니다.\n\n## 요약 📝\n\n***\n\n이번 장에서는 시스템의 전원이 켜졌을 때의 **부팅 과정**과 펌웨어 초기화 코드를 작성하였습니다.\n\nARM 프로세서의 초기 진입 코드를 구현하고, 앞으로 만들 **나빌로스(Navilos)**의 메모리 맵을 구성하였습니다.\n\n다음 장에서는 하드웨어 중 **UART**를 제어하여 **gdb**가 아닌 **터미널 화면**과의 상호작용을 구현할 예정입니다.\n\n***\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n",
    "date": "2024-11-04",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-04-4_chunk_0",
        "text": "[RTOS개발] 4장 부팅하기\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n본 장에서는 시스템의 전원이 켜진 후 초기화 작업을 완료하고 대기 상태(idle)에 도달하는 **부팅 과정**에 대해 다룹니다.\n\n## 서론 📚\n\n***\n\n컴퓨터를 켰을 때 운영체제의 화면이나 바탕화면이 나타나는 과정을 일반적으로 **부팅**이라고 합니다. 💻\n\n펌웨어 관점에서 부팅은 특정한 규칙이 정해져 있지 않지만, 시스템 전원이 켜진 후 모든 초기화 작업을 완료하고 펌웨어가 대기 상태에 도달할 때까지의 과정을 의미합니다. 또한, ARM 코어가 리셋 익셉션 핸들러를 모두 처리한 후, 본격적으로 C 언어 코드로 전환되기 직전의 상태도 부팅 과정에 포함됩니다.\n\n## 메모리 설계 🧠\n\n***\n\n실행 파일은 메모리를 크게 세 가지 영역으로 나눠 사용합니다.\n\n1. **text 영역:** 코드가 위치하며 변경이 불가능합니다.\n2. **data 영역:** 초기화된 전역 변수가 저장됩니다.\n3. **bss 영역:** 초기화되지 않은 전역 변수가 저장됩니다.",
        "index": 0
      },
      {
        "id": "2024-11-04-4_chunk_1",
        "text": "영역:** 코드가 위치하며 변경이 불가능합니다.\n2. **data 영역:** 초기화된 전역 변수가 저장됩니다.\n3. **bss 영역:** 초기화되지 않은 전역 변수가 저장됩니다.",
        "index": 1
      },
      {
        "id": "2024-11-04-4_chunk_2",
        "text": "영역:** 코드가 위치하며 변경이 불가능합니다.\n2. **data 영역:** 초기화된 전역 변수가 저장됩니다.\n3. **bss 영역:** 초기화되지 않은 전역 변수가 저장됩니다.",
        "index": 2
      },
      {
        "id": "2024-11-04-4_chunk_3",
        "text": "영역:** 코드가 위치하며 변경이 불가능합니다.\n2. **data 영역:** 초기화된 전역 변수가 저장됩니다.\n3. **bss 영역:** 초기화되지 않은 전역 변수가 저장됩니다.",
        "index": 3
      },
      {
        "id": "2024-11-04-4_chunk_4",
        "text": "영역:** 코드가 위치하며 변경이 불가능합니다.\n2. **data 영역:** 초기화된 전역 변수가 저장됩니다.\n3. **bss 영역:** 초기화되지 않은 전역 변수가 저장됩니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-04-3",
    "title": "[RTOS개발] 3장 일단 시작하기",
    "path": "/2024/11/04/3장-일단-시작하기/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지에선 직접 코드를 작성해 펌웨어를 실행시켜보는 것에 대해 다룹니다.\n\n## 서론\n***\n이 장의 소스 코드는 아래 명령어를 통해 다운로드할 수 있습니다.\n\n```bash\n$ wget https://github.com/navilera/Navilos/archive/95f2b8d.zip # 1절\n$ wget https://github.com/navilera/Navilos/archive/d99603c.zip # 3절\n$ wget https://github.com/navilera/Navilos/archive/be7a34c.zip # 4절\n$ wget https://github.com/navilera/Navilos/archive/0ea7fe7.zip # 5절\n```\n## 리셋 벡터\n***\n- ARM 코어에 전원이 들어가면 가장 먼저 하는 일은 리셋 벡터에 있는 명령을 실행하는 것\n  - **리셋 벡터 = 메모리 주소 0x00000000**\n  - 전원이 들어오면 가장 먼저 메모리 주소 0x00000000에서 32비트를 읽어서 명령을 바로 실행\n\n- 우리가 해야 할 일: 메모리 주소 0x00000000에 명령어 넣기\n  - boot라는 이름의 디렉토리를 만들고, `Entry.S`라는 코드 작성\n\n```bash\n$ mkdir boot && cd boot\n$ vi Entry.S\n```\n\n### `Entry.S`\n\n```bash\n.text\n  .code 32\n\n  .global vector_start\n  .global vector_end\n\n  vector_start:\n    LDR R0, =0x10000000\n    LDR R1, [R0]\n  vector_end:\n    .space 1024, 0\n.end\n```\n\n![코드 예시 이미지](/assets/img/OS/os201.png)\n\n- 코드의 처음과 끝에 있는 `.text`와 `.end`는 그 사이에 있는 코드가 text 섹션임을 의미\n- 실행 파일: 소프트웨어를 구성하는 요소를 파일 시스템에 바이너리로 만든 것\n  - 소프트웨어는 **데이터**와 그 데이터를 변경하는 **코드**로 구성\n  - 선언하는 변수 = 데이터, 변수의 값을 변경하는 로직 = 코드\n  - 코드를 바이너리로 변경해 모아 놓은 것을 **text 섹션**이라 부름\n\n💡 `.text`: 컴파일러가 만든 기계어가 위치하는 섹션. 컴파일러가 생성한 바이너리 파일을 역어셈블하면 어셈블리어가 나오는데, 그 어셈블리어가 바로 .text 섹션의 기계어를 어셈블리어로 바꾼 출력 결과\n\n- `.code 32`: 명령어 크기가 32비트\n- `.global`: C언어의 `.extern`과 같이 외부 파일에서 읽을 수 있도록 함\n- `vector_start`: 레이블 선언\n- `MOV R0, R1`: 레지스터 R1의 값을 R0에 넣음 (R0, R1은 레지스터 이름)\n- `vector_end`: 레이블 선언\n- `.space 1024, 0`: 해당 위치부터 1024바이트를 0으로 채움\n\n- 위 코드의 의미:\n  - 메모리 주소 0x00000000에는 `MOV R0, R1`\n  - 0x00000004부터 0x00000400까지는 0으로 채움\n\n- 이 코드를 확인하기 위해 `Entry.S`를 어셈블러로 컴파일 후 확인\n\n### `Entry.S`를 컴파일 후 확인\n\n```bash\n$ arm-none-eabi-as -march=armv7-a -mcpu=cortex-a8 -o Entry.o ./Entry.S\n$ arm-none-eabi-objcopy -O binary Entry.o Entry.bin\n$ hexdump Entry.bin\n```\n\n![컴파일 결과 이미지](/assets/img/OS/os202.png)\n\n- 1번째 줄: 어셈블리어 소스 파일을 컴파일하는 명령어\n  - GCC 크로스 컴파일러 설치 시 함께 설치된 ARM용 어셈블러 사용\n  - 컴파일 성공 시 `Entry.o`라는 파일 생성\n- 2번째 줄: `Entry.o`에서 바이너리만 추출하여 `Entry.bin`에 저장\n- 3번째 줄: `Entry.bin` 내용을 `hexdump` 명령어로 확인\n  - `0001 e1a0`: 기계어로 `MOV R0, R1` 의미\n  - 예측한 대로 0x00000400까지 0으로 채워짐 확인\n\n## 실행 파일 만들기\n***\n- QEMU가 펌웨어 파일을 읽어 부팅하려면 **ELF 파일 형식**이어야 함\n  - ELF 파일을 만들기 위해 링커(Linker)의 도움이 필요\n  - 링커: 여러 오브젝트 파일을 묶어 하나의 실행 파일로 만드는 프로그램\n  - 링커가 동작하려면 링커에 정보를 제공하는 **링커 스크립트** 필요\n\n### 링커 스크립트 `navilos.ld`\n\n```bash\n$ vi navilos.ld\n```\n\n```bash\nENTRY(vector_start)\nSECTIONS\n{\n  . = 0x0;\n\n  .text :\n  {\n    *(vector_start)\n    *(.text .rodata)\n  }\n  .data :\n  {\n    *(.data)\n  }\n  .bss :\n  {\n    *(.bss)\n  }\n}\n```\n\n- 1번째 줄: `ENTRY` 지시어로 시작 위치의 심벌 지정\n- 2번째 줄: `SECTIONS` 지시어로 3~20번째 줄까지의 블록이 섹션 배치 설정 정보 가짐\n- 4번째 줄: `. = 0x0;` - 첫 번째 섹션이 메모리 주소 0x00000000에 위치하도록 지정\n- 이후 `.text`, `.data`, `.bss` 섹션은 연속된 메모리에 배치되도록 설정\n  - `.text` 섹션에는 리셋 벡터가 위치해야 하므로 `vector_start` 심벌이 먼저 나옴\n\n### 링커로 실행 파일 만들기\n\n```bash\n$ arm-none-eabi-ld -n -T ./navilos.ld -nostdlib -o navilos.axf Entry.o\n$ arm-none-eabi-objdump -D navilos.axf\n```\n\n![링커 결과 이미지](/assets/img/OS/os203.png)\n\n- 1번째 명령어로 실행 파일 생성\n  - `-n`: 링커에 섹션의 정렬을 자동으로 맞추지 않도록 지시\n  - `-T`: 링커 스크립트 파일명 지정\n  - `-nostdlib`: 표준 라이브러리를 링킹하지 않도록 설정\n- 동작 완료 후 `navilos.axf` 파일 생성\n- 2번째 명령어: 이 파일을 디스어셈블하여 내부를 출력\n\n## QEMU에서 실행해 보기\n***\n- 실행 파일 생성 성공, 하지만 현재 파일은 실행되지 않음\n\n![실행 불가 이미지 1](/assets/img/OS/os204.png)\n![실행 불가 이미지 2](/assets/img/OS/os205.png)\n\n- ELF 파일 형식으로 만든 실행 파일이 맞지만, 리눅스 커널에서 동작하지 않는 섹션 배치로 만들어짐\n- 실행을 위해 ARM 개발 보드에 다운로드해 동작을 확인하거나 QEMU로 실행 가능\n\n### QEMU로 실행해 보기\n\n```bash\n$ qemu-system-arm -M realview-pb-a8 -kernel navilos.axf -S -gdb tcp::1234,ipv4\n```\n\n![QEMU 실행 이미지 1](/assets/img/OS/os206.png)\n![QEMU 실행 이미지 2](/assets/img/OS/os207.png)\n\n- `-S`: QEMU가 동작하자마자 일시정지시키는 옵션\n- `gdb tcp::1234,ipv4` 옵션으로 gdb와 연결\n  - QEMU로 실행했을 때 화면에 아무것도 출력되지 않아 확인을 위해 사용\n- 이제 gdb를 이용해 QEMU와 연결하여 디버깅 진행\n\n💡 기존 터미널을 유지한 채, 새로운 터미널을 실행하여 진행. 경로에 주의.\n\n### gdb와 QEMU 연결하기\n***\n\n```bash\n# gdb 설치 후 QEMU와 연결\n$ sudo apt install gdb-multiarch\n$ gdb-multiarch navilos.axf\n```\n\n![gdb 실행 이미지](/assets/img/OS/os208.png)\n\n- `target remote:1234`로 QEMU와 연결 후, `x/4b 0` 명령어로 0x00000000 메모리 주소에서 4바이트 출력\n  - 이전 `MOV R0, R1` 결과와 일치 (`0xE1A00001`)\n  - 코드 데이터가 QEMU 메모리에 제대로 다운로드됨을 확인\n\n> 💡 펌웨어와 RTOS 개발의 핵심은 코드를 작성하고 빌드, 디버깅하는 과정을 반복하는 것임 \n{: .prompt-tip }\n\n![navilos.ld 파일 경로 수정 이미지](/assets/img/OS/os209.png)\n\n## 빌드 자동화하기\n***\n- `navilos.axf` 실행 파일을 얻기 위해 매번 컴파일 및 링킹을 수동으로 하기에는 비효율적임\n- **Makefile**을 이용해 빌드 자동화 수행\n\n### Makefile 예시\n\n```bash\nARCH = armv7-a\nMCPU = cortex-a8\n\nCC = arm-none-eabi-gcc\nAS = arm-none-eabi-as\nLD = arm-none-eabi-ld\nOC = arm-none-eabi-objcopy\n\nLINKER_SCRIPT = ./navilos.ld\n\nASM_SRCS = $(wildcard boot/*.S)\nASM_OBJS = $(patsubst boot/%.S, build/%.o, $(ASM_SRCS))\n\nnavilos = build/navilos.axf\n...\n\n.PHONY: all clean run debug gdb\n\nall: $(navilos)\n\nclean:\n\t@rm -fr build\n\nrun: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos)\n\ndebug: $(navilos)\n\tqemu-system-arm -M realview-pb-a8 -kernel $(navilos) -S -gdb tcp::1234,ipv4\n```\n\n- 1~2번째 줄: RealViewPB의 아키텍처와 CPU 정보\n- 4~7번째 줄: 크로스 컴파일러 실행 파일 정의 (툴 체인)\n\n- `make` 명령어로 빌드 자동화 실행\n\n```bash\n$ make all\n```\n\n![make 실행 이미지](/assets/img/OS/os210.png)\n\n> 💡 `build` 폴더에 오브젝트 파일, 바이너리 파일, 실행 파일이 생성됨 \n{: .prompt-tip }\n\n```bash\n$ make debug\n```\n\n![QEMU 디버그 실행 이미지](/assets/img/OS/os211.png)\n\n> 💡 QEMU가 실행됨 \n{: .prompt-tip }\n\n\n- 현재까지의 코드 트리\n\n![코드 트리 이미지](/assets/img/OS/os212.png)\n\n## 하드웨어 정보 읽어오기 - 데이터시트를 읽는 방법\n***\n- 소프트웨어는 결국 하드웨어와 상호작용하는 것이 목적\n  - 펌웨어는 하드웨어와 밀접하게 연동됨\n  - 하드웨어와의 상호작용: 정보를 읽고 쓰는 작업 (레지스터 사용)\n\n### 레지스터: 하드웨어와 소프트웨어 간 인터페이스\n- 하드웨어의 레지스터 사용법은 데이터시트에 설명되어 있음\n- 하드웨어에서 정보를 읽어오는 간단한 작업 수행\n\n### Entry.S 코드 수정\n\n```bash\n.text\n  .code 32\n\n  .global vector_start\n  .global vector_end\n\n  vector_start:\n    LDR R0, =0x10000000\n    LDR R1, [R0]\n  vector_end:\n    .space 1024, 0\n.end\n```\n\n- 8번째 줄: R0에 0x10000000 저장\n- 9번째 줄: R0에 저장된 메모리 주소에서 값을 읽어 R1에 저장\n- 메모리 주소 0x10000000의 값은 RealViewPB의 데이터시트를 통해 확인\n\n![데이터시트 이미지 1](/assets/img/OS/os213.png)\n![데이터시트 이미지 2](/assets/img/OS/os214.png)\n\n- 0x10000000은 ID 레지스터로, 하드웨어 식별 정보를 가짐 (SYS_ID)\n- SYS_ID는 32비트를 5개의 필드로 나누어 사용\n  - **REV**: 보드 버전\n  - **HBI**: 보드 번호 (기본값 0x178)\n  - **BUILD**: 빌드 변형\n  - **ARCH**: 버스 아키텍처 (기본값 0x5)\n  - **FPGA**: FPGA 빌드\n\n> 데이터시트는 보통 설명만 제공하며, 예제는 없음 \n{:.prompt-tip}\n\n- 펌웨어 동작 확인: HBI와 ARCH의 기본값 (0x178, 0x5) 확인\n\n```bash\n$ make\n$ make debug\n```\n\n![QEMU 실행 이미지](/assets/img/OS/os215.png)\n\n```bash\n$ make gdb\n```\n\n![gdb 실행 이미지](/assets/img/OS/os216.png)\n\n### [Error] `make gdb` 실행 오류 해결 방법 1\n이 블로그를 참고해 수행했습니다.[https://goobgood.tistory.com/31](https://goobgood.tistory.com/31)<br>\n\n1. GNU Tool Chain 설치 필요\n   - [GNU Tool Chain 다운로드 링크](https://developer.arm.com/tools-and-software/open-source-software/developer-tools/gnu-toolchain/gnu-rm/downloads)\n2. 기존 패키지 삭제\n\n```bash\n$ sudo apt remove gcc-arm-none-eabi\n```\n\n3. 다운로드 받은 패키지 압축 해제 후 심볼릭 링크 생성\n\n```bash\n$ sudo tar xjf gcc-arm-none-eabi-10.3-2021.10-x86_64-linux.tar.bz2 -C /usr/share\n$ sudo ln -s /usr/share/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-gcc /usr/bin/arm-none-eabi-gcc \n$ sudo ln -s /usr/share/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-g++ /usr/bin/arm-none-eabi-g++\n$ sudo ln -s /usr/share/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-gdb /usr/bin/arm-none-eabi-gdb\n$ sudo ln -s /usr/share/gcc-arm-none-eabi-10.3-2021.10/bin/arm-none-eabi-size /usr/bin/arm-none-eabi-size\n```\n\n4. 의존성 패키지 설치 (필요 시)\n\n![의존성 설치 이미지](/assets/img/OS/os217.png)\n\n위와 같은 출력이 발생할 경우 의존성 패키지를 설치해야 합니다.\n\n```bash\n$ sudo apt install libncurses5\n```\n\n### [Error] `make gdb` 실행 오류 해결 방법 2\n\n아래 깃허브 커밋을 참고합니다.\n\n[https://github.com/navilera/Navilos/commit/145fb5b9fef4cf0d5bb6d8957a0090a2316938cf](https://github.com/navilera/Navilos/commit/145fb5b9fef4cf0d5bb6d8957a0090a2316938cf)\n\n```bash\n...\ngdb:\n    arm-none-eabi-gdb // 삭제\n    gdb-multiarch $(navilos) // 추가\n...\n```\n\n- Makefile에서 gdb를 `gdb-multiarch`로 수정\n\n\n### QEMU 연결 후 확인\n```bash\n$ make gdb\n(gdb) target remote:1234\n(gdb) file build/navilos.axf\n```\n- `target` 명령으로 QEMU 디버깅 소켓 연결 후, `file` 명령으로 `navilos.axf` 읽기\n- `list` 명령으로 디버깅 심벌 확인\n\n![디버깅 심벌 확인 이미지](/assets/img/OS/os219.png)\n\n- QEMU는 아직 실행 파일을 실행하지 않은 상태\n- `info register` 명령으로 레지스터 값 확인 (모두 0)\n\n```bash\n(gdb) s\n(gdb) info register\n```\n\n![레지스터 값 확인 이미지 1](/assets/img/OS/os220.png)\n\n- 첫 번째 명령 실행 후, R0에 0x10000000 저장 확인\n- 다음 줄 실행 시, 메모리 주소 0x10000000에서 값을 읽어 R1에 저장하고 0x178 포함 여부 확인\n\n```bash\n(gdb) s\n(gdb) i r\n```\n\n![레지스터 값 확인 이미지 2](/assets/img/OS/os221.png)\n\n- R1에 0x178과 0x5 포함 확인 (HBI와 ARCH 항목)\n- 펌웨어와 QEMU가 올바르게 동작함을 확인\n\n## 요약\n***\n- 소스 코드 작성 및 컴파일, 하드웨어에서의 실행 확인\n- 레지스터 접근 및 gdb 사용을 통해 하드웨어 동작 확인\n- 이제 준비가 완료되었으므로, 다음 장부터 프로젝트 시작\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n",
    "date": "2024-11-04",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-04-3_chunk_0",
        "text": "[RTOS개발] 3장 일단 시작하기\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n\n본 페이지에선 직접 코드를 작성해 펌웨어를 실행시켜보는 것에 대해 다룹니다.\n\n## 서론\n***\n이 장의 소스 코드는 아래 명령어를 통해 다운로드할 수 있습니다.\n\n```bash\n$ wget https://github.com/navilera/Navilos/archive/95f2b8d.zip # 1절\n$ wget https://github.com/navilera/Navilos/archive/d99603c.zip # 3절\n$ wget https://github.com/navilera/Navilos/archive/be7a34c.zip # 4절\n$ wget https://github.com/navilera/Navilos/archive/0ea7fe7.zip # 5절\n```\n## 리셋 벡터\n***\n- ARM 코어에 전원이 들어가면 가장 먼저 하는 일은 리셋 벡터에 있는 명령을 실행하는 것\n  - **리셋 벡터 = 메모리 주소 0x00000000**\n  - 전원이 들어오면 가장 먼저 메모리 주소 0x00000000에서 32비트를 읽어서 명령을 바로 실행\n\n- 우리가 해야 할 일: 메모리 주소 0x00000000에 명령어 넣기\n  - boot라는 이름의 디렉토리를 만들고, `Entry.S`라는 코드 작성\n\n```bash\n$ mkdir boot && c",
        "index": 0
      },
      {
        "id": "2024-11-04-3_chunk_1",
        "text": "일: 메모리 주소 0x00000000에 명령어 넣기\n  - boot라는 이름의 디렉토리를 만들고, `Entry.S`라는 코드 작성\n\n```bash\n$ mkdir boot && cd boot\n$ vi Entry.S\n```\n\n### `Entry.S`\n\n```bash\n.text\n  .code 32\n\n  .global vector_start\n  .global vector_end\n\n  vector_start:\n    LDR R0, =0x10000000\n    LDR R1, [R0]\n  vector_end:\n    .space 1024, 0\n.end\n```\n\n![코드 예시 이미지](/assets/img/OS/os201.png)\n\n- 코드의 처음과 끝에 있는 `.text`와 `.end`는 그 사이에 있는 코드가 text 섹션임을 의미\n- 실행 파일: 소프트웨어를 구성하는 요소를 파일 시스템에 바이너리로 만든 것\n  - 소프트웨어는 **데이터**와 그 데이터를 변경하는 **코드**로 구성\n  - 선언하는 변수 = 데이터, 변수의 값을 변경하는 로직 = 코드\n  - 코드를 바이너리로 변경해 모아 놓은 것을 **text 섹션**이라 부름\n\n💡 `.text`: 컴파일러가 만든 기계어가 위치하는 섹션.",
        "index": 1
      },
      {
        "id": "2024-11-04-3_chunk_2",
        "text": "변수의 값을 변경하는 로직 = 코드\n  - 코드를 바이너리로 변경해 모아 놓은 것을 **text 섹션**이라 부름\n\n💡 `.text`: 컴파일러가 만든 기계어가 위치하는 섹션.",
        "index": 2
      },
      {
        "id": "2024-11-04-3_chunk_3",
        "text": "변수의 값을 변경하는 로직 = 코드\n  - 코드를 바이너리로 변경해 모아 놓은 것을 **text 섹션**이라 부름\n\n💡 `.text`: 컴파일러가 만든 기계어가 위치하는 섹션.",
        "index": 3
      },
      {
        "id": "2024-11-04-3_chunk_4",
        "text": "변수의 값을 변경하는 로직 = 코드\n  - 코드를 바이너리로 변경해 모아 놓은 것을 **text 섹션**이라 부름\n\n💡 `.text`: 컴파일러가 만든 기계어가 위치하는 섹션.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-03-1",
    "title": "[RTOS개발] 1장 임베디드 운영체제",
    "path": "/2024/11/03/1장-임베디드-운영체제/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n# 🖥️ OS와 임베디드 OS 소개\n\n이 페이지에서는 운영체제(OS)와 임베디드 OS를 소개하고, 프로젝트의 개발 방향과 목표를 설명합니다.\n## ✨ 서론\n***\n임베디드 운영체제는 하드웨어에 내장된 형태의 운영체제로, 필요한 기능만 구현하여 시스템에 최적화된 효율적인 운영체제를 목표로 합니다.\n## 🖥️ 운영체제 (OS)\n***\n운영체제(OS)는 하드웨어를 관리하고, 응용 프로그램과 하드웨어 사이의 인터페이스 역할을 수행하는 시스템 소프트웨어입니다. 주요 기능은 다음과 같습니다:\n\n### 1️⃣ 프로세스 관리\n- 응용 프로그램의 실행을 관리하고 CPU 자원을 효율적으로 분배합니다.\n\n### 2️⃣ 저장장치 관리\n- 메인 메모리와 SSD/HDD 같은 저장장치를 관리하며, 메모리 할당, 해제, 가상 메모리 기능을 제공합니다.\n- 파일 시스템을 통해 데이터를 관리하고 파일 교환을 지원합니다.\n\n### 3️⃣ 네트워킹 관리\n- 네트워크 프로토콜에 따라 데이터를 처리하고 송수신합니다.\n\n### 4️⃣ 사용자 관리\n- 여러 사용자가 컴퓨터를 사용할 수 있도록 각 계정을 관리합니다.\n\n### 5️⃣ 디바이스 드라이버\n- 다양한 하드웨어를 인식하고 사용할 수 있도록 관리하며, 디바이스 드라이버를 통해 하드웨어와 소통합니다.\n\n> 운영체제를 잘 만드는 것은 어렵지만, 이론을 충실히 구현한다면 기본적인 운영체제를 누구나 만들 수 있습니다.\n\n## 🤖 임베디드 운영체제와 펌웨어\n***\n임베디드 장치도 소프트웨어가 필요하며, 자원과 복잡도 관리를 위해 운영체제를 사용하는 것이 일반적입니다. 최근 하드웨어 성능의 발전으로 임베디드 운영체제 사용에 따른 성능 저하 문제는 크게 줄었습니다.\n\n임베디드 운영체제는 펌웨어의 일종이며, 임베디드 시스템 전체 소프트웨어를 펌웨어라고 부릅니다.\n\n## ⏱️ RTOS (실시간 운영체제)\n***\nRTOS(Real Time Operating System)는 실시간 응답이 필요한 임베디드 운영체제입니다. 이 책에서는 RTOS를 개발하며, 임베디드 운영체제를 RTOS로 정의하여 설명합니다.\n\n## 🌟 나빌로스 (Navilos)\n***\n이 책에서는 \"나빌로스\"라는 임베디드 운영체제를 개발합니다. 과정은 일반적인 펌웨어 개발과 최소한의 임베디드 운영체제를 설계하고 구현하는 두 가지로 나뉩니다.\n\n## 🛠️ 에뮬레이터 개발 환경\n***\n임베디드 소프트웨어를 개발하기 위해 대상 하드웨어가 필요하지만, 이 책에서는 QEMU 에뮬레이터를 사용해 개발을 진행합니다. QEMU에서 프로젝트를 완료한 후 실제 하드웨어를 구입해도 됩니다.\n\n## 📥 깃허브 리포지토리에서 아카이브 다운로드\n***\n나빌로스 소스 코드는 GitHub에서 제공되며, 특정 버전의 소스를 다운로드하려면 커밋 아이디를 사용합니다.\n\n[🔗 GitHub 링크](https://github.com/navilera/Navilos)\n\n예를 들어, \"Chapter 3.1\"에 해당하는 소스 코드를 다운로드하려면 아래 명령어를 사용하세요.\n\n```bash\n# 해당 커밋 아이디 = 95f2b8d\nwget https://github.com/navilera/Navilos/archive/95f2b8d.zip\n```\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n",
    "date": "2024-11-03",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-03-1_chunk_0",
        "text": "[RTOS개발] 1장 임베디드 운영체제\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n# 🖥️ OS와 임베디드 OS 소개\n\n이 페이지에서는 운영체제(OS)와 임베디드 OS를 소개하고, 프로젝트의 개발 방향과 목표를 설명합니다.\n## ✨ 서론\n***\n임베디드 운영체제는 하드웨어에 내장된 형태의 운영체제로, 필요한 기능만 구현하여 시스템에 최적화된 효율적인 운영체제를 목표로 합니다.\n## 🖥️ 운영체제 (OS)\n***\n운영체제(OS)는 하드웨어를 관리하고, 응용 프로그램과 하드웨어 사이의 인터페이스 역할을 수행하는 시스템 소프트웨어입니다.",
        "index": 0
      },
      {
        "id": "2024-11-03-1_chunk_1",
        "text": "를 목표로 합니다.\n## 🖥️ 운영체제 (OS)\n***\n운영체제(OS)는 하드웨어를 관리하고, 응용 프로그램과 하드웨어 사이의 인터페이스 역할을 수행하는 시스템 소프트웨어입니다. 주요 기능은 다음과 같습니다:\n\n### 1️⃣ 프로세스 관리\n- 응용 프로그램의 실행을 관리하고 CPU 자원을 효율적으로 분배합니다.\n\n### 2️⃣ 저장장치 관리\n- 메인 메모리와 SSD/HDD 같은 저장장치를 관리하며, 메모리 할당, 해제, 가상 메모리 기능을 제공합니다.\n- 파일 시스템을 통해 데이터를 관리하고 파일 교환을 지원합니다.\n\n### 3️⃣ 네트워킹 관리\n- 네트워크 프로토콜에 따라 데이터를 처리하고 송수신합니다.\n\n### 4️⃣ 사용자 관리\n- 여러 사용자가 컴퓨터를 사용할 수 있도록 각 계정을 관리합니다.\n\n### 5️⃣ 디바이스 드라이버\n- 다양한 하드웨어를 인식하고 사용할 수 있도록 관리하며, 디바이스 드라이버를 통해 하드웨어와 소통합니다.\n\n> 운영체제를 잘 만드는 것은 어렵지만, 이론을 충실히 구현한다면 기본적인 운영체제를 누구나 만들 수 있습니다.\n\n## 🤖 임베디드 운영체제와 펌웨어\n***\n임베디드 장치도 소프트웨어가 필요하며, 자원과 복잡도 관리를 위해 운영체제를 사용하는 것이 일반적입니다.",
        "index": 1
      },
      {
        "id": "2024-11-03-1_chunk_2",
        "text": "누구나 만들 수 있습니다.\n\n## 🤖 임베디드 운영체제와 펌웨어\n***\n임베디드 장치도 소프트웨어가 필요하며, 자원과 복잡도 관리를 위해 운영체제를 사용하는 것이 일반적입니다. 최근 하드웨어 성능의 발전으로 임베디드 운영체제 사용에 따른 성능 저하 문제는 크게 줄었습니다.\n\n임베디드 운영체제는 펌웨어의 일종이며, 임베디드 시스템 전체 소프트웨어를 펌웨어라고 부릅니다.\n\n## ⏱️ RTOS (실시간 운영체제)\n***\nRTOS(Real Time Operating System)는 실시간 응답이 필요한 임베디드 운영체제입니다. 이 책에서는 RTOS를 개발하며, 임베디드 운영체제를 RTOS로 정의하여 설명합니다.\n\n## 🌟 나빌로스 (Navilos)\n***\n이 책에서는 \"나빌로스\"라는 임베디드 운영체제를 개발합니다. 과정은 일반적인 펌웨어 개발과 최소한의 임베디드 운영체제를 설계하고 구현하는 두 가지로 나뉩니다.\n\n## 🛠️ 에뮬레이터 개발 환경\n***\n임베디드 소프트웨어를 개발하기 위해 대상 하드웨어가 필요하지만, 이 책에서는 QEMU 에뮬레이터를 사용해 개발을 진행합니다.",
        "index": 2
      },
      {
        "id": "2024-11-03-1_chunk_3",
        "text": "나뉩니다.\n\n## 🛠️ 에뮬레이터 개발 환경\n***\n임베디드 소프트웨어를 개발하기 위해 대상 하드웨어가 필요하지만, 이 책에서는 QEMU 에뮬레이터를 사용해 개발을 진행합니다. QEMU에서 프로젝트를 완료한 후 실제 하드웨어를 구입해도 됩니다.\n\n## 📥 깃허브 리포지토리에서 아카이브 다운로드\n***\n나빌로스 소스 코드는 GitHub에서 제공되며, 특정 버전의 소스를 다운로드하려면 커밋 아이디를 사용합니다.\n\n[🔗 GitHub 링크](https://github.com/navilera/Navilos)\n\n예를 들어, \"Chapter 3.1\"에 해당하는 소스 코드를 다운로드하려면 아래 명령어를 사용하세요.\n\n```bash\n# 해당 커밋 아이디 = 95f2b8d\nwget https://github.com/navilera/Navilos/archive/95f2b8d.zip\n```\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 3
      },
      {
        "id": "2024-11-03-1_chunk_4",
        "text": "m/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-0-------OS",
    "title": "[RTOS개발] 0장-임베디드 OS 개발 프로젝트 시작하기",
    "path": "/2024/11/02/0장-임베디드-OS-개발-프로젝트-시작하기/",
    "categories": [
      "Embedded System",
      "임베디드 OS 개발 프로젝트",
      "Embedded/RTOS"
    ],
    "content": "![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n본 프로젝트에서는 ARM 기반 펌웨어(RTOS)를 개발하며, 그 과정에서 필요한 ARM 내용을 부록에서 다룹니다.\n\n이 프로젝트를 통해 얻을 수 있는 내용은 아래와 같습니다.\n1. 임베디드 소프트웨어 개발에 대한 기본적인 환경 설정\n2. 디버깅 및 실행\n3. 테스트\n4. ARM 프로세서와 타깃 SoC 하드웨어\n5. 운영체제에 대한 전반적인 지식\n\n\n총 1장부터 14장으로, QEMU 에뮬레이터를 활용해 진행합니다.\n\n> 프로젝트 후기\n> \n> 힘들지만 재미있었습니다.\n> 시작하기 전에 비해 OS에 대한 이해도가 크게 늘었고, 이 덕에 리눅스 공부에 크게 도움이 되었습니다. \n>\n> 임베디드 분야에 관심이 있는 분이라면, 정말 추천드리는 책입니다.\n{: .prompt-tip }\n\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n",
    "date": "2024-11-02",
    "tags": [
      "Embedded System",
      "RTOS",
      "Firmware",
      "OS"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-0-------OS_chunk_0",
        "text": "[RTOS개발] 0장-임베디드 OS 개발 프로젝트 시작하기\n\n![image.png](/assets/img/OS/OS000.jpg){: .w-25}\n<br>\n\n**본 프로젝트는 이만우 저자님의 \"임베디드 OS 개발 프로젝트\" 교재를 따라 RTOS를 만드는 것을 목표로 합니다.**\n\n<br>\n\n***\n본 프로젝트에서는 ARM 기반 펌웨어(RTOS)를 개발하며, 그 과정에서 필요한 ARM 내용을 부록에서 다룹니다.\n\n이 프로젝트를 통해 얻을 수 있는 내용은 아래와 같습니다.\n1. 임베디드 소프트웨어 개발에 대한 기본적인 환경 설정\n2. 디버깅 및 실행\n3. 테스트\n4. ARM 프로세서와 타깃 SoC 하드웨어\n5. 운영체제에 대한 전반적인 지식\n\n\n총 1장부터 14장으로, QEMU 에뮬레이터를 활용해 진행합니다.\n\n> 프로젝트 후기\n> \n> 힘들지만 재미있었습니다.\n> 시작하기 전에 비해 OS에 대한 이해도가 크게 늘었고, 이 덕에 리눅스 공부에 크게 도움이 되었습니다. \n>\n> 임베디드 분야에 관심이 있는 분이라면, 정말 추천드리는 책입니다.\n{: .prompt-tip }\n\n\n\n## 참고\n***\n\n참고 깃허브 : [https://github.com/navilera/Navilos](https://github.com/navilera/Navilos)\n\n이만우 저자님의 블로그 주소 : [https://kldp.org/node/162560](https://kldp.org/node/162560)\n",
        "index": 0
      }
    ]
  },
  {
    "id": "2024-11-02-PV-Mount---HyperParameter-Tuning",
    "title": "PV Mount & HyperParameter Tuning",
    "path": "/2024/11/02/PV-Mount-&-HyperParameter-Tuning/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 문서는 파이프라인을 PV에 마운트하는 것과 YOLOv8에서 기본으로 제공하는 raytune을 이용해 하이퍼파라미터 튜닝을 하는 것에 대해 다룹니다.<br>\n\n[https://happycloud-lee.tistory.com/256](https://happycloud-lee.tistory.com/256) ← PV/PVC 참고<br>\n\n[https://docs.ultralytics.com/integrations/ray-tune/?h=hyper](https://docs.ultralytics.com/integrations/ray-tune/?h=hyper) ← HP Tuning 공식문서<br>\n\n# PV / PVC\n\n---\n\n## k8s 환경에서의 볼륨\n\n### 외부 볼륨의 필요성\n\n쿠버네티스 환경에서는 모든 어플리케이션이 Pod안에 컨테이너로 실행됩니다.\n\n보통 **컨테이너**에서 데이터를 읽고 저장할 때는 자신의 내부 볼륨이 아닌 **외부 볼륨**을 사용합니다.\n\n→ 컨테이너는 언제든 사라질 수 있기에, 데이터를 잃는 상황을 막기 위해!\n\n### 사용 목적별 볼륨 유형\n\nPod안에 컨테이너화되어 실행되는 것은 크게 **어플리케이션**과 **데이터베이스**입니다.\n\n볼륨을 크게 나누면 Pod 로컬 볼륨, Node 로컬 볼륨, 네트워크 볼륨이 있습니다.(공식적인건 아님)\n\n볼륨 유형을 정리하면 아래와 같습니다.\n\n| 구분         | 사용 목적                            | 파드 삭제시 볼륨 폐기 | 볼륨 유형      |\n| ------------ | ------------------------------------ | --------------------- | -------------- |\n| 어플리케이션 | 어떤 처리를 위한 임시 공간           | **Y**                 | 파드 로컬 볼륨 |\n|              | 컨피그맵, 시크릿, 파드 정보 참조     | **Y**                 | 파드 로컬 볼륨 |\n|              | 파드가 실행된 노드의 파일 접근       | N                     | 노드 로컬 볼륨 |\n|              | 특정 노드의 파일 접근                | N                     | 노드 로컬 볼륨 |\n|              | 클러스터 외부 스토리지의 파일 접근   | N                     | 네트워크 볼륨  |\n| 데이터베이스 | 컨피그맵, 시크릿, 파드 정보 참조     | **Y**                 | 파드 로컬 볼륨 |\n|              | 파드가 실행된 노드에만 데이터 저장   | N                     | 노드 로컬 볼륨 |\n|              | 특정 노드에만 데이터 저장            | N                     | 노드 로컬 볼륨 |\n|              | 클러스터 외부 스토리지에 데이터 저장 | N                     | 노드 로컬 볼륨 |\n\n### Pod의 볼륨 접근 아키텍처와 PV 라이프 사이클\n\n![https://happycloud-lee.tistory.com/256](/assets/img/kubeflow/kubeyolo101.png)\n\nhttps://happycloud-lee.tistory.com/256\n\nPod가 볼륨을 사용하는 방법은 ‘**마운트**’ 입니다.\n\nPod내에 볼륨을 ‘마운트’ 함으로써 어떤 유형의 볼륨이든 Pod의 내부 파일 시스템처럼 사용할 수 있습니다.\n\n하지만, 이 아키텍처는 쿠버네티스와 인프라스트럭처가 너무 강한 결합(**Tightly Coupled**)되어버립니다.\n\n이로 인해 스토리지 제품의 변화나 스토리지 서버의 변화가 Pod에 직접적인 영향을 미칩니다.\n\n- **예시**\n    \n    `nfs` 라는 네트워크 볼륨을 Pod에 마운트하려면 `nfs` 서버의 IP나 호스트를 지정해야 하는데, `nfs` 서버의 IP가 변경되면 서비스에 문제가 발생할 수 있습니다.\n    \n\n이를 해결하기 위해 쿠버네티스와 인프라스트럭처를 느슨하게 결합(**Loosly Coupled**)시키면 됩니다.\n\n이를 위해 중간에 중계자 역할을 하는 **PV/PVC** 를 만들게 됩니다.\n\n\n> 네트워크 볼륨을 위해 CSIContainer Storage Interface라는 중계자 역할도 있습니다.\n> 하지만, 딥러닝 학습 시 네트워크 볼륨을 사용하게 된다면 학습이 느려진다는 단점이 있어 로컬 볼륨을 사용하기에 CSI에 대해서는 다루지 않겠습니다.\n{: .prompt-tip }\n\n![https://happycloud-lee.tistory.com/256](/assets/img/kubeflow/kubeyolo102.png)\nhttps://happycloud-lee.tistory.com/256\n\n1. Pod정보, Config-map, Secret은 파드 명세에 정의하여 마운트합니다.\n\n2. 노드 로컬 볼륨과 네트워크 볼륨은 PV리소스로 정의하고 PVC에 바운드(연결)합니다.\n    파드 명세에서는 PVC만 지정하면 연결된 볼륨이 마운트 됩니다.\n\n3. 스토리지 제품별로 PV을 정의하여 볼륨을 접근할 수 있습니다.<br>\n\n이렇게 되면 PV를 정의하고, PVC에 연결한 후 Pod에 PVC만 지정해주면 됩니다.\n\n## 파이프라인 볼륨\n\n파이프라인은 1개 이상의 컴포넌트로 이루어져 있습니다. 각각의 컴포넌트는 Pod로 구성되어 파이프라인을 통해 실행됩니다. \n즉, 각각의 컴포넌트는 서로 다른 로컬 볼륨을 사용하므로 다른 컴포넌트의 데이터를 읽거나 쓰는 등의 작업이 불가합니다.<br>\n\n이를 위해, PV를 만들고, 각각의 컴포넌트(혹은 Pod)에서 PVC를 통해 볼륨을 마운트 하겠습니다.<br>\n\n\n> PV를 생성하고 PVC를 통해 Pod에 연결하는 방법은 다양한 것 같지만, 본 페이지에서는 다른 방법을 잘 모르기에, yaml파일을 통해 Persistent Volume을 생성하고, PVC로 PV를 연결한 후, Pod에서 PVC를 지정하는 방법으로 하겠습니다.\n{: .prompt-tip }\n\n### PV 생성\n\n- `pv.yaml` 를 통해 PV 정의\n\n```yaml\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pv-test\nspec:\n  capacity:\n    storage: 5Gi\n  volumeMode: Filesystem\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: 'knowgyu-pv-test'\n  hostPath:\n    path: \"/data/datasets/coco8\"\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - knowgyu\n```\n\n> `accessModes` 의 경우 Many와 Once가 있는데, Many로 설정하게 된다면 여러 개의 노드에서 동시에 사용할 수 있도록 지정하는 것입니다. 하지만, 현재 minikube를 이용해 단일 노드로 생성했기에, RWO모드로 지정합니다.\n\n\n> 변경해야 하는 값들 \n{: .prompt-info }\n\n- `name: pv-test`\n- `storage: 1Gi`\n- `storageClassName: 'knowgyu-pv-test'`\n- `path: \"/data/datasets/coco8\"`\n- `values : knowgyu`\n\n<br>\n\n- PV 생성\n\n```yaml\nkubectl apply -f pv.yaml\n# 정상적으로 생성되면 아래 메세지 출력\npersistentvolume/pv-test created\n```\n\n- 확인\n\n```bash\nkubectl get pv -A\n# 모든 PV가 표시됩니다. 그 중 생성한 pv를 확인합니다. 아직 마운트되지 않았기에 CLAIM은 비어있어야합니다.\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                                                         STORAGECLASS   REASON   AGE\npv-test                                    1Gi        RWO            Retain           Available                                                                 local-path              22s\n```\n\n### PVC 생성\n\n`pvc.yaml`을 작성하지 않아도, Kubeflow 대시보드의 **Volume**탭을 이용하거나, Pipeline 작성 시 `VolumeOp`를 통해 생성할 수 있습니다. 하지만, 본 페이지에선 동적 할당이 아닌 수동 할당을 위해 직접 명세를 작성해 PVC를 생성하겠습니다.\n\n- *~~+) 위 내용이 정확한 사실인지는 잘 모르겠습니다. 제가 공부하고 실험해 본 결과 그랬던 것 같습니다.~~*\n    \n    ![Untitled](/assets/img/kubeflow/kubeyolo109.png)\n\n    \n- `pvc.yaml`\n\n```yaml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc-test\n  namespace: knowgyu \nspec:\n  accessModes:\n  - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: \"scn-test\"\n```\n\n- PVC 생성\n\n```bash\nkubectl apply -f pvc.yaml\n# 정상적으로 생성되면 아래 메세지 출력\npersistentvolumeclaim/pvc-test created\n```\n\n- 확인\n\n```bash\nkubectl get pvc -A\n# 모든 PVC가 표시됩니다. 네임스페이스를 knowgyu로 지정해주었고, pv-test와 제대로 Bound 되었는지 확인합니다.\nNAMESPACE                   NAME                                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nknowgyu                     pvc-test                                        Bound    pv-test                                    5Gi        RWO            scn-test       100m\n```\n\n### PV/PVC 생성 확인\n\n제대로 지정되었는지 확인해보겠습니다.\n\n- PV 확인\n\n```bash\nkubectl get pv -A |grep pv-test\n```\n\n위 명령어를 통해 비어있던 CLAIM이 `knowgyu/pvc-test` 로 변경되었는지 확인합니다.\n\n```bash\npv-test                                    5Gi        RWO            Retain           Bound    knowgyu/pvc-test                                           scn-test                103m\n```\n\n또한, Kubeflow 대시보드를 통해 재차 확인할 수 있습니다.\n\n`knowgyu` 네임스페이스를 사용하는 사용자 계정으로 로그인 후 좌측의 Volume탭을 클릭합니다.\n\n![만약 위의 과정을 똑같이 따라했다면, Name은 pvc-test로 나와야합니다.](/assets/img/kubeflow/kubeyolo103.png)\n\n\n만약 위의 과정을 똑같이 따라했다면, Name은 pvc-test로 나와야합니다.\n\n### Pod → PV 마운트\n\nPV/PVC를 생성했으니, 이 볼륨을 사용할 Pod에 마운트를 시켜야 합니다.\n\n이를 위해 Pipeline 작성 시 각 컴포넌트에 PV를 마운트하겠습니다.\n\n- 파이프라인 작성 코드 스니펫\n\n```python\nfrom kfp import dsl\n\n@dsl.pipeline(name=\"pipeline_name\",\n          description=\"MLpipline Description\",\n          )\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n    ):\n    import os\n    \n    vop = dsl.VolumeOp(\n        name=\"create-pvc\",\n        resource_name=\"pvc-test\",\n        storage_class='scn-test',\n        modes=dsl.VOLUME_MODE_RWO,\n        size=\"5Gi\",\n        generate_unique_name=False,\n        action='apply',\n    )\n    \n    check = verify_training(model_name, epochs, imgsz, batchsize).add_pvolumes({\"/data\":vop.volume})\n    \n\t\ttrained = train(\n        check.output, model_name, epochs, imgsz, batchsize\n        ).add_pvolumes({\"/data\":vop.volume})\n```\n\n**`dsl.VolumeOp(...)`** : k8s PVC를 생성하는 파이프라인 태스크\n\n- 변경 사항\n\n```python\n    vop = dsl.VolumeOp(\n        name=\"create-pvc\",  <- Pipeline에서 표시될 이름인 것 같습니다.\n        resource_name=\"pvc-test\", <- 생성될 PVC 이름. 기존의 PVC를 사용하기에 똑같이 해야함\n        storage_class='scn-test', <- *동적으로 생성되는 PVC에 사용할 스토리지 클래스를 지정// 잘 모르는 기능*\n        modes=dsl.VOLUME_MODE_RWO, <- 모드. Single Node이므로 ReadWriteOnce\n        size=\"5Gi\",         <- 생성될 PVC 크기. 기존PVC 명세보다 크게는 가능하나 작게 지정할 시 에러가 발생합니다.\n        generate_unique_name=False, <- True시 pvc-test-1sfd.. 이런식으로 생성될 것 같습니다. 기존 생성한 PVC와 이름이 같아야하기에 False로 합니다.\n        action='apply', <- 깃 이슈에서 참고했는데, 추가해야 적용됐습니다.\n    )\n```\n\n```python\n    check = verify_training(..).add_pvolumes({\"/data\":vop.volume}) <- 해당 컴포넌트에 마운트\n    \n\t\ttrained = train(\n        ..\n        ).add_pvolumes({\"/data\":vop.volume}) <- 해당 컴포넌트에 마운트\n# 파드 로컬 볼륨인 /data에 vop.volume을 마운트함.\n# vop.volume은 PV.yaml에서 지정한 /data/dataset/coco8\n```\n\n## 정리\n\nYOLOv8의 경우 모델과 데이터셋이 없더라도, 기본적으로 `coco128` 데이터셋과 `yolov8n.pt` 모델을 다운로드해 학습을 실행합니다. 하지만, 커스텀 데이터셋을 학습시키기 위해선 파이프라인의 각 컴포넌트들이 실행될 때 내 클러스터 노드의 볼륨에 있는 데이터에 접근해 읽고, 아티팩트를 저장할 수 있어야합니다.\n\n이를 위해, `pv.yaml`을 통해 내 클러스터 노드의 경로를 지정해 Persistent Volume을 생성하였고, 각 컴포넌트에서 PV에 마운트하기위해 `pvc.yaml`을 생성했고, `dsl.VolumeOp` 에서 PVC를 생성할 수 있지만, 미리 생성한 PVC를 이용해 PV와 PVC를 바인딩하여 각 컴포넌트에서 내 클러스터 노드 로컬 볼륨에 접근할 수 있습니다.\n\n이를 통해 Kubeflow 대시보드의 Jupyter Notebook와 학습 파이프라인 모두 내 PV에 접근할 수 있습니다.\n\n그렇다면, 정말로 내 클러스터 노드의 로컬 볼륨에 제대로 마운트 되었는지 확인을 위해 **하이퍼 파라미터 튜닝** 기능을 추가하며 확인하겠습니다.\n\n# Hyperparameter Tuning(231215수정예정)\n\n---\n\n> 하이퍼 파라미터 튜닝은 최적의 하이퍼 파라미터 세트를 찾아 모델의 최대 성능을 이끌어내는데 필수적입니다.\nhttps://docs.ultralytics.com/integrations/ray-tune/?h=hyper\n> \n\n\n> **(23.12.14)** ray-tune 사용 시 train_args와 데이터셋 경로 설정 등 문제가 발생합니다.\n> ultralytics 패키지와 raytune Integration이 제대로 이뤄지지않아 생기는 버그같습니다.\n>\n> raytune이 아닌, ultralytics에서 제공하는 하이퍼파라미터 튜닝 기능을 사용하는 것으로 수정할 예정입니다.\n{: .prompt-warning}\n\n~~YOLOv8은 Ray Tune 패키지와 통합해 `model.tune` 으로 쉽게 하이퍼 파라미터 기능을 사용할 수 있습니다.~~\n\n~~예제)~~\n\n```python\nmodel = YOLO(\"yolov8n.pt\")\n\nresult_grid = model.tune(data='coco8.yaml', use_ray=True)\n```\n\n~~학습 컴포넌트를 거쳐 생성된 `knowgyu`를 불러와 하이퍼파라미터 튜닝을 하는 컴포넌트를 추가해보겠습니다.~~\n\n- ~~tune 컴포넌트~~\n\n```python\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.1\",\n    packages_to_install=[\"ultralytics\",\"ray[tune]\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n)\ndef tune(\n    model_path: str,\n    ):\n    from ultralytics import YOLO\n    from ray import tune\n    import os\n\n    os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n    \n    model = YOLO(model_path)\n    \n    result = model.tune(\n                data=\"coco8.yaml\",\n                space={\"lr0\": tune.uniform(1e-5, 1e-1)},\n                epochs=2,\n                grace_period=2,\n                gpu_per_trial=1,\n                iterations=1,\n                batch=4,\n                use_ray=True\n                )\n```\n\n~~기본적으로 학습 컴포넌트와 유사하게 작성되며 모델의 경로를 문자열로 받아 모델을 불러옵니다.~~ \n\n~~⚠️ 만약, 볼륨이 마운트 되어있지 않다면, 서로 다른 로컬 볼륨을 사용하므로 `No such file or directory` 에러가 발생할 것입니다.~~\n\n<aside>\n💡 ~~문자열로 받아오는게 아닌, `kfp.components.InputPath` `kfp.components.OutputPath` 를 통해 모델을 주고 받을 수 있습니다. 본 페이지에서는 다루지 않겠습니다.~~\n\n</aside>\n\n### 전체 코드\n\n```python\nfrom functools import partial\n\nimport kfp\nfrom kfp.components import create_component_from_func, InputPath, OutputPath\nfrom kfp import dsl\n\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.1\",\n)\ndef verify_training(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n    ) -> bool:\n    import torch\n\n    assert isinstance(model_name, str), \"model_name must be a string\"\n    assert isinstance(epochs, int), \"epochs must be an integer\"\n    assert isinstance(imgsz, int), \"imgsz must be an integer\"\n    assert isinstance(batchsize, int), \"batchsize must be an integer\"\n        \n    print(torch.cuda.is_available())\n    print(torch.cuda.get_device_name())\n    print(torch.cuda.device_count())\n    \n    return torch.cuda.is_available()\n    \n    \n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.1\",\n    packages_to_install=[\"ultralytics\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n)\ndef train(\n    checker: bool,\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n        ) -> str:\n    import os\n    from ultralytics import YOLO\n    import mlflow\n    \n    if not checker:\n        print(\"CUDA is not available.\\nPlease Check GPU Device\")\n        return None\n\n    os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n\n    model = YOLO(model_name)    \n    \n    results = model.train(data='coco8.yaml', epochs=epochs, imgsz=imgsz, batch=batchsize,\n                          project='testprj', name='testexp', exist_ok=True,)\n\n    return os.path.join('testprj','testexp','weights','knowgyu')\n    \n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.1\",\n    packages_to_install=[\"ultralytics\",\"ray[tune]\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n)\ndef tune(\n    model_path: str,\n    ):\n    from ultralytics import YOLO\n    import os\n\n    os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n    \n    model = YOLO(model_path)\n    \n    result = model.tune(\n                data=\"coco8.yaml\",\n                space={\"lr0\": tune.uniform(1e-5, 1e-1)},\n                epochs=2,\n                grace_period=2,\n                gpu_per_trial=1,\n                iterations=1,\n                batch=4,\n                use_ray=True\n                )\n        \n        \n@dsl.pipeline(name=\"Thisisplname\",\n          description=\"MLpipline Description\",\n          )\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n    ):\n    import os\n    \n    vop = dsl.VolumeOp(\n        name=\"create-pvc\",\n        resource_name=\"this-is-pvc\",\n        storage_class='scn-test',\n        modes=dsl.VOLUME_MODE_RWO,\n        size=\"5Gi\",\n        generate_unique_name=False,\n        action='apply',\n    )\n    \n    check = verify_training(model_name, epochs, imgsz, batchsize).add_pvolumes({\"/data\":vop.volume})\n    trained = train(\n        check.output, model_name, epochs, imgsz, batchsize\n        ).add_pvolumes({\"/data\":vop.volume})\n    tune(trained.output).add_pvolumes({\"/data\":vop.volume})\n\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(train_pipeline, \"knowgyu_MountTest.yaml\")\n```\n\n- `knowgyu_MountTest.yaml` *~~# 전체코드와 yaml파일은 예제와 다를 수 있습니다.~~*\n    \n    ```python\n    apiVersion: argoproj.io/v1alpha1\n    kind: Workflow\n    metadata:\n      generateName: thisisplname-\n      annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9, pipelines.kubeflow.org/pipeline_compilation_time: '2023-12-01T16:49:44.795741',\n        pipelines.kubeflow.org/pipeline_spec: '{\"description\": \"MLpipline Description\",\n          \"inputs\": [{\"name\": \"model_name\", \"type\": \"String\"}, {\"name\": \"epochs\", \"type\":\n          \"Integer\"}, {\"name\": \"imgsz\", \"type\": \"Integer\"}, {\"name\": \"batchsize\", \"type\":\n          \"Integer\"}], \"name\": \"Thisisplname\"}'}\n      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9}\n    spec:\n      entrypoint: thisisplname\n      templates:\n      - name: create-pvc\n        resource:\n          action: apply\n          manifest: |\n            apiVersion: v1\n            kind: PersistentVolumeClaim\n            metadata:\n              name: this-is-pvc\n...\n...\n...\n생략\n...\n...\n...\n        volumes:\n        - name: create-pvc\n          persistentVolumeClaim: {claimName: '{{inputs.parameters.create-pvc-name}}'}\n      arguments:\n        parameters:\n        - {name: model_name}\n        - {name: epochs}\n        - {name: imgsz}\n        - {name: batchsize}\n      serviceAccountName: pipeline-runner\n    ```\n    \n\n## 파이프라인 업로드 및 실행\n\n---\n\n- **파이프라인 업로드**\n\n![Untitled](/assets/img/kubeflow/kubeyolo104.png)\n\n\n- **파이프라인 실행 결과**\n\n![Untitled](/assets/img/kubeflow/kubeyolo105.png)\n\n\n- **주피터 노트북 확인 결과**\n    \n    ![노트북 생성 중 볼륨 생성이 아닌 기존 볼륨을 사용해 생성해야 합니다.](/assets/img/kubeflow/kubeyolo106.png)\n    \n    노트북 생성 중 볼륨 생성이 아닌 기존 볼륨을 사용해 생성해야 합니다.\n    \n    ![Jupyter Notebook 접속 사진](/assets/img/kubeflow/kubeyolo107.png)\n    \n    Jupyter Notebook 접속 사진\n    \n    ![클러스터 노드 로컬 볼륨](/assets/img/kubeflow/kubeyolo108.png)\n    \n    클러스터 노드 로컬 볼륨\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-PV-Mount---HyperParameter-Tuning_chunk_0",
        "text": "PV Mount & HyperParameter Tuning\n\n본 문서는 파이프라인을 PV에 마운트하는 것과 YOLOv8에서 기본으로 제공하는 raytune을 이용해 하이퍼파라미터 튜닝을 하는 것에 대해 다룹니다.<br>\n\n[https://happycloud-lee.tistory.com/256](https://happycloud-lee.tistory.com/256) ← PV/PVC 참고<br>\n\n[https://docs.ultralytics.com/integrations/ray-tune/?h=hyper](https://docs.ultralytics.com/integrations/ray-tune/?h=hyper) ← HP Tuning 공식문서<br>\n\n# PV / PVC\n\n---\n\n## k8s 환경에서의 볼륨\n\n### 외부 볼륨의 필요성\n\n쿠버네티스 환경에서는 모든 어플리케이션이 Pod안에 컨테이너로 실행됩니다.\n\n보통 **컨테이너**에서 데이터를 읽고 저장할 때는 자신의 내부 볼륨이 아닌 **외부 볼륨**을 사용합니다.\n\n→ 컨테이너는 언제든 사라질 수 있기에, 데이터를 잃는 상황을 막기 위해!\n\n### 사용 목적별 볼륨 유형\n\nPod안에 컨테이너화되어 실행되는 것은 크게 **어플리케이션**과 **데이터베이스**입니다.\n\n볼륨을 크게 나누면 Pod 로컬 볼륨, Node 로컬 볼륨, 네트워크 볼륨이 있습니다.(공식적인건 아님)\n\n볼륨 유형을 정리하면 아래와 같습니다.\n\n| 구분         | 사용 목적                            | 파드 삭제시 볼륨 폐기 | 볼륨 유형      |\n| -",
        "index": 0
      },
      {
        "id": "2024-11-02-PV-Mount---HyperParameter-Tuning_chunk_1",
        "text": "형을 정리하면 아래와 같습니다.\n\n| 구분         | 사용 목적                            | 파드 삭제시 볼륨 폐기 | 볼륨 유형      |\n| ------------ | ------------------------------------ | --------------------- | -------------- |\n| 어플리케이션 | 어떤 처리를 위한 임시 공간           | **Y**                 | 파드 로컬 볼륨 |\n|              | 컨피그맵, 시크릿, 파드 정보 참조     | **Y**                 | 파드 로컬 볼륨 |\n|              | 파드가 실행된 노드의 파일 접근       | N                     | 노드 로컬 볼륨 |\n|              | 특정 노드의 파일 접근                | N                     | 노드 로컬 볼륨 |\n|              | 클러스터 외부 스토리지의 파일 접근   | N                     | 네트워크 볼륨  |\n| 데이터베이스 | 컨피그맵, 시크릿, 파드 정보 참조     | **Y**                 | 파드 로컬 볼륨 |\n|              | 파드가 실행된 노드에만 데이터 저장   | N                     | 노드 로컬 볼륨 |\n|              | 특정 노드에만 데이터 저장            | N                     | 노",
        "index": 1
      },
      {
        "id": "2024-11-02-PV-Mount---HyperParameter-Tuning_chunk_2",
        "text": "| 노드 로컬 볼륨 |\n|              | 특정 노드에만 데이터 저장            | N                     | 노드 로컬 볼륨 |\n|              | 클러스터 외부 스토리지에 데이터 저장 | N                     | 노드 로컬 볼륨 |\n\n### Pod의 볼륨 접근 아키텍처와 PV 라이프 사이클\n\n![https://happycloud-lee.tistory.com/256](/assets/img/kubeflow/kubeyolo101.png)\n\nhttps://happycloud-lee.tistory.com/256\n\nPod가 볼륨을 사용하는 방법은 ‘**마운트**’ 입니다.\n\nPod내에 볼륨을 ‘마운트’ 함으로써 어떤 유형의 볼륨이든 Pod의 내부 파일 시스템처럼 사용할 수 있습니다.\n\n하지만, 이 아키텍처는 쿠버네티스와 인프라스트럭처가 너무 강한 결합(**Tightly Coupled**)되어버립니다.\n\n이로 인해 스토리지 제품의 변화나 스토리지 서버의 변화가 Pod에 직접적인 영향을 미칩니다.\n\n- **예시**\n    \n    `nfs` 라는 네트워크 볼륨을 Pod에 마운트하려면 `nfs` 서버의 IP나 호스트를 지정해야 하는데, `nfs` 서버의 IP가 변경되면 서비스에 문제가 발생할 수 있습니다.\n    \n\n이를 해결하기 위해 쿠버네티스와 인프라스트럭처를 느슨하게 결합(**Loosly Coupled**)시키면 됩니다.\n\n이를 위해 중간에 중계자 역할을 하는 **PV/PVC** 를 만들게 됩니다.\n\n\n> 네트워크 볼륨을",
        "index": 2
      },
      {
        "id": "2024-11-02-PV-Mount---HyperParameter-Tuning_chunk_3",
        "text": "라스트럭처를 느슨하게 결합(**Loosly Coupled**)시키면 됩니다.\n\n이를 위해 중간에 중계자 역할을 하는 **PV/PVC** 를 만들게 됩니다.\n\n\n> 네트워크 볼륨을 위해 CSIContainer Storage Interface라는 중계자 역할도 있습니다.\n> 하지만, 딥러닝 학습 시 네트워크 볼륨을 사용하게 된다면 학습이 느려진다는 단점이 있어 로컬 볼륨을 사용하기에 CSI에 대해서는 다루지 않겠습니다.\n{: .prompt-tip }\n\n![https://happycloud-lee.tistory.com/256](/assets/img/kubeflow/kubeyolo102.png)\nhttps://happycloud-lee.tistory.com/256\n\n1. Pod정보, Config-map, Secret은 파드 명세에 정의하여 마운트합니다.\n\n2. 노드 로컬 볼륨과 네트워크 볼륨은 PV리소스로 정의하고 PVC에 바운드(연결)합니다.\n    파드 명세에서는 PVC만 지정하면 연결된 볼륨이 마운트 됩니다.\n\n3. 스토리지 제품별로 PV을 정의하여 볼륨을 접근할 수 있습니다.<br>\n\n이렇게 되면 PV를 정의하고, PVC에 연결한 후 Pod에 PVC만 지정해주면 됩니다.\n\n## 파이프라인 볼륨\n\n파이프라인은 1개 이상의 컴포넌트로 이루어져 있습니다. 각각의 컴포넌트는 Pod로 구성되어 파이프라인을 통해 실행됩니다.",
        "index": 3
      },
      {
        "id": "2024-11-02-PV-Mount---HyperParameter-Tuning_chunk_4",
        "text": "에 PVC만 지정해주면 됩니다.\n\n## 파이프라인 볼륨\n\n파이프라인은 1개 이상의 컴포넌트로 이루어져 있습니다. 각각의 컴포넌트는 Pod로 구성되어 파이프라인을 통해 실행됩니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Pipeline-Upload",
    "title": "Pipeline-Upload",
    "path": "/2024/11/02/Pipeline-Upload/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n\n컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행\n\n→ 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다.\n\n## Pipeline\n\n> 파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있습니다.\n순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n\n\n## Upload Pipeline\n\n이전에 만든 파이프라인을 Kubeflow에 업로드\n\nkubeflow 대시보드 UI를 통해 진행할 수 있음.\n\n```yaml\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\nhttp://localhost:8080/ 접속\n\n### 1. Pipelines 탭 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe601.png)\n\n### 2. 우측 상단 Upload Pipeline 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe602.png)\n\n### 3. yaml파일 업로드\n\n![Untitled](/assets/img/kubeflow/kubepipe603.png)\n\n> Pipeline Name과 Pipeline Description 작성 후 **`Create`** 버튼 클릭\n \n\n### 4. 생성\n\n![Untitled](/assets/img/kubeflow/kubepipe604.png)\n\n### +) Upload Pipeline Version\n\n![Untitled](/assets/img/kubeflow/kubepipe605.png)\n\n> 3번 과정에서 **`Create a new pipeline version under an existing pipeline`** 클릭\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Pipeline-Upload_chunk_0",
        "text": "Pipeline-Upload\n\n# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n\n컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행\n\n→ 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다.\n\n## Pipeline\n\n> 파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있습니다.\n순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n\n\n## Upload Pipeline\n\n이전에 만든 파이프라인을 Kubeflow에 업로드\n\nkubeflow 대시보드 UI를 통해 진행할 수 있음.\n\n```yaml\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\nhttp://localhost:8080/ 접속\n\n### 1. Pipelines 탭 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe601.png)\n\n### 2. 우측 상단 Upload Pipeline 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe602.png)\n\n### 3. yaml파일 업로드\n\n![Untitled](/assets/img/kubeflow/kubepipe603.png)\n\n> Pipeline Name과 Pipeline Description 작성 후 **`Create`** 버튼 클릭\n \n\n### 4.",
        "index": 0
      },
      {
        "id": "2024-11-02-Pipeline-Upload_chunk_1",
        "text": "/kubeflow/kubepipe603.png)\n\n> Pipeline Name과 Pipeline Description 작성 후 **`Create`** 버튼 클릭\n \n\n### 4. 생성\n\n![Untitled](/assets/img/kubeflow/kubepipe604.png)\n\n### +) Upload Pipeline Version\n\n![Untitled](/assets/img/kubeflow/kubepipe605.png)\n\n> 3번 과정에서 **`Create a new pipeline version under an existing pipeline`** 클릭",
        "index": 1
      },
      {
        "id": "2024-11-02-Pipeline-Upload_chunk_2",
        "text": "eflow/kubepipe605.png)\n\n> 3번 과정에서 **`Create a new pipeline version under an existing pipeline`** 클릭",
        "index": 2
      },
      {
        "id": "2024-11-02-Pipeline-Upload_chunk_3",
        "text": "eflow/kubepipe605.png)\n\n> 3번 과정에서 **`Create a new pipeline version under an existing pipeline`** 클릭",
        "index": 3
      },
      {
        "id": "2024-11-02-Pipeline-Upload_chunk_4",
        "text": "eflow/kubepipe605.png)\n\n> 3번 과정에서 **`Create a new pipeline version under an existing pipeline`** 클릭",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Kubeflow-Pipeline",
    "title": "Kubeflow Pipeline을 활용한 Yolo 학습 파이프라인 시작하기",
    "path": "/2024/11/02/Kubeflow-Pipeline-시작하기/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\n이전의 문서들에서 언급했듯 Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n컴포넌트의 경우 함수의 형태로 표현되며, 필요한 인자(Config)들을 받아 동작합니다.\n\n하나 이상의 컴포넌트를 작성했다면, 이를 실행하기 위해 파이프라인을 작성해야합니다.\n\n# YOLOv7\n\n---\n\nYOLOv7 repo : [https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)\n\nYOLOv7을 학습시키기 위해 Github에서 저장소를 복제한 후 필요한 라이브러리를 설치하고 아래 명령어를 입력합니다.\n\n```bash\npython train.py --workers 8 --device 0 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights '' --name yolov7 --hyp data/hyp.scratch.p5.yaml\n```\n\n`os` 라이브러리의 `system` 함수 혹은 `subprocess` 를 이용해 파이썬에서 우분투 셸 명령어를 호출할 수 있기에, \n\n아래와 같이 컴포넌트를 작성할 수 있습니다.\n\n```bash\n@create_component_from_func\ndef train():\n\t\timport subprocess\n    command = [\"python\", \"train.py\", \"--workers\", \"8\", \"--device\", \"0\", \"--batch-size\", \"32\", \"--data\", \"data/coco.yaml\", \"--img\", \"640\", \"640\", \"--cfg\", \"cfg/training/yolov7.yaml\", \"--weights\", \"\", \"--name\", \"yolov7\", \"--hyp\", \"data/hyp.scratch.p5.yaml\"]\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n\n    if process.returncode != 0:\n        print(f\"Error occurred: {stderr.decode('utf-8')}\")\n    else:\n        print(f\"Output: {stdout.decode('utf-8')}\")\n```\n\n하지만, 학습 후 아티팩트를 저장하거나 학습 전 데이터셋을 조작 등 학습 전, 후 컴포넌트와 연결하는 것이 어려울 것이라 예상됩니다.\n\n## YOLOv8\n\n---\n\nYOLOv8 docs : [https://docs.ultralytics.com/](https://docs.ultralytics.com/)\n\nYOLOv8의 경우 비교적 다른 버전에 비해 수월하게 설치 및 학습이 가능합니다.\n\npip를 이용해 `ultralytics` 패키지를 설치하면 의존성에 관한 문제도 크게 신경 쓸 필요 없습니다.\n\n따라서 먼저 사용하기 쉬운 YOLOv8을 이용해 학습 파이프라인을 구성해본 후 YOLOv7 학습 파이프라인을 작성하려 합니다.\n\n![Untitled](/assets/img/kubeflow/kubepipe000.png)\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Kubeflow-Pipeline_chunk_0",
        "text": "Kubeflow Pipeline을 활용한 Yolo 학습 파이프라인 시작하기\n\n# Kubeflow\n\n---\n\n이전의 문서들에서 언급했듯 Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n컴포넌트의 경우 함수의 형태로 표현되며, 필요한 인자(Config)들을 받아 동작합니다.\n\n하나 이상의 컴포넌트를 작성했다면, 이를 실행하기 위해 파이프라인을 작성해야합니다.\n\n# YOLOv7\n\n---\n\nYOLOv7 repo : [https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)\n\nYOLOv7을 학습시키기 위해 Github에서 저장소를 복제한 후 필요한 라이브러리를 설치하고 아래 명령어를 입력합니다.\n\n```bash\npython train.py --workers 8 --device 0 --batch-size 32 --data data/coco.yaml --img 640 640 --cfg cfg/training/yolov7.yaml --weights '' --name yolov7 --hyp data/hyp.scratch.p5.yaml\n```\n\n`os` 라이브러리의 `system` 함수 혹은 `subprocess` 를 이용해 파이썬에서 우분투 셸 명령어를 호출할 수 있기에, \n\n아래와 같이 컴포넌트를 작성할 수 있습니다.\n\n```bash\n@create_component_from_func\ndef train():\n\t\timport subprocess\n    command = [\"python\", \"train.py",
        "index": 0
      },
      {
        "id": "2024-11-02-Kubeflow-Pipeline_chunk_1",
        "text": "bash\n@create_component_from_func\ndef train():\n\t\timport subprocess\n    command = [\"python\", \"train.py\", \"--workers\", \"8\", \"--device\", \"0\", \"--batch-size\", \"32\", \"--data\", \"data/coco.yaml\", \"--img\", \"640\", \"640\", \"--cfg\", \"cfg/training/yolov7.yaml\", \"--weights\", \"\", \"--name\", \"yolov7\", \"--hyp\", \"data/hyp.scratch.p5.yaml\"]\n    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    stdout, stderr = process.communicate()\n\n    if process.returncode != 0:\n        print(f\"Error occurred: {stderr.decode('utf-8')}\")\n    else:\n        print(f\"Output: {stdout.decode('utf-8')}\")\n```\n\n하지만, 학습 후 아티팩트를 저장하거나 학습 전 데이터셋을 조작 등 학습 전, 후 컴포넌트와 연결하는 것이 어려울 것이라 예상됩니다.\n\n## YOLOv8\n\n---\n\nYOLOv8 docs : [https://docs.ultralytics.com/](https://docs.ultralytics.com/)\n\nYOLOv8의 경우 비교적 다른 버",
        "index": 1
      },
      {
        "id": "2024-11-02-Kubeflow-Pipeline_chunk_2",
        "text": "-\n\nYOLOv8 docs : [https://docs.ultralytics.com/](https://docs.ultralytics.com/)\n\nYOLOv8의 경우 비교적 다른 버전에 비해 수월하게 설치 및 학습이 가능합니다.\n\npip를 이용해 `ultralytics` 패키지를 설치하면 의존성에 관한 문제도 크게 신경 쓸 필요 없습니다.\n\n따라서 먼저 사용하기 쉬운 YOLOv8을 이용해 학습 파이프라인을 구성해본 후 YOLOv7 학습 파이프라인을 작성하려 합니다.\n\n![Untitled](/assets/img/kubeflow/kubepipe000.png)",
        "index": 2
      },
      {
        "id": "2024-11-02-Kubeflow-Pipeline_chunk_3",
        "text": "이용해 학습 파이프라인을 구성해본 후 YOLOv7 학습 파이프라인을 작성하려 합니다.\n\n![Untitled](/assets/img/kubeflow/kubepipe000.png)",
        "index": 3
      },
      {
        "id": "2024-11-02-Kubeflow-Pipeline_chunk_4",
        "text": "이용해 학습 파이프라인을 구성해본 후 YOLOv7 학습 파이프라인을 작성하려 합니다.\n\n![Untitled](/assets/img/kubeflow/kubepipe000.png)",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Pipeline-Write",
    "title": "Pipeline-Write",
    "path": "/2024/11/02/Pipeline-Write/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n> \n\n컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행\n\n→ 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다.\n\n## Pipeline\n\n> 파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있습니다.<br>\n> 순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n\n\n숫자를 입력받고 출력하는 컴포넌트와 두 숫자를 입력받아 합을 출력하는 컴포넌트가 있는 파이프라인 구성하기\n\n## Component Set\n\n1. 숫자를 입력받아 출력하고 반환하는 컴포넌트\n    \n```python\n@create_component_from_func\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n```\n    \n2. 두 개의 숫자를 입력받아 합을 출력하는 컴포넌트\n    \n```python\n@create_component_from_func\ndef sum_and_print_numbers(number_1: int, number_2: int) -> int:\n    sum_num = number_1 + number_2\n    print(sum_num)\n    return sum_num\n```\n    \n\n## Pipeline write with python code\n\n```python\ndef example_pipeline(number_1: int, number_2: int):\n\tnumber_1_result = print_and_return_number(number_1)\n\tnumber_2_result = print_and_return_number(number_2)\n\n\tsum_result = sum_and_print_numbers(\n\t\t\tnumber_1 = number_1_result.output, number_2 = number_2_result.output\n\t)\n```\n\n## Convert to Kubeflow Format\n\n마지막으로 kubeflow에서 사용할 수 있는 형식으로 변환합니다.\n\n```python\nfrom kfp.dsl import pipeline\n\n@pipeline(name='example_pipeline')\ndef example_pipeline(number_1: int, number_2: int):\n\tnumber_1_result = print_and_return_number(number_1)\n\tnumber_2_result = print_and_return_number(number_2)\n\n\tsum_result = sum_and_print_numbers(\n\t\t\tnumber_1 = number_1_result.output, number_2 = number_2_result.output\n\t)\n\nif __name__ == \"__main__\":\n\timport kfp\n\tkfp.compiler.Compiler().compile(example_pipeline, \"example_pipeline.yaml\")\n```\n\n<aside>\n💡 Kubeflow에서 파이프라인 실행은 yaml형식으로만 가능\n`kfp.compiler.Compiler().compile(example_pipeline, \"example_pipeline.yaml\")` 를 이용해 컴파일\n\n</aside>\n\n## Conclusion\n\n```python\nimport kfp\nfrom kfp.components import create_component_from_func\nfrom kfp.dsl import pipeline\n\n@create_component_from_func\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n\n@create_component_from_func\ndef sum_and_print_numbers(number_1: int, number_2: int):\n    print(number_1 + number_2)\n\n@pipeline(name=\"example_pipeline\")\ndef example_pipeline(number_1: int, number_2: int):\n    number_1_result = print_and_return_number(number_1)\n    number_2_result = print_and_return_number(number_2)\n\n    sum_result = sum_and_print_numbers(\n        number_1=number_1_result.output, number_2=number_2_result.output\n    )\n\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(example_pipeline, \"example_pipeline.yaml\")\n```\n\n샘플 yaml\n- `example_pipeline.yaml`\n    \n    ```yaml\n    apiVersion: argoproj.io/v1alpha1\n    kind: Workflow\n    metadata:\n      generateName: example-pipeline-\n      annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9, pipelines.kubeflow.org/pipeline_compilation_time: '2023-11-23T16:06:24.189360',\n        pipelines.kubeflow.org/pipeline_spec: '{\"inputs\": [{\"name\": \"number_1\", \"type\":\n          \"Integer\"}, {\"name\": \"number_2\", \"type\": \"Integer\"}], \"name\": \"example_pipeline\"}'}\n      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9}\n    spec:\n      entrypoint: example-pipeline\n      templates:\n      - name: example-pipeline\n        inputs:\n          parameters:\n          - {name: number_1}\n          - {name: number_2}\n        dag:\n          tasks:\n          - name: print-and-return-number\n            template: print-and-return-number\n            arguments:\n              parameters:\n              - {name: number_1, value: '{{inputs.parameters.number_1}}'}\n          - name: print-and-return-number-2\n            template: print-and-return-number-2\n            arguments:\n              parameters:\n              - {name: number_2, value: '{{inputs.parameters.number_2}}'}\n          - name: sum-and-print-numbers\n            template: sum-and-print-numbers\n            dependencies: [print-and-return-number, print-and-return-number-2]\n            arguments:\n              parameters:\n              - {name: print-and-return-number-2-Output, value: '{{tasks.print-and-return-number-2.outputs.parameters.print-and-return-number-2-Output}}'}\n              - {name: print-and-return-number-Output, value: '{{tasks.print-and-return-number.outputs.parameters.print-and-return-number-Output}}'}\n      - name: print-and-return-number\n        container:\n          args: [--number, '{{inputs.parameters.number_1}}', '----output-paths', /tmp/outputs/Output/data]\n          command:\n          - sh\n          - -ec\n          - |\n            program_path=$(mktemp)\n            printf \"%s\" \"$0\" > \"$program_path\"\n            python3 -u \"$program_path\" \"$@\"\n          - |\n            def print_and_return_number(number):\n                print(number)\n                return number\n    \n            def _serialize_int(int_value: int) -> str:\n                if isinstance(int_value, str):\n                    return int_value\n                if not isinstance(int_value, int):\n                    raise TypeError('Value \"{}\" has type \"{}\" instead of int.'.format(\n                        str(int_value), str(type(int_value))))\n                return str(int_value)\n    \n            import argparse\n            _parser = argparse.ArgumentParser(prog='Print and return number', description='')\n            _parser.add_argument(\"--number\", dest=\"number\", type=int, required=True, default=argparse.SUPPRESS)\n            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n            _parsed_args = vars(_parser.parse_args())\n            _output_files = _parsed_args.pop(\"_output_paths\", [])\n    \n            _outputs = print_and_return_number(**_parsed_args)\n    \n            _outputs = [_outputs]\n    \n            _output_serializers = [\n                _serialize_int,\n    \n            ]\n    \n            import os\n            for idx, output_file in enumerate(_output_files):\n                try:\n                    os.makedirs(os.path.dirname(output_file))\n                except OSError:\n                    pass\n                with open(output_file, 'w') as f:\n                    f.write(_output_serializers[idx](_outputs[idx]))\n          image: python:3.7\n        inputs:\n          parameters:\n          - {name: number_1}\n        outputs:\n          parameters:\n          - name: print-and-return-number-Output\n            valueFrom: {path: /tmp/outputs/Output/data}\n          artifacts:\n          - {name: print-and-return-number-Output, path: /tmp/outputs/Output/data}\n        metadata:\n          labels:\n            pipelines.kubeflow.org/kfp_sdk_version: 1.8.9\n            pipelines.kubeflow.org/pipeline-sdk-type: kfp\n            pipelines.kubeflow.org/enable_caching: \"true\"\n          annotations: {pipelines.kubeflow.org/component_spec: '{\"implementation\": {\"container\":\n              {\"args\": [\"--number\", {\"inputValue\": \"number\"}, \"----output-paths\", {\"outputPath\":\n              \"Output\"}], \"command\": [\"sh\", \"-ec\", \"program_path=$(mktemp)\\nprintf \\\"%s\\\"\n              \\\"$0\\\" > \\\"$program_path\\\"\\npython3 -u \\\"$program_path\\\" \\\"$@\\\"\\n\", \"def\n              print_and_return_number(number):\\n    print(number)\\n    return number\\n\\ndef\n              _serialize_int(int_value: int) -> str:\\n    if isinstance(int_value, str):\\n        return\n              int_value\\n    if not isinstance(int_value, int):\\n        raise TypeError(''Value\n              \\\"{}\\\" has type \\\"{}\\\" instead of int.''.format(\\n            str(int_value),\n              str(type(int_value))))\\n    return str(int_value)\\n\\nimport argparse\\n_parser\n              = argparse.ArgumentParser(prog=''Print and return number'', description='''')\\n_parser.add_argument(\\\"--number\\\",\n              dest=\\\"number\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"----output-paths\\\",\n              dest=\\\"_output_paths\\\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files\n              = _parsed_args.pop(\\\"_output_paths\\\", [])\\n\\n_outputs = print_and_return_number(**_parsed_args)\\n\\n_outputs\n              = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_int,\\n\\n]\\n\\nimport\n              os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except\n              OSError:\\n        pass\\n    with open(output_file, ''w'') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n\"],\n              \"image\": \"python:3.7\"}}, \"inputs\": [{\"name\": \"number\", \"type\": \"Integer\"}],\n              \"name\": \"Print and return number\", \"outputs\": [{\"name\": \"Output\", \"type\":\n              \"Integer\"}]}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{\"number\":\n              \"{{inputs.parameters.number_1}}\"}'}\n      - name: print-and-return-number-2\n        container:\n          args: [--number, '{{inputs.parameters.number_2}}', '----output-paths', /tmp/outputs/Output/data]\n          command:\n          - sh\n          - -ec\n          - |\n            program_path=$(mktemp)\n            printf \"%s\" \"$0\" > \"$program_path\"\n            python3 -u \"$program_path\" \"$@\"\n          - |\n            def print_and_return_number(number):\n                print(number)\n                return number\n    \n            def _serialize_int(int_value: int) -> str:\n                if isinstance(int_value, str):\n                    return int_value\n                if not isinstance(int_value, int):\n                    raise TypeError('Value \"{}\" has type \"{}\" instead of int.'.format(\n                        str(int_value), str(type(int_value))))\n                return str(int_value)\n    \n            import argparse\n            _parser = argparse.ArgumentParser(prog='Print and return number', description='')\n            _parser.add_argument(\"--number\", dest=\"number\", type=int, required=True, default=argparse.SUPPRESS)\n            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n            _parsed_args = vars(_parser.parse_args())\n            _output_files = _parsed_args.pop(\"_output_paths\", [])\n    \n            _outputs = print_and_return_number(**_parsed_args)\n    \n            _outputs = [_outputs]\n    \n            _output_serializers = [\n                _serialize_int,\n    \n            ]\n    \n            import os\n            for idx, output_file in enumerate(_output_files):\n                try:\n                    os.makedirs(os.path.dirname(output_file))\n                except OSError:\n                    pass\n                with open(output_file, 'w') as f:\n                    f.write(_output_serializers[idx](_outputs[idx]))\n          image: python:3.7\n        inputs:\n          parameters:\n          - {name: number_2}\n        outputs:\n          parameters:\n          - name: print-and-return-number-2-Output\n            valueFrom: {path: /tmp/outputs/Output/data}\n          artifacts:\n          - {name: print-and-return-number-2-Output, path: /tmp/outputs/Output/data}\n        metadata:\n          labels:\n            pipelines.kubeflow.org/kfp_sdk_version: 1.8.9\n            pipelines.kubeflow.org/pipeline-sdk-type: kfp\n            pipelines.kubeflow.org/enable_caching: \"true\"\n          annotations: {pipelines.kubeflow.org/component_spec: '{\"implementation\": {\"container\":\n              {\"args\": [\"--number\", {\"inputValue\": \"number\"}, \"----output-paths\", {\"outputPath\":\n              \"Output\"}], \"command\": [\"sh\", \"-ec\", \"program_path=$(mktemp)\\nprintf \\\"%s\\\"\n              \\\"$0\\\" > \\\"$program_path\\\"\\npython3 -u \\\"$program_path\\\" \\\"$@\\\"\\n\", \"def\n              print_and_return_number(number):\\n    print(number)\\n    return number\\n\\ndef\n              _serialize_int(int_value: int) -> str:\\n    if isinstance(int_value, str):\\n        return\n              int_value\\n    if not isinstance(int_value, int):\\n        raise TypeError(''Value\n              \\\"{}\\\" has type \\\"{}\\\" instead of int.''.format(\\n            str(int_value),\n              str(type(int_value))))\\n    return str(int_value)\\n\\nimport argparse\\n_parser\n              = argparse.ArgumentParser(prog=''Print and return number'', description='''')\\n_parser.add_argument(\\\"--number\\\",\n              dest=\\\"number\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"----output-paths\\\",\n              dest=\\\"_output_paths\\\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files\n              = _parsed_args.pop(\\\"_output_paths\\\", [])\\n\\n_outputs = print_and_return_number(**_parsed_args)\\n\\n_outputs\n              = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_int,\\n\\n]\\n\\nimport\n              os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except\n              OSError:\\n        pass\\n    with open(output_file, ''w'') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n\"],\n              \"image\": \"python:3.7\"}}, \"inputs\": [{\"name\": \"number\", \"type\": \"Integer\"}],\n              \"name\": \"Print and return number\", \"outputs\": [{\"name\": \"Output\", \"type\":\n              \"Integer\"}]}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{\"number\":\n              \"{{inputs.parameters.number_2}}\"}'}\n      - name: sum-and-print-numbers\n        container:\n          args: [--number-1, '{{inputs.parameters.print-and-return-number-Output}}', --number-2,\n            '{{inputs.parameters.print-and-return-number-2-Output}}']\n          command:\n          - sh\n          - -ec\n          - |\n            program_path=$(mktemp)\n            printf \"%s\" \"$0\" > \"$program_path\"\n            python3 -u \"$program_path\" \"$@\"\n          - |\n            def sum_and_print_numbers(number_1, number_2):\n                print(number_1 + number_2)\n    \n            import argparse\n            _parser = argparse.ArgumentParser(prog='Sum and print numbers', description='')\n            _parser.add_argument(\"--number-1\", dest=\"number_1\", type=int, required=True, default=argparse.SUPPRESS)\n            _parser.add_argument(\"--number-2\", dest=\"number_2\", type=int, required=True, default=argparse.SUPPRESS)\n            _parsed_args = vars(_parser.parse_args())\n    \n            _outputs = sum_and_print_numbers(**_parsed_args)\n          image: python:3.7\n        inputs:\n          parameters:\n          - {name: print-and-return-number-2-Output}\n          - {name: print-and-return-number-Output}\n        metadata:\n          labels:\n            pipelines.kubeflow.org/kfp_sdk_version: 1.8.9\n            pipelines.kubeflow.org/pipeline-sdk-type: kfp\n            pipelines.kubeflow.org/enable_caching: \"true\"\n          annotations: {pipelines.kubeflow.org/component_spec: '{\"implementation\": {\"container\":\n              {\"args\": [\"--number-1\", {\"inputValue\": \"number_1\"}, \"--number-2\", {\"inputValue\":\n              \"number_2\"}], \"command\": [\"sh\", \"-ec\", \"program_path=$(mktemp)\\nprintf \\\"%s\\\"\n              \\\"$0\\\" > \\\"$program_path\\\"\\npython3 -u \\\"$program_path\\\" \\\"$@\\\"\\n\", \"def\n              sum_and_print_numbers(number_1, number_2):\\n    print(number_1 + number_2)\\n\\nimport\n              argparse\\n_parser = argparse.ArgumentParser(prog=''Sum and print numbers'',\n              description='''')\\n_parser.add_argument(\\\"--number-1\\\", dest=\\\"number_1\\\",\n              type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--number-2\\\",\n              dest=\\\"number_2\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parsed_args\n              = vars(_parser.parse_args())\\n\\n_outputs = sum_and_print_numbers(**_parsed_args)\\n\"],\n              \"image\": \"python:3.7\"}}, \"inputs\": [{\"name\": \"number_1\", \"type\": \"Integer\"},\n              {\"name\": \"number_2\", \"type\": \"Integer\"}], \"name\": \"Sum and print numbers\"}',\n            pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{\"number_1\":\n              \"{{inputs.parameters.print-and-return-number-Output}}\", \"number_2\": \"{{inputs.parameters.print-and-return-number-2-Output}}\"}'}\n      arguments:\n        parameters:\n        - {name: number_1}\n        - {name: number_2}\n      serviceAccountName: pipeline-runner\n    ```\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Pipeline-Write_chunk_0",
        "text": "Pipeline-Write\n\n# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n> \n\n컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행\n\n→ 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다.\n\n## Pipeline\n\n> 파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있습니다.<br>\n> 순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n\n\n숫자를 입력받고 출력하는 컴포넌트와 두 숫자를 입력받아 합을 출력하는 컴포넌트가 있는 파이프라인 구성하기\n\n## Component Set\n\n1. 숫자를 입력받아 출력하고 반환하는 컴포넌트\n    \n```python\n@create_component_from_func\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n```\n    \n2.",
        "index": 0
      },
      {
        "id": "2024-11-02-Pipeline-Write_chunk_1",
        "text": "nc\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n```\n    \n2.",
        "index": 1
      },
      {
        "id": "2024-11-02-Pipeline-Write_chunk_2",
        "text": "nc\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n```\n    \n2.",
        "index": 2
      },
      {
        "id": "2024-11-02-Pipeline-Write_chunk_3",
        "text": "nc\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n```\n    \n2.",
        "index": 3
      },
      {
        "id": "2024-11-02-Pipeline-Write_chunk_4",
        "text": "nc\ndef print_and_return_number(number: int) -> int:\n    print(number)\n    return number\n```\n    \n2.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Yolov8---pp",
    "title": "Yolov8 학습 파이프라인 실행",
    "path": "/2024/11/02/Yolov8-학습pp실행/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# YOLOv8 파이프라인 실행\n\n---\n\n이전 문서에서 YOLOv8 학습 컴포넌트를 작성한 후 이를 실행시키기 위해 파이프라인을 작성하고, kubeflow에서 사용할 수 있도록 yaml로 변환했습니다.\n\n이번 문서에서는 yaml파일로 변환한 파이프라인을 Kubeflow 대쉬보드를 이용해 업로드하고 실행시켜보겠습니다.\n\n## Pipeline Upload\n\n---\n\n우선, 웹 UI에 접속하기 위해 포트포워딩을 합니다.\n\n```python\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\n### 좌측 탭에서 Pipelines 클릭 후 우측 상단의 Upload pipeline 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe108.png)\n\n### 내용 입력 후 Create 버튼 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe107.png)\n\n### 업로드 완료\n\n![Untitled](/assets/img/kubeflow/kubepipe106.png)\n\n> 파이프라인을 작성할 때, `Train` 컴포넌트만을 사용했기에 하나의 블럭만 표시됩니다.\n{: .prompt-info }\n\n## Pipeline Run\n\n---\n\n### Create run\n\n![Untitled](/assets/img/kubeflow/kubepipe105.png)\n\n### 내용 입력 후 Start\n\n![Untitled](/assets/img/kubeflow/kubepipe104.png)\n### 실행 완료\n\n![Untitled](/assets/img/kubeflow/kubepipe103.png)\n\n>💡 정상적으로 학습을 진행했는지 log를 확인합니다.\n{: .prompt-info }\n\n![Untitled](/assets/img/kubeflow/kubepipe102.png)\n\n- main.log\n    \n    ```bash\n    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n    \n      0%|          | 0.00/6.23M [00:00<?, ?B/s]\n      4%|â–Ž         | 224k/6.23M [00:00<00:02, 2.14MB/s]\n     13%|â–ˆâ–Ž        | 848k/6.23M [00:00<00:01, 4.24MB/s]\n     31%|â–ˆâ–ˆâ–ˆ       | 1.92M/6.23M [00:00<00:00, 7.34MB/s]\n     56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3.52M/6.23M [00:00<00:00, 10.9MB/s]\n     73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4.57M/6.23M [00:00<00:00, 10.9MB/s]\n     91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5.67M/6.23M [00:00<00:00, 11.0MB/s]\n    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 9.64MB/s]\n    ...\n    ...생략\n    ...\n                      sink        128          6      0.419      0.253      0.336      0.232\n              refrigerator        128          5      0.342        0.4      0.553      0.425\n                      book        128         29      0.462      0.172      0.301      0.146\n                     clock        128          9      0.815      0.889      0.893      0.725\n                      vase        128          2      0.354          1      0.828      0.679\n                  scissors        128          1          1          0      0.332      0.073\n                teddy bear        128         21      0.883      0.361      0.577      0.354\n                toothbrush        128          5      0.561        0.2      0.678      0.416\n    Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 0.6ms postprocess per image\n    Results saved to [1mruns/detect/train[0m\n    ```\n    \n\n## ⚠️ Shared Memory(shm) Error\n\n---\n\n학습 파이프라인 실행 시 배치사이즈를 크게 설정했을 때, 아래와 같은 에러가 발생할 수 있습니다.\n\n```bash\nERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n```\n\n- log\n    \n    ```bash\n    Downloading \n    https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n     to 'yolov8n.pt'...\n      0%|          | 0.00/6.23M [00:00<?, ?B/s]  1%|▏         | 80.0k/6.23M [00:00<00:12, 502kB/s]  3%|▎         | 192k/6.23M [00:00<00:08, 708kB/s]   4%|▍         | 272k/6.23M [00:00<00:08, 698kB/s]  6%|▌         | 368k/6.23M [00:00<00:08, 767kB/s]  7%|▋         | 464k/6.23M [00:00<00:07, 824kB/s]  9%|▉         | 576k/6.23M [00:00<00:06, 881kB/s] 11%|█         | 688k/6.23M [00:00<00:06, 950kB/s] 13%|█▎        | 800k/6.23M [00:00<00:05, 1.00MB/s] 14%|█▍        | 912k/6.23M [00:01<00:05, 1.03MB/s] 16%|█▌        | 0.99M/6.23M [00:01<00:05, 954kB/s] 18%|█▊        | 1.11M/6.23M [00:01<00:05, 1.00MB/s] 19%|█▉        | 1.21M/6.23M [00:01<00:05, 1.00MB/s] 21%|██        | 1.31M/6.23M [00:01<00:05, 976kB/s]  23%|██▎       | 1.41M/6.23M [00:01<00:05, 977kB/s] 24%|██▍       | 1.52M/6.23M [00:01<00:04, 1.00MB/s] 26%|██▋       | 1.64M/6.23M [00:01<00:04, 1.02MB/s] 28%|██▊       | 1.77M/6.23M [00:01<00:04, 1.08MB/s] 31%|███       | 1.91M/6.23M \n      ...\n      ...생략   \n      ...\n     21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n     22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n    Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n    Transferred 355/355 items from pretrained weights\n    [34m[1mTensorBoard: [0mStart with 'tensorboard --logdir runs/detect/train', view at \n    http://localhost:6006/\n    Freezing layer 'model.22.dfl.conv.weight'\n    [34m[1mAMP: [0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n    [34m[1mAMP: [0mchecks passed ✅\n    [34m[1mtrain: [0mScanning /workspace/datasets/coco128/labels/train2017...:   0%|          | 0/128 [00:00<?, ?it/s][34m[1mtrain: [0mScanning /workspace/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<00:00, 1857.43it/s]\n    [34m[1mtrain: [0mNew cache created: /workspace/datasets/coco128/labels/train2017.cache\n    [34m[1mval: [0mScanning /workspace/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s][34m[1mval: [0mScanning /workspace/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n    ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n    ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n    ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n    ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n    ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n    DataLoader worker (pid 147) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n    ```\n    \n\n위 에러는 컨테이너 내부 통신 시 공유 메모리가 부족할 때 발생하는 에러입니다.\n\n도커 컨테이너 안에서 부족한 공유메모리를 재 설정 해야합니다.\n\n이를 해결하기 위해 3가지 방법이 있습니다.\n\n1. `privileged: true` 컨테이너 안에서 호스트의 리눅스 커널 기능을 사용해 자원에 접근(특권 모드)\n2. `hostIPC: true` 호스트 시스템의 IPC Namespace를 활용합니다.\n3. 호스트의 `shm`을 마운트해 사이즈 조정\n\n\n> 도커의 경우 호스트와 분리해 사용하기 위함입니다. 하지만 1번과 2번 방법의 경우 호스트에 접근하여 사용하기에 보안 문제를 일으킬 수 있습니다. 3번의 경우에도 호스트의 공유메모리에 접근하지만, 우선 테스트를 위해 3번의 방법을 사용합니다.\n{: .prompt-tip }\n\n\n> **(23.12.12작성)** Docker를 사용해 컨테이너를 운영할 경우 `--shm-size=256m` 과 같은 옵션으로 shm 사이즈를 조정할 수 있습니다.\n>하지만, 쿠버네티스는 이러한 옵션을 제공하지 않고 있어 다른 방법을 사용해야합니다.\n>→ 쿠버네티스의 메모리타입 emptyDir 마운트 방식을 통해 해결할 수 있습니다.\n{: .prompt-tip }\n\n- `yolov8_train.yaml` (다른 방법 권장)\n\n```yaml\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\n...생략\nspec:\n  entrypoint: yolov8-train\n  ...생략\n\tcontainer:\n\t\t...생략\n\t\timage: nohgyu/test:v1.0\n\t\t# 아래 volume 설정 추가\n\t\tvolumeMounts:\n    - mountPath: /dev/shm\n      name: dshm\n  volumes:\n  - name: dshm\n    emptyDir:\n      medium: Memory\n      sizeLimit: \"128M\"\n```\n\n- EmptyDir 생성 후 `/dev/shm` 마운트 **(23.12.12작성)**\n\n```python\n# shm-memory Resize(using EmptyDir)\n    shm_volume = V1Volume(name=\"dshm\", \n                          empty_dir = V1EmptyDirVolumeSource(medium='Memory', size_limit='1Gi'))\n    shm_pvolume = dsl.PipelineVolume(volume=shm_volume)\n    # Resize shm size\n    verifier.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    get_distribution.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    plotting.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    trainer.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    tester.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    raytuner.add_pvolumes({\"/dev/shm\":shm_pvolume})\n```\n\n![Untitled](/assets/img/kubeflow/kubepipe101.png)\n\n> Print device의 경우 GPU를 정상적으로 인식하는지 확인을 위해 추가한 컴포넌트입니다.\n{: .prompt-tip }\n\n- 학습 로그\n    \n    ```bash\n    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: \n    https://pip.pypa.io/warnings/venv\n    Downloading \n    https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n     to 'yolov8n.pt'...\n      0%|          | 0.00/6.23M [00:00<?, ?B/s]  3%|▎         | 216k/6.23M [00:00<00:02, 2.18MB/s] 15%|█▍        | 952k/6.23M [00:00<00:01, 5.29MB/s] 32%|███▏      | 1.98M/6.23M [00:00<00:00, 7.88MB/s] 44%|████▍     | 2.74M/6.23M [00:00<00:00, 7.51MB/s] 56%|█████▌    | 3.47M/6.23M [00:00<00:00, 7.54MB/s] 67%|██████▋   | 4.20M/6.23M [00:00<00:00, 7.24MB/s] 78%|███████▊  | 4.89M/6.23M [00:00<00:00, 7.04MB/s] 89%|████████▉ | 5.57M/6.23M [00:00<00:00, 6.82MB/s]100%|█████████▉| 6.23M/6.23M [00:00<00:00, 6.82MB/s]100%|██████████| 6.23M/6.23M [00:00<00:00, 6.86MB/s]\n    Ultralytics YOLOv8.0.218 🚀 Python-3.8.10 torch-1.13.0a0+936e930 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7972MiB)\n    WARNING ⚠️ Upgrade to torch>=2.0.0 for deterministic training.\n    [34m[1mengine/trainer: [0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n    Dataset 'coco128.yaml' images not found ⚠️, missing path '/workspace/datasets/coco128/images/train2017'\n    Downloading \n    https://ultralytics.com/assets/coco128.zip\n     to '/workspace/datasets/coco128.zip'...\n      0%|          | 0.00/6.66M [00:00<?, ?B/s]  3%|▎         | 176k/6.66M [00:00<00:03, 1.78MB/s] 13%|█▎        | 912k/6.66M [00:00<00:01, 5.13MB/s] 27%|██▋       | 1.78M/6.66M [00:00<00:00, 7.01MB/s] 39%|███▉      | 2.62M/6.66M [00:00<00:00, 7.72MB/s] 51%|█████     | 3.41M/6.66M [00:00<00:00, 7.87MB/s] 63%|██████▎   | 4.20M/6.66M [00:00<00:00, 8.00MB/s] 75%|███████▍  | 4.97M/6.66M [00:00<00:00, 7.33MB/s] 87%|████████▋ | 5.81M/6.66M [00:00<00:00, 7.78MB/s] 99%|█████████▊| 6.57M/6.66M [00:00<00:00, 7.01MB/s]100%|██████████| 6.66M/6.66M [00:00<00:00, 7.12MB/s]\n    Unzipping /workspace/datasets/coco128.zip to /workspace/datasets/coco128...:   0%|          | 0/263 [00:00<?, ?file/s]Unzipping /workspace/datasets/coco128.zip to /workspace/datasets/coco128...: 100%|██████████| 263/263 [00:00<00:00, 2913.97file/s]\n    Dataset download success ✅ (2.8s), saved to [1m/workspace/datasets[0m\n    Downloading \n    https://ultralytics.com/assets/Arial.ttf\n     to '/root/.config/Ultralytics/Arial.ttf'...\n      0%|          | 0.00/755k [00:00<?, ?B/s] 17%|█▋        | 128k/755k [00:00<00:00, 1.30MB/s] 40%|████      | 304k/755k [00:00<00:00, 1.45MB/s] 66%|██████▌   | 496k/755k [00:00<00:00, 1.56MB/s] 90%|█████████ | 680k/755k [00:00<00:00, 1.67MB/s]100%|██████████| 755k/755k [00:00<00:00, 1.63MB/s]\n                       from  n    params  module                                       arguments                     \n      0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n      1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n      2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n...(생략)\n                     Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 1/4 [00:00<00:00,  6.39it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|███████▌  | 3/4 [00:00<00:00,  8.20it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.67it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:00<00:00,  8.35it/s]\n    3 epochs completed in 0.035 hours.\n    Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n    Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n    Validating runs/detect/train/weights/best.pt...\n    Ultralytics YOLOv8.0.218 🚀 Python-3.8.10 torch-1.13.0a0+936e930 CUDA:0 (NVIDIA GeForce RTX 2080 SUPER, 7972MiB)\n    Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n                     Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/4 [00:00<?, ?it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  50%|█████     | 2/4 [00:01<00:01,  1.70it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  75%|███████▌  | 3/4 [00:01<00:00,  1.93it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.06it/s]                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]\n                       all        128        929       0.66      0.563       0.62      0.461\n                    person        128        254      0.802      0.681       0.77      0.549\n                   bicycle        128          6      0.558      0.333      0.317      0.264\n                       car        128         46      0.657      0.217       0.28       0.18\n                motorcycle        128          5      0.688          1      0.962      0.777\n                  airplane        128          6      0.714      0.667       0.83      0.616\n...생략\n                  scissors        128          1          1          0      0.199     0.0453\n                teddy bear        128         21          1      0.381      0.599      0.416\n                toothbrush        128          5      0.847        0.6      0.793      0.551\n    Speed: 2.4ms preprocess, 1.2ms inference, 0.0ms loss, 8.2ms postprocess per image\n    Results saved to [1mruns/detect/train[0m\n    ```\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Yolov8---pp_chunk_0",
        "text": "Yolov8 학습 파이프라인 실행\n\n# YOLOv8 파이프라인 실행\n\n---\n\n이전 문서에서 YOLOv8 학습 컴포넌트를 작성한 후 이를 실행시키기 위해 파이프라인을 작성하고, kubeflow에서 사용할 수 있도록 yaml로 변환했습니다.\n\n이번 문서에서는 yaml파일로 변환한 파이프라인을 Kubeflow 대쉬보드를 이용해 업로드하고 실행시켜보겠습니다.\n\n## Pipeline Upload\n\n---\n\n우선, 웹 UI에 접속하기 위해 포트포워딩을 합니다.\n\n```python\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\n### 좌측 탭에서 Pipelines 클릭 후 우측 상단의 Upload pipeline 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe108.png)\n\n### 내용 입력 후 Create 버튼 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe107.png)\n\n### 업로드 완료\n\n![Untitled](/assets/img/kubeflow/kubepipe106.png)\n\n> 파이프라인을 작성할 때, `Train` 컴포넌트만을 사용했기에 하나의 블럭만 표시됩니다.\n{: .prompt-info }\n\n## Pipeline Run\n\n---\n\n### Create run\n\n![Untitled](/assets/img/kubeflow/kubepipe105.png)\n\n### 내용 입력 후 Start\n\n![Untitled](/assets/img/kubeflow/kub",
        "index": 0
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_1",
        "text": "tled](/assets/img/kubeflow/kubepipe105.png)\n\n### 내용 입력 후 Start\n\n![Untitled](/assets/img/kubeflow/kubepipe104.png)\n### 실행 완료\n\n![Untitled](/assets/img/kubeflow/kubepipe103.png)\n\n>💡 정상적으로 학습을 진행했는지 log를 확인합니다.\n{: .prompt-info }\n\n![Untitled](/assets/img/kubeflow/kubepipe102.png)\n\n- main.log\n    \n    ```bash\n    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager.",
        "index": 1
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_2",
        "text": "t' user can result in broken permissions and conflicting behaviour with the system package manager.",
        "index": 2
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_3",
        "text": "t' user can result in broken permissions and conflicting behaviour with the system package manager.",
        "index": 3
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_4",
        "text": "t' user can result in broken permissions and conflicting behaviour with the system package manager.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-2MLflow------------------2",
    "title": "MLflow 학습 트래킹 및 아티팩트 저장 2",
    "path": "/2024/11/02/2MLflow-학습-트래킹-및-아티팩트-저장-2/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 문서는 YOLOv8 학습 파이프라인에 MLflow 학습 트래킹 및 아티팩트 저장에 대해 다룹니다.\n\n# MLflow\n\n---\n\n> MLflow는 대표적인 오픈소스 ML 실험 관리 도구입니다. \nMLflow는 실험 관리 용도 외에도 ML 모델 패키징, 배포 관리, 저장과 같은 기능도 제공합니다.<br>\n[Setup Components(MLflow Tracking Server)](https://knowgyu.github.io/posts/Setup-Components(MLflow-Tracking-Server)/)\n\n## YOLOv8 with MLflow\n\n---\n\nYOLOv8의 경우 사용하는 파이썬 환경에 `mlflow` 패키지가 설치되어 있다면, 자동으로 인식하여 학습 트래킹 및 아티팩트를 저장합니다. \n\n**단,** 기존에 구축한 MLflow Tracking Server로 로깅하도록 **환경변수를 설정**해줘야 합니다.\n\n> MLFLOW_TRACKING_URI: The URI for MLflow tracking. If not set, defaults to 'runs/mlflow'. MLFLOW_EXPERIMENT_NAME: The name of the MLflow experiment. If not set, defaults to trainer.args.project. MLFLOW_RUN: The name of the MLflow run. If not set, defaults to trainer.args.name.\n\n[https://docs.ultralytics.com/reference/utils/callbacks/mlflow/](https://docs.ultralytics.com/reference/utils/callbacks/mlflow/)\n\n### Components\n\n- `verify_train` 컴포넌트\n\n```python\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.0\",\n)\ndef verify_training() -> bool:\n    import torch\n    \n    print(torch.cuda.is_available())\n    print(torch.cuda.get_device_name())\n    print(torch.cuda.device_count())\n    \n    return torch.cuda.is_available()\n```\n\n- `train` 컴포넌트\n\n```python\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.0\",\n    packages_to_install=[\"ultralytics\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n)\ndef train(\n    CUDA_AVAIL: bool,\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n        ):\n    import os\n    from ultralytics import YOLO\n    import mlflow\n    \n    if not CUDA_AVAIL:\n        print(\"CUDA is not available.\\nPlease Check GPU Device\")\n        return None\n    \n    os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n\n    model = YOLO(model_name)    \n    results = model.train(data='coco128.yaml', epochs=epochs, imgsz=imgsz, batch=batchsize)\n```\n\n### Pipeline\n\n```python\n@pipeline(name=\"yolov8withmlflow\")\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n    ):\n\n    check = verify_training()\n    train(\n        check.output, model_name, epochs, imgsz, batchsize\n        ).set_display_name(\"YOLOv8 test training\")\n```\n\n## Conclusion\n\n---\n\n지금까지의 코드를 정리하면 아래와 같습니다.\n\n```python\nfrom functools import partial\n\nimport kfp\nfrom kfp.components import create_component_from_func\nfrom kfp.dsl import pipeline\n\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.0\",\n)\ndef verify_training() -> bool:\n    import torch\n    \n    print(torch.cuda.is_available())\n    print(torch.cuda.get_device_name())\n    print(torch.cuda.device_count())\n    \n    return torch.cuda.is_available()\n    \n    \n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.0\",\n    packages_to_install=[\"ultralytics\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n)\ndef train(\n    checker: bool,\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n        ):\n    import os\n    from ultralytics import YOLO\n    import mlflow\n    \n    if not checker:\n        print(\"CUDA is not available.\\nPlease Check GPU Device\")\n        return None\n    \n    os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n\n    model = YOLO(model_name)    \n    results = model.train(data='coco128.yaml', epochs=epochs, imgsz=imgsz, batch=batchsize)\n    \n\n@pipeline(name=\"yolov8withmlflow\")\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n    ):\n\n    check = verify_training()\n    train(\n        check.output, model_name, epochs, imgsz, batchsize\n        ).set_display_name(\"YOLOv8 test training\")\n\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(train_pipeline, \"yolov8withmlflow.yaml\")\n```\n\n- `yolov8withmlflow.yaml`\n    \n    ```yaml\n    apiVersion: argoproj.io/v1alpha1\n    kind: Workflow\n    metadata:\n      generateName: yolov8withmlflow-\n      annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9, pipelines.kubeflow.org/pipeline_compilation_time: '2023-11-28T17:00:07.869752',\n        pipelines.kubeflow.org/pipeline_spec: '{\"inputs\": [{\"name\": \"model_name\", \"type\":\n          \"String\"}, {\"name\": \"epochs\", \"type\": \"Integer\"}, {\"name\": \"imgsz\", \"type\":\n          \"Integer\"}, {\"name\": \"batchsize\", \"type\": \"Integer\"}], \"name\": \"yolov8withmlflow\"}'}\n      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9}\n    spec:\n      entrypoint: yolov8withmlflow\n      templates:\n      - name: train\n        container:\n          args: [--checker, '{{inputs.parameters.verify-training-Output}}', --model-name,\n            '{{inputs.parameters.model_name}}', --epochs, '{{inputs.parameters.epochs}}',\n            --imgsz, '{{inputs.parameters.imgsz}}', --batchsize, '{{inputs.parameters.batchsize}}']\n          command:\n          - sh\n          - -c\n          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n            'ultralytics' 'opencv-python==4.8.0.74' 'mlflow' 'boto3' || PIP_DISABLE_PIP_VERSION_CHECK=1\n            python3 -m pip install --quiet --no-warn-script-location 'ultralytics' 'opencv-python==4.8.0.74'\n            'mlflow' 'boto3' --user) && \"$0\" \"$@\"\n          - sh\n          - -ec\n          - |\n            program_path=$(mktemp)\n            printf \"%s\" \"$0\" > \"$program_path\"\n            python3 -u \"$program_path\" \"$@\"\n          - \"def train(\\n    checker,\\n    model_name,\\n    epochs,\\n    imgsz,\\n    batchsize,\\n\\\n            \\        ):\\n    import os\\n    from ultralytics import YOLO\\n    import mlflow\\n\\\n            \\n    if not checker:\\n        print(\\\"CUDA is not available.\\\\nPlease Check\\\n            \\ GPU Device\\\")\\n        return None\\n\\n    os.environ[\\\"MLFLOW_TRACKING_URI\\\"\\\n            ] = \\\"http://mlflow-server-service.mlflow-system.svc:5000\\\"\\n    os.environ[\\\"\\\n            MLFLOW_S3_ENDPOINT_URL\\\"] = \\\"http://minio-service.kubeflow.svc:9000\\\"\\n \\\n            \\   os.environ[\\\"AWS_ACCESS_KEY_ID\\\"] = \\\"minio\\\"\\n    os.environ[\\\"AWS_SECRET_ACCESS_KEY\\\"\\\n            ] = \\\"minio123\\\"\\n\\n    model = YOLO(model_name)    \\n    results = model.train(data='coco128.yaml',\\\n            \\ epochs=epochs, imgsz=imgsz, batch=batchsize)\\n\\ndef _deserialize_bool(s)\\\n            \\ -> bool:\\n    from distutils.util import strtobool\\n    return strtobool(s)\\\n            \\ == 1\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog='Train',\\\n            \\ description='')\\n_parser.add_argument(\\\"--checker\\\", dest=\\\"checker\\\", type=_deserialize_bool,\\\n            \\ required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--model-name\\\"\\\n            , dest=\\\"model_name\\\", type=str, required=True, default=argparse.SUPPRESS)\\n\\\n            _parser.add_argument(\\\"--epochs\\\", dest=\\\"epochs\\\", type=int, required=True,\\\n            \\ default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--imgsz\\\", dest=\\\"imgsz\\\"\\\n            , type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"\\\n            --batchsize\\\", dest=\\\"batchsize\\\", type=int, required=True, default=argparse.SUPPRESS)\\n\\\n            _parsed_args = vars(_parser.parse_args())\\n\\n_outputs = train(**_parsed_args)\\n\"\n          image: nohgyu/test:v1.0\n        inputs:\n          parameters:\n          - {name: batchsize}\n          - {name: epochs}\n          - {name: imgsz}\n          - {name: model_name}\n          - {name: verify-training-Output}\n        metadata:\n          annotations: {pipelines.kubeflow.org/task_display_name: YOLOv8 test training,\n            pipelines.kubeflow.org/component_spec: '{\"implementation\": {\"container\": {\"args\":\n              [\"--checker\", {\"inputValue\": \"checker\"}, \"--model-name\", {\"inputValue\":\n              \"model_name\"}, \"--epochs\", {\"inputValue\": \"epochs\"}, \"--imgsz\", {\"inputValue\":\n              \"imgsz\"}, \"--batchsize\", {\"inputValue\": \"batchsize\"}], \"command\": [\"sh\",\n              \"-c\", \"(PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n              ''ultralytics'' ''opencv-python==4.8.0.74'' ''mlflow'' ''boto3'' || PIP_DISABLE_PIP_VERSION_CHECK=1\n              python3 -m pip install --quiet --no-warn-script-location ''ultralytics''\n              ''opencv-python==4.8.0.74'' ''mlflow'' ''boto3'' --user) && \\\"$0\\\" \\\"$@\\\"\",\n              \"sh\", \"-ec\", \"program_path=$(mktemp)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path\\\"\\npython3\n              -u \\\"$program_path\\\" \\\"$@\\\"\\n\", \"def train(\\n    checker,\\n    model_name,\\n    epochs,\\n    imgsz,\\n    batchsize,\\n        ):\\n    import\n              os\\n    from ultralytics import YOLO\\n    import mlflow\\n\\n    if not checker:\\n        print(\\\"CUDA\n              is not available.\\\\nPlease Check GPU Device\\\")\\n        return None\\n\\n    os.environ[\\\"MLFLOW_TRACKING_URI\\\"]\n              = \\\"http://mlflow-server-service.mlflow-system.svc:5000\\\"\\n    os.environ[\\\"MLFLOW_S3_ENDPOINT_URL\\\"]\n              = \\\"http://minio-service.kubeflow.svc:9000\\\"\\n    os.environ[\\\"AWS_ACCESS_KEY_ID\\\"]\n              = \\\"minio\\\"\\n    os.environ[\\\"AWS_SECRET_ACCESS_KEY\\\"] = \\\"minio123\\\"\\n\\n    model\n              = YOLO(model_name)    \\n    results = model.train(data=''coco128.yaml'',\n              epochs=epochs, imgsz=imgsz, batch=batchsize)\\n\\ndef _deserialize_bool(s)\n              -> bool:\\n    from distutils.util import strtobool\\n    return strtobool(s)\n              == 1\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=''Train'',\n              description='''')\\n_parser.add_argument(\\\"--checker\\\", dest=\\\"checker\\\",\n              type=_deserialize_bool, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--model-name\\\",\n              dest=\\\"model_name\\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--epochs\\\",\n              dest=\\\"epochs\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--imgsz\\\",\n              dest=\\\"imgsz\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--batchsize\\\",\n              dest=\\\"batchsize\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parsed_args\n              = vars(_parser.parse_args())\\n\\n_outputs = train(**_parsed_args)\\n\"], \"image\":\n              \"nohgyu/test:v1.0\"}}, \"inputs\": [{\"name\": \"checker\", \"type\": \"Boolean\"},\n              {\"name\": \"model_name\", \"type\": \"String\"}, {\"name\": \"epochs\", \"type\": \"Integer\"},\n              {\"name\": \"imgsz\", \"type\": \"Integer\"}, {\"name\": \"batchsize\", \"type\": \"Integer\"}],\n              \"name\": \"Train\"}', pipelines.kubeflow.org/component_ref: '{}', pipelines.kubeflow.org/arguments.parameters: '{\"batchsize\":\n              \"{{inputs.parameters.batchsize}}\", \"checker\": \"{{inputs.parameters.verify-training-Output}}\",\n              \"epochs\": \"{{inputs.parameters.epochs}}\", \"imgsz\": \"{{inputs.parameters.imgsz}}\",\n              \"model_name\": \"{{inputs.parameters.model_name}}\"}'}\n          labels:\n            pipelines.kubeflow.org/kfp_sdk_version: 1.8.9\n            pipelines.kubeflow.org/pipeline-sdk-type: kfp\n            pipelines.kubeflow.org/enable_caching: \"true\"\n      - name: verify-training\n        container:\n          args: ['----output-paths', /tmp/outputs/Output/data]\n          command:\n          - sh\n          - -ec\n          - |\n            program_path=$(mktemp)\n            printf \"%s\" \"$0\" > \"$program_path\"\n            python3 -u \"$program_path\" \"$@\"\n          - |\n            def verify_training():\n                import torch\n    \n                print(torch.cuda.is_available())\n                print(torch.cuda.get_device_name())\n                print(torch.cuda.device_count())\n    \n                return torch.cuda.is_available()\n    \n            def _serialize_bool(bool_value: bool) -> str:\n                if isinstance(bool_value, str):\n                    return bool_value\n                if not isinstance(bool_value, bool):\n                    raise TypeError('Value \"{}\" has type \"{}\" instead of bool.'.format(\n                        str(bool_value), str(type(bool_value))))\n                return str(bool_value)\n    \n            import argparse\n            _parser = argparse.ArgumentParser(prog='Verify training', description='')\n            _parser.add_argument(\"----output-paths\", dest=\"_output_paths\", type=str, nargs=1)\n            _parsed_args = vars(_parser.parse_args())\n            _output_files = _parsed_args.pop(\"_output_paths\", [])\n    \n            _outputs = verify_training(**_parsed_args)\n    \n            _outputs = [_outputs]\n    \n            _output_serializers = [\n                _serialize_bool,\n    \n            ]\n    \n            import os\n            for idx, output_file in enumerate(_output_files):\n                try:\n                    os.makedirs(os.path.dirname(output_file))\n                except OSError:\n                    pass\n                with open(output_file, 'w') as f:\n                    f.write(_output_serializers[idx](_outputs[idx]))\n          image: nohgyu/test:v1.0\n        outputs:\n          parameters:\n          - name: verify-training-Output\n            valueFrom: {path: /tmp/outputs/Output/data}\n          artifacts:\n          - {name: verify-training-Output, path: /tmp/outputs/Output/data}\n        metadata:\n          labels:\n            pipelines.kubeflow.org/kfp_sdk_version: 1.8.9\n            pipelines.kubeflow.org/pipeline-sdk-type: kfp\n            pipelines.kubeflow.org/enable_caching: \"true\"\n          annotations: {pipelines.kubeflow.org/component_spec: '{\"implementation\": {\"container\":\n              {\"args\": [\"----output-paths\", {\"outputPath\": \"Output\"}], \"command\": [\"sh\",\n              \"-ec\", \"program_path=$(mktemp)\\nprintf \\\"%s\\\" \\\"$0\\\" > \\\"$program_path\\\"\\npython3\n              -u \\\"$program_path\\\" \\\"$@\\\"\\n\", \"def verify_training():\\n    import torch\\n\\n    print(torch.cuda.is_available())\\n    print(torch.cuda.get_device_name())\\n    print(torch.cuda.device_count())\\n\\n    return\n              torch.cuda.is_available()\\n\\ndef _serialize_bool(bool_value: bool) -> str:\\n    if\n              isinstance(bool_value, str):\\n        return bool_value\\n    if not isinstance(bool_value,\n              bool):\\n        raise TypeError(''Value \\\"{}\\\" has type \\\"{}\\\" instead of\n              bool.''.format(\\n            str(bool_value), str(type(bool_value))))\\n    return\n              str(bool_value)\\n\\nimport argparse\\n_parser = argparse.ArgumentParser(prog=''Verify\n              training'', description='''')\\n_parser.add_argument(\\\"----output-paths\\\",\n              dest=\\\"_output_paths\\\", type=str, nargs=1)\\n_parsed_args = vars(_parser.parse_args())\\n_output_files\n              = _parsed_args.pop(\\\"_output_paths\\\", [])\\n\\n_outputs = verify_training(**_parsed_args)\\n\\n_outputs\n              = [_outputs]\\n\\n_output_serializers = [\\n    _serialize_bool,\\n\\n]\\n\\nimport\n              os\\nfor idx, output_file in enumerate(_output_files):\\n    try:\\n        os.makedirs(os.path.dirname(output_file))\\n    except\n              OSError:\\n        pass\\n    with open(output_file, ''w'') as f:\\n        f.write(_output_serializers[idx](_outputs[idx]))\\n\"],\n              \"image\": \"nohgyu/test:v1.0\"}}, \"name\": \"Verify training\", \"outputs\": [{\"name\":\n              \"Output\", \"type\": \"Boolean\"}]}', pipelines.kubeflow.org/component_ref: '{}'}\n      - name: yolov8withmlflow\n        inputs:\n          parameters:\n          - {name: batchsize}\n          - {name: epochs}\n          - {name: imgsz}\n          - {name: model_name}\n        dag:\n          tasks:\n          - name: train\n            template: train\n            dependencies: [verify-training]\n            arguments:\n              parameters:\n              - {name: batchsize, value: '{{inputs.parameters.batchsize}}'}\n              - {name: epochs, value: '{{inputs.parameters.epochs}}'}\n              - {name: imgsz, value: '{{inputs.parameters.imgsz}}'}\n              - {name: model_name, value: '{{inputs.parameters.model_name}}'}\n              - {name: verify-training-Output, value: '{{tasks.verify-training.outputs.parameters.verify-training-Output}}'}\n          - {name: verify-training, template: verify-training}\n      arguments:\n        parameters:\n        - {name: model_name}\n        - {name: epochs}\n        - {name: imgsz}\n        - {name: batchsize}\n      serviceAccountName: pipeline-runner\n    ```\n    \n\n# 결과 확인\n\n---\n\n- 파이프라인 실행 결과\n\n![Untitled](/assets/img/kubeflow/kubepipe303.png)\n\n- MLflow\n\n![Untitled](/assets/img/kubeflow/kubepipe302.png)\n\n- MLflow artifacts\n\n![Untitled](/assets/img/kubeflow/kubepipe301.png)\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-2MLflow------------------2_chunk_0",
        "text": "MLflow 학습 트래킹 및 아티팩트 저장 2\n\n본 문서는 YOLOv8 학습 파이프라인에 MLflow 학습 트래킹 및 아티팩트 저장에 대해 다룹니다.\n\n# MLflow\n\n---\n\n> MLflow는 대표적인 오픈소스 ML 실험 관리 도구입니다. \nMLflow는 실험 관리 용도 외에도 ML 모델 패키징, 배포 관리, 저장과 같은 기능도 제공합니다.<br>\n[Setup Components(MLflow Tracking Server)](https://knowgyu.github.io/posts/Setup-Components(MLflow-Tracking-Server)/)\n\n## YOLOv8 with MLflow\n\n---\n\nYOLOv8의 경우 사용하는 파이썬 환경에 `mlflow` 패키지가 설치되어 있다면, 자동으로 인식하여 학습 트래킹 및 아티팩트를 저장합니다. \n\n**단,** 기존에 구축한 MLflow Tracking Server로 로깅하도록 **환경변수를 설정**해줘야 합니다.\n\n> MLFLOW_TRACKING_URI: The URI for MLflow tracking. If not set, defaults to 'runs/mlflow'. MLFLOW_EXPERIMENT_NAME: The name of the MLflow experiment. If not set, defaults to trainer.args.project. MLFLOW_RUN: The name of the MLflow run.",
        "index": 0
      },
      {
        "id": "2024-11-02-2MLflow------------------2_chunk_1",
        "text": "w experiment. If not set, defaults to trainer.args.project. MLFLOW_RUN: The name of the MLflow run.",
        "index": 1
      },
      {
        "id": "2024-11-02-2MLflow------------------2_chunk_2",
        "text": "w experiment. If not set, defaults to trainer.args.project. MLFLOW_RUN: The name of the MLflow run.",
        "index": 2
      },
      {
        "id": "2024-11-02-2MLflow------------------2_chunk_3",
        "text": "w experiment. If not set, defaults to trainer.args.project. MLFLOW_RUN: The name of the MLflow run.",
        "index": 3
      },
      {
        "id": "2024-11-02-2MLflow------------------2_chunk_4",
        "text": "w experiment. If not set, defaults to trainer.args.project. MLFLOW_RUN: The name of the MLflow run.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Yolov8---pp",
    "title": "Yolov8 학습 파이프라인 작성",
    "path": "/2024/11/02/Yolov8-학습pp작성/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# YOLOv8\n\n---\n\nYOLOv7 학습 파이프라인을 구축하기 전, YOLOv8을 이용해 학습 파이프라인을 구축합니다.\n\nYOLOv8은 기존의 YOLO 버전들과 다르게, `pip`를 통해 간단하게 설치 및 사용이 가능합니다.\n\n- 학습 예시 코드\n\n```python\n!pip install ultralytics\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n.pt')\nmodel.train()\n```\n\n## Components\n\n---\n\n이전의 글에서 다뤘듯, Kubeflow를 사용하기 위해선 컴포넌트와 파이프라인을 작성해야 합니다.\n\n### Components Contents\n\n1. Environment\n\n```python\nfrom ultralytics import YOLO\n```\n\n> 단, pyTorch와 GPU사용을 위한 CUDA, Cudnn이 설치되어야합니다.\n{: .prompt-info }\n\n1. Python code with Config\n\n```python\nmodel = YOLO('yolov8n.pt')\nresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n```\n\n1. Generate Artifacts\n\n```python\n\n# 본 예제에서는 다루지 않겠습니다.\n\n```\n\n### Components Wrapper\n\n이제, 컴포넌트 콘텐츠를 컴포넌트 래퍼로 감싸고, Kubeflow 형식으로 변환하면 아래와 같습니다.\n\n```python\nfrom kfp.components import create_component_from_func\n\n@create_component_from_func\ndef train(\n\tdata: str,\n\tepochs: int,\n\timgsz: int,\n\tbatch: int,\n)\n\tfrom ultralytics import YOLO\n\n\tmodel = YOLO('yolov8n.pt')\n\tresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n\n```\n\n>⚠️ 현재 콘테이너 이미지는 python:3.7로, pyTorch와 CUDA가 설치되어있지 않습니다.\n>이를 해결하기 위해 pyTorch와 CUDA가 설치있는 이미지를 기본 이미지로 지정하고,\n>ultralytics를 설치한 환경을 구성해야합니다.\n{: .prompt-warning }\n\n```python\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.0\",\n    packages_to_install=[\"ultralytics\",\"opencv-python==4.8.0.74\"],\n)\ndef train(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n        ):\n    from ultralytics import YOLO\n\n    model = YOLO(model_name)\n    \n    results = model.train(data='coco128.yaml', epochs=epochs, imgsz=imgsz, batch=batchsize)\n```\n\n> base_image로 Ubuntu20.04 CUDA11.8 pyTorch 1.13을 사용합니다.\n{: .prompt-info }\n\n- Dockerfile\n    \n    ```python\n    # Ubuntu20.04 CUDA11.8 pyTorch 1.13 https://docs.nvidia.com/deeplearning/frameworks/pdf/PyTorch-Release-Notes.pdf\n    FROM nvcr.io/nvidia/pytorch:22.11-py3\n    \n    RUN rm -f /etc/apt/source.list.d/*.list\n    ENV DEBIAN_FRONTEND=noninteractive\n    \n    RUN apt-get -y update && apt-get install -y \\ \n    \tgit \\\n    \tlibgl1-mesa-glx \\\n    \tlibglib2.0-0 \\\n    \tbuild-essential \\\n    \tsudo \\\n        wget \\\n        curl \\\n        vim \\\n        apt-utils \\\n        python3-pip \\\n        python-is-python3 && \\\n        rm -rf /var/lib/apt/lists/*\n    \n    ENV TZ=Asia/Seoul\n    ENV PIP_ROOT_USER_ACTION=ignore\n    \n    RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone\n    ```\n    \n\n## Pipeline\n\n---\n\n컴포넌트를 실행하기 위해 파이프라인을 작성하겠습니다.\n\n```python\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n                ):\n    train(model_name, epochs, imgsz, batchsize)\n```\n\n### Convert to Kubeflow Format\n\n이제, Kubeflow에서 사용할 수 있는 형식으로 변환합니다.\n\n```python\nfrom kfp.dsl import pipeline\n\n@pipeline(name='yolov8_train')\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n                ):\n    train(model_name, epochs, imgsz, batchsize)\n\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(train_pipeline, \"yolov8_train.yaml\")\n```\n\n## Conclusion\n\n---\n\n지금까지의 코드를 정리하면 아래와 같습니다.\n\n```python\nfrom functools import partial\n\nimport kfp\nfrom kfp.components import create_component_from_func, OutputPath\nfrom kfp.dsl import pipeline\n\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.0\",\n    packages_to_install=[\"ultralytics\",\"opencv-python==4.8.0.74\"],\n)\ndef train(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n        ):\n    from ultralytics import YOLO\n\n    model = YOLO(model_name)\n    \n    results = model.train(data='coco128.yaml', epochs=epochs, imgsz=imgsz, batch=batchsize)\n    \n\n@pipeline(name=\"yolov8_train\")\ndef train_pipeline(\n    model_name: str,\n    epochs: int,\n    imgsz: int,\n    batchsize: int,\n                ):\n    train(model_name, epochs, imgsz, batchsize)\n\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(train_pipeline, \"yolov8_train.yaml\")\n```\n<br><br><br>\n\n아래와 같은 `yaml`파일이 생성됩니다.\n- `yolov8_train.yaml`\n    \n    ```python\n    apiVersion: argoproj.io/v1alpha1\n    kind: Workflow\n    metadata:\n      generateName: yolov8-train-\n      annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9, pipelines.kubeflow.org/pipeline_compilation_time: '2023-11-27T11:49:43.249375',\n        pipelines.kubeflow.org/pipeline_spec: '{\"inputs\": [{\"name\": \"model_name\", \"type\":\n          \"String\"}, {\"name\": \"epochs\", \"type\": \"Integer\"}, {\"name\": \"imgsz\", \"type\":\n          \"Integer\"}, {\"name\": \"batchsize\", \"type\": \"Integer\"}], \"name\": \"yolov8_train\"}'}\n      labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.9}\n    spec:\n      entrypoint: yolov8-train\n      templates:\n      - name: train\n        container:\n          args: [--model-name, '{{inputs.parameters.model_name}}', --epochs, '{{inputs.parameters.epochs}}',\n            --imgsz, '{{inputs.parameters.imgsz}}', --batchsize, '{{inputs.parameters.batchsize}}']\n          command:\n          - sh\n          - -c\n          - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location\n            'ultralytics' 'opencv-python==4.8.0.74' || PIP_DISABLE_PIP_VERSION_CHECK=1\n            python3 -m pip install --quiet --no-warn-script-location 'ultralytics' 'opencv-python==4.8.0.74'\n            --user) && \"$0\" \"$@\"\n          - sh\n          - -ec\n          - |\n            program_path=$(mktemp)\n            printf \"%s\" \"$0\" > \"$program_path\"\n            python3 -u \"$program_path\" \"$@\"\n          - |\n            def train(\n                model_name,\n                epochs,\n                imgsz,\n                batchsize,\n                    ):\n                from ultralytics import YOLO\n    \n                model = YOLO(model_name)\n    \n                results = model.train(data='coco128.yaml', epochs=epochs, imgsz=imgsz, batch=batchsize)\n    \n            import argparse\n            _parser = argparse.ArgumentParser(prog='Train', description='')\n            _parser.add_argument(\"--model-name\", dest=\"model_name\", type=str, required=True, default=argparse.SUPPRESS)\n            _parser.add_argument(\"--epochs\", dest=\"epochs\", type=int, required=True, default=argparse.SUPPRESS)\n            _parser.add_argument(\"--imgsz\", dest=\"imgsz\", type=int, required=True, default=argparse.SUPPRESS)\n            _parser.add_argument(\"--batchsize\", dest=\"batchsize\", type=int, required=True, default=argparse.SUPPRESS)\n            _parsed_args = vars(_parser.parse_args())\n    \n            _outputs = train(**_parsed_args)\n          image: nohgyu/test:v1.0\n        inputs:\n          parameters:\n          - {name: batchsize}\n          - {name: epochs}\n          - {name: imgsz}\n          - {name: model_name}\n        metadata:\n          labels:\n            pipelines.kubeflow.org/kfp_sdk_version: 1.8.9\n            pipelines.kubeflow.org/pipeline-sdk-type: kfp\n            pipelines.kubeflow.org/enable_caching: \"true\"\n          annotations: {pipelines.kubeflow.org/component_spec: '{\"implementation\": {\"container\":\n              {\"args\": [\"--model-name\", {\"inputValue\": \"model_name\"}, \"--epochs\", {\"inputValue\":\n              \"epochs\"}, \"--imgsz\", {\"inputValue\": \"imgsz\"}, \"--batchsize\", {\"inputValue\":\n              \"batchsize\"}], \"command\": [\"sh\", \"-c\", \"(PIP_DISABLE_PIP_VERSION_CHECK=1\n              python3 -m pip install --quiet --no-warn-script-location ''ultralytics''\n              ''opencv-python==4.8.0.74'' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m\n              pip install --quiet --no-warn-script-location ''ultralytics'' ''opencv-python==4.8.0.74''\n              --user) && \\\"$0\\\" \\\"$@\\\"\", \"sh\", \"-ec\", \"program_path=$(mktemp)\\nprintf\n              \\\"%s\\\" \\\"$0\\\" > \\\"$program_path\\\"\\npython3 -u \\\"$program_path\\\" \\\"$@\\\"\\n\",\n              \"def train(\\n    model_name,\\n    epochs,\\n    imgsz,\\n    batchsize,\\n        ):\\n    from\n              ultralytics import YOLO\\n\\n    model = YOLO(model_name)\\n\\n    results =\n              model.train(data=''coco128.yaml'', epochs=epochs, imgsz=imgsz, batch=batchsize)\\n\\nimport\n              argparse\\n_parser = argparse.ArgumentParser(prog=''Train'', description='''')\\n_parser.add_argument(\\\"--model-name\\\",\n              dest=\\\"model_name\\\", type=str, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--epochs\\\",\n              dest=\\\"epochs\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--imgsz\\\",\n              dest=\\\"imgsz\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parser.add_argument(\\\"--batchsize\\\",\n              dest=\\\"batchsize\\\", type=int, required=True, default=argparse.SUPPRESS)\\n_parsed_args\n              = vars(_parser.parse_args())\\n\\n_outputs = train(**_parsed_args)\\n\"], \"image\":\n              \"nohgyu/test:v1.0\"}}, \"inputs\": [{\"name\": \"model_name\", \"type\": \"String\"},\n              {\"name\": \"epochs\", \"type\": \"Integer\"}, {\"name\": \"imgsz\", \"type\": \"Integer\"},\n              {\"name\": \"batchsize\", \"type\": \"Integer\"}], \"name\": \"Train\"}', pipelines.kubeflow.org/component_ref: '{}',\n            pipelines.kubeflow.org/arguments.parameters: '{\"batchsize\": \"{{inputs.parameters.batchsize}}\",\n              \"epochs\": \"{{inputs.parameters.epochs}}\", \"imgsz\": \"{{inputs.parameters.imgsz}}\",\n              \"model_name\": \"{{inputs.parameters.model_name}}\"}'}\n      - name: yolov8-train\n        inputs:\n          parameters:\n          - {name: batchsize}\n          - {name: epochs}\n          - {name: imgsz}\n          - {name: model_name}\n        dag:\n          tasks:\n          - name: train\n            template: train\n            arguments:\n              parameters:\n              - {name: batchsize, value: '{{inputs.parameters.batchsize}}'}\n              - {name: epochs, value: '{{inputs.parameters.epochs}}'}\n              - {name: imgsz, value: '{{inputs.parameters.imgsz}}'}\n              - {name: model_name, value: '{{inputs.parameters.model_name}}'}\n      arguments:\n        parameters:\n        - {name: model_name}\n        - {name: epochs}\n        - {name: imgsz}\n        - {name: batchsize}\n      serviceAccountName: pipeline-runner\n    ```\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Yolov8---pp_chunk_0",
        "text": "Yolov8 학습 파이프라인 작성\n\n# YOLOv8\n\n---\n\nYOLOv7 학습 파이프라인을 구축하기 전, YOLOv8을 이용해 학습 파이프라인을 구축합니다.\n\nYOLOv8은 기존의 YOLO 버전들과 다르게, `pip`를 통해 간단하게 설치 및 사용이 가능합니다.\n\n- 학습 예시 코드\n\n```python\n!pip install ultralytics\nfrom ultralytics import YOLO\n\nmodel = YOLO('yolov8n.pt')\nmodel.train()\n```\n\n## Components\n\n---\n\n이전의 글에서 다뤘듯, Kubeflow를 사용하기 위해선 컴포넌트와 파이프라인을 작성해야 합니다.\n\n### Components Contents\n\n1. Environment\n\n```python\nfrom ultralytics import YOLO\n```\n\n> 단, pyTorch와 GPU사용을 위한 CUDA, Cudnn이 설치되어야합니다.\n{: .prompt-info }\n\n1. Python code with Config\n\n```python\nmodel = YOLO('yolov8n.pt')\nresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n```\n\n1.",
        "index": 0
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_1",
        "text": "yolov8n.pt')\nresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n```\n\n1.",
        "index": 1
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_2",
        "text": "yolov8n.pt')\nresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n```\n\n1.",
        "index": 2
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_3",
        "text": "yolov8n.pt')\nresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n```\n\n1.",
        "index": 3
      },
      {
        "id": "2024-11-02-Yolov8---pp_chunk_4",
        "text": "yolov8n.pt')\nresult = model.train(data=data, epochs=epochs, imgsz=imgsz, batch=batch, ...등)\n```\n\n1.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02",
    "title": "YOLOv8 커스텀 데이터셋 학습 파이프라인",
    "path": "/2024/11/02/커스텀-데이터셋-학습-파이프라인/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Train YOLOv8 on a Custom Dataset\n\n---\n\n사용하려는 목적에 맞게 사전훈련된 모델을 학습시키는 것은 매우 중요합니다.\n\n이를 위해 Ultralytics, Roboflow 공식문서에서도 YOLOv8 모델을 커스텀 데이터셋에 학습시키는 문서들을 제공합니다.\n\n[https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#train-on-custom-data](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#train-on-custom-data)\n\n[https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/)\n\n쿠버네티스의 Pod들은 모두 컨테이너화되어 실행되므로 로컬의 볼륨과 독립적으로 실행됩니다.<br> \n따라서, 데이터셋을 인터넷 등에 업로드 후 git, curl과 같은 방식으로 다운로드받아 사용할 수 있으나, 크기가 큰 데이터셋의 경우 이와 같은 방법을 사용하기 어려울 것입니다.<br>\n\n도커 컨테이너의 경우 **마운트**를 통해 컨테이너에서 로컬의 볼륨에 접근하는데, 쿠버네티스에서도 **동일한 방법**을 사용합니다.<br>\n\n하지만, 쿠버네티스의 경우 Tightly Coupled를 피하기 위해 **PV/PVC, 그리고 CSI**라는 중계자를 두는 방법으로 마운트합니다.<br>\n\n본 테스크에선 파이프라인에서 PV/PVC를 이용해 노드 로컬 볼륨에 접근하고, 커스텀 데이터셋을 학습하는 파이프라인을 작성하겠습니다.<br>\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02_chunk_0",
        "text": "YOLOv8 커스텀 데이터셋 학습 파이프라인\n\n# Train YOLOv8 on a Custom Dataset\n\n---\n\n사용하려는 목적에 맞게 사전훈련된 모델을 학습시키는 것은 매우 중요합니다.\n\n이를 위해 Ultralytics, Roboflow 공식문서에서도 YOLOv8 모델을 커스텀 데이터셋에 학습시키는 문서들을 제공합니다.\n\n[https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#train-on-custom-data](https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/#train-on-custom-data)\n\n[https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/)\n\n쿠버네티스의 Pod들은 모두 컨테이너화되어 실행되므로 로컬의 볼륨과 독립적으로 실행됩니다.<br> \n따라서, 데이터셋을 인터넷 등에 업로드 후 git, curl과 같은 방식으로 다운로드받아 사용할 수 있으나, 크기가 큰 데이터셋의 경우 이와 같은 방법을 사용하기 어려울 것입니다.<br>\n\n도커 컨테이너의 경우 **마운트**를 통해 컨테이너에서 로컬의 볼륨에 접근하는데, 쿠버네티스에서도 **동일한 방법**을 사용합니다.<br>\n\n하지만, 쿠버네티스의 경우 Tightly Coupled를 피하기 위해 **PV/PVC, 그리고 CSI**라",
        "index": 0
      },
      {
        "id": "2024-11-02_chunk_1",
        "text": "접근하는데, 쿠버네티스에서도 **동일한 방법**을 사용합니다.<br>\n\n하지만, 쿠버네티스의 경우 Tightly Coupled를 피하기 위해 **PV/PVC, 그리고 CSI**라는 중계자를 두는 방법으로 마운트합니다.<br>\n\n본 테스크에선 파이프라인에서 PV/PVC를 이용해 노드 로컬 볼륨에 접근하고, 커스텀 데이터셋을 학습하는 파이프라인을 작성하겠습니다.<br>",
        "index": 1
      },
      {
        "id": "2024-11-02_chunk_2",
        "text": "두는 방법으로 마운트합니다.<br>\n\n본 테스크에선 파이프라인에서 PV/PVC를 이용해 노드 로컬 볼륨에 접근하고, 커스텀 데이터셋을 학습하는 파이프라인을 작성하겠습니다.<br>",
        "index": 2
      },
      {
        "id": "2024-11-02_chunk_3",
        "text": "두는 방법으로 마운트합니다.<br>\n\n본 테스크에선 파이프라인에서 PV/PVC를 이용해 노드 로컬 볼륨에 접근하고, 커스텀 데이터셋을 학습하는 파이프라인을 작성하겠습니다.<br>",
        "index": 3
      },
      {
        "id": "2024-11-02_chunk_4",
        "text": "두는 방법으로 마운트합니다.<br>\n\n본 테스크에선 파이프라인에서 PV/PVC를 이용해 노드 로컬 볼륨에 접근하고, 커스텀 데이터셋을 학습하는 파이프라인을 작성하겠습니다.<br>",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Pipeline",
    "title": "Pipeline 실행해보기",
    "path": "/2024/11/02/Pipeline-실행해보기/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\nKubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 함.\n\nPipeline 공식 문서 : [https://www.kubeflow.org/docs/components/pipelines/v1/overview/quickstart/](https://www.kubeflow.org/docs/components/pipelines/v1/overview/quickstart/)<br>\n\n## Component Component-Write\n\n**컴포넌트**는 **컴포넌트 콘텐츠**와 **컴포넌트 래퍼**로 구성됨.\n\n하나의 컴포넌트는 래퍼를 통해 kubeflow에 전달되며 전달된 컴포넌트는 정의된 컴포넌트 콘텐츠를 실행(execute)하고 아티팩트(artifacts)들을 생산\n\n### Component Contents\n\n컴포넌트 콘텐츠는 3개로 구성됨.\n\n1. Environment\n2. Python code with Config\n3. Generates Artifacts\n\nex) 데이터를 불러와 SVC를 학습한 후 SVC 모델을 저장하는 과정\n\n```python\nimport dill\nimport pandas as pd\n\nfrom sklearn.svm import SVC\n\ntrain_data = pd.read_csv(train_data_path)\ntrain_target= pd.read_csv(train_target_path)\n\nclf= SVC(\n    kernel=kernel\n)\nclf.fit(train_data)\n\nwith open(model_path, mode=\"wb\") as file_writer:\n     dill.dump(clf, file_writer)\n```\n\n1. Environment\n\n```python\nimport dill\nimport pandas as pd\n\nfrom sklearn.svm import SVC\n```\n\n1. Python code with Config\n\n```python\ntrain_data = pd.read_csv(train_data_path)\ntrain_target= pd.read_csv(train_target_path)\n\nclf= SVC(\n    **kernel=kernel** <--- Config\n)\nclf.fit(train_data)\n```\n\n1. Generates Artifacts\n\n```python\nwith open(model_path, mode=\"wb\") as file_writer:\n     dill.dump(clf, file_writer)\n```\n\n### Component Wrapper\n\n컴포넌트 래퍼는 컴포넌트 콘텐츠에 필요한 Config를 전달하고 실행시키는 작업을 함\n\nKubeflow에서는 컴포넌트 래퍼를 **함수의 형태**로 저장함.\n\n위 컴포넌트 콘텐츠를 컴포넌트 래퍼가 감싸면 아래와 같이 됨.\n\n```python\ndef train_svc_from_csv( ... ):\n\timport dill\n\t...생략\n\twith open(model_path, mode=\"wb\") as file_writer:\n\t     dill.dump(clf, file_writer)\n```\n\n## Artifacts\n\n아티팩트란 evaluation, result, log 등 어떤 형태든 파일로 생성되는 것을 통틀어서 칭함.\n\n**Model**\n\n파이썬 코드와 학습된 Weights와 Network 구조, 그리고 실행시키기 위한 환경\n\n**Data**\n\n전 처리된 피처, 모델의 예측 값 등\n\n**Metric**\n\n동적 지표 - train loss와 같이 학습 진행 중 계속 변화하는 값\n\n정적 지표 - 학습이 끝난 후 최종적으로 모델을 평가하는 정확도 등\n\n# Pipeline\n\n파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있음.\n\n순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n\n![Untitled](/assets/img/kubeflow/kubepipe501.png)\n\n## Pipeline Config\n\n컴포넌트를 실행시키기 위해서는 Config가 필요함. \n파이프라인을 구성하는 컴포넌트의 Config들을 모아 둔 것이 파이프라인 Config\n\n## Run\n\n파이프라인이 필요로 하는 파이프라인 Config가 주어져야지만 파이프라인을 실행할 수 있음.\n\nKubeflow에서는 실행된 파이프라인을 Run이라고 부름.\n\n파이프라인이 실행되면 각 컴포넌트가 아티팩트들을 생성.\n\nKubeflow pipeline에서는 Run 하나당 고유한 ID를 생성하고, Run에서 생성되는 모든 아티팩트를 저장\n\n![Untitled](/assets/img/kubeflow/kubepipe502.png)\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Pipeline_chunk_0",
        "text": "Pipeline 실행해보기\n\n# Kubeflow\n\n---\n\nKubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 함.\n\nPipeline 공식 문서 : [https://www.kubeflow.org/docs/components/pipelines/v1/overview/quickstart/](https://www.kubeflow.org/docs/components/pipelines/v1/overview/quickstart/)<br>\n\n## Component Component-Write\n\n**컴포넌트**는 **컴포넌트 콘텐츠**와 **컴포넌트 래퍼**로 구성됨.\n\n하나의 컴포넌트는 래퍼를 통해 kubeflow에 전달되며 전달된 컴포넌트는 정의된 컴포넌트 콘텐츠를 실행(execute)하고 아티팩트(artifacts)들을 생산\n\n### Component Contents\n\n컴포넌트 콘텐츠는 3개로 구성됨.\n\n1. Environment\n2. Python code with Config\n3.",
        "index": 0
      },
      {
        "id": "2024-11-02-Pipeline_chunk_1",
        "text": "cts)들을 생산\n\n### Component Contents\n\n컴포넌트 콘텐츠는 3개로 구성됨.\n\n1. Environment\n2. Python code with Config\n3. Generates Artifacts\n\nex) 데이터를 불러와 SVC를 학습한 후 SVC 모델을 저장하는 과정\n\n```python\nimport dill\nimport pandas as pd\n\nfrom sklearn.svm import SVC\n\ntrain_data = pd.read_csv(train_data_path)\ntrain_target= pd.read_csv(train_target_path)\n\nclf= SVC(\n    kernel=kernel\n)\nclf.fit(train_data)\n\nwith open(model_path, mode=\"wb\") as file_writer:\n     dill.dump(clf, file_writer)\n```\n\n1. Environment\n\n```python\nimport dill\nimport pandas as pd\n\nfrom sklearn.svm import SVC\n```\n\n1. Python code with Config\n\n```python\ntrain_data = pd.read_csv(train_data_path)\ntrain_target= pd.read_csv(train_target_path)\n\nclf= SVC(\n    **kernel=kernel** <--- Config\n)\nclf.fit(train_data)\n```\n\n1.",
        "index": 1
      },
      {
        "id": "2024-11-02-Pipeline_chunk_2",
        "text": "d_csv(train_target_path)\n\nclf= SVC(\n    **kernel=kernel** <--- Config\n)\nclf.fit(train_data)\n```\n\n1. Generates Artifacts\n\n```python\nwith open(model_path, mode=\"wb\") as file_writer:\n     dill.dump(clf, file_writer)\n```\n\n### Component Wrapper\n\n컴포넌트 래퍼는 컴포넌트 콘텐츠에 필요한 Config를 전달하고 실행시키는 작업을 함\n\nKubeflow에서는 컴포넌트 래퍼를 **함수의 형태**로 저장함.\n\n위 컴포넌트 콘텐츠를 컴포넌트 래퍼가 감싸면 아래와 같이 됨.\n\n```python\ndef train_svc_from_csv( ...",
        "index": 2
      },
      {
        "id": "2024-11-02-Pipeline_chunk_3",
        "text": "포넌트 래퍼를 **함수의 형태**로 저장함.\n\n위 컴포넌트 콘텐츠를 컴포넌트 래퍼가 감싸면 아래와 같이 됨.\n\n```python\ndef train_svc_from_csv( ... ):\n\timport dill\n\t...생략\n\twith open(model_path, mode=\"wb\") as file_writer:\n\t     dill.dump(clf, file_writer)\n```\n\n## Artifacts\n\n아티팩트란 evaluation, result, log 등 어떤 형태든 파일로 생성되는 것을 통틀어서 칭함.\n\n**Model**\n\n파이썬 코드와 학습된 Weights와 Network 구조, 그리고 실행시키기 위한 환경\n\n**Data**\n\n전 처리된 피처, 모델의 예측 값 등\n\n**Metric**\n\n동적 지표 - train loss와 같이 학습 진행 중 계속 변화하는 값\n\n정적 지표 - 학습이 끝난 후 최종적으로 모델을 평가하는 정확도 등\n\n# Pipeline\n\n파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있음.\n\n순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n\n![Untitled](/assets/img/kubeflow/kubepipe501.png)\n\n## Pipeline Config\n\n컴포넌트를 실행시키기 위해서는 Config가 필요함.",
        "index": 3
      },
      {
        "id": "2024-11-02-Pipeline_chunk_4",
        "text": "[Untitled](/assets/img/kubeflow/kubepipe501.png)\n\n## Pipeline Config\n\n컴포넌트를 실행시키기 위해서는 Config가 필요함. \n파이프라인을 구성하는 컴포넌트의 Config들을 모아 둔 것이 파이프라인 Config\n\n## Run\n\n파이프라인이 필요로 하는 파이프라인 Config가 주어져야지만 파이프라인을 실행할 수 있음.\n\nKubeflow에서는 실행된 파이프라인을 Run이라고 부름.\n\n파이프라인이 실행되면 각 컴포넌트가 아티팩트들을 생성.\n\nKubeflow pipeline에서는 Run 하나당 고유한 ID를 생성하고, Run에서 생성되는 모든 아티팩트를 저장\n\n![Untitled](/assets/img/kubeflow/kubepipe502.png)",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Pipeline-Run",
    "title": "Pipeline-Run",
    "path": "/2024/11/02/Pipeline-Run/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n> \n\n컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행\n\n→ 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다.\n\n## Pipeline\n\n> 파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있습니다.\n순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n> \n\n## Before Run\n\n업로드한 파이프라인을 실행시키기 전 Experiment를 생성해야 합니다.\n\n> Experiment란 Kubeflow에서 실행되는 Run을 논리적으로 관리하는 단위입니다.\n> \n\n### Experiments (KFP)페이지에서 우측 상단의 `Create experiment` 버튼 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe701.png)\n\n> Experiments (AutoML) 페이지는 Hyperparameter Tuning과 Neural Architecture Search를 담당하는 Katib관리 페이지\n> \n\n### Create Experiment\n\n![Untitled](/assets/img/kubeflow/kubepipe702.png)\n\n<aside>\n💡 Next 버튼 클릭 시 자동으로 Create Run화면으로 이동됩니다.\n\n</aside>\n\n## Run Pipeline\n\n### 실행하려는 파이프라인 선택 후 우측 상단의 `Create run` 버튼 클릭\n\n(New Experiment로 생성했다면 이 단계는 건너뜀)\n\n![Untitled](/assets/img/kubeflow/kubepipe703.png)\n\n### 내용 입력 후 `Start` 버튼 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe704.png)\n\n> **`Run parameters`**에 Pipeline Config 값들을 입력해야합니다.\n> \n\n### 실행 완료\n\n![Untitled](/assets/img/kubeflow/kubepipe705.png)\n\n> 컴포넌트 실행이 완료되면 초록색 체크 표시가 나옵니다.\n\n가장 마지막 컴포넌트를 보면 입력한 Config값인 3과 5의 합인 8이 출력된 것을 확인할 수 있습니다.\n>\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Pipeline-Run_chunk_0",
        "text": "Pipeline-Run\n\n# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n> \n\n컴포넌트는 독립적으로 실행되지 않고 파이프라인의 구성요소로써 실행\n\n→ 컴포넌트를 실행해 보려면 파이프라인을 작성해야 합니다.\n\n## Pipeline\n\n> 파이프라인은 컴포넌트의 집합과 컴포넌트를 실행시키는 순서도로 구성되어 있습니다.\n순서도는 방향 순환이 없는 그래프, 간단한 조건문 포함 가능\n> \n\n## Before Run\n\n업로드한 파이프라인을 실행시키기 전 Experiment를 생성해야 합니다.\n\n> Experiment란 Kubeflow에서 실행되는 Run을 논리적으로 관리하는 단위입니다.\n> \n\n### Experiments (KFP)페이지에서 우측 상단의 `Create experiment` 버튼 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe701.png)\n\n> Experiments (AutoML) 페이지는 Hyperparameter Tuning과 Neural Architecture Search를 담당하는 Katib관리 페이지\n> \n\n### Create Experiment\n\n![Untitled](/assets/img/kubeflow/kubepipe702.png)\n\n<aside>\n💡 Next 버튼 클릭 시 자동으로 Create Run화면으로 이동됩니다.\n\n</aside>\n\n## Run Pipeline\n\n### 실행하려는 파이프라인 선택 후 우측 상단의 `Create run` 버튼 클릭\n\n(New Experiment",
        "index": 0
      },
      {
        "id": "2024-11-02-Pipeline-Run_chunk_1",
        "text": "로 이동됩니다.\n\n</aside>\n\n## Run Pipeline\n\n### 실행하려는 파이프라인 선택 후 우측 상단의 `Create run` 버튼 클릭\n\n(New Experiment로 생성했다면 이 단계는 건너뜀)\n\n![Untitled](/assets/img/kubeflow/kubepipe703.png)\n\n### 내용 입력 후 `Start` 버튼 클릭\n\n![Untitled](/assets/img/kubeflow/kubepipe704.png)\n\n> **`Run parameters`**에 Pipeline Config 값들을 입력해야합니다.\n> \n\n### 실행 완료\n\n![Untitled](/assets/img/kubeflow/kubepipe705.png)\n\n> 컴포넌트 실행이 완료되면 초록색 체크 표시가 나옵니다.\n\n가장 마지막 컴포넌트를 보면 입력한 Config값인 3과 5의 합인 8이 출력된 것을 확인할 수 있습니다.\n>",
        "index": 1
      },
      {
        "id": "2024-11-02-Pipeline-Run_chunk_2",
        "text": "g)\n\n> 컴포넌트 실행이 완료되면 초록색 체크 표시가 나옵니다.\n\n가장 마지막 컴포넌트를 보면 입력한 Config값인 3과 5의 합인 8이 출력된 것을 확인할 수 있습니다.\n>",
        "index": 2
      },
      {
        "id": "2024-11-02-Pipeline-Run_chunk_3",
        "text": "g)\n\n> 컴포넌트 실행이 완료되면 초록색 체크 표시가 나옵니다.\n\n가장 마지막 컴포넌트를 보면 입력한 Config값인 3과 5의 합인 8이 출력된 것을 확인할 수 있습니다.\n>",
        "index": 3
      },
      {
        "id": "2024-11-02-Pipeline-Run_chunk_4",
        "text": "g)\n\n> 컴포넌트 실행이 완료되면 초록색 체크 표시가 나옵니다.\n\n가장 마지막 컴포넌트를 보면 입력한 Config값인 3과 5의 합인 8이 출력된 것을 확인할 수 있습니다.\n>",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-1MLflow------------------1",
    "title": "MLflow 학습 트래킹 및 아티팩트 저장 1",
    "path": "/2024/11/02/1MLflow-학습-트래킹-및-아티팩트-저장-1/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "이전 문서를 통해 YOLOv8 모델을 학습시키는 파이프라인을 작성했습니다.\n\n본 문서부터는 MLflow에 모델 학습을 추적하고, 아티팩트를 저장하는 파이프라인을 작성하겠습니다.\n\n# MLflow\n\n---\n\n> MLflow는 대표적인 오픈소스 ML 실험 관리 도구입니다. \nMLflow는 실험 관리 용도 외에도 ML 모델 패키징, 배포 관리, 저장과 같은 기능도 제공합니다.<br>\n[Setup Components(MLflow Tracking Server)](https://knowgyu.github.io/posts/Setup-Components(MLflow-Tracking-Server)/)\n\n이전 문서에서 MLflow Tracking Server를 구축했었습니다. 이 서버를 이용해 진행하겠습니다.\n\n현재 MLflow에 접속하려면 아래 명령어를 통해 포트포워딩을 한 후 접속해야합니다.\n\n```bash\nkubectl port-forward svc/mlflow-server-service -n mlflow-system 5000:5000\n```\n\n[http://127.0.0.1:5000/](http://127.0.0.1:5000/)\n\n조금 더 편리한 사용을 위해 Kubeflow 대시보드에서 MLflow에 접근할 수 있도록 합니다.\n\n# Customize Kubeflow Central Dashboard\n\n---\n\n우선, Kubeflow의 탭에 MLflow를 생성하겠습니다.\n\n## Port-forward Central Dashboard\n\n```bash\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\n- 접속 화면\n\n![Untitled](/assets/img/kubeflow/kubepipe204.png)\n\n## Edit config file\n\n```bash\nkubectl edit cm centraldashboard-config -n kubeflow\n```\n\n```bash\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\ndata:\n  links: |-\n    {\n      \"menuLinks\": [\n        {\n          \"type\": \"item\",\n          \"link\": \"/jupyter/\",\n          \"text\": \"Notebooks\",\n          \"icon\": \"book\"\n        },\n... # 아래 설정 추가\n        {\n          \"type\": \"item\",\n          \"link\": \"/mlflow/\",\n          \"text\": \"MLFlow\",\n          \"icon\": \"icons:cached\"\n        }\n      ],\n```\n\n```bash\n# 정상적으로 저장되면 아래와 같은 메세지가 출력됩니다.\nconfigmap/centraldashboard-config edited\n```\n\n정상적으로 저장되었다면 대시보드를 새로고침(F5)합니다.\n\n![Untitled](/assets/img/kubeflow/kubepipe203.png)\n\n## Deploy Virtual Service\n\n---\n\n대시보드 탭에 MLflow를 클릭하면 아래와 같은 화면이 나옵니다.\n\n![Untitled](/assets/img/kubeflow/kubepipe202.png)\n\nMLflow tab을 생성은 했지만, 이전 설정에서 확인할 수 있듯 `\"link\": \"/mlflow/\"` 로 연결해주는 서비스가 없기에, 위와 같이 **`/mlflow/** is not a valid page` 라는 문구가 발생합니다.\n\n따라서, virtual service를 정의하고 이를 Istio Ingress를 통해 MLflow service를 사용할 수 있도록 만들겠습니다.\n\n```bash\n# 어떤 경로든 상관없으나, 동일한 파일이 없는 곳에 저장합니다.\n# 본 문서에서는 manifests/MLflow/ 경로에서 yaml파일을 정의했습니다.\nvi virtual-service.yaml\n```\n\n```yaml\napiVersion: networking.istio.io/v1alpha3\nkind: VirtualService\nmetadata:\n  name: mlflow\n  namespace: mlflow-system\nspec:\n  gateways:\n  - kubeflow/kubeflow-gateway\n  hosts:\n  - '*'\n  http:\n  - match:\n    - uri:\n        prefix: /mlflow/\n    rewrite:\n      uri: /\n    route:\n     - destination:\n        host: mlflow-server-service.mlflow-system.svc.cluster.local\n        port:\n          number: 5000\n```\n\n```bash\nkubectl apply -f virtual-service.yaml\n# 정상적으로 수행했다면 아래와 같은 메세지가 출력됩니다.\nvirtualservice.networking.istio.io/mlflow created\n```\n\n![Untitled](/assets/img/kubeflow/kubepipe201.png)\n\n만약, 화면이 바뀌지 않는다면, 아래 명령어를 사용해 대시보드를 재시작 합니다.\n{: .prompt-tip }\n\n```bash\nkubectl rollout restart deploy centraldashboard -n kubeflow\n```\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-1MLflow------------------1_chunk_0",
        "text": "MLflow 학습 트래킹 및 아티팩트 저장 1\n\n이전 문서를 통해 YOLOv8 모델을 학습시키는 파이프라인을 작성했습니다.\n\n본 문서부터는 MLflow에 모델 학습을 추적하고, 아티팩트를 저장하는 파이프라인을 작성하겠습니다.\n\n# MLflow\n\n---\n\n> MLflow는 대표적인 오픈소스 ML 실험 관리 도구입니다. \nMLflow는 실험 관리 용도 외에도 ML 모델 패키징, 배포 관리, 저장과 같은 기능도 제공합니다.<br>\n[Setup Components(MLflow Tracking Server)](https://knowgyu.github.io/posts/Setup-Components(MLflow-Tracking-Server)/)\n\n이전 문서에서 MLflow Tracking Server를 구축했었습니다.",
        "index": 0
      },
      {
        "id": "2024-11-02-1MLflow------------------1_chunk_1",
        "text": "ithub.io/posts/Setup-Components(MLflow-Tracking-Server)/)\n\n이전 문서에서 MLflow Tracking Server를 구축했었습니다. 이 서버를 이용해 진행하겠습니다.\n\n현재 MLflow에 접속하려면 아래 명령어를 통해 포트포워딩을 한 후 접속해야합니다.\n\n```bash\nkubectl port-forward svc/mlflow-server-service -n mlflow-system 5000:5000\n```\n\n[http://127.0.0.1:5000/](http://127.0.0.1:5000/)\n\n조금 더 편리한 사용을 위해 Kubeflow 대시보드에서 MLflow에 접근할 수 있도록 합니다.\n\n# Customize Kubeflow Central Dashboard\n\n---\n\n우선, Kubeflow의 탭에 MLflow를 생성하겠습니다.\n\n## Port-forward Central Dashboard\n\n```bash\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\n- 접속 화면\n\n![Untitled](/assets/img/kubeflow/kubepipe204.png)\n\n## Edit config file\n\n```bash\nkubectl edit cm centraldashboard-config -n kubeflow\n```\n\n```bash\n# Please edit the object below.",
        "index": 1
      },
      {
        "id": "2024-11-02-1MLflow------------------1_chunk_2",
        "text": "sh\nkubectl edit cm centraldashboard-config -n kubeflow\n```\n\n```bash\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\ndata:\n  links: |-\n    {\n      \"menuLinks\": [\n        {\n          \"type\": \"item\",\n          \"link\": \"/jupyter/\",\n          \"text\": \"Notebooks\",\n          \"icon\": \"book\"\n        },\n...",
        "index": 2
      },
      {
        "id": "2024-11-02-1MLflow------------------1_chunk_3",
        "text": "\"link\": \"/jupyter/\",\n          \"text\": \"Notebooks\",\n          \"icon\": \"book\"\n        },\n...",
        "index": 3
      },
      {
        "id": "2024-11-02-1MLflow------------------1_chunk_4",
        "text": "\"link\": \"/jupyter/\",\n          \"text\": \"Notebooks\",\n          \"icon\": \"book\"\n        },\n...",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Misc--Pipeline",
    "title": "Misc. Pipeline 설명",
    "path": "/2024/11/02/Misc.-Pipeline-설명/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 문서에서는 지금까지 작성한 커스텀 데이터셋 학습 파이프라인에 대한 설명과 설정에 대해 다룹니다.\n\n# Training Pipeline\n\n---\n\n## Pipeline Graph\n\n---\n\n![Untitled](/assets/img/kubeflow/kubeyolo501.png){: .w-50}\n\n### Volume-mount\n\n파이프라인에서 각 Pod들이 Node 로컬 볼륨에 **마운트**하기 위해 `pvc` 를 생성하는 Op입니다. 대부분의 작업이 데이터를 읽고 저장해야하기에, 필수적인 요소입니다. \n\n### Verify pipeline op\n\n파이프라인 실행 시 **입력**한 파라미터들이 **유효**한 지 확인하는 Op입니다. 모델의 경로, 학습 CFG파일, 데이터셋 yaml파일을 입력받아 확장자가 없다면, 이를 추가하고 해당 파일들이 폴더에 존재하는 지 확인합니다.\n\n### Get data distribution op\n\n데이터의 **분포**를 파악하는 Op입니다. 입력받은 데이터셋 yaml파일을 읽어 데이터셋의 위치와 클래스 이름을 저장하고, 데이터셋의 라벨링 파일을 통해 클래스 별 이미지 파일의 수와 인스턴스 수를 구합니다. 이후 Plot을 위해 데이터 분포를 반환하고, Pipeline UI를 통해 데이터 분포표를 출력합니다.\n\n### Plot data distribution op\n\n데이터의 분포를 `matplotlib`를 이용해 시각화합니다. \n\n클래스별 이미지 파일의 수와 인스턴스 수를 Plot합니다.\n\n### Train op\n\n모델을 학습합니다. 학습 설정 변경 및 하이퍼파라미터 조정은 cfg파일을 이용합니다. 또한, MLflow에 로깅합니다.\n\n### Tune op\n\n학습 후 `best.pt`를 불러와 하이퍼 파라미터 튜닝을 진행합니다. 또한, MLflow에 로깅합니다.\n\n### Test op\n\n학습 후 `best.pt`를 불러와 테스트 데이터셋에 대한 모델의 일반화 성능을 평가합니다. 또한, MLflow에 로깅합니다.\n\n\n\n## Pipeline Config\n\n---\n\n파이프라인 실행 시 필요한 파라미터들은 아래와 같습니다.\n\n![Kubeflow Dashboard → Runs → Create Run → Choose Pipeline](/assets/img/kubeflow/kubeyolo502.png)\n\nKubeflow Dashboard → Runs → Create Run → Choose Pipeline\n\n- `model_name`(str) : 학습할 모델의 파일명을 입력합니다. (`.pt` 혹은 `.yaml`)\n- `cfg`(str) : YOLOv8 학습 구성 및 하이퍼파라미터를 담고있는 cfg파일의 파일명을 입력합니다.\n- `data`(str) : 학습할 데이터셋의 정보를 담고있는 yaml파일의 파일명을 입력합니다.\n- `bool_train`(bool) : True 입력 시 모델을 학습합니다.\n- `bool_tune`(bool) : True 입력 시 모델 학습 후 `best.pt`모델의 하이퍼 파라미터를 튜닝합니다.\n\n<br>\n💡 `bool_train` , `bool_tune` 이 각각 False, True일 경우에 Tuning을 진행하지 않습니다.\n\n\n## Pipeline Settings\n\n---\n\n파이프라인을 정의하는 함수는 아래와 같습니다.\n\n```python\n@dsl.pipeline(name=\"pipelinename\",\n          description=\"MLpipline Description\",\n          )\ndef train_pipeline(\n    model_name: str = 'yolov8n.pt',\n    cfg: str = 'cfg-custom',\n    data: str = 'data-custom',\n    bool_train: bool=True,\n    bool_tune: bool=False,\n    ):\n    \n    vop = dsl.VolumeOp(\n        name=\"volume mount\",\n        resource_name=\"pvc-local-cocodata\",\n        storage_class='train',\n        modes=dsl.VOLUME_MODE_RWO,\n        size=\"3Gi\",\n        generate_unique_name=False,\n        action='apply',\n        )\n    \n    \n    \n    verifier = verify_pipeline_op(model_name, cfg, data)\n    \n    get_distribution = get_data_distribution_op(verifier.outputs['data_yaml'])\n    \n    plotting = plot_data_distribution_op(get_distribution.outputs[\"result_json\"], get_distribution.outputs[\"cls_names_json\"])\n    \n    with dsl.Condition(bool_train == True , \"train\"):\n        trainer = train_op(verifier.outputs['model_path'], verifier.outputs['cfg_yaml'], verifier.outputs['data_yaml'])\n        tester = test_op(trainer.outputs['last_pt'], trainer.outputs['best_pt'], trainer.outputs['data_yaml'])\n        \n        with dsl.Condition(bool_tune == True , 'tune'):\n            raytuner = tune_op(trainer.outputs['last_pt'],trainer.outputs['best_pt'],trainer.outputs['data_yaml'])        \n\n    # Volume Mount\n    verifier.add_pvolumes({\"/data\":vop.volume})\n    get_distribution.add_pvolumes({\"/data\":verifier.pvolume})\n    plotting.add_pvolumes({\"/data\":get_distribution.pvolume})\n    trainer.add_pvolumes({\"/data\":plotting.pvolume})\n    tester.add_pvolumes({\"/data\":trainer.pvolume})\n    raytuner.add_pvolumes({\"/data\":trainer.pvolume})\n\n    # shm-memory Resize(using EmptyDir)\n    shm_volume = V1Volume(name=\"dshm\", \n                          empty_dir = V1EmptyDirVolumeSource(medium='Memory', size_limit='1Gi'))\n    shm_pvolume = dsl.PipelineVolume(volume=shm_volume)\n    # Resize shm size\n    verifier.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    get_distribution.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    plotting.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    trainer.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    tester.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    raytuner.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    \n    # Disable caching. Two Options \n    '''\n    This Option doesn't work well\n    Use `.execution_options.caching_strategy.max_cache_staleness = \"P0D\"` instead.\n    \n    # verifier.set_caching_options(False)\n    # get_distribution.set_caching_options(False)\n    # plotting.set_caching_options(False)\n    # trainer.set_caching_options(False)\n    # raytuner.set_caching_options(False)\n    '''\n    verifier.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n    get_distribution.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n    plotting.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n    trainer.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n    tester.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n    raytuner.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n    \n    # UI Component name settings (Default is Op name)\n    '''\n    vop.set_display_name(\"UI Component name settings\")\n    verifier.set_display_name(\"UI Component name settings\")\n    get_distribution.set_display_name(\"UI Component name settings\")\n    plotting.set_display_name(\"UI Component name settings\")\n    trainer.set_display_name(\"UI Component name settings\")\n    tester.set_display_name(\"UI Component name settings\")\n    raytuner.set_display_name(\"UI Component name settings\")\n    '''\n\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(train_pipeline, \"knowgyu_almost.yaml\")\n```\n\n- `@dsl.pipeline` : `kfp` 라이브러리를 이용해 파이프라인을 생성합니다.\n    - `name` : 파이프라인의 이름. 기본값은 함수명을 사용합니다.\n    - `description` : (Optional) 파이프라인 설명\n    - `pipeline_root` : (Optional) Input/Output URI placeholder가 사용되는 경우 필요합니다.\n\n- `def train_pipeline(*args)` : 파이프라인을 정의합니다. args를 통해 파이프라인의 Config를 정의합니다.\n- `vop = dsl.VolumeOp()` : PVC를 생성합니다. \n💡본 문서에서는 기존에 생성한 PVC를 사용하기에, `generate_unique_name=False` 옵션을 사용하였습니다.\n\n### 컴포넌트 실행\n\n```python\nverifier = verify_pipeline_op(model_name, cfg, data)\n\nget_distribution = get_data_distribution_op(verifier.outputs['data_yaml'])\n\nplotting = plot_data_distribution_op(get_distribution.outputs[\"result_json\"], get_distribution.outputs[\"cls_names_json\"])\n\nwith dsl.Condition(bool_train == True , \"train\"):\n    trainer = train_op(verifier.outputs['model_path'], verifier.outputs['cfg_yaml'], verifier.outputs['data_yaml'])\n    tester = test_op(trainer.outputs['last_pt'], trainer.outputs['best_pt'], trainer.outputs['data_yaml'])\n    \n    with dsl.Condition(bool_tune == True , 'tune'):\n        raytuner = tune_op(trainer.outputs['last_pt'],trainer.outputs['best_pt'],trainer.outputs['data_yaml'])        \n```\n\n실행할 컴포넌트를 호출합니다. Python 함수 호출 방식과 동일합니다.\n\n단, 조건문 사용 시 `kfp.dsl.Condition`을 사용해야합니다.\n\n### 볼륨 마운트 (+ 컴포넌트 실행 순서)\n\n```python\n# Volume Mount\nverifier.add_pvolumes({\"/data\":vop.volume})\nget_distribution.add_pvolumes({\"/data\":verifier.pvolume})\nplotting.add_pvolumes({\"/data\":get_distribution.pvolume})\ntrainer.add_pvolumes({\"/data\":plotting.pvolume})\ntester.add_pvolumes({\"/data\":trainer.pvolume})\nraytuner.add_pvolumes({\"/data\":trainer.pvolume})\n```\n\n> Updates the existing pvolumes dict, extends volumes and volume_mounts and redefines the pvolume attribute.\n> \n\n볼륨을 마운트합니다. pvolume dict를 입력할 때, 모두 `vop.volume`을 입력해도 되지만, 위처럼 마운트할 경우 순서를 지정할 수 있습니다.\n\n혹은, 직접 `after()`를 이용해 컴포넌트 실행 순서를 지정할 수 있습니다.\n\n```python\n# Volume Mount\nverifier.add_pvolumes({\"/data\":vop.volume})\nget_distribution.add_pvolumes({\"/data\":vop.volume})\nplotting.add_pvolumes({\"/data\":vop.volume})\ntrainer.add_pvolumes({\"/data\":vop.volume})\ntester.add_pvolumes({\"/data\":vop.volume})\nraytuner.add_pvolumes({\"/data\":vop.volume})\n\n# after()를 이용해 순서 정하기\nget_distribution.after(verifier)\nplotting.after(get_distribution)\ntrainer.after(plotting)\ntester.after(trainer)\nraytuner.after(trainer)\n```\n\n> 컴포넌트 실행 순서를 **지정하지 않을 경우** ContainerOp가 **순서 없이 병렬적으로 실행**될 수 있습니다!\n>\n>위 컴포넌트 실행의 Argument들을 확인해보면, `trainer`컴포넌트는 모두 `verifier` 컴포넌트의 결과물만을 인자로 받습니다.\n>만약, 순서를 지정하지 않을 경우, 데이터 분포를 분석하고 plot하는 컴포넌트와 학습하고 테스트하는 컴포넌트가 병렬적으로 실행되게니다.\n{: .prompt-info }\n\n\n### Share Memory(shm) 크기 변경\n\n쿠버네티스에서 Pod가 생성되면 기본적으로 64MB의 shm 공유 메모리가 할당됩니다.\n\n하지만, 이 공간만으로는 학습과 같은 작업 시 공유메모리가 부족해 에러가 발생하는 상황이 종종 발생하게됩니다.\n\n> ~~주로 데이터 로드 시 멀티프로세싱 방식으로 로드할 때 공유 메모리 부족에러가 발생했습니다.~~\n\nDocker에서는 이러한 상황이 발생했을 때 `--ipc=host` 혹은 `--shm-size=256m` 과 같은 옵션을 사용해 해결할 수 있습니다.\n\n하지만, 쿠버네티스 환경에서 `ipc=host` 옵션 사용 시 보안 이슈가 발생할 수 있으며, shm 사이즈를 조정할 수 있는 별도의 옵션을 제공하지 않습니다.\n\n이러한 문제를 쿠버네티스의 memory타입 EmptyDir 마운트 방식으로 문제를 해결할 수 있습니다. \n\n[⚠️ Shared Memory(shm) Error](https://knowgyu.github.io/posts/Yolov8-%ED%95%99%EC%8A%B5pp%EC%8B%A4%ED%96%89/#%EF%B8%8F-shared-memoryshm-error)\n\n> [https://ykarma1996.tistory.com/106](https://ykarma1996.tistory.com/106)\n\n위 블로그를 통해 yaml파일을 수정하여 shm 사이즈를 조정할 수 있습니다.\n\n하지만, 이 방법을 사용할 경우 아래와 같이 작업이 번거로워집니다.\n\nPython 코드 → yaml로 컴파일 → yaml파일에서 각 Pod를 찾아 마운트(현재 6개 Pod)\n\n따라서, 파이썬으로 파이프라인을 작성할 때 볼륨을 마운트 할 수 있도록 하겠습니다.\n\n```python\n@dsl.pipeline(name=\"pipelinename\",\n          description=\"MLpipline Description\",\n          )\ndef train_pipeline(\n...생략\n    ):\n    \n...생략\n\n    # shm-memory Resize(using EmptyDir)\n    shm_volume = V1Volume(name=\"dshm\", \n                          empty_dir = V1EmptyDirVolumeSource(medium='Memory', size_limit='1Gi'))\n    shm_pvolume = dsl.PipelineVolume(volume=shm_volume)\n\n    # shm Mount\n    verifier.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    get_distribution.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    plotting.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    trainer.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    tester.add_pvolumes({\"/dev/shm\":shm_pvolume})\n    raytuner.add_pvolumes({\"/dev/shm\":shm_pvolume})\n```\n\n- `from kubernetes.client import V1Volume, V1EmptyDirVolumeSource`\n    \n    V1Volume : Pod의 스토리지 볼륨을 추상화합니다. 컨테이너는 이 객체를 참조해 스토리지 볼륨을 마운트할 위치를 결정합니다.(PVC같은 역할)\n    \n    V1EmptyDirVolumeSource : Pod가 실행되는 동안 유지되는 임시 볼륨입니다. Pod가 종료되거나 재시작되면 데이터는 삭제됩니다.\n    \n\n### 캐싱기능 종료\n\n```python\n# Disable caching. Two Options \n'''\nThis Option doesn't work well\nUse `.execution_options.caching_strategy.max_cache_staleness = \"P0D\"` instead.\n\n# verifier.set_caching_options(False)\n# get_distribution.set_caching_options(False)\n# plotting.set_caching_options(False)\n# trainer.set_caching_options(False)\n# raytuner.set_caching_options(False)\n'''\nverifier.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\nget_distribution.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\nplotting.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\ntrainer.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\ntester.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\nraytuner.execution_options.caching_strategy.max_cache_staleness = \"P0D\"\n```\n\n`set_caching_options(False)` 를 통해 기능을 종료할 수 있습니다. 혹은\n\n`execution_options.caching_strategy.max_cache_staleness = \"P0D\"` 를 통해 종료할 수 있습니다.\n\n첫번째 옵션의 경우 `False` 옵션으로 실행했음에도 불구하고, 캐시된 아웃풋을 이용해 컴포넌트 실행을 건너뛰는 경우가 발생했습니다.\n\n따라서, Kubeflow 공식문서에서 기술한 두 번째 방법을 이용해 캐시 기능을 종료하는 것을 권장합니다.\n\n> 첫번째 옵션의 경우, 캐시기능을 완전 종료하는게 아닌, 새롭게 캐시하지 않는 것을 의미하는 것 같습니다.\n> 따라서, 만약 `.cache` 폴더를 삭제하고 첫번째 옵션 사용 시 정상적으로 작동할 수 있으나, 따로 테스트하진 않았습니다.\n{: .prompt-tip }\n\n### 컴포넌트 UI 이름 설정\n\n```python\n# UI Component name settings (Default is Op name)\n'''\nvop.set_display_name(\"UI Component name settings\")\nverifier.set_display_name(\"UI Component name settings\")\nget_distribution.set_display_name(\"UI Component name settings\")\nplotting.set_display_name(\"UI Component name settings\")\ntrainer.set_display_name(\"UI Component name settings\")\ntester.set_display_name(\"UI Component name settings\")\nraytuner.set_display_name(\"UI Component name settings\")\n'''\n```\n\nKubeflow Pipeline UI에 표시되는 이름을 설정할 수 있습니다. 기본값은 함수명으로 지정되며, 필요에 따라 직접 설정할 수 있습니다.\n\n본 문서의 파이프라인은 중복되는 컴포넌트를 사용하지 않지만, 만약 동일한 컴포넌트를 여러 개 사용할 경우 어떤 컴포넌트가 어떤 역할을 하는 지 헷갈릴 수 있습니다. 이러한 경우 사용하면 휴먼 에러를 줄일 수 있습니다.\n\n### 파이프라인 컴파일\n\n```python\nif __name__ == \"__main__\":\n    kfp.compiler.Compiler().compile(train_pipeline, \"knowgyu_almost.yaml\")\n```\n\n파이썬 코드를 Kubeflow Pipeline에 업로드할 수 있도록 YAML파일로 컴파일합니다.\n\n# YOLOv8 Training Configuration\n\n---\n\n위 파이프라인을 이용해 YOLOv8을 학습할 때 데이터셋 변경 혹은 학습 구성을 변경하는 것은 `yaml`파일을 통해 변경 가능합니다.\n\n> [https://docs.ultralytics.com/usage/cfg/#tasks](https://docs.ultralytics.com/usage/cfg/#tasks)\n\n![Kubeflow Dashboard → Runs → Create Run → Choose Pipeline](/assets/img/kubeflow/kubeyolo503.png)\n\nKubeflow Dashboard → Runs → Create Run → Choose Pipeline\n\n위 예시와 같이 `custom`이라는 구성파일을 만들어 수정해 사용하거나, 혹은 프로젝트별로 `cfg-insight3.yaml` `data-insight3.yaml` 과 같이 생성해 사용할 수 있습니다.\n\n위 구성파일들을 수정하는 방법은 Kubeflow Jupyter Web App을 사용하거나, 직접 로컬에서 구성파일을 수정할 수 있습니다.\n\n## Edit Configuration file\n\n![Untitled](/assets/img/kubeflow/kubeyolo504.png)\n\nKubeflow 대시보드에서 좌측 탭 중 Notebooks 클릭하면 위 이미지와 같이 사용중인 노트북들을 확인할 수 있습니다.\n\n이 중, 학습 하려는 폴더에 마운트된 주피터 노트북을 확인한 후 `CONNECT` 를 클릭해 주피터 노트북에 접속합니다.\n\n- `cfg-custom.yaml`\n\n![Untitled](/assets/img/kubeflow/kubeyolo505.png)\n\n- `data-custom.yaml`\n\n![Untitled](/assets/img/kubeflow/kubeyolo506.png)\n\n위와 같이 Jupyter Notebook에 접속해 마운트된 폴더에 있는 구성 파일들을 통해 데이터셋 변경 혹은 학습 설정을 변경할 수 있습니다.\n\n또한, 파일이 늘어날 경우 `cfg-yaml`, `data-yaml`, `weights` 폴더를 생성해 각각의 폴더에 파일들을 정리하여 사용할 수 있습니다.\n\n> 위와 같이 구성파일을 수정해 데이터셋을 변경하거나 학습 설정을 변경하는 것은 파이프라인 수정이 필요하지 않기에 바로 적용됩니다.\n{: .prompt-tip }\n\n### (23.12.14) Model from scratch\n\n학습 구성, 데이터셋 구성 파일들과 같은 위치에 `yolov8-scratch.yaml` 을 둡니다.\n\n이 파일을 이용해 상황에 따라 백본 혹은 헤드를 수정하여 모델을 생성할 수 있습니다.\n\n- `yolov8-scratch.yaml`\n\n```bash\n# Ultralytics YOLO 🚀, AGPL-3.0 license\n# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect\n\n# Parameters\nnc: 80  # number of classes\nscales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\n  # [depth, width, max_channels]\n  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs\n  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs\n  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs\n  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs\n  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs\n\n# YOLOv8.0n backbone\nbackbone:\n  # [from, repeats, module, args]\n  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2\n  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4\n  - [-1, 3, C2f, [128, True]]\n  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8\n  - [-1, 6, C2f, [256, True]]\n  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16\n  - [-1, 6, C2f, [512, True]]\n  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32\n  - [-1, 3, C2f, [1024, True]]\n  - [-1, 1, SPPF, [1024, 5]]  # 9\n\n# YOLOv8.0n head\nhead:\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4\n  - [-1, 3, C2f, [512]]  # 12\n\n  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]\n  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3\n  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)\n\n  - [-1, 1, Conv, [256, 3, 2]]\n  - [[-1, 12], 1, Concat, [1]]  # cat head P4\n  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)\n\n  - [-1, 1, Conv, [512, 3, 2]]\n  - [[-1, 9], 1, Concat, [1]]  # cat head P5\n  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)\n\n  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)\n```\n\n> Pipeline 실행 시 `yolov8n-scratch.yaml` 혹은 `yolov8s-scratch.yaml` 과 같은 형식으로 입력해야합니다.\n{: .prompt-info }\n\n# 참고 사항\n\n---\n\n## Kubeflow Docs\n\n[https://www.kubeflow.org/docs/components/pipelines/v1/introduction/](https://www.kubeflow.org/docs/components/pipelines/v1/introduction/)\n\n본 문서에선 Pipelines SDK (v2)를 지원하지 않습니다. 따라서, Kubeflow Pipelines v1만 참고합니다.\n\n## `kfp` 라이브러리(v1.8.22)\n\n[https://kubeflow-pipelines.readthedocs.io/en/1.8.22/source/kfp.dsl.html](https://kubeflow-pipelines.readthedocs.io/en/1.8.22/source/kfp.dsl.html)\n\n> Kubeflow Pipelines is a platform for building and deploying portable, scalable machine learning workflows based on Docker containers within the [Kubeflow](https://www.kubeflow.org/) project.\n> \n> \n> Use Kubeflow Pipelines to compose a multi-step workflow ([pipeline](https://www.kubeflow.org/docs/components/pipelines/concepts/pipeline/)) as a [graph](https://www.kubeflow.org/docs/components/pipelines/concepts/graph/) of containerized [tasks](https://www.kubeflow.org/docs/components/pipelines/concepts/step/) using Python code and/or YAML. Then, [run](https://www.kubeflow.org/docs/components/pipelines/concepts/run/) your pipeline with specified pipeline arguments, rerun your pipeline with new arguments or data, [schedule](https://www.kubeflow.org/docs/components/pipelines/concepts/run-trigger/) your pipeline to run on a recurring basis, organize your runs into [experiments](https://www.kubeflow.org/docs/components/pipelines/concepts/experiment/), save machine learning artifacts to compliant [artifact registries](https://www.kubeflow.org/docs/components/pipelines/concepts/metadata/), and visualize it all through the [Kubeflow Dashboard](https://www.kubeflow.org/docs/components/central-dash/overview/).\n> \n\n[https://kubeflow-pipelines.readthedocs.io/en/1.8.22/source/kfp.dsl.html](https://kubeflow-pipelines.readthedocs.io/en/1.8.22/source/kfp.dsl.html)\n\n> 파이썬을 이용해 Kubeflow Pipeline을 작성할 때 사용되는 라이브러리로, 매우 자주 사용하고 확인합니다.\n**v1.8.22 버전**\n\n## 모두를 위한 MLOps\n\n[https://mlops-for-all.github.io/docs/introduction/intro/](https://mlops-for-all.github.io/docs/introduction/intro/)\n\n위 튜토리얼을 통해 클러스터를 구축하고, 파이프라인을 작성했습니다.\n\n💡 진행 중 에러 발생 시 깃허브 이슈 참고\n[https://github.com/mlops-for-all/mlops-for-all.github.io/issues](https://github.com/mlops-for-all/mlops-for-all.github.io/issues)\n\n## 기타 블로그\n\n마켓컬리 : “**Kurly만의 MLOps 구축하기 - 쿠브플로우 도입기**” [https://helloworld.kurly.com/blog/second-mlops/](https://helloworld.kurly.com/blog/second-mlops/)\n\n당근마켓 : “**Kubeflow 파이프라인 운용하기**” [https://medium.com/daangn/kubeflow-파이프라인-운용하기-6c6d7bc98c30](https://medium.com/daangn/kubeflow-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9A%B4%EC%9A%A9%ED%95%98%EA%B8%B0-6c6d7bc98c30)\n\n삼성SDS : “**쿠버네티스 기반의 AI 플랫폼: 쿠브플로우(Kubeflow)**” [https://www.samsungsds.com/kr/insights/kubeflow.html](https://www.samsungsds.com/kr/insights/kubeflow.html)\n\n\n---\n이상으로 Kubeflow 설명을 마칩니다.\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Misc--Pipeline_chunk_0",
        "text": "Misc. Pipeline 설명\n\n본 문서에서는 지금까지 작성한 커스텀 데이터셋 학습 파이프라인에 대한 설명과 설정에 대해 다룹니다.\n\n# Training Pipeline\n\n---\n\n## Pipeline Graph\n\n---\n\n![Untitled](/assets/img/kubeflow/kubeyolo501.png){: .w-50}\n\n### Volume-mount\n\n파이프라인에서 각 Pod들이 Node 로컬 볼륨에 **마운트**하기 위해 `pvc` 를 생성하는 Op입니다. 대부분의 작업이 데이터를 읽고 저장해야하기에, 필수적인 요소입니다. \n\n### Verify pipeline op\n\n파이프라인 실행 시 **입력**한 파라미터들이 **유효**한 지 확인하는 Op입니다. 모델의 경로, 학습 CFG파일, 데이터셋 yaml파일을 입력받아 확장자가 없다면, 이를 추가하고 해당 파일들이 폴더에 존재하는 지 확인합니다.\n\n### Get data distribution op\n\n데이터의 **분포**를 파악하는 Op입니다. 입력받은 데이터셋 yaml파일을 읽어 데이터셋의 위치와 클래스 이름을 저장하고, 데이터셋의 라벨링 파일을 통해 클래스 별 이미지 파일의 수와 인스턴스 수를 구합니다. 이후 Plot을 위해 데이터 분포를 반환하고, Pipeline UI를 통해 데이터 분포표를 출력합니다.\n\n### Plot data distribution op\n\n데이터의 분포를 `matplotlib`를 이용해 시각화합니다. \n\n클래스별 이미지 파일의 수와 인스턴스 수를 Plot합니다.\n\n### Train op\n\n모델을 학습합니다.",
        "index": 0
      },
      {
        "id": "2024-11-02-Misc--Pipeline_chunk_1",
        "text": "op\n\n데이터의 분포를 `matplotlib`를 이용해 시각화합니다. \n\n클래스별 이미지 파일의 수와 인스턴스 수를 Plot합니다.\n\n### Train op\n\n모델을 학습합니다. 학습 설정 변경 및 하이퍼파라미터 조정은 cfg파일을 이용합니다. 또한, MLflow에 로깅합니다.\n\n### Tune op\n\n학습 후 `best.pt`를 불러와 하이퍼 파라미터 튜닝을 진행합니다. 또한, MLflow에 로깅합니다.\n\n### Test op\n\n학습 후 `best.pt`를 불러와 테스트 데이터셋에 대한 모델의 일반화 성능을 평가합니다. 또한, MLflow에 로깅합니다.\n\n\n\n## Pipeline Config\n\n---\n\n파이프라인 실행 시 필요한 파라미터들은 아래와 같습니다.\n\n![Kubeflow Dashboard → Runs → Create Run → Choose Pipeline](/assets/img/kubeflow/kubeyolo502.png)\n\nKubeflow Dashboard → Runs → Create Run → Choose Pipeline\n\n- `model_name`(str) : 학습할 모델의 파일명을 입력합니다.",
        "index": 1
      },
      {
        "id": "2024-11-02-Misc--Pipeline_chunk_2",
        "text": "Kubeflow Dashboard → Runs → Create Run → Choose Pipeline\n\n- `model_name`(str) : 학습할 모델의 파일명을 입력합니다.",
        "index": 2
      },
      {
        "id": "2024-11-02-Misc--Pipeline_chunk_3",
        "text": "Kubeflow Dashboard → Runs → Create Run → Choose Pipeline\n\n- `model_name`(str) : 학습할 모델의 파일명을 입력합니다.",
        "index": 3
      },
      {
        "id": "2024-11-02-Misc--Pipeline_chunk_4",
        "text": "Kubeflow Dashboard → Runs → Create Run → Choose Pipeline\n\n- `model_name`(str) : 학습할 모델의 파일명을 입력합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Misc-Kubeflow-Change-password---Add-User",
    "title": "Misc. Kubeflow Change password & Add User",
    "path": "/2024/11/02/Misc-Kubeflow-Change-password-&-Add-User/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 페이지에서는 Kubeflow 대시보드에 접속하기 위한 사용자의 비밀번호를 변경하고, 사용자를 추가하는 법에 대해 다루겠습니다.\n\n# Change User Password\n\n---\n\n우선, Kubeflow 구축시 기본 ID와 PW는 아래와 같습니다.\n\n- ID : `user@example.com`\n- PW : `12341234`\n\nKubeflow에선 Hash를 사용해 PW를 configmap에 저장합니다.\n\n우선, 사용할 비밀번호를 생성하겠습니다.\n\n### Hash password\n\n```bash\n# passlib 라이브러리가 필요합니다.\n# 만약 설치되어있지 않다면 pip install passlib을 통해 설치합니다.\npython3 -c 'from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\n```\n\n- 예시\n\n```bash\ngyu@gyu:~$ python3 -c 'from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\nPassword: # 입력한 비밀번호는 표시되지 않습니다. 예시에서는 'Hi'를 입력했습니다.\n$2y$12$7JDOZDuVSop3nsg4QduEoOPi46DJl2A8phUKEbbtawWmPhaE1x1CG\n```\n\n### Edit config-map\n\n`manifests/common/dex/base/config-map.yaml` 수정\n\n```bash\n...\n    enablePasswordDB: true\n    staticPasswords:\n    - email: user@example.com\n\t\t\t# 아래 hash 값을 변경합니다.\n      hash: $2y$12$7JDOZDuVSop3nsg4QduEoOPi46DJl2A8phUKEbbtawWmPhaE1x1CG\n      # https://github.com/dexidp/dex/pull/1601/commits\n      # FIXME: Use hashFromEnv instead\n      username: user\n      userID: \"15841185641784\"\n```\n\n### Rebuild and Restart pod\n\nconfig-map 변경 사항을 적용하겠습니다.\n\n```bash\nkustomize build common/dex/base | kubectl apply -f -\nkubectl rollout restart deployment dex -n auth\n```\n\n# Add User\n\n---\n\n다른 사용자를 추가하기 위해선 두 가지 과정이 필요합니다.\n\n- Dex에서 ID/PW 생성\n- 자원을 사용하기 위한 네임스페이스 생성(혹은 profile 생성)\n\n### Create ID/PW\n\n우선, 사용자를 추가하겠습니다. 비밀번호 변경 방법과 유사합니다.\n\n`manifests/common/dex/base/config-map.yaml` 수정\n\n```yaml\n...\n    enablePasswordDB: true\n    staticPasswords:\n    - email: user@example.com\n      hash: $2y$12$7JDOZDuVSop3nsg4QduEoOPi46DJl2A8phUKEbbtawWmPhaE1x1CG\n      # https://github.com/dexidp/dex/pull/1601/commits\n      # FIXME: Use hashFromEnv instead\n      username: user\n      userID: \"15841185641784\"\n      # 이 아래 부분 추가\n    - email: insert_your_email.com\n      hash: $2y$12$7JDOZDuVSop3nsg4QduEoOPi46DJl2A8phUKEbbtawWmPhaE1x1CG\n      username: gyu\n      userID: \"knowgyu\"\n```\n\n### Rebuild and Restart pod\n\nconfig-map 변경 사항을 적용하겠습니다.\n\n```yaml\nkustomize build common/dex/base | kubectl apply -f -\nkubectl rollout restart deployment dex -n auth\n```\n\n- 접속 확인\n\n![Untitled.png](/assets/img/kubeflow/kubepipe402.png)\n\n⚠️ 위 이미지에서 좌측 상단을 보면, 네임스페이스가 할당되지 않은 것을 확인할 수 없습니다.\n\n네임스페이스가 없을 경우 자원을 생성할 수 없기에, 추가한 사용자를 위해 네임스페이스(Profile)을 생성하겠습니다.\n\n### Create Profile\n\n`profile.yaml` 작성 (`manifests/apps/profiles/upstream/samples` 참고)\n\n```yaml\napiVersion: kubeflow.org/v1beta1\nkind: Profile\nmetadata:\n  name: insert_username\nspec:\n  owner:\n    kind: User\n    name: insert_email_here.com\n#  resourceQuotaSpec:\n#    hard:\n#      cpu: \"8\"\n#      memory: 8Gi\n```\n\n> 이름과 사용할 리소스 등을 수정합니다.\n> \n\n\n> resourceQuotaSpec 지정 후 네임스페이스 생성 시 pod 생성마다 resource 제한을 걸어줘야합니다.\n>하지만, 사용자마다 자원을 제한할게아닌, 로컬 리소스를 모두 사용하려하기에 주석처리하였습니다.\n>\n>만약, resource를 지정하였는데, 이를 제거하고싶다면 `kubectl describe quota -n 유저네임` 명령어를 통해 `유저네임` 네임스페이스의 ResourceQuota 확인 후 `kubectl delete quota >kf-resource-quota -n 유저네임` 명령어를 통해 제거합니다.\n{: .prompt-warning }\n\n```bash\nkubectl apply -f profile.yaml\n\n# 정상적으로 실행 시 아래 메세지 출력됨.\nprofile.kubeflow.org/유저네임 created\n```\n\n### Refresh Dashboard\n\nKubeflow 대시보드를 새로고침(F5) 합니다.\n\n![Untitled.png](/assets/img/kubeflow/kubepipe401.png)\n\n정상적으로 네임스페이스가 할당된 것을 확인할 수 있습니다.\n\n> 사용자 정보를 Config-map을 이용해 관리하게 된다면, 보안 문제가 발생할 수 있습니다.\n이를 위해 DB로 저장하는 방식으로 변경하는 것을 고려해볼 수 있습니다.\n{: .prompt-tip }\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Misc-Kubeflow-Change-password---Add-User_chunk_0",
        "text": "Misc. Kubeflow Change password & Add User\n\n본 페이지에서는 Kubeflow 대시보드에 접속하기 위한 사용자의 비밀번호를 변경하고, 사용자를 추가하는 법에 대해 다루겠습니다.\n\n# Change User Password\n\n---\n\n우선, Kubeflow 구축시 기본 ID와 PW는 아래와 같습니다.\n\n- ID : `user@example.com`\n- PW : `12341234`\n\nKubeflow에선 Hash를 사용해 PW를 configmap에 저장합니다.\n\n우선, 사용할 비밀번호를 생성하겠습니다.\n\n### Hash password\n\n```bash\n# passlib 라이브러리가 필요합니다.\n# 만약 설치되어있지 않다면 pip install passlib을 통해 설치합니다.\npython3 -c 'from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\n```\n\n- 예시\n\n```bash\ngyu@gyu:~$ python3 -c 'from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\nPassword: # 입력한 비밀번호는 표시되지 않습니다.",
        "index": 0
      },
      {
        "id": "2024-11-02-Misc-Kubeflow-Change-password---Add-User_chunk_1",
        "text": "rint(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\nPassword: # 입력한 비밀번호는 표시되지 않습니다.",
        "index": 1
      },
      {
        "id": "2024-11-02-Misc-Kubeflow-Change-password---Add-User_chunk_2",
        "text": "rint(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\nPassword: # 입력한 비밀번호는 표시되지 않습니다.",
        "index": 2
      },
      {
        "id": "2024-11-02-Misc-Kubeflow-Change-password---Add-User_chunk_3",
        "text": "rint(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\nPassword: # 입력한 비밀번호는 표시되지 않습니다.",
        "index": 3
      },
      {
        "id": "2024-11-02-Misc-Kubeflow-Change-password---Add-User_chunk_4",
        "text": "rint(bcrypt.using(rounds=12, ident=\"2y\").hash(getpass.getpass()))'\nPassword: # 입력한 비밀번호는 표시되지 않습니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Component-Environment",
    "title": "Component-Environment",
    "path": "/2024/11/02/Component-Environment/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n\n컴포넌트와 파이프라인을 작성하기 전, 필요한 패키지들과 버전을 설치합니다.\n\n## Component\n\n> **컴포넌트**는 **컴포넌트 콘텐츠**와 **컴포넌트 래퍼**로 구성됨.<br>\n>\n> 하나의 컴포넌트는 래퍼를 통해 kubeflow에 전달되며 전달된 컴포넌트는 정의된 컴포넌트 콘텐츠를 실행(execute)하고 아티팩트(artifacts)들을 생산\n\n# How Kubernetes executes component\n\n---\n\nKubeflow에서 컴포넌트가 실행되는 순서는 아래와 같습니다.\n\n1. `docker pull <image>` : 정의된 컴포넌트의 실행 환경 정보가 담긴 이미지를 pull\n2. run `command` : pull한 이미지에서 컴포넌트 콘텐츠를 실행합니다.\n\n이전에 작성한 YAML파일을 확인해보면 `image: python:3.7` 입니다.\n\n즉, 파이프라인 실행 시\n\n1. `docker pull python:3.7`\n2. run `command`\n\n\n> 따라서 `torch`, `numpy`와 같은 라이브러리를 사용하려면 **패키지를 추가**해야 합니다.\n{: .prompt-tip }\n\n## 패키지 추가 방법\n\n1. `base_image` 사용\n2. `package_to_install` 사용\n\n컴포넌트를 컴파일할 때 사용했던 함수가 어떤 arg를 받는지 확인합니다.[Component-Write](https://www.notion.so/Component-Write-3e4cfaff96dc472b8c669c784adf4edd?pvs=21)\n\n```python\ndef create_component_from_func(\n    func: Callable,\n    output_component_file: Optional[str] = None,\n    base_image: Optional[str] = None,\n    packages_to_install: List[str] = None,\n    annotations: Optional[Mapping[str, str]] = None,\n):\n```\n\n- `func`: 컴포넌트로 만들 컴포넌트 래퍼 함수\n- `base_image`: 컴포넌트 래퍼가 실행할 이미지\n- `packages_to_install`: 컴포넌트를 위해 추가로 설치해야 하는 패키지\n\n### `base_image` 사용\n\n```python\nfrom functools import partial\nfrom kfp.components import InputPath, OutputPath, create_component_from_func\n\n@partial(\n    create_component_from_func,\n    base_image=\"ghcr.io/mlops-for-all/base-image:latest\",\n)\ndef train_from_csv(\n    train_data_path: InputPath(\"csv\"),\n...생략\n    kernel: str,\n):\n    import dill\n...생략\n    with open(model_path, mode=\"wb\") as file_writer:\n        dill.dump(clf, file_writer)\n\nif __name__ == \"__main__\":\n    train_from_csv.component_spec.save(\"train_from_csv.yaml\")\n```\n\n### `packages_to_install` 사용\n\n```python\nfrom functools import partial\nfrom kfp.components import InputPath, OutputPath, create_component_from_func\n\n@partial(\n    create_component_from_func,\n    packages_to_install=[\"dill==0.3.4\", \"pandas==1.3.4\", \"scikit-learn==1.0.1\"],\n)\ndef train_from_csv(\n    train_data_path: InputPath(\"csv\"),\n...생략\n    kernel: str,\n):\n    import dill\n...생략\n    with open(model_path, mode=\"wb\") as file_writer:\n        dill.dump(clf, file_writer)\n\nif __name__ == \"__main__\":\n    train_from_csv.component_spec.save(\"train_from_csv.yaml\")\n```\n\n\n> 컴포넌트 실행 시 컨테이너화되어 동작하기에, **각각의 Base Image**에 해당 **라이브러리가 설치**되어있어야합니다.<br>\n> 하지만, 파이프라인 **컴파일 시** `kfp` 라이브러리만 설치되어있다면, 컴포넌트 실행에 필요한 라이브러리는 필요하지 않습니다.<br>\n> ex) YOLOv8을 학습 혹은 추론 등 사용할 경우, `torch`와 `ultralytics` 패키지가 설치되어 있어야합니다.<br>\n> 하지만,  yaml파일로 컴파일하는 환경에서 해당 패키지들이 설치되어있지않아도 `No module named 패키지이름` 에러는 발생하지 않습니다.\n{: .prompt-info }\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Component-Environment_chunk_0",
        "text": "Component-Environment\n\n# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n\n컴포넌트와 파이프라인을 작성하기 전, 필요한 패키지들과 버전을 설치합니다.\n\n## Component\n\n> **컴포넌트**는 **컴포넌트 콘텐츠**와 **컴포넌트 래퍼**로 구성됨.<br>\n>\n> 하나의 컴포넌트는 래퍼를 통해 kubeflow에 전달되며 전달된 컴포넌트는 정의된 컴포넌트 콘텐츠를 실행(execute)하고 아티팩트(artifacts)들을 생산\n\n# How Kubernetes executes component\n\n---\n\nKubeflow에서 컴포넌트가 실행되는 순서는 아래와 같습니다.\n\n1. `docker pull <image>` : 정의된 컴포넌트의 실행 환경 정보가 담긴 이미지를 pull\n2. run `command` : pull한 이미지에서 컴포넌트 콘텐츠를 실행합니다.\n\n이전에 작성한 YAML파일을 확인해보면 `image: python:3.7` 입니다.\n\n즉, 파이프라인 실행 시\n\n1. `docker pull python:3.7`\n2. run `command`\n\n\n> 따라서 `torch`, `numpy`와 같은 라이브러리를 사용하려면 **패키지를 추가**해야 합니다.\n{: .prompt-tip }\n\n## 패키지 추가 방법\n\n1. `base_image` 사용\n2.",
        "index": 0
      },
      {
        "id": "2024-11-02-Component-Environment_chunk_1",
        "text": ", `numpy`와 같은 라이브러리를 사용하려면 **패키지를 추가**해야 합니다.\n{: .prompt-tip }\n\n## 패키지 추가 방법\n\n1. `base_image` 사용\n2.",
        "index": 1
      },
      {
        "id": "2024-11-02-Component-Environment_chunk_2",
        "text": ", `numpy`와 같은 라이브러리를 사용하려면 **패키지를 추가**해야 합니다.\n{: .prompt-tip }\n\n## 패키지 추가 방법\n\n1. `base_image` 사용\n2.",
        "index": 2
      },
      {
        "id": "2024-11-02-Component-Environment_chunk_3",
        "text": ", `numpy`와 같은 라이브러리를 사용하려면 **패키지를 추가**해야 합니다.\n{: .prompt-tip }\n\n## 패키지 추가 방법\n\n1. `base_image` 사용\n2.",
        "index": 3
      },
      {
        "id": "2024-11-02-Component-Environment_chunk_4",
        "text": ", `numpy`와 같은 라이브러리를 사용하려면 **패키지를 추가**해야 합니다.\n{: .prompt-tip }\n\n## 패키지 추가 방법\n\n1. `base_image` 사용\n2.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset",
    "title": "Pipeline for Train YOLOv8 on a Custom Dataset",
    "path": "/2024/11/02/Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 문서에서는 YOLOv8 커스텀 데이터셋 학습과 cfg파일을 통해 학습 설정을 변경하는 것에 대해 다루겠습니다.\n\n# Customize Ultralytics\n\n---\n\nUltralytics 라이브러리는 실험에 대한 미세한 제어를 가능하게 하는 설정 관리 시스템(Settings Management system)을 제공합니다. `ultralytics.utils` 모듈 내에 있는 `SettingsManager`를 사용함으로써 사용자는 쉽게 설정을 접근하고 변경할 수 있습니다.\n\nCLI에서 간단한 명령어 하나로 확인하고, 업데이트할 수 있습니다.\n\n```bash\n# Check Settings\nyolo settings\n\n# Update a setting\nyolo settings mlflow=False\n\n# Reset settings to Default\nyolo settings reset\n```\n\nhttps://docs.ultralytics.com/quickstart/#inspecting-settings\n\n또한, YOLOv8 모델을 사용하며 최적의 성능을 찾기 위한 다양한 configuration도 제공합니다.\n\n## Configuration\n\n---\n\nhttps://docs.ultralytics.com/usage/cfg/?h=configuration#modes\n\n> YOLO 설정과 하이퍼파라미터는 모델의 성능, 속도, 정확도에 큰 영향을 끼칩니다.\n\n- Docs example\n\n```python\nfrom ultralytics import YOLO\n\n# Load a YOLOv8 model from a pre-trained weights file\nmodel = YOLO('yolov8n.pt')\n\n# Run MODE mode using the custom arguments ARGS (guess TASK)\nmodel.MODE(ARGS)\n```\n\n> Where:\n> \n> - `TASK` (optional) is one of ([detect](https://docs.ultralytics.com/tasks/detect/), [segment](https://docs.ultralytics.com/tasks/segment/), [classify](https://docs.ultralytics.com/tasks/classify/), [pose](https://docs.ultralytics.com/tasks/pose/))\n> - `MODE` (required) is one of ([train](https://docs.ultralytics.com/modes/train/), [val](https://docs.ultralytics.com/modes/val/), [predict](https://docs.ultralytics.com/modes/predict/), [export](https://docs.ultralytics.com/modes/export/), [track](https://docs.ultralytics.com/modes/track/))\n> - `ARGS` (optional) are `arg=value` pairs like `imgsz=640` that override defaults.\n\nYOLOv8 모델을 학습 시킬 때, 다양한 하이퍼 파라미터와 설정들이 있습니다. 이러한 설정과 하이퍼파라미터들은 `cfg/defaults.yaml`에 정의되어있어 사용자가 직접 입력하지 않더라도, 기본값을 이용해 학습하게되며, 만약 원하는 Args를 입력한다면 기본값에 덮어쓰여 해당 Args를 사용할 수 있습니다.\n\n이러한 Custom Args는 커스텀 데이터셋을 사용하거나, Epochs, Batch size, Resume 등 필요에 따라 다양하게 사용할 수 있습니다.\n\n### YOLOv8 모델 학습 예시\n\nYOLOv8의 CLI 명령어는 아래와 같습니다\n\n```bash\n# YOLOv8 with DDP\nyolo detect train model=yolov8m.pt data=/data1/dataset/custom_dataset/custom_data.yaml \\\nbatch=48 workers=8 device=0,1 imgsz=640 \\ \nproject=custom_yolov8 name=Test1 \\\nsave=True save_period=30\n```\n\n이를 Kubeflow Component 형식으로 나타내면 아래와 같습니다.\n\n```python\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.1\",\n    packages_to_install=[\"ultralytics\",\"ray[tune]\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n)\ndef train(\n    checker: bool,\n    model_path: str,\n    data: str,\n    batch: int,\n    workers: int,\n    device: int,\n    imgsz: int,\n    project: str,\n    name: str,\n    save: bool,\n    save_period: int,\n        ) -> str:\n    import os\n    from ultralytics import YOLO\n    import mlflow\n    \n    if not checker:\n        print(\"CUDA is not available.\\nPlease Check GPU Device\")\n        return None\n\n    model = YOLO(model_path)    \n\n    results = model.train(data=data, batch=batch, workers=workers,\n                          device=device, imgsz=imgsz, project=project,\n                          name=name, save=save, save_period=save_period)\n\n    return os.path.join(project,name,'weights','last.pt')\n```\n\n위 예시처럼 모델을 학습하는 과정에서 최적의 성능을 찾기 위해 다양한 Args로 실험하는 것은 매우 중요합니다.\n\n하지만, 학습을 실행할 때마다 많은 Args들을 직접 입력해줘야합니다.\n\n특히, Kubeflow 파이프라인을 **실행할 때마다** 많은 Config값들을 **직접 입력**해야하며, 이는 **휴먼에러**를 일으킬 수 있습니다.\n\n이러한 문제들을 해결하기 위해 `cfg`파일을 이용하겠습니다.\n\n### YOLOv8 `cfg-custom.yaml`\n\n- `cfg/defaults.yaml`\n    \n    ```python\n    # Ultralytics YOLO 🚀, AGPL-3.0 license\n    # Default training settings and hyperparameters for medium-augmentation COCO training\n    \n    task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose\n    mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark\n    \n    # Train settings -------------------------------------------------------------------------------------------------------\n    model:  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml\n    data:  # (str, optional) path to data file, i.e. coco128.yaml\n    epochs: 300  # (int) number of epochs to train for\n    patience: 50  # (int) epochs to wait for no observable improvement for early stopping of training\n    batch: 16  # (int) number of images per batch (-1 for AutoBatch)\n    imgsz: 640  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes\n    save: True  # (bool) save train checkpoints and predict results\n    save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)\n    cache: False  # (bool) True/ram, disk or False. Use cache for data loading\n    device:  # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu\n    workers: 8  # (int) number of worker threads for data loading (per RANK if DDP)\n    project:  # (str, optional) project name\n    name:  # (str, optional) experiment name, results saved to 'project/name' directory\n    exist_ok: False  # (bool) whether to overwrite existing experiment\n    pretrained: True  # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)\n    optimizer: auto  # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n    verbose: True  # (bool) whether to print verbose output\n    seed: 0  # (int) random seed for reproducibility\n    deterministic: True  # (bool) whether to enable deterministic mode\n    single_cls: False  # (bool) train multi-class data as single-class\n    rect: False  # (bool) rectangular training if mode='train' or rectangular validation if mode='val'\n    cos_lr: False  # (bool) use cosine learning rate scheduler\n    close_mosaic: 10  # (int) disable mosaic augmentation for final epochs (0 to disable)\n    resume: False  # (bool) resume training from last checkpoint\n    amp: True  # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check\n    fraction: 1.0  # (float) dataset fraction to train on (default is 1.0, all images in train set)\n    profile: False  # (bool) profile ONNX and TensorRT speeds during training for loggers\n    freeze: None  # (int | list, optional) freeze first n layers, or freeze list of layer indices during training\n    # Segmentation\n    overlap_mask: True  # (bool) masks should overlap during training (segment train only)\n    mask_ratio: 4  # (int) mask downsample ratio (segment train only)\n    # Classification\n    dropout: 0.0  # (float) use dropout regularization (classify train only)\n    \n    # Val/Test settings ----------------------------------------------------------------------------------------------------\n    val: True  # (bool) validate/test during training\n    split: val  # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'\n    save_json: False  # (bool) save results to JSON file\n    save_hybrid: False  # (bool) save hybrid version of labels (labels + additional predictions)\n    conf:  # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)\n    iou: 0.7  # (float) intersection over union (IoU) threshold for NMS\n    max_det: 300  # (int) maximum number of detections per image\n    half: False  # (bool) use half precision (FP16)\n    dnn: False  # (bool) use OpenCV DNN for ONNX inference\n    plots: True  # (bool) save plots during train/val\n    \n    # Prediction settings --------------------------------------------------------------------------------------------------\n    source:  # (str, optional) source directory for images or videos\n    show: False  # (bool) show results if possible\n    save_txt: False  # (bool) save results as .txt file\n    save_conf: False  # (bool) save results with confidence scores\n    save_crop: False  # (bool) save cropped images with results\n    show_labels: True  # (bool) show object labels in plots\n    show_conf: True  # (bool) show object confidence scores in plots\n    vid_stride: 1  # (int) video frame-rate stride\n    stream_buffer: False  # (bool) buffer all streaming frames (True) or return the most recent frame (False)\n    line_width:   # (int, optional) line width of the bounding boxes, auto if missing\n    visualize: False  # (bool) visualize model features\n    augment: False  # (bool) apply image augmentation to prediction sources\n    agnostic_nms: False  # (bool) class-agnostic NMS\n    classes:  # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]\n    retina_masks: False  # (bool) use high-resolution segmentation masks\n    boxes: True  # (bool) Show boxes in segmentation predictions\n    \n    # Export settings ------------------------------------------------------------------------------------------------------\n    format: torchscript  # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats\n    keras: False  # (bool) use Kera=s\n    optimize: False  # (bool) TorchScript: optimize for mobile\n    int8: False  # (bool) CoreML/TF INT8 quantization\n    dynamic: False  # (bool) ONNX/TF/TensorRT: dynamic axes\n    simplify: False  # (bool) ONNX: simplify model\n    opset:  # (int, optional) ONNX: opset version\n    workspace: 4  # (int) TensorRT: workspace size (GB)\n    nms: False  # (bool) CoreML: add NMS\n    \n    # Hyperparameters ------------------------------------------------------------------------------------------------------\n    lr0: 0.01  # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\n    lrf: 0.01  # (float) final learning rate (lr0 * lrf)\n    momentum: 0.937  # (float) SGD momentum/Adam beta1\n    weight_decay: 0.0005  # (float) optimizer weight decay 5e-4\n    warmup_epochs: 3.0  # (float) warmup epochs (fractions ok)\n    warmup_momentum: 0.8  # (float) warmup initial momentum\n    warmup_bias_lr: 0.1  # (float) warmup initial bias lr\n    box: 7.5  # (float) box loss gain\n    cls: 0.5  # (float) cls loss gain (scale with pixels)\n    dfl: 1.5  # (float) dfl loss gain\n    pose: 12.0  # (float) pose loss gain\n    kobj: 1.0  # (float) keypoint obj loss gain\n    label_smoothing: 0.0  # (float) label smoothing (fraction)\n    nbs: 64  # (int) nominal batch size\n    hsv_h: 0.015  # (float) image HSV-Hue augmentation (fraction)\n    hsv_s: 0.7  # (float) image HSV-Saturation augmentation (fraction)\n    hsv_v: 0.4  # (float) image HSV-Value augmentation (fraction)\n    degrees: 0.0  # (float) image rotation (+/- deg)\n    translate: 0.1  # (float) image translation (+/- fraction)\n    scale: 0.5  # (float) image scale (+/- gain)\n    shear: 0.0  # (float) image shear (+/- deg)\n    perspective: 0.0  # (float) image perspective (+/- fraction), range 0-0.001\n    flipud: 0.0  # (float) image flip up-down (probability)\n    fliplr: 0.5  # (float) image flip left-right (probability)\n    mosaic: 1.0  # (float) image mosaic (probability)\n    mixup: 0.0  # (float) image mixup (probability)\n    copy_paste: 0.0  # (float) segment copy-paste (probability)\n    \n    # Custom config.yaml ---------------------------------------------------------------------------------------------------\n    cfg:  # (str, optional) for overriding defaults.yaml\n    \n    # Tracker settings ------------------------------------------------------------------------------------------------------\n    tracker: botsort.yaml  # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]\n    ```\n    \n\n위 파일은 기본으로 사용되는 `ARG`값들이 정의되어있는 파일입니다.  이 파일을 이용해 `cfg-custom.yaml` 을 만들겠습니다.\n\n- `cfg-custom.yaml`\n\n```\n# Ultralytics YOLO 🚀, AGPL-3.0 license\n# Default training settings and hyperparameters for medium-augmentation COCO training\n\ntask: detect  # (str) YOLO task, i.e. detect, segment, classify, pose\nmode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark\n\n# Train settings -------------------------------------------------------------------------------------------------------\nmodel: **yolov8m.pt**  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml\ndata: **/data1/dataset/custom_dataset/custom_data.yaml** # (str, optional) path to data file, i.e. coco128.yaml\nepochs: **300**  # (int) number of epochs to train for\npatience: 50  # (int) epochs to wait for no observable improvement for early stopping of training\nbatch: **48**  # (int) number of images per batch (-1 for AutoBatch)\nimgsz: **640**  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes\n...\n...생략\n...\n\n```\n\n이렇게 `cfg-custom.yaml` 파일을 생성했다면, 아래와 같이 실행할 수 있습니다.\n\n```bash\n# 수정 전 코드\nyolo detect train model=yolov8m.pt data=/data1/dataset/custom_dataset/custom_data.yaml \\\nbatch=48 workers=8 device=0,1 imgsz=640 \\ \nproject=custom_yolov8 name=Test \\\nsave=True save_period=30\n\n# 수정 후 코드\nyolo detect train cfg=cfg-custom.yaml\n```\n\n이처럼 `cfg-custom.yaml` 파일을 이용하면 더욱 편리하게 YOLO 설정 및 하이퍼파라미터 조정이 가능합니다.\n\n이를 활용해 Kubeflow Pipeline에 적용하도록 하겠습니다.\n\n## Custom Dataset Training Pipeline\n\n---\n\n노드 **로컬** 볼륨에 있는 COCO128 데이터셋을 학습하는 파이프라인을 작성하겠습니다.\n\n우선, 폴더 구조는 아래와 같습니다\n\n```bash\nkfcocotest/\n├── cfg-custom.yaml\n├── data-custom.yaml\n├── datasets\n│   ├── coco128  [256 entries exceeds filelimit, not opening dir]\n│   ├── coco128test.txt\n│   └── coco128train.txt\n└── KFP_compiler.py\n```\n\n### 볼륨 마운트\n\n이전 PV Mount 문서에서 다룬 방법대로 PV/PVC를 생성한 후 Pipeline에 연결하겠습니다.\n\n- `cocopv.yaml`\n\n```bash\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: local-cocodata\nspec:\n  capacity:\n    storage: 3Gi\n  volumeMode: Filesystem\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: \"train\"\n  hostPath:\n    path: \"/data/kfcocotest\"\n  nodeAffinity:\n    required:\n      nodeSelectorTerms:\n      - matchExpressions:\n        - key: kubernetes.io/hostname\n          operator: In\n          values:\n          - knowgyu\n```\n\n- `cocopvc.yaml`\n\n```bash\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pvc-local-cocodata\n  namespace: knowgyu\nspec:\n  accessModes:\n  - ReadWriteOnce\n  volumeMode: Filesystem\n  resources:\n    requests:\n      storage: 3Gi\n  storageClassName: \"train\"\n```\n\n- 생성 및 확인\n\n```bash\nkubectl apply -f cocopv.yaml \nkubectl apply -f cocopvc.yaml \n\n# 각각 아래와 같은 메세지가 출력됩니다.\npersistentvolume/local-cocodata created\npersistentvolumeclaim/pvc-local-cocodata created\n```\n\n![Kubeflow Dashboard에서 확인. pvc-local-cocodata 생성 확인 완료](/assets/img/kubeflow/kubeyolo201.png)\n\nKubeflow Dashboard에서 확인. pvc-local-cocodata 생성 확인 완료\n\n![해당 PVC에 연결한 Jupyter Notebook 확인](/assets/img/kubeflow/kubeyolo202.png)\n\n해당 PVC에 연결한 Jupyter Notebook 확인\n\n### 학습 설정\n\n정상적으로 마운트된 것을 확인했다면, Notebook에서 yaml파일들을 수정합니다.\n\n![Untitled](/assets/img/kubeflow/kubeyolo203.png)\n\n- `cfg-custom.yaml`\n    \n    ```yaml\n    # Ultralytics YOLO 🚀, AGPL-3.0 license\n    # Default training settings and hyperparameters for medium-augmentation COCO training\n    \n    task: detect  # (str) YOLO task, i.e. detect, segment, classify, pose\n    mode: train  # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark\n    \n    # Train settings -------------------------------------------------------------------------------------------------------\n    model:  # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml\n    data:  # (str, optional) path to data file, i.e. coco128.yaml\n    epochs: 2  # (int) number of epochs to train for\n    patience: 50  # (int) epochs to wait for no observable improvement for early stopping of training\n    batch: 4  # (int) number of images per batch (-1 for AutoBatch)\n    imgsz: 320  # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes\n    save: True  # (bool) save train checkpoints and predict results\n    save_period: 30 # (int) Save checkpoint every x epochs (disabled if < 1)\n    cache: False  # (bool) True/ram, disk or False. Use cache for data loading\n    device:  # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu\n    workers: 8  # (int) number of worker threads for data loading (per RANK if DDP)\n    project: testprj  # (str, optional) project name\n    name: testexp  # (str, optional) experiment name, results saved to 'project/name' directory\n    exist_ok: False  # (bool) whether to overwrite existing experiment\n    pretrained: True  # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)\n    optimizer: auto  # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n    verbose: True  # (bool) whether to print verbose output\n    seed: 404  # (int) random seed for reproducibility\n    deterministic: True  # (bool) whether to enable deterministic mode\n    single_cls: False  # (bool) train multi-class data as single-class\n...\n...\n생략\n...\n...\n    mixup: 0.0  # (float) image mixup (probability)\n    copy_paste: 0.0  # (float) segment copy-paste (probability)\n    \n    # Custom config.yaml ---------------------------------------------------------------------------------------------------\n    cfg:  # (str, optional) for overriding defaults.yaml\n    \n    # Tracker settings ------------------------------------------------------------------------------------------------------\n    tracker: botsort.yaml  # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]\n    ```\n    \n- `data-custom.yaml`\n    \n    ```bash\n    # train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n    train: ./coco128train.txt # 6,331\n    val: ./coco128test.txt # 1,118\n    \n    # number of classes\n    nc: 80\n    \n    # class names\n    names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n             'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n             'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n             'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n             'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n             'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n             'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n             'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n             'hair drier', 'toothbrush' ]\n    ```\n    \n\n>`yolo settings` 명령어로 `datasets_dir` 경로를 잘 확인해야합니다.\n>\n>`coco128train.txt` 는 아래와 같은 형식으로 입력되어 있습니다.\n>`./coco128/000000000357.jpg` \n>`./coco128/000000000450.jpg`\n{: .prompt-tip }\n\n### 파이프라인 작성 및 업로드\n\n- `KFP_compiler.py`\n    \n    ```python\n    from functools import partial\n    \n    import kfp\n    from kfp.components import create_component_from_func, InputPath, OutputPath\n    from kfp import dsl\n    \n    @partial(\n        create_component_from_func,\n        base_image=\"nohgyu/test:v1.1\",\n    )\n    def verify_training(\n        model_name: str,\n        cfg: str,\n        data: str,\n        ) -> bool:\n        import torch\n    \n        assert isinstance(model_name, str), \"model_name must be a string\"\n        assert isinstance(cfg, str), \"model_name must be a string\"\n        assert isinstance(data, str), \"model_name must be a string\"\n        \n        return torch.cuda.is_available()\n        \n        \n    @partial(\n        create_component_from_func,\n        base_image=\"nohgyu/test:v1.1\",\n        packages_to_install=[\"ultralytics\",\"opencv-python==4.8.0.74\",\"mlflow\", \"boto3\"],\n    )\n    def train(\n        checker: bool,\n        model_name: str,\n        cfg: str,\n        data: str,\n            ) -> str:\n        import os\n        from ultralytics import YOLO\n        import mlflow\n        import yaml\n        \n        if not checker:\n            print(\"CUDA is not available.\\nPlease Check GPU Device\")\n            return None\n    \n        os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n        os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n ...",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset_chunk_0",
        "text": "Pipeline for Train YOLOv8 on a Custom Dataset\n\n본 문서에서는 YOLOv8 커스텀 데이터셋 학습과 cfg파일을 통해 학습 설정을 변경하는 것에 대해 다루겠습니다.\n\n# Customize Ultralytics\n\n---\n\nUltralytics 라이브러리는 실험에 대한 미세한 제어를 가능하게 하는 설정 관리 시스템(Settings Management system)을 제공합니다.",
        "index": 0
      },
      {
        "id": "2024-11-02-Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset_chunk_1",
        "text": "ytics\n\n---\n\nUltralytics 라이브러리는 실험에 대한 미세한 제어를 가능하게 하는 설정 관리 시스템(Settings Management system)을 제공합니다.",
        "index": 1
      },
      {
        "id": "2024-11-02-Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset_chunk_2",
        "text": "ytics\n\n---\n\nUltralytics 라이브러리는 실험에 대한 미세한 제어를 가능하게 하는 설정 관리 시스템(Settings Management system)을 제공합니다.",
        "index": 2
      },
      {
        "id": "2024-11-02-Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset_chunk_3",
        "text": "ytics\n\n---\n\nUltralytics 라이브러리는 실험에 대한 미세한 제어를 가능하게 하는 설정 관리 시스템(Settings Management system)을 제공합니다.",
        "index": 3
      },
      {
        "id": "2024-11-02-Pipeline-for-Train-YOLOv8-on-a-Custom-Dataset_chunk_4",
        "text": "ytics\n\n---\n\nUltralytics 라이브러리는 실험에 대한 미세한 제어를 가능하게 하는 설정 관리 시스템(Settings Management system)을 제공합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Evaluate-model-with-TEST-dataset",
    "title": "Evaluate model with TEST dataset",
    "path": "/2024/11/02/Evaluate-model-with-TEST-dataset/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 문서에서는 학습이 완료된 모델을 평가하는 컴포넌트를 작성하겠습니다.\n\n학습이 완료된 모델을 테스트셋으로 평가하고, Precision, Recall, mAP 등 메트릭을 Kubeflow UI를 통해 표로 시각화하는 것을 다룹니다.\n\n# Evaluate MLmodel\n\n---\n\n모델 학습을 완료한 후 테스트셋을 이용해 평가하는 것은 매우 중요합니다. 실제 환경에서 새로운 데이터에 대해 모델이 얼마나 잘 예측할 것인가를 예상하기 위해, 학습에 사용되지 않은 데이터에 대한 모델의 일반화 성능을 평가합니다.\n\nYOLOv8 에서는 `model.val()` 를 이용해 모델을 평가할 수 있습니다. \n\n> [https://docs.ultralytics.com/modes/val/](https://docs.ultralytics.com/modes/val/)\n\nValidation 설정은 아래와 같습니다.\n\n| **Key**       | **Value** | **Description**                                                    |\n| ------------- | --------- | ------------------------------------------------------------------ |\n| `data`        | `None`    | path to data file, i.e. coco128.yaml                               |\n| `imgsz`       | `640`     | size of input images as integer                                    |\n| `batch`       | `16`      | number of images per batch (-1 for AutoBatch)                      |\n| `save_json`   | `False`   | save results to JSON file                                          |\n| `save_hybrid` | `False`   | save hybrid version of labels (labels + additional predictions)    |\n| `conf`        | `0.001`   | object confidence threshold for detection                          |\n| `iou`         | `0.6`     | intersection over union (IoU) threshold for NMS                    |\n| `max_det`     | `300`     | maximum number of detections per image                             |\n| `half`        | `True`    | use half precision (FP16)                                          |\n| `device`      | `None`    | device to run on, i.e. cuda device=0/1/2/3 or device=cpu           |\n| `dnn`         | `False`   | use OpenCV DNN for ONNX inference                                  |\n| `plots`       | `False`   | save plots and images during train/val                             |\n| `rect`        | `False`   | rectangular val with each batch collated for minimum padding       |\n| `split`       | `val`     | dataset split to use for validation, i.e. 'val', 'test' or 'train' |\n\n`split`을 보면, 기본값으로 `val`을 사용하고 있는 것을 알 수 있습니다. 하지만, 본 테스크에선 데이터셋을 train, val, test로 나눠 test 데이터셋을 이용해 평가를 하려합니다.\n\n우선, 평가 이전 데이터셋을 확인하겠습니다.\n\n## Dataset\n\n---\n\n### Directory Tree\n\n```bash\n.\n├── cfg-custom.yaml\n├── data-custom.yaml\n├── data-custom.yaml\n├── datasets\n│   ├── custom_augment  [30000 entries exceeds filelimit, not opening dir]\n│   ├── custom_test.txt\n│   ├── custom_train.txt\n│   ├── custom_val.txt\n│   ├── coco128  [256 entries exceeds filelimit, not opening dir]\n│   ├── coco128_test.txt\n│   ├── coco128_train.txt\n│   └── coco128_val.txt\n├── yolov8n.pt\n└── yolov8s.pt\n```\n\n> Jupyter 노트북과 마운트되어있는 폴더입니다.\n> \n\n### Split Dataset\n\n현재 데이터 관리를 폴더별로 구분지어 하는게 아닌, 데이터의 경로가 담긴 텍스트파일을 이용해 데이터를 불러오고 있습니다.\n\n기존에 있던 스크립트를 사용해 train, val, test 세 개의 텍스트 파일을 생성합니다.\n\n- 텍스트 파일 내용\n\n```\n./custom_augment/img0001.jpg\n./custom_augment/img0002.jpg\n./custom_augment/img0003.jpg\n...\n```\n\n- `data-custom.yaml`\n\n```yaml\n# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n# Default path is '/data/datasets'\n# To edit default path check this link \"https://docs.ultralytics.com/quickstart/#inspecting-settings\"\ntrain: custom_train.txt\nval: custom_val.txt\ntest: custom_test.txt\n\n# number of classes\nnc: 5\n\n# class names\nnames: [ 'cat', 'dog', 'orange', 'octopus', 'person' ]\n```\n\n## Evaluate\n\n---\n\n이제, 파이프라인에 평가 단계를 추가하기 위한 컴포넌트를 작성하겠습니다.\n\n### `test_op`\n\n```python\n@partial(\n    create_component_from_func,\n    base_image=\"nohgyu/test:v1.2\",\n)\ndef test_op(\n    model_path: str,\n    data: str,\n    mlpipeline_ui_metadata_path: OutputPath(\"UI_Metadata\"),\n    ):\n    import os\n    from ultralytics import YOLO    \n    import mlflow\n    import json\n    import pandas as pd\n\n    # MLflow Setup\n    os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n    \n    # Load and Test\n    model = YOLO(model_path)\n    \n    metrics = model.val(data=data, split='test')\n    \n    precision, recall, map50, map50_95, fitness = list(metrics.results_dict.values())\n\n    # Define table schema\n    schema = [\n        {\"name\": \"Metrics\", \"type\": \"STRING\"},\n        {\"name\": \"Value\", \"type\": \"NUMBER\"},\n    ]\n\n    # Prepare table data\n    prediction_results = [\n        {\"name\": \"Precision\", \"value\": precision},\n        {\"name\": \"Recall\", \"value\": recall},\n        {\"name\": \"mAP@0.5\", \"value\": map50},\n        {\"name\": \"mAP@0.5-0.95\", \"value\": map50_95},\n        {\"name\": \"Fitness\", \"value\": fitness},\n    ]\n    \n    # Convert to CSV\n    df = pd.DataFrame(prediction_results)\n    csvsource = df.to_csv(index=False, header=False)\n\n    # Generate metadata for UI visualization\n    metadata = {\n        \"outputs\": [{\n                \"type\": \"table\",\n                \"format\": \"csv\",\n                \"header\": [x[\"name\"] for x in schema],\n                \"source\": csvsource,\n                \"storage\": \"inline\",\n        }]\n    }   \n    # Write metadata to file\n    with open(mlpipeline_ui_metadata_path, 'w', encoding='utf-8') as metadata_file:\n        json.dump(metadata, metadata_file)\n```\n\n코드는 기존의 `train_op` , `tune_op` 와 매우 유사합니다.\n\n`split='test'` 를 통해 `data-yaml`에서 정의한 `custom_test.txt` 파일에 대해 평가를 진행하게 됩니다.\n\n평가가 끝난 후, MLflow에 로깅되지만, Pipeline UI에서 바로 확인할 수 있도록 Table을 만들어 출력하게 됩니다.\n\n`metrics` 에 관한 자세한 내용은<br>\n[https://docs.ultralytics.com/reference/utils/metrics/?h=detmetrics#ultralytics.utils.metrics.DetMetrics](https://docs.ultralytics.com/reference/utils/metrics/?h=detmetrics#ultralytics.utils.metrics.DetMetrics) 참고\n\n### `train_pipeline`\n\n```python\n@dsl.pipeline(name=\"pipelinename\",\n          description=\"MLpipline Description\",\n          )\ndef train_pipeline(\n    model_name: str = 'yolov8n.pt',\n    cfg: str = 'cfg-custom',\n    data: str = 'data-custom',\n    bool_train: bool=True,\n    bool_tune: bool=False,\n    ):\n    import os\n    \n    vop = dsl.VolumeOp(\n        name=\"volume mount\",\n        resource_name=\"pvc-local-cocodata\",\n        storage_class='train',\n        modes=dsl.VOLUME_MODE_RWO,\n        size=\"3Gi\",\n        generate_unique_name=False,\n        action='apply',\n        )\n    \n    verifier = verify_pipeline_op(model_name, cfg, data)\n    \n    get_distribution = get_data_distribution_op(verifier.outputs['data_yaml'])\n    \n    plotting = plot_data_distribution_op(get_distribution.outputs[\"result_json\"], get_distribution.outputs[\"cls_names_json\"])\n    \n    with dsl.Condition(bool_train == True , \"train\"):\n        trainer = train_op(model_name, verifier.outputs['cfg_yaml'], verifier.outputs['data_yaml'])\n        tester = test_op(trainer.outputs['last_pt'], trainer.outputs['data_yaml'])\n        \n        with dsl.Condition(bool_tune == True , 'tune'):\n            raytuner = tune_op(trainer.outputs['last_pt'],trainer.outputs['best_pt'],trainer.outputs['data_yaml'])\n...\n```\n\n컴포넌트 작성을 완료했다면, 학습이 완료된 모델의 경로와 데이터 yaml파일을 입력받아 컴포넌트를 실행할 수 있도록 추가합니다.\n\n- 실행 화면\n\n![Untitled](/assets/img/kubeflow/kubeyolo401.png)\n\n## Conclusion\n\n---\n\nultralytics 패키지를 이용해 쉽게 평가를 진행할 수 있습니다.<br>\n또한, 학습과 튜닝하는 컴포넌트와 유사한 코드로 작성할 수 있어 편리합니다.\n\nKubeflow Pipeline UI는 Visualization기능을 제공해 위와 같이 metrics를 받아 Table로 시각화할 수 있습니다.\n\n현재는 모델의 Precision, Recall, mAP@0.5, mAP@0.5-0.95, Fitness를 표로 출력하고 있지만, 필요에 따라 클래스별 성능 지표를 추가할 수 있을 것으로 보입니다.\n\n![Untitled](/assets/img/kubeflow/kubeyolo402.png)\n\n> (23.12.12작성) <br>\n> Kubeflow Piepelines v1SDK는 Table외에도 Confusion matrix, Markdown, ROC curve, TensorBoard, Web app을 지원합니다. 여기서 Web app을 사용하면, 이미지를 HTML형식으로 바꿔 시각화하는 것이 가능합니다.<br>\n[Data Analysis Component + Visualization](https://www.notion.so/Data-Analysis-Component-Visualization-d18d8dba0c684e7cb868d3c2a9b7120b?pvs=21) \n>\n>이를 이용해 YOLO 학습 및 평가 시 기본으로 생성되는 그래프들을 불러와 시각화하는 기능을 추가했습니다.\n  - Train : `labels.jpg`, `labels_correlogram.jpg`, `train_batch0.jpg`, `confusion_matrix.png`, `results.png`\n  - Test : `confusion_matrix.png`, `confusion_matrix_normalized.png`\n{: .prompt-tip }\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Evaluate-model-with-TEST-dataset_chunk_0",
        "text": "Evaluate model with TEST dataset\n\n본 문서에서는 학습이 완료된 모델을 평가하는 컴포넌트를 작성하겠습니다.\n\n학습이 완료된 모델을 테스트셋으로 평가하고, Precision, Recall, mAP 등 메트릭을 Kubeflow UI를 통해 표로 시각화하는 것을 다룹니다.\n\n# Evaluate MLmodel\n\n---\n\n모델 학습을 완료한 후 테스트셋을 이용해 평가하는 것은 매우 중요합니다. 실제 환경에서 새로운 데이터에 대해 모델이 얼마나 잘 예측할 것인가를 예상하기 위해, 학습에 사용되지 않은 데이터에 대한 모델의 일반화 성능을 평가합니다.\n\nYOLOv8 에서는 `model.val()` 를 이용해 모델을 평가할 수 있습니다. \n\n> [https://docs.ultralytics.com/modes/val/](https://docs.ultralytics.com/modes/val/)\n\nValidation 설정은 아래와 같습니다.\n\n| **Key**       | **Value** | **Description**                                                    |\n| ------------- | --------- | ------------------------------------------------------------------ |\n| `data`        | `None`    | path to data file, i.e.",
        "index": 0
      },
      {
        "id": "2024-11-02-Evaluate-model-with-TEST-dataset_chunk_1",
        "text": "------------------------------------------- |\n| `data`        | `None`    | path to data file, i.e.",
        "index": 1
      },
      {
        "id": "2024-11-02-Evaluate-model-with-TEST-dataset_chunk_2",
        "text": "------------------------------------------- |\n| `data`        | `None`    | path to data file, i.e.",
        "index": 2
      },
      {
        "id": "2024-11-02-Evaluate-model-with-TEST-dataset_chunk_3",
        "text": "------------------------------------------- |\n| `data`        | `None`    | path to data file, i.e.",
        "index": 3
      },
      {
        "id": "2024-11-02-Evaluate-model-with-TEST-dataset_chunk_4",
        "text": "------------------------------------------- |\n| `data`        | `None`    | path to data file, i.e.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Kubeflow",
    "title": "Kubeflow 시작하기",
    "path": "/2024/11/02/Kubeflow-시작하기/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "Kubeflow 시스템  구축\n\n- 미니쿠브(minikube)를 통해 단일노드로 구축\n- Kubeflow Web UI가 접속 가능하도록 함\n\n---\n\n참고 : [https://mlops-for-all.github.io/](https://mlops-for-all.github.io/)\n\n\n> 클러스터와 클라이언트 노드의 구분 중요.\n>\n> 별도 표기 없을 경우 모두 클러스터 노드에서 진행\n{: .prompt-tip }\n\n![Untitled](/assets/img/kubeflow/kube000.png)\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Kubeflow_chunk_0",
        "text": "Kubeflow 시작하기\n\nKubeflow 시스템  구축\n\n- 미니쿠브(minikube)를 통해 단일노드로 구축\n- Kubeflow Web UI가 접속 가능하도록 함\n\n---\n\n참고 : [https://mlops-for-all.github.io/](https://mlops-for-all.github.io/)\n\n\n> 클러스터와 클라이언트 노드의 구분 중요.\n>\n> 별도 표기 없을 경우 모두 클러스터 노드에서 진행\n{: .prompt-tip }\n\n![Untitled](/assets/img/kubeflow/kube000.png)\n",
        "index": 0
      }
    ]
  },
  {
    "id": "2024-11-02-Component-Write",
    "title": "Component-Write",
    "path": "/2024/11/02/Component-Write/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n\n컴포넌트와 파이프라인을 작성하기 전, 필요한 패키지들과 버전을 설치합니다.\n\n## Install Requirements\n\n- Python version ≥ 3.7, ≤3.9 (3.10버전부터 `scikit-learn==1.0.1` 설치 에러 발생)\n- requirements.txt\n    \n    ```python\n    kfp==1.8.9\n    scikit-learn==1.0.1\n    mlflow==1.21.0\n    pandas==1.3.4\n    dill==0.3.4\n    urllib3<2.0\n    numpy<1.20\n    ```\n    \n\n\n> (23.12.11. 작성) 가상환경을 생성해 테스트하길 권장하며, `kfp==1.8.22` 버전 사용 가능\n{: .prompt-tip }\n\n## Component\n\n컴포넌트를 작성하기 위해서는 아래와 같은 내용을 작성해야 합니다.\n\n1. 컴포넌트 콘텐츠(Component Contents) 작성\n2. 컴포넌트 래퍼(Component Wrapper) 작성\n\n### Component Contents\n\n컴포넌트 콘텐츠는 흔히 작성하는 파이썬 코드와 동일함.\n\nex) 숫자를 입력으로 받고 입력받은 숫자를 출력한 뒤 반환하는 컴포넌트 작성\n\n```python\nprint(number)\n```\n\n위 코드에서 `number` 가 정의되어 있지 않아 에러가 발생함.\n\nKubeflow에서 `number`와 같이 컴포넌트 콘텐츠에 필요한 값들은 **Config**로 정의함.\n\n→ 컴포넌트 콘텐츠를 실행시키기 위해 필요한 Config들은 컴포넌트 래퍼에서 전달\n\n### Component Wrapper\n\n**필요한 Config를 전달할 수 있도록 컴포넌트 래퍼 작성**\n\n```python\ndef print_and_return_number(number: int) -> int:\n\tprint(number)\n\treturn number\n```\n\n콘텐츠에 필요한 Config를 래퍼의 argument로 추가.\n\n**💡argument 타입 힌트 작성 이유**\n  → 파이프라인을 Kubeflow Format으로 변환할 때, 컴포넌트 간 입출력 타입이 일치하는지 체크함\n\n**Convert to Kubeflow Format**\n\n```python\nfrom kfp.components import create_component_from_func\n\n@create_component_from_func\ndef print_and_return_number(number: int) -> int:\n\tprint(number)\n\treturn number\n```\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Component-Write_chunk_0",
        "text": "Component-Write\n\n# Kubeflow\n\n---\n\n> Kubeflow를 사용하기 위해서는 **컴포넌트**와 **파이프라인**을 작성해야 합니다.\n\n\n컴포넌트와 파이프라인을 작성하기 전, 필요한 패키지들과 버전을 설치합니다.\n\n## Install Requirements\n\n- Python version ≥ 3.7, ≤3.9 (3.10버전부터 `scikit-learn==1.0.1` 설치 에러 발생)\n- requirements.txt\n    \n    ```python\n    kfp==1.8.9\n    scikit-learn==1.0.1\n    mlflow==1.21.0\n    pandas==1.3.4\n    dill==0.3.4\n    urllib3<2.0\n    numpy<1.20\n    ```\n    \n\n\n> (23.12.11. 작성) 가상환경을 생성해 테스트하길 권장하며, `kfp==1.8.22` 버전 사용 가능\n{: .prompt-tip }\n\n## Component\n\n컴포넌트를 작성하기 위해서는 아래와 같은 내용을 작성해야 합니다.\n\n1. 컴포넌트 콘텐츠(Component Contents) 작성\n2.",
        "index": 0
      },
      {
        "id": "2024-11-02-Component-Write_chunk_1",
        "text": "pt-tip }\n\n## Component\n\n컴포넌트를 작성하기 위해서는 아래와 같은 내용을 작성해야 합니다.\n\n1. 컴포넌트 콘텐츠(Component Contents) 작성\n2.",
        "index": 1
      },
      {
        "id": "2024-11-02-Component-Write_chunk_2",
        "text": "pt-tip }\n\n## Component\n\n컴포넌트를 작성하기 위해서는 아래와 같은 내용을 작성해야 합니다.\n\n1. 컴포넌트 콘텐츠(Component Contents) 작성\n2.",
        "index": 2
      },
      {
        "id": "2024-11-02-Component-Write_chunk_3",
        "text": "pt-tip }\n\n## Component\n\n컴포넌트를 작성하기 위해서는 아래와 같은 내용을 작성해야 합니다.\n\n1. 컴포넌트 콘텐츠(Component Contents) 작성\n2.",
        "index": 3
      },
      {
        "id": "2024-11-02-Component-Write_chunk_4",
        "text": "pt-tip }\n\n## Component\n\n컴포넌트를 작성하기 위해서는 아래와 같은 내용을 작성해야 합니다.\n\n1. 컴포넌트 콘텐츠(Component Contents) 작성\n2.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Data-Analysis-Component---Visualization",
    "title": "Data Analysis Component + Visualization",
    "path": "/2024/11/02/Data-Analysis-Component-+-Visualization/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 문서에서는 학습 전 데이터셋 분석을 위한 컴포넌트를 작성하겠습니다.\n\n클래스별 이미지 파일 수와 인스턴스 수를 json형태로 저장하고, Kubeflow UI를 통해 시각화하는 것을 다룹니다.\n\n# Data Analysis\n\n---\n\nML모델을 학습할 때, 데이터셋은 매우 중요한 역할을 합니다. 데이터에 의해 ML모델의 성능 저하가 일어날 수 있는 문제점들은 아래와 같습니다.\n\n- 작은 크기의 데이터셋\n- 입력 이미지의 크기\n- (상대적으로) 작은 인스턴스 : 입력 이미지 내에 라벨링되는 객체가 작은 경우\n- 겹쳐있는 인스턴스\n- 부정확한 바운딩 박스\n- 클래스 불균형\n\n위 문제들 외에도 데이터에 의한 ML모델 성능 저하는 다양한 원인으로 발생합니다.\n\n이러한 데이터셋의 문제를 해결 혹은 데이터셋을 더욱 잘 이해하기 위해 CDA, EDA와 같은 데이터 분석 기법이 존재합니다.\n\n무수히 많은 데이터를 분석하고 이해하기 위해서 시각화는 매우 중요한 사항입니다.\n\n이를 위해 본 페이지에서는 파이프라인 Config로 입력받은 `data-custom.yaml` 에서 데이터셋의 위치와 클래스 이름을 확인하고, 해당 데이터셋의 클래스별 이미지 파일의 수와 인스턴스 수를 Kubeflow Dashboard UI를 이용해 시각화하겠습니다.\n\n## Pipeline Visualization\n\n---\n\nKubeflow 대시보드의 Runs에서 실행된 파이프라인의 진행사항과 결과를 볼 수 있습니다.\n\n그래프에서 실행된 컴포넌트를 누르면 컴포넌트의 입출력, Logs, Visualization과 같은 실행 정보를 확인할 수 있습니다.\n\n이 중, Visualization 기능을 사용해 컴포넌트에서 생성된 Plot을 확인하겠습니다.\n\n> [https://mlops-for-all.github.io/docs/kubeflow/advanced-run](https://mlops-for-all.github.io/docs/kubeflow/advanced-run)\n> \n\n### 시각화 예시\n\n`mlpipeline_ui_metadata: OutputPath(\"UI_Metadata\")` argument에 html 포맷으로 저장해 plot을 생성할 수 있습니다.\n\n```python\n@partial(\n    create_component_from_func,\n    packages_to_install=[\"matplotlib\"],\n)\ndef plot_linear(\n    mlpipeline_ui_metadata: OutputPath(\"UI_Metadata\")\n):\n    import base64\n    import json\n    from io import BytesIO\n\n    import matplotlib.pyplot as plt\n\n    plt.plot(x=[1, 2, 3], y=[1, 2,3])\n\n    tmpfile = BytesIO()\n    plt.savefig(tmpfile, format=\"png\")\n    encoded = base64.b64encode(tmpfile.getvalue()).decode(\"utf-8\")\n\n    html = f\"<img src='data:image/png;base64,{encoded}'>\"\n    metadata = {\n        \"outputs\": [\n            {\n                \"type\": \"web-app\",\n                \"storage\": \"inline\",\n                \"source\": html,\n            },\n        ],\n    }\n    with open(mlpipeline_ui_metadata, \"w\") as html_writer:\n        json.dump(metadata, html_writer)\n```\n\n💡 Kubeflow Pipeline UI에서 시각화를 하기 위해 아티팩트의 이름은 반드시 `mlpipeline-ui-metadata` 로 지정해야합니다.\n\n\n> For KFP v1, the pipeline component must write a JSON file specifying metadata for the output viewer(s) that you want to use for visualizing the results. The component must also export a file output artifact with an artifact name of `mlpipeline-ui-metadata`, or else the Kubeflow Pipelines UI will not render the visualization. In other words, the `.outputs.artifacts` setting for the generated pipeline component should show: `- {name: mlpipeline-ui-metadata, path: /mlpipeline-ui-metadata.json}`. The JSON filepath does not matter, although `/mlpipeline-ui-metadata.json` is used for consistency in the examples below.\n\n- 실행 결과\n\n![모두를 위한 MLOps https://mlops-for-all.github.io/docs/kubeflow/advanced-run](/assets/img/kubeflow/kubeyolo301.png)\n\n\n## Data distribution\n\n---\n\n위 기능을 이용해 Plot하기 전, `data-custom.yaml`을 읽고, 클래스 이름과 데이터셋의 클래스별 분포를 분석하겠습니다.\n\n\n- `data-custom.yaml`\n\n```python\n# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n# Default path is '/data/datasets'\n# To edit default path check this link \"https://docs.ultralytics.com/quickstart/#inspecting-settings\"\ntrain: custom_train.txt\nval: custom_test.txt\n\n# number of classes\nnc: 5\n\n# class names\nnames: [ 'cat', 'dog', 'orange', 'person', 'glasses' ]\n```\n\n### 데이터 분포 분석 컴포넌트\n\n- `get_data_distribution_op`(1/2)\n\n```python\ndef get_data_distribution_op(\n    data_yaml: str,\n    mlpipeline_metrics_path: OutputPath(\"Metrics\"), # Unused\n    result_json_path: OutputPath(\"json\"),\n    cls_names_json_path: OutputPath(\"json\"),\n    ):\n    import os\n    import yaml\n    import json\n    from collections import defaultdict\n    from tqdm import tqdm\n    from ultralytics import settings\n    \n    yolo_default_dir = settings['datasets_dir']\n    \n    # Read yaml and Get train.txt path\n    with open(data_yaml, 'r', encoding='utf-8') as file:\n        data = yaml.safe_load(file)\n        train_txt_rel_path = data['train']\n        train_txt_abs_path = yolo_default_dir + '/' + train_txt_rel_path\n        \n        # Get Class names from yaml file\n        cls_names = data['names']\n        print('cls_names:',cls_names)\n        \n        cls_dict = {i: cls_names[i] for i in range(len(cls_names))}\n\n        \n    # Read train.txt and Get dataset path\n    with open(train_txt_abs_path, 'r', encoding='utf-8') as file:\n        line = file.readline().strip()\n        dir = os.path.dirname(line)\n        \n        # if folders are nested, dirname func may not work as desired\n        folders = dir.split(os.path.sep)\n        print(folders)\n        \n        dataset_dir = os.path.join(yolo_default_dir, folders[1])\n```\n\n위 함수의 Args는 아래와 같습니다.\n\n- `data_yaml` : 파이프라인 실행 시 입력받은 데이터셋 구성 정보를 담은 yaml파일 경로입니다.\n- `mlpipeline_metrics_path` : 아직 구현하지 않은 기능입니다.(metrics기능을 이용 표로 나타낼 예정)\n- `result_json_path` : json형태의 파일을 plot 컴포넌트로 보내기 위한 인자입니다.\n- `cls_names_json_path` : json형태의 파일을 plot 컴포넌트로 보내기 위한 인자입니다.\n\n위 코드 스니펫은 입력받은 yaml파일을 읽어 학습하려는 파일들의 경로가 담긴 `train.txt` 파일의 위치를 찾고, `train.txt` 의 첫번째 줄을 읽어 데이터셋의 경로를 찾습니다. 또한, yaml파일로부터 클래스 이름을 딕셔너리 형태로 저장합니다.\n\n> `train.txt` 는 `./coco128/025324.jpg` 와 같이 `./` 를 포함해야합니다.<br>\n> `./animal/cat/siamesecat/029384.jpg` 와 같이 중첩된 폴더일 경우 `dir.split(os.path.sep)` 을 이용해 `./animal` 의 형태로 저장합니다.\n{: .prompt-tip }\n\n- `get_data_distribution_op`(2/2)\n\n```python\n# Search txt files and count imgs and instances per class\n    cls_files = defaultdict(set)\n    class_instances = defaultdict(int)\n    \n    for root, _, files in tqdm(os.walk(dataset_dir)):\n        for filename in files:\n            if filename.endswith('.txt'):\n                with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n                    for line in f.readlines():\n                        try:\n                            cls_id = int(line.split()[0])\n                        \n                        except ValueError:\n                            continue\n                        \n                        cls_files[cls_id].add(filename)\n                        class_instances[cls_id] += 1\n                        \n    class_imgs = {k:len(cls_files[k]) for k in sorted(cls_files.keys())}\n    class_instances = {k:v for k,v in sorted(class_instances.items())}\n    \n    result_dict = {key: {'img': class_imgs[key], 'instances': class_instances[key]} for key in class_instances}\n    \n    print('Result dict\\n',result_dict)\n    print('Class name dict\\n',cls_dict)\n\n    with open(result_json_path, 'w', encoding='utf-8') as f:\n        json.dump(result_dict, f)\n        \n    with open(cls_names_json_path, 'w', encoding='utf-8') as f:\n        json.dump(cls_dict, f)\n    \n    # Unused\n    with open(mlpipeline_metrics_path, 'w', encoding='utf-8') as f:\n        json.dump(result_dict, f)\n```\n\n데이터셋의 경로를 찾았다면, 해당 데이터셋을 순회하며 클래스 별 파일 수와 인스턴스 수를 저장합니다.\n\n`result_dict` 와 `cls_dict` 의 경우 아래와 같이 저장됩니다.\n\n```python\n# result_dict\n{\"0\": {\"img\": 62, \"instances\": 261}, \"1\": {\"img\": 3, \"instances\": 6}, \"2\": {\"img\": 13, \"instances\": 48}, \"3\": {\"img\": 5, \"instances\": 6}, ...\n\n# cls_dict\n{\"0\": \"person\", \"1\": \"bicycle\", \"2\": \"car\", \"3\": \"motorcycle\", \"4\": \"airplane\", \"5\": \"bus\", \"6\": \"train\", \"7\": \"truck\",\n```\n\n위와 같이 딕셔너리 형태로 저장했다면, Json형태로 저장해 다음 컴포넌트로 전달합니다.\n\n- 실행 결과\n\n![Untitled](/assets/img/kubeflow/kubeyolo302.png)\n\n### 데이터 Plot 컴포넌트\n\n- `plot_data_distribution_op` (1/2)\n\n```python\ndef plot_data_distribution_op(\n    result_json_path: InputPath(\"json\"),\n    cls_names_json_path: InputPath(\"json\"),\n    mlpipeline_ui_metadata: OutputPath(\"UI_Metadata\"),\n    ) -> bool:\n    import os\n    from collections import defaultdict\n    from tqdm import tqdm\n    import json\n    \n    import base64\n    from io import BytesIO\n    import matplotlib.pyplot as plt\n    \n    import pandas as pd\n    import seaborn as sns\n    from matplotlib.ticker import MultipleLocator\n\n    # Load data from JSON\n    with open(result_json_path, 'r', encoding='utf-8') as f:\n        result_dict = json.load(f)\n    \n    with open(cls_names_json_path, 'r', encoding='utf-8') as f:\n        cls_dict = json.load(f)\n        \n    result_dict = {int(key): value for key, value in result_dict.items()}\n    cls_dict = {int(key): value for key, value in cls_dict.items()}\n    print('result dict\\n',result_dict)\n    print('cls_dict\\n',cls_dict)\n\n    # Convert data to DataFrame\n    df = pd.DataFrame(list(result_dict.items()), columns=['Classes', 'Values'], index=result_dict.keys())\n    df_values = pd.json_normalize(df['Values'])\n    df = pd.concat([df.drop('Values', axis=1), df_values], axis=1)\n    df_melted = pd.melt(df, id_vars=['Classes'], value_vars=['img', 'instances'], var_name='Category', value_name='Values')\n    df_melted['Classes'] = df_melted['Classes'].map(cls_dict)\n```\n\n위 함수의 Args들은 아래와 같습니다.\n\n- `result_json_path` : 데이터 분석 컴포넌트에서 생성한 클래스 인덱스별 이미지수와 인스턴스 수를 담은 Json을 받아옵니다.\n- `cls_names_json_path` : 데이터 분석 컴포넌트에서 생성한 클래스 인덱스별 클래스 이름을 담은 Json을 받아옵니다.\n- `mlpipeline_ui_metadata` : Kubeflow Pipeline UI에 시각화하기위한 HTML을 반환합니다.\n\n위 코드 스니펫은 데이터 분포 분석 컴포넌트에서 받은 Json파일을 통해 받아온 후, `result_dict`와 `cls_dict`형태로 저장합니다.\n\n그 후, matplotlib로 Plot하기 전, `pandas` 라이브러리를 이용해 `DataFrame` 형태로 변환합니다.\n\n<aside>\n💡 `result_dict = {int(key): value for key, value in result_dict.items()}` \n위 코드의 경우 이전 컴포넌트에서 Json형태로 딕셔너리를 가져올 때, key값이 String으로 바뀌어 저장되었는데, Plot하는 코드에서 key값을 int로 처리하기에 형변환하였습니다.\n\n</aside>\n\n```python\n# Plotting\n...\n    # Save plot as image and encode to base64\n    tmpfile = BytesIO()\n    plt.savefig(tmpfile, format='png')\n    encoded = base64.b64encode(tmpfile.getvalue()).decode(\"utf-8\")\n\n    # Create HTML string\n    html = f\"<img src='data:image/png;base64,{encoded}'>\"\n\n    # Define metadata for the web app\n    metadata = {\n        \"outputs\": [\n            {\n                \"type\": \"web-app\",\n                \"storage\": \"inline\",\n                \"source\": html,\n            },\n        ],\n    }\n\n    # Save metadata to file\n    with open(mlpipeline_ui_metadata, \"w\") as html_writer:\n        json.dump(metadata, html_writer)\n        \n    return True\n```\n\nPlot하는 과정은 생략하였습니다.\n\nPlot 후 ‘png’형태로 저장 → HTML로 변환해 `mlpipeline_ui_metadata`로 저장합니다.\n\n- 실행 결과\n\n![Untitled](/assets/img/kubeflow/kubeyolo303.png)\n\n## Conclusion\n\n---\n\n전체 코드는 아래와 같습니다.\n\n- `pipeline_compiler.py`\n    \n    ```python\n    from functools import partial\n    from typing import NamedTuple\n    \n    import kfp\n    from kfp.components import create_component_from_func, InputPath, OutputPath\n    from kfp import dsl\n    \n    @partial(\n        create_component_from_func,\n        base_image=\"nohgyu/test:v1.2\",\n    )\n    def verify_pipeline_op(\n        model_path: str,\n        cfg_input: str,\n        data_input: str,\n        ) -> NamedTuple(\"Yamlfiles\",[(\"cfg_yaml\", str), (\"data_yaml\", str)]):\n        import os\n        import torch\n        from collections import namedtuple\n    \n        if not cfg_input.endswith('.yaml'):\n            cfg_input += '.yaml'\n        if not data_input.endswith('.yaml'):\n            data_input += '.yaml'    \n        \n        if not os.path.isfile(model_path):\n            raise FileNotFoundError(f\"FileNotFound : {model_path}\")    \n        if not os.path.isfile(cfg_input):\n            raise FileNotFoundError(f\"FileNotFound : {cfg_input}\")\n        if not os.path.isfile(data_input):\n            raise FileNotFoundError(f\"FileNotFound : {data_input}\")\n        \n        verify_outputs = namedtuple(\n            'Yamlfiles',\n            ['cfg_yaml', 'data_yaml'],\n        )\n        \n        return verify_outputs(cfg_input,data_input)\n    \n    @partial(\n        create_component_from_func,\n        base_image=\"nohgyu/test:v1.2\",\n    )    \n    def get_data_distribution_op(\n        data_yaml: str,\n        mlpipeline_metrics_path: OutputPath(\"Metrics\"), # Unused\n        result_json_path: OutputPath(\"json\"),\n        cls_names_json_path: OutputPath(\"json\"),\n        ):\n        import os\n        import yaml\n        import json\n        from collections import defaultdict\n        from tqdm import tqdm\n        from ultralytics import settings\n        \n        yolo_default_dir = settings['datasets_dir']\n        \n        # Read yaml and Get train.txt path\n        with open(data_yaml, 'r', encoding='utf-8') as file:\n            data = yaml.safe_load(file)\n            train_txt_rel_path = data['train']\n            train_txt_abs_path = yolo_default_dir + '/' + train_txt_rel_path\n            \n            # Get Class names from yaml file\n            cls_names = data['names']\n            print('cls_names:',cls_names)\n            \n            cls_dict = {i: cls_names[i] for i in range(len(cls_names))}\n    \n            \n        # Read train.txt and Get dataset path\n        with open(train_txt_abs_path, 'r', encoding='utf-8') as file:\n            line = file.readline().strip()\n            dir = os.path.dirname(line)\n            \n            # if folders are nested, dirname func may not work as desired\n            folders = dir.split(os.path.sep)\n            print(folders)\n            \n            dataset_dir = os.path.join(yolo_default_dir, folders[1])\n            \n        # Search txt files and count imgs and instances per class\n        cls_files = defaultdict(set)\n        class_instances = defaultdict(int)\n        \n        for root, _, files in tqdm(os.walk(dataset_dir)):\n            for filename in files:\n                if filename.endswith('.txt'):\n                    with open(os.path.join(root, filename), 'r', encoding='utf-8') as f:\n                        for line in f.readlines():\n                            try:\n                                cls_id = int(line.split()[0])\n                            \n                            except ValueError:\n                                continue\n                            \n                            cls_files[cls_id].add(filename)\n                            class_instances[cls_id] += 1\n                            \n        class_imgs = {k:len(cls_files[k]) for k in sorted(cls_files.keys())}\n        class_instances = {k:v for k,v in sorted(class_instances.items())}\n        \n        result_dict = {key: {'img': class_imgs[key], 'instances': class_instances[key]} for key in class_instances}\n        \n        print('Result dict\\n',result_dict)\n        print('Class name dict\\n',cls_dict)\n    \n        with open(result_json_path, 'w', encoding='utf-8') as f:\n            json.dump(result_dict, f)\n            \n        with open(cls_names_json_path, 'w', encoding='utf-8') as f:\n            json.dump(cls_dict, f)\n        \n        # Unused\n        with open(mlpipeline_metrics_path, 'w', encoding='utf-8') as f:\n            json.dump(result_dict, f)\n    \n    @partial(\n        create_component_from_func,\n        base_image=\"nohgyu/test:v1.2\",\n        packages_to_install=[\"seaborn\",\"pandas\"]\n    )    \n    def plot_data_distribution_op(\n        result_json_path: InputPath(\"json\"),\n        cls_names_json_path: InputPath(\"json\"),\n        mlpipeline_ui_metadata: OutputPath(\"UI_Metadata\"),\n        ) -> bool:\n        import os\n        from collections import defaultdict\n        from tqdm import tqdm\n        import json\n        \n        import base64\n        from io import BytesIO\n        import matplotlib.pyplot as plt\n        \n        import pandas as pd\n        import seaborn as sns\n        from matplotlib.ticker import MultipleLocator\n    \n        # Load data from JSON\n        with open(result_json_path, 'r', encoding='utf-8') as f:\n            result_dict = json.load(f)\n        \n        with open(cls_names_json_path, 'r', encoding='utf-8') as f:\n            cls_dict = json.load(f)\n            \n        result_dict = {int(key): value for key, value in result_dict.items()}\n        cls_dict = {int(key): value for key, value in cls_dict.items()}\n        print('result dict\\n',result_dict)\n        print('cls_dict\\n',cls_dict)\n    \n        # Convert data to DataFrame\n        df = pd.DataFrame(list(result_dict.items()), columns=['Classes', 'Values'], index=result_dict.keys())\n        df_values = pd.json_normalize(df['Values'])\n        df = pd.concat([df.drop('Values', axis=1), df_values], axis=1)\n        df_melted = pd.melt(df, id_vars=['Classes'], value_vars=['img', 'instances'], var_name='Category', value_name='Values')\n        df_melted['Classes'] = df_melted['Classes'].map(cls_dict)\n    \n        # Plotting\n        sns.set(style='whitegrid')\n        plt.figure(figsize=(14, 8))\n    \n        # Define display variable\n        display = 'both'\n    \n        # Plot based on display value\n        palette = 'Set2'\n        title = '< Distribution of Img & GT per Class >'\n    \n        # Create bar plot\n        ax = sns.barplot(data=df_melted,\n                        x='Values',\n                        y='Classes',\n                        hue='Category',\n                        palette=palette,\n                        order=df_melted['Classes'].unique(),\n                        orient='h')\n    \n        # Customize plot\n        plt.xlabel('Count', rotation=0, fontsize=12)\n        plt.ylabel('Classes', rotation=90, fontsize=12)\n        plt.title(title)\n        plt.gca().yaxis.set_major_locator(MultipleLocator(base=1))\n    \n        # Display values on the plot\n        for p in ax.patches:\n            ax.text(p.get_width() + 200,\n                    p.get_y() + p.get_height() / 1.7,\n                    f\"{p.get_width():.0f}\",\n                    ha='left', va='center', fontsize=10)\n    \n            if display == 'img':\n                ax.text(p.get_width() + 2500,\n                        p.get_y() + p.get_height() / 1.7,\n                        f\"({round((int(p.get_width()) / sum(df_melted[df_melted['Category'] == 'img']['Values']) * 100), 1)}%)\",\n                        ha='left', va='center', fontsize=9, color='purple', alpha=1.0)\n            elif display == 'instances':\n                ax.text(p.get_width() + 5200,\n                        p.get_y() + p.get_height() / 1.7,\n                        f\"({round((int(p.get_width()) / sum(df_melted[df_melted['Category'] == 'instances']['Values']) * 100), 1)}%)\",\n                        ha='left', va='center', fontsize=9, color='#004d97', alpha=1.0)\n    \n        # Save plot as image and encode to base64\n        tmpfile = BytesIO()\n        plt.savefig(tmpfile, format='png')\n        encoded = base64.b64encode(tmpfile.getvalue()).decode(\"utf-8\")\n    \n        # Create HTML string\n        html = f\"<img src='data:image/png;base64,{encoded}'>\"\n    \n        # Define metadata for the web app\n        metadata = {\n            \"outputs\": [\n                {\n                    \"type\": \"web-app\",\n                    \"storage\": \"inline\",\n                    \"source\": html,\n                },\n            ],\n        }\n    \n        # Save metadata to file\n        with open(mlpipeline_ui_metadata, \"w\") as html_writer:\n            json.dump(metadata, html_writer)\n            \n        return True\n    \n    @partial(\n        create_component_from_func,\n        base_image=\"nohgyu/test:v1.2\",\n    )\n    def train_op(\n        model_path: str,\n        cfg: str,\n        data: str,\n        ) -> NamedTuple(\"trainOutputs\",[(\"last_pt\",str), (\"best_pt\",str), (\"data_yaml\",str), (\"project\",str), (\"exp_name\", str)]):\n        import os\n        from ultralytics import YOLO\n        import mlflow\n        import yaml\n        from collections import namedtuple\n    \n        # MLflow Setup\n        os.environ[\"MLFLOW_TRACKING_URI\"] = \"http://mlflow-server-service.mlflow-system.svc:5000\"\n        os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://minio-service.kubeflow.svc:9000\"\n        os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n        os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n    \n        # Train\n        model = YOLO(model_path)    \n        \n        results = model.train(cfg=cfg,data=data)\n    \n        with open(cfg,'r',encoding='utf-8') as file:\n            config = yaml.safe_load(file)\n            \n        train_outputs = namedtuple(\n            'trainOutputs',\n            ['last_pt','best_pt','data_yaml','project','exp_name'],\n        )\n    \n        data_yaml = data\n        project = config.get('project')\n        exp_name = config.get('name')\n        last_pt = os.path.join(project,exp_name,'we...",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Data-Analysis-Component---Visualization_chunk_0",
        "text": "Data Analysis Component + Visualization\n\n본 문서에서는 학습 전 데이터셋 분석을 위한 컴포넌트를 작성하겠습니다.\n\n클래스별 이미지 파일 수와 인스턴스 수를 json형태로 저장하고, Kubeflow UI를 통해 시각화하는 것을 다룹니다.\n\n# Data Analysis\n\n---\n\nML모델을 학습할 때, 데이터셋은 매우 중요한 역할을 합니다.",
        "index": 0
      },
      {
        "id": "2024-11-02-Data-Analysis-Component---Visualization_chunk_1",
        "text": "n형태로 저장하고, Kubeflow UI를 통해 시각화하는 것을 다룹니다.\n\n# Data Analysis\n\n---\n\nML모델을 학습할 때, 데이터셋은 매우 중요한 역할을 합니다.",
        "index": 1
      },
      {
        "id": "2024-11-02-Data-Analysis-Component---Visualization_chunk_2",
        "text": "n형태로 저장하고, Kubeflow UI를 통해 시각화하는 것을 다룹니다.\n\n# Data Analysis\n\n---\n\nML모델을 학습할 때, 데이터셋은 매우 중요한 역할을 합니다.",
        "index": 2
      },
      {
        "id": "2024-11-02-Data-Analysis-Component---Visualization_chunk_3",
        "text": "n형태로 저장하고, Kubeflow UI를 통해 시각화하는 것을 다룹니다.\n\n# Data Analysis\n\n---\n\nML모델을 학습할 때, 데이터셋은 매우 중요한 역할을 합니다.",
        "index": 3
      },
      {
        "id": "2024-11-02-Data-Analysis-Component---Visualization_chunk_4",
        "text": "n형태로 저장하고, Kubeflow UI를 통해 시각화하는 것을 다룹니다.\n\n# Data Analysis\n\n---\n\nML모델을 학습할 때, 데이터셋은 매우 중요한 역할을 합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-11-02-Misc-MetalLB-Settings",
    "title": "Misc. MetalLB Settings",
    "path": "/2024/11/02/Misc-MetalLB-Settings/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "본 페이지에서는 베어메탈 클러스터용 로드밸런서 MetalLB 설치 및 설정에 대해 다루겠습니다.\n\n# Load Balancer\n\n---\n\n로드 밸런서란? 네트워크 트래픽을 여러 서버에 분산시키는 역할입니다.\n\n> *부하 분산*은 백 엔드 서버 또는 리소스의 그룹에서 들어오는 네트워크 트래픽을 효율적으로 분산하는 것을 의미합니다.<br>\n[https://learn.microsoft.com/ko-kr/azure/load-balancer/load-balancer-overview](https://learn.microsoft.com/ko-kr/azure/load-balancer/load-balancer-overview)\n\n쿠버네티스 사용 시 AWS, GCP, Azure와 같은 클라우드 플랫폼에서는 자체적으로 로드 밸런서를 제공하지만,\n\n온 프레미스 클러스터에선 로드 밸런싱 기능을 제공하는 모듈을 추가적으로 설치해야 합니다.\n\n**MetalLB**는 베어메탈 환경에서 사용할 수 있는 로드 밸런서를 제공하는 오픈소스 입니다.\n\n## MetalLB 설치 요구사항\n\n---\n\n| 요구 사항                                                                           | 버전 및 내용                                                     |\n| ----------------------------------------------------------------------------------- | ---------------------------------------------------------------- |\n| Kubernetes                                                                          | 로드 벨런싱 기능이 없는 >= v1.13.0                               |\n| [호환가능한 네트워크 CNI](https://metallb.universe.tf/installation/network-addons/) | Calico, Canal, Cilium, Flannel, Kube-ovn, Kube-router, Weave Net |\n| IPv4 주소                                                                           | MetalLB 배포에 사용                                              |\n| BGP 모드를 사용할 경우                                                              | BGP 기능을 지원하는 하나 이상의 라우터                           |\n| 노드 간 포트 TCP/UDP 7946 오픈                                                      | memberlist 요구 사항                                             |\n\n💡 BGP모드가 아닌 Layer2모드를 사용할 것이며, 추가로 설치하거나 준비할 것은 없었습니다.\n\n## MetalLB 설치\n\n---\n\n### Preparation\n\nIPVS 모드에서 kube-proxy를 사용하는 경우 K8s v1.14.2 이후부터는 엄격한 ARP(strictARP)모드를 사용해야 합니다.\n\n저희가 사용하는 환경은 v1.21.7로, ARP 모드를 적용합니다.\n\n```bash\n# 현재 모드 확인\nkubectl get configmap kube-proxy -n kube-system -o yaml | \\\ngrep strictARP\n```\n\n```bash\nstrictARP: false\n```\n\nfalse로 되어있는 경우 true로 변경하겠습니다.\n\n```bash\n# actually apply the changes, returns nonzero returncode on errors only\nkubectl get configmap kube-proxy -n kube-system -o yaml | \\\nsed -e \"s/strictARP: false/strictARP: true/\" | \\\nkubectl apply -f - -n kube-system\n```\n\n```bash\nWarning: resource configmaps/kube-proxy is missing the kubectl.kubernetes.io/last-applied-configuration annotation which is required by kubectl apply. kubectl apply should only be used on resources created declaratively by either kubectl create --save-config or kubectl apply. The missing annotation will be patched automatically.\nconfigmap/kube-proxy configured\n```\n\n### 설치 - Manifest\n\n```bash\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/namespace.yaml\nkubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.11.0/manifests/metallb.yaml\n\n# 정상적으로 설치되었는지 확인합니다. 2개의 pod가 모두 Running이 될 때까지 기다림\nkubectl get pod -n metallb-system\n```\n\n```bash\nNAME                          READY   STATUS    RESTARTS   AGE\ncontroller-7dcc8764f4-8n92q   1/1     Running   1          1m\nspeaker-fnf8l                 1/1     Running   1          1m\n```\n\n- **controller** : deployment로 배포되며, 로드 밸런싱을 수행할 외부 IP주소 할당을 처리\n- **speaker** : deamonset 형태로 배포되며, 외부 트래픽과 서비스를 연결해 네트워크 통신이 가능하도록\n\n<aside>\n💡 서비스에는 컨트롤러 및 스피커와 구성 요소가 작동하는 데 필요한 RBAC 사용 권한이 포함됩니다.\n\n</aside>\n\n## Configuration\n\n---\n\nMetalLB의 로드 밸런싱 정책 설정은 configmap을 배포하여 설정할 수 있습니다.\n\nMetalLB에서 구성할 수 있는 모드는 `Layer2 모드` 와 `BGP 모드` 가 있습니다.\n\n### Layer 2 Configuration\n\nLayer 2 모드는 사용할 IP주소의 대역만 설정하면 됩니다.\n\nLayer 2 모드를 사용할 경우 워커 노드의 네트워크 인터페이스에 IP를 바인딩 하지 않아도 됩니다.\n\n→ 로컬 네트워크의 ARP 요청에 직접 응답해 컴퓨터의 MAC주소를 클라이언트에 제공\n\n- `metallb_config.yaml`\n\n```bash\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 192.168.1.87-192.168.1.97 # IP 대역폭\n```\n\n> 위 파일은 192.168.1.87 ~ 192.168.1.97의 IP에 대한 제어 권한을 제공하고, Layer 2 모드를 구성하는 설정\n클러스터 노드와 클라이언트 노드가 분리된 경우, 위 IP 대역이 두 노드 모두 접근 가능한 대역이어야 합니다.\n> \n\n```bash\nkubectl apply -f metallb_config.yaml\n```\n\n```bash\n# 정상적으로 배포되면 아래와 같은 메세지가 출력됩니다.\nconfigmap/config created\n```\n\n## MetalLB 사용\n\n---\n\n### Kubeflow Dashboard\n\nkubeflow의 대시보드를 제공하는 istio-system 네임스페이스의 istio-ingressgateway 서비스 타입을 변경합니다.\n\n```bash\n# 현재 서비스타입 확인\nkubectl get svc/istio-ingressgateway -n istio-system\n```\n\n```bash\nNAME                   TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)                                        AGE\nistio-ingressgateway   ClusterIP   10.98.123.79   <none>        15021/TCP,80/TCP,443/TCP,31400/TCP,15443/TCP   4h21m\n```\n\n> 서비스의 타입은 ClusterIP이며, 외부 IP 값은 `none` 입니다.\n> \n\n```bash\n# 타입을 LoadBalancer로 변경하고 IP주소 입력 (만약 IP주소 입력하지 않을 경우 위에서 설정한 IP 주소풀에서 배정)\nkubectl edit svc/istio-ingressgateway -n istio-system\n```\n\n```yaml\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{},\"labels\":{\"app\":\"istio-ingressgateway\",\"install.operator.istio.io/owning-resource\":\"unknown\",\"istio\":\"ingressgateway\",\"istio.io/rev\":\"default\",\"operator.istio.io/component\":\"IngressGateways\",\"release\":\"istio\"},\"name\":\"istio-ingressgateway\",\"namespace\":\"istio-system\"},\"spec\":{\"ports\":[{\"name\":\"status-port\",\"port\":15021,\"protocol\":\"TCP\",\"targetPort\":15021},{\"name\":\"http2\",\"port\":80,\"protocol\":\"TCP\",\"targetPort\":8080},{\"name\":\"https\",\"port\":443,\"protocol\":\"TCP\",\"targetPort\":8443},{\"name\":\"tcp\",\"port\":31400,\"protocol\":\"TCP\",\"targetPort\":31400},{\"name\":\"tls\",\"port\":15443,\"protocol\":\"TCP\",\"targetPort\":15443}],\"selector\":{\"app\":\"istio-ingressgateway\",\"istio\":\"ingressgateway\"},\"type\":\"NodePort\"}}\n  creationTimestamp: \"2023-11-29T08:38:45Z\"\n  labels:\n    app: istio-ingressgateway\n    install.operator.istio.io/owning-resource: unknown\n    istio: ingressgateway\n    istio.io/rev: default\n    operator.istio.io/component: IngressGateways\n    release: istio\n  name: istio-ingressgateway\n  namespace: istio-system\n  resourceVersion: \"560305\"\n  uid: 4ba0fce1-69ed-4ef6-ae52-07c8fc2d9b3d\nspec:\n  clusterIP: 10.98.123.79\n  clusterIPs:\n  - 10.98.123.79\n  externalTrafficPolicy: Cluster\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  ports:\n\t- name: status-port\n    nodePort: 30824\n    port: 15021\n    protocol: TCP\n    targetPort: 15021\n  - name: http2\n    nodePort: 31277\n    port: 80\n    protocol: TCP\n    targetPort: 8080\n  - name: https\n    nodePort: 30779\n    port: 443\n    protocol: TCP\n    targetPort: 8443\n  - name: tcp\n    nodePort: 31259\n    port: 31400\n    protocol: TCP\n    targetPort: 31400\n  - name: tls\n    nodePort: 31998\n    port: 15443\n    protocol: TCP\n    targetPort: 15443\n  selector:\n    app: istio-ingressgateway\n    istio: ingressgateway\n  sessionAffinity: None\n  type: LoadBalancer               <------- LoadBalancer로 변경\n  loadBalancerIP: 192.168.1.88     <------- 원하는 IP주소 입력\nstatus:\n  loadBalancer: {}\n```\n\n```bash\n# 적용되었는지 확인\nkubectl get svc/istio-ingressgateway -n istio-system\n```\n\n```bash\nNAME                   TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)                                                                      AGE\nistio-ingressgateway   LoadBalancer   10.98.123.79   192.168.1.88   15021:30824/TCP,80:31277/TCP,443:30779/TCP,31400:31259/TCP,15443:31998/TCP   44h\n```\n\n> 만약, 외부IP주소가 `none` 으로 출력된다면, 다른 서비스가 해당 IP주소를 사용하고 있을 수 있습니다.\n{: .prompt-warning }\n\n```bash\nkubectl get svc -A\n```\n\n위 명령어를 통해 모든 서비스를 출력하고, 사용할 수 있는 IP대역폭 중 할당되지 않은 IP주소로 변경 후 저장합니다.\n\n저장 후 `kubectl get svc/istio-ingressgateway -n istio-system` 을 통해 외부IP 값이 지정한 IP인지 확인합니다.\n\n웹 브라우저로 접속이 되는지 확인합니다. `http://192.168.1.88` ~~(user@example.com, 12341234)~~\n\n### MinIO Dashboard\n\n위와 동일한 방법으로 진행합니다.\n\n```bash\n# 현재 서비스 상태 확인\nkubectl get svc/minio-service -n kubeflow\n```\n\n```bash\nNAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE\nminio-service   ClusterIP   10.99.88.190   <none>        9000/TCP   5h14m\n```\n\nKubeflow 대시보드와 동일하게 수정합니다.(IP주소는 변경해야함)\n\n```bash\nkubectl edit svc/minio-service -n kubeflow\n```\n\n```yaml\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{},\"labels\":{\"application-crd-id\":\"kubeflow-pipelines\"},\"name\":\"minio-service\",\"namespace\":\"kubeflow\"},\"spec\":{\"ports\":[{\"name\":\"http\",\"port\":9000,\"protocol\":\"TCP\",\"targetPort\":9000}],\"selector\":{\"app\":\"minio\",\"application-crd-id\":\"kubeflow-pipelines\"}}}\n  creationTimestamp: \"2023-11-21T07:55:40Z\"\n  labels:\n    application-crd-id: kubeflow-pipelines\n  name: minio-service\n  namespace: kubeflow\n  resourceVersion: \"554411\"\n  uid: 1c6fd99e-6ee5-4baf-935b-d69a5cf9634c\nspec:\n  clusterIP: 10.99.88.190\n  clusterIPs:\n  - 10.99.88.190\n  externalTrafficPolicy: Cluster\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  ports:\n  - name: http\n    nodePort: 31772\n    port: 9000\n    protocol: TCP\n    targetPort: 9000\n  selector:\n    app: minio\n    application-crd-id: kubeflow-pipelines\n  sessionAffinity: None\n  type: LoadBalancer               <------- LoadBalancer로 변경\n  loadBalancerIP: 192.168.1.89     <------- 원하는 IP주소 입력\nstatus:\n  loadBalancer: {}\n```\n\n```bash\n# 적용되었는지 확인\nkubectl get svc/minio-service -n kubeflow\n```\n\n```bash\nNAME            TYPE           CLUSTER-IP     EXTERNAL-IP    PORT(S)          AGE\nminio-service   LoadBalancer   10.99.88.190   192.168.1.89   9000:31772/TCP   9d\n```\n\n웹 브라우저로 접속이 되는지 확인합니다. `http://192.168.1.89:9000/` ~~(minio, minio123)~~\n\n### Grafana Dashboard\n\n위 과정들과 동일합니다.\n\n```yaml\n# 현재 서비스 상태 확인\nkubectl get svc/seldon-core-analytics-grafana -n seldon-system\n```\n\n```yaml\nNAME                            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\nseldon-core-analytics-grafana   ClusterIP   10.99.201.117   <none>        80/TCP    94s\n```\n\n위 과정들과 동일하게 수정합니다.(IP주소는 변경)\n\n```yaml\nkubectl edit svc/seldon-core-analytics-grafana -n seldon-system\n```\n\n```yaml\n# Please edit the object below. Lines beginning with a '#' will be ignored,\n# and an empty file will abort the edit. If an error occurs while saving this file will be\n# reopened with the relevant failures.\n#\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: seldon-core-analytics\n    meta.helm.sh/release-namespace: seldon-system\n  creationTimestamp: \"2023-11-21T08:12:29Z\"\n  labels:\n    app.kubernetes.io/instance: seldon-core-analytics\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: grafana\n    app.kubernetes.io/version: 7.0.3\n    helm.sh/chart: grafana-5.1.4\n  name: seldon-core-analytics-grafana\n  namespace: seldon-system\n  resourceVersion: \"554665\"\n  uid: e3e52bd2-3cc6-4cd0-8566-76a22f120547\nspec:\n  clusterIP: 10.99.201.117\n  clusterIPs:\n  - 10.99.201.117\n  externalTrafficPolicy: Cluster\n  ipFamilies:\n  - IPv4\n  ipFamilyPolicy: SingleStack\n  loadBalancerIP: 192.168.1.90\n  ports:\n  - name: service\n    nodePort: 30315\n    port: 80\n    protocol: TCP\n    targetPort: 3000\n  selector:\n    app.kubernetes.io/instance: seldon-core-analytics\n    app.kubernetes.io/name: grafana\n  sessionAffinity: None\n  type: LoadBalancer\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: 192.168.1.90\n```\n\n```yaml\nkubectl get svc/seldon-core-analytics-grafana -n seldon-system\n```\n\n```bash\nNAME                            TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)        AGE\nseldon-core-analytics-grafana   LoadBalancer   10.99.201.117   192.168.1.90   80:30315/TCP   9d\n```\n\n웹 브라우저로 접속이 되는지 확인합니다. `http://192.168.1.90/`  ~~(admin, password)~~\n",
    "date": "2024-11-02",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-11-02-Misc-MetalLB-Settings_chunk_0",
        "text": "Misc. MetalLB Settings\n\n본 페이지에서는 베어메탈 클러스터용 로드밸런서 MetalLB 설치 및 설정에 대해 다루겠습니다.\n\n# Load Balancer\n\n---\n\n로드 밸런서란?",
        "index": 0
      },
      {
        "id": "2024-11-02-Misc-MetalLB-Settings_chunk_1",
        "text": "lLB Settings\n\n본 페이지에서는 베어메탈 클러스터용 로드밸런서 MetalLB 설치 및 설정에 대해 다루겠습니다.\n\n# Load Balancer\n\n---\n\n로드 밸런서란?",
        "index": 1
      },
      {
        "id": "2024-11-02-Misc-MetalLB-Settings_chunk_2",
        "text": "lLB Settings\n\n본 페이지에서는 베어메탈 클러스터용 로드밸런서 MetalLB 설치 및 설정에 대해 다루겠습니다.\n\n# Load Balancer\n\n---\n\n로드 밸런서란?",
        "index": 2
      },
      {
        "id": "2024-11-02-Misc-MetalLB-Settings_chunk_3",
        "text": "lLB Settings\n\n본 페이지에서는 베어메탈 클러스터용 로드밸런서 MetalLB 설치 및 설정에 대해 다루겠습니다.\n\n# Load Balancer\n\n---\n\n로드 밸런서란?",
        "index": 3
      },
      {
        "id": "2024-11-02-Misc-MetalLB-Settings_chunk_4",
        "text": "lLB Settings\n\n본 페이지에서는 베어메탈 클러스터용 로드밸런서 MetalLB 설치 및 설정에 대해 다루겠습니다.\n\n# Load Balancer\n\n---\n\n로드 밸런서란?",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-Ubuntu-22-04--nvidia--Docker",
    "title": "Ubuntu 22.04 (nvidia) Docker 설치하기",
    "path": "/2024/10/31/Ubuntu-22.04-(nvidia)-Docker-설치하기/",
    "categories": [
      "Computer Science",
      "Docker",
      "DL"
    ],
    "content": "![](https://velog.velcdn.com/images/noehuyg/post/6ed9b1af-1add-4dd9-8790-0451e255a461/image.png)\n<br>\n<br>\n<br>\n<br>\n<br>\n본 페이지에서는 Ubuntu 22.04에서 Docker를 설치하고, nvidia-docker를 설치까지 다루겠습니다.\n\n들어가기 전 본 페이지에서는 Docker Desktop이 아닌, **Docker Engine**을 설치합니다.\n\n# Docker\n***\n[Get Started | Docker](https://www.docker.com/get-started/)<br>\n[Install Docker Desktop on Ubuntu](https://docs.docker.com/desktop/install/ubuntu/) <- 도커 데스크탑 설치 시 참고<br>\n[Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)<br>\n## 1. Install Using the apt repository\n도커를 설치하기 전, 도커 저장소를 설정해야합니다.\n\n### Set up Docker's `apt` repo\n```bash\n# 업데이트 및 apt가 HTTPS를 사용할 수 있도록 해주는 패키지 설치\n$ sudo apt-get update\n$ sudo apt-get install ca-certificates curl gnupg\n\n# 도커 공식 GPG키 추가\n$ sudo install -m 0755 -d /etc/apt/keyrings\n$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n$ sudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# Set up Repository\n$ echo \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$UBUNTU_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n  \n# 업데이트 \n$ sudo apt-get update\n```\n\n### 도커 패키지 설치\n\n```bash\n# 최신 버전이 설치됩니다.\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n```\n\n### 설치 확인\n```bash\nsudo docker run hello-world\n```\n<br/>도커를 사용하려면, 루트 사용자의 권한이 필요합니다.\n하지만, 일일히 sudo를 입력하기 귀찮으니, sudo 없이 사용할 수 있도록 설정하겠습니다.<br/><br/><br/>\n\n\n## 2. sudo 없이 도커 사용하기\n### sudo 없이 사용하기\n```bash\n$ sudo usermod -a -G docker $USER\n# 이후 재부팅\n$ id\nuid=1000(gyu) gid=1000(gyu) groups=1000(gyu),..생략..,999(docker)\n# 출력에 docker가 있는지 확인합니다. \n```\n\n## 3. Nvidia Docker 설치\n[nvidia 공식문서](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html])\n### Configure the repository\n```bash\ncurl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list \\\n  && \\\n    sudo apt-get update\n```\n\n### Install the NVIDIA Container Toolkit packages\n```bash\nsudo apt-get install -y nvidia-container-toolkit\n```\n\n### 설정 및 nvidia를 기본 런타임으로 변경\nConfigure the container runtime\n```bash\nsudo nvidia-ctk runtime configure --runtime=docker\n# nvidia-ctk 명령어로 /etc/docker/daemon.json 파일 생성 후 수정\n```\n\nRestart Docker daemon\n```bash\nsudo systemctl restart docker\n```\n\nConfigure the container runtime \"containerd\"\n```bash\nsudo nvidia-ctk runtime configure --runtime=containerd\n\n# 위와 같음. /etc/containerd/config.toml을 수정함\n```\n\nRestart Docker daemon\n```bash\nsudo systemctl restart containerd\n```\n\n> CRI-O는 사용하지 않기에 추가하지않음.\n\ndocker의 기본 런타임을 nvidia로 수정\n```bash\nsudo vi /etc/docker/daemon.json\n```\n\n```json\n{\n    \"default-runtime\": \"nvidia\",\n    \"runtimes\": {\n        \"nvidia\": {\n            \"args\": [],\n            \"path\": \"nvidia-container-runtime\"\n        }\n    }\n}\n```\n## + Docker 경로 변경\n도커의 기본 경로는 `/var/lib`에 위치합니다. 만약, `/`에 용량을 적게 할당했거나, 다른 볼륨에서 도커 이미지, 컨테이너 등을 사용하고 싶다면 이 방법을 사용합니다.\n\ndocker 기본 경로 확인\n```bash\ndocker info | grep Root\nDocker Root Dir: /var/lib/docker\n```\n> docker 기본 경로는 `/var/lib/docker` \n\n도커 기본 저장 경로 변경\n```bash\nsudo systemctl stop docker\nsudo vi /etc/docker/daemon.json\n```\n\n```json\n{\n    \"default-runtime\": \"nvidia\",\n    \"data-root\": \"/path/to/location\", // <-- 이 곳에 원하는 경로를 입력합니다.\n    \"runtimes\": {\n        \"nvidia\": {\n            \"args\": [],\n            \"path\": \"nvidia-container-runtime\"\n        }\n    }\n    \n}\n```\n```bash\nsudo systemctl daemon-reload\nsudo service docker restart\n\n# 확인\ndocker info | grep Root\n```\n",
    "date": "2024-10-31",
    "tags": [
      "Docker",
      "Ubuntu",
      "Setup"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Ubuntu-22-04--nvidia--Docker_chunk_0",
        "text": "Ubuntu 22.04 (nvidia) Docker 설치하기\n\n![](https://velog.velcdn.com/images/noehuyg/post/6ed9b1af-1add-4dd9-8790-0451e255a461/image.png)\n<br>\n<br>\n<br>\n<br>\n<br>\n본 페이지에서는 Ubuntu 22.04에서 Docker를 설치하고, nvidia-docker를 설치까지 다루겠습니다.\n\n들어가기 전 본 페이지에서는 Docker Desktop이 아닌, **Docker Engine**을 설치합니다.\n\n# Docker\n***\n[Get Started | Docker](https://www.docker.com/get-started/)<br>\n[Install Docker Desktop on Ubuntu](https://docs.docker.com/desktop/install/ubuntu/) <- 도커 데스크탑 설치 시 참고<br>\n[Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)<br>\n## 1.",
        "index": 0
      },
      {
        "id": "2024-10-31-Ubuntu-22-04--nvidia--Docker_chunk_1",
        "text": "참고<br>\n[Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)<br>\n## 1. Install Using the apt repository\n도커를 설치하기 전, 도커 저장소를 설정해야합니다.\n\n### Set up Docker's `apt` repo\n```bash\n# 업데이트 및 apt가 HTTPS를 사용할 수 있도록 해주는 패키지 설치\n$ sudo apt-get update\n$ sudo apt-get install ca-certificates curl gnupg\n\n# 도커 공식 GPG키 추가\n$ sudo install -m 0755 -d /etc/apt/keyrings\n$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n$ sudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# Set up Repository\n$ echo \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(.",
        "index": 1
      },
      {
        "id": "2024-10-31-Ubuntu-22-04--nvidia--Docker_chunk_2",
        "text": "hitecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release && echo \"$UBUNTU_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n  \n# 업데이트 \n$ sudo apt-get update\n```\n\n### 도커 패키지 설치\n\n```bash\n# 최신 버전이 설치됩니다.\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n```\n\n### 설치 확인\n```bash\nsudo docker run hello-world\n```\n<br/>도커를 사용하려면, 루트 사용자의 권한이 필요합니다.\n하지만, 일일히 sudo를 입력하기 귀찮으니, sudo 없이 사용할 수 있도록 설정하겠습니다.<br/><br/><br/>\n\n\n## 2. sudo 없이 도커 사용하기\n### sudo 없이 사용하기\n```bash\n$ sudo usermod -a -G docker $USER\n# 이후 재부팅\n$ id\nuid=1000(gyu) gid=1000(gyu) groups=1000(gyu),..생략..,999(docker)\n# 출력에 docker가 있는지 확인합니다. \n```\n\n## 3.",
        "index": 2
      },
      {
        "id": "2024-10-31-Ubuntu-22-04--nvidia--Docker_chunk_3",
        "text": "id=1000(gyu) gid=1000(gyu) groups=1000(gyu),..생략..,999(docker)\n# 출력에 docker가 있는지 확인합니다. \n```\n\n## 3.",
        "index": 3
      },
      {
        "id": "2024-10-31-Ubuntu-22-04--nvidia--Docker_chunk_4",
        "text": "id=1000(gyu) gid=1000(gyu) groups=1000(gyu),..생략..,999(docker)\n# 출력에 docker가 있는지 확인합니다. \n```\n\n## 3.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--Error--Docker-CLI-Context",
    "title": "[Error] Docker CLI Context 에러",
    "path": "/2024/10/31/[Error]-Docker-CLI-Context-에러/",
    "categories": [
      "Computer Science",
      "Docker",
      "DL"
    ],
    "content": "### 현상\nDocker 설정 중 아래와 같이 CLI에서 에러 발생\n```bash\nUnable to resolve the current Docker CLI context \"default\": context \"default\" does not exist\n```\n\n### 원인\nDocker CLI context \"default\"를 가져올 수 없어 발생하는 에러입니다.\n\"default\"라는 이름의 Docker Context가 존재하지 않거나, 현재 작업 중인 context가 \"default\"로 설정되어 있지 않은 경우 발생합니다.\n\n### 해결 방안\n```bash\ndocker context ls # 현재 사용 가능한 컨텍스트 확인\ndocker context create default # \"default\" 없을 경우\ndocker context use default # 현재 작업중인 컨텍스트를 \"default\"로 설정\n```\n\n---\n---\n---\n",
    "date": "2024-10-31",
    "tags": [
      "Docker",
      "Trouble Shooting"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--Error--Docker-CLI-Context_chunk_0",
        "text": "[Error] Docker CLI Context 에러\n\n### 현상\nDocker 설정 중 아래와 같이 CLI에서 에러 발생\n```bash\nUnable to resolve the current Docker CLI context \"default\": context \"default\" does not exist\n```\n\n### 원인\nDocker CLI context \"default\"를 가져올 수 없어 발생하는 에러입니다.\n\"default\"라는 이름의 Docker Context가 존재하지 않거나, 현재 작업 중인 context가 \"default\"로 설정되어 있지 않은 경우 발생합니다.\n\n### 해결 방안\n```bash\ndocker context ls # 현재 사용 가능한 컨텍스트 확인\ndocker context create default # \"default\" 없을 경우\ndocker context use default # 현재 작업중인 컨텍스트를 \"default\"로 설정\n```\n\n---\n---\n---\n",
        "index": 0
      }
    ]
  },
  {
    "id": "2024-10-31-Ubuntu-22-04",
    "title": "Ubuntu 22.04 딥러닝 환경 구축",
    "path": "/2024/10/31/Ubuntu-22.04-딥러닝-환경-구축/",
    "categories": [
      "AI & CV",
      "Setup",
      "DL"
    ],
    "content": "## PC 사양\nCPU : I7-11700F (amd64)<br>\nGPU : GTX2080 SUPER<br>\nOS : Ubuntu22.04\n---\n본 문서에서는 Ubuntu22.04에서 딥러닝 공부를 위한 환경 구축을 하겠습니다.<br>\n\n# 1. Nvidia Driver 설치\n### 권장 드라이버 자동 설치\n```bash\nsudo ubuntu-drivers autoinstall\n```\n\n### 드라이버 수동 설치\n```bash\n# if gcc is not installed\nsudo apt update\nsudo apt install build-essential\n\n\nuname -r\nsudo apt-get install linux-headers-$(uname -r)\n\n# 설치 가능한 드라이버 버전 리스트를 확인합니다.\nubuntu-drivers devices\n\n## 23년 8월 기준 권장 버전은 535\nsudo apt install nvidia-driver-535\nsudo reboot\n```\n\n- 설치 확인<br>\n\n\n```bash\ngyu@gyu:~$ nvidia-smi\nWed Aug 23 00:28:18 2023       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.1     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3050 ...    Off | 00000000:01:00.0 Off |                  N/A |\n| N/A   48C    P8               8W /  35W |    617MiB /  4096MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1345      G   /usr/lib/xorg/Xorg                          292MiB |\n|    0   N/A  N/A      3508    C+G   ...61033818,9382365274700985078,262144      308MiB |\n+---------------------------------------------------------------------------------------+\n```\n\n# 2. CUDA 11.8 설치\n본인이 사용하려는 환경에 맞게 CUDA를 설치합니다.<br>\n본 페이지에서는 11.8버전을 설치하겠습니다.<br>\nhttps://developer.nvidia.com/cuda-11-8-0-download-archive?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=22.04&target_type=runfile_local<br>\n\n![](https://velog.velcdn.com/images/noehuyg/post/23d7c54a-c1f0-458f-a603-431a2558a158/image.png)\n\n버전을 선택하면 아래 이미지와 같이 설치 방법이 나옵니다.<br>\n![](https://velog.velcdn.com/images/noehuyg/post/e5324e6e-37c0-4e0a-bc1b-ff6b9c4bd1c0/image.png)\n\n# 3. cuDNN 8.9.3 설치\n  cuDNN의 경우 Nvidia 계정이 필요합니다.<br>\n  https://developer.nvidia.com/rdp/cudnn-archive\n  ![](https://velog.velcdn.com/images/noehuyg/post/44abc31d-c135-41eb-96c0-ac64df1cda45/image.png)\n사용하는 환경에 맞게 Local Installer를 다운로드합니다.<br>\n본 페이지에서는 `Local Installer for Ubuntu22.04 x86_64 (Deb)`를 설치합니다.<br>\n\n```bash\ntar -xvf cudnn-linux-x86_64-8.8.1.3_cuda11-archive.tar.xz\n\n## after unzip\nsudo cp cudnn-linux-x86_64-8.8.1.3_cuda11-archive/include/cudnn*.h /usr/local/cuda/include\nsudo cp cudnn-linux-x86_64-8.8.1.3_cuda11-archive/lib/libcudnn* /usr/local/cuda/lib64\nsudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*\n```\n\n\n```bash\n# 설치 확인\ncat /usr/local/cuda/include/cudnn_version.h | grep CUDNN_MAJOR -A 2\n```\n\n> cuDNN Symbolic link 오류 발생 시 아래 링크를 참고했습니다.\nhttps://lapina.tistory.com/130\n\n# 4. Conda 설치\nhttps://repo.anaconda.com/archive/<br>\n본인의 환경에 맞게 다운로드합니다.<br>\n본 페이지에서는 `Anaconda3-2023.09-0-Linux-x86_64.sh`를 다운로드하겠습니다.<br>\n![](https://velog.velcdn.com/images/noehuyg/post/692e3e0f-c8a0-4153-b71f-9238ce3ceab1/image.png)\n클릭으로 다운로드 혹은 `curl` 명령어를 통해 다운로드<br>\n\n\n```bash\ncurl --output conda_install.sh https://repo.anaconda.com/archive/Anaconda3-2023.09-0-Linux-x86_64.sh\n```\n\n다운로드가 완료되었다면 설치 스크립트를 실행합니다.\n```bash\n# Match the \"SHA-256\" Checksum\n# sha256sum conda_install.sh (Optional)\nbash conda_install.sh\n```\n\n\n설치 진행 중 여러차례 yes를 입력하면 설치가 완료됩니다.\n\n\n```bash\nEnter\nyes\n설치 경로 입력 혹은 Enter\nno # yes를 입력할 경우 shell에서 conda 환경을 기본으로 사용\n```\n> 💡 설치 중 Anaconda3 경로를 변경할 수 있습니다.\n> 기본 경로는 /home/{USER}/anaconda3로 홈 디렉토리에 생성됩니다.\n\n\n\n환경 변수 설정\n\n\n```bash\nsudo vi ~/.bashrc\n```\n\n\n```\n# 아래 줄 추가\nexport PATH=~/anaconda3/bin:~/anaconda3/condabin:$PATH\n```\n\n설치 확인\n\n\n```bash\nconda -V\n```\n\n\n# 5. PyTorch 설치\nhttps://pytorch.org/get-started/locally/<br>\n23년 8월 기준 latest 버전은 2.0.1입니다.<br>\n본인의 환경에 맞게 선택한 후 생성되는 명령어를 터미널창에 입력합니다.<br>\n![](https://velog.velcdn.com/images/noehuyg/post/a6572218-2df3-487d-afae-50139bdd12da/image.png)\n\n설치 후 GPU 사용을 확인합니다.<br>\n\n\n```bash\n$ python\n>> import torch\n>> torch.cuda.is_available()\nTrue\n```\n\n\n만약 False가 출력된다면, Nvidia driver, CUDA, cuDNN을 제대로 설치했는지 확인합니다.\n> CUDA와 cuDNN을 설치했는데, `nvcc -V` 명령어를 찾을 수 없다는 에러가 발생한다면, CUDA 환경변수를 제대로 지정했는지 확인합니다.\n---\n# + alias 설정\n우분투를 사용해 공부를 하는 중, `source ~/.bashrc` 혹은 `conda activate [환경이름]` 과 같이 자주 사용해야하는 명령어가 많이 있었습니다.\n\n또는, 아래는 제가 MLflow 공부를 하며 Tracking server를 구동하기 위한 명령어입니다. \n```bash\nmlflow server --backend-store-uri sqlite:///mlflow.db \\\n--default-artifact-root $(pwd)/artifacts \\\n--host 0.0.0.0 --port 8888\n```\n\n\n위와 같이 자주 변경하지 않지만, 자주 사용되는 명령어의 경우 일일히 치기 번거로웠습니다.\n\n\n따라서 이렇게 자주 사용되는 명령어들을 `alias`를 통해 명령어를 간소화하겠습니다.\n\n\n```bash\nvi ~/.bashrc\n```\n\n\n```\n...생략\nalias sb='source ~/.bashrc'\nalias eb='vi ~/.bashrc'\n\nalias CA='conda activate'\nalias CD='conda deactivate'\n...생략\n```\n\n\n```bash\n# 적용하기\nsourcve ~/.bashrc\n```\n\n\n> ⚠️ 기본 명령어와 겹치지 않게 주의합니다!!\n> {: .prompt:warning }\n\n\n위와 같이 설정하면, `CA` 명령어를 통해 conda 가상환경을 켤 수 있고, `CA yolov7`과 같이 사용해 이미 만들어둔 가상환경을 편하게 켤 수 있습니다.\n\n  \n하지만, 사용하다보면 `~/.bashrc`파일이 지저분해질 수 있습니다.<br>\n이를 위해 `~/.bashrc_aliases` 파일을 생성해 이 파일에 `alias` 명령어를 작성한 후, `~/.bashrc`에서 불러오도록 하겠습니다.<br>\n```bash\nvi ~/.bashrc_aliases\n```\n\n\n```\nalias sb='source ~/.bashrc'\nalias eb='vi ~/.bashrc'\n\n# Conda 명령어\nalias CA='conda activate'\nalias CD='conda deactivate'\n\n# MLflow 명령어\nalias mls='mlflow server --backend-store-uri sqlite:///mlflow.db \\\n--default-artifact-root $(pwd)/artifacts \\\n--host 0.0.0.0 --port 8888'\n\n# Git 명령어\nalias gs='git status'\n\n...등등\n```\n\n이제, `~/.bashrc` 파일에서 `~/.bashrc_aliases`를 불러오도록 하겠습니다.\n\n\n```bash\neb\n```\n\n\n```\n...생략\nif [ -f ~/.bash_aliases ]; then\n    . ~/.bash_aliases\nfi\n...생략\n```\n\n\n```\nsb\n```\n\n이렇게 하면 `~/.bashrc`를 깔끔하게 유지하며 `~/.bashrc_aliases`에 `alias`할 명령어들을 정리해주면 됩니다.\n\n---\n---\n",
    "date": "2024-10-31",
    "tags": [
      "Deep Learning",
      "Ubuntu",
      "Setup"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Ubuntu-22-04_chunk_0",
        "text": "Ubuntu 22.04 딥러닝 환경 구축\n\n## PC 사양\nCPU : I7-11700F (amd64)<br>\nGPU : GTX2080 SUPER<br>\nOS : Ubuntu22.04\n---\n본 문서에서는 Ubuntu22.04에서 딥러닝 공부를 위한 환경 구축을 하겠습니다.<br>\n\n# 1.",
        "index": 0
      },
      {
        "id": "2024-10-31-Ubuntu-22-04_chunk_1",
        "text": "U : GTX2080 SUPER<br>\nOS : Ubuntu22.04\n---\n본 문서에서는 Ubuntu22.04에서 딥러닝 공부를 위한 환경 구축을 하겠습니다.<br>\n\n# 1.",
        "index": 1
      },
      {
        "id": "2024-10-31-Ubuntu-22-04_chunk_2",
        "text": "U : GTX2080 SUPER<br>\nOS : Ubuntu22.04\n---\n본 문서에서는 Ubuntu22.04에서 딥러닝 공부를 위한 환경 구축을 하겠습니다.<br>\n\n# 1.",
        "index": 2
      },
      {
        "id": "2024-10-31-Ubuntu-22-04_chunk_3",
        "text": "U : GTX2080 SUPER<br>\nOS : Ubuntu22.04\n---\n본 문서에서는 Ubuntu22.04에서 딥러닝 공부를 위한 환경 구축을 하겠습니다.<br>\n\n# 1.",
        "index": 3
      },
      {
        "id": "2024-10-31-Ubuntu-22-04_chunk_4",
        "text": "U : GTX2080 SUPER<br>\nOS : Ubuntu22.04\n---\n본 문서에서는 Ubuntu22.04에서 딥러닝 공부를 위한 환경 구축을 하겠습니다.<br>\n\n# 1.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-2",
    "title": "[혼공컴운] 2장 데이터",
    "path": "/2024/10/31/2장-데이터/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "컴퓨터는 0과 1로 표현되는 것을 어떻게 다양한 숫자와 문자를 표현하는 지 학습\n\n# 2-1 0과 1로 숫자를 표현하는 방법\n\n키워드 : 비트, 바이트, 이진법, 2의 보수, 십육진법\n\n---\n\n컴퓨터는 0과 1로 모든 정보를 표현하고, 0과 1로 표현된 정보만을 이해할 수 있는데,\n\n어떻게 3과 4를 인식하고 3+4 = 7이라는 결과를 내놓을 수 있을까?\n\n## 정보 단위\n\n컴퓨터가 이해하는 가장 작은 정보 단위는 0과 1을 나타내는 비트!\n\n즉, 1비트는 2가지 상태를 나타낼 수 있다!\n\n> 2비트는 00, 01, 10, 11 총 4(2*2)가지,<br>\n>  3비트는 000, 001, … , 110, 111 총 8(2*2*2)가지\n{: .prompt-tip }\n\n\n즉, n개의 전구로 표현할 수 있는 상태는 $2^n$가지입니다.\n\n하지만, 우리는 어떤 파일의 용량을 얘기할 때 “이 동영상은 4.2GB 크기야.” 라고 말함.\n\n여기서 바이트는 8개의 비트를 묶은 단위로, 비트보다 한 단계 큰 단위입니다.\n\n1 byte = 8bits\n\n1 kB = 1000 bytes\n\n1 MB = 1000 kBytes\n\n…\n\n```markdown\n왜 1 byte = 8bits 인 가?에 대해서는 정확한 이유는 모르겠습니다.\n\n초기에는 1 byte의 정의가 다양했으나, 컴퓨터를 이용해서 문자를 표현할 때,\n\n아스키코드라는 체계를 이용했는데, 아스키코드가 7비트이며,\n\nIBM 360 시리즈는 8-bit byte로 개발되었고, 그 구조가 지금까지 전해진 것이라 생각합니다.\n```\n\n> 워드(word)<br>\n<br>\n워드란 CPU가 한 번에 처리할 수 있는 데이터 크기를 의미합니다.<br>\n만약 CPU가 한 번에 16비트를 처리할 수 있다면 1워드는 16비트가 되는 것입니다.<br>\n<br>\n현대 컴퓨터의 워드 크기는 대부분 32비트 혹은 64비트로,<br>\n인텔의 x86 CPU는 32비트 워드 CPU, x64 CPU는 64비트 워드 CPU입니다.<br>\n{: .prompt-tip }\n\n\n\n## 이진법\n\n이진법의 설명은 넘어가겠습니다.\n\n### 이진수의 음수 표현\n\n0과 1만으로 음수를 표현하기 위해, 2의 보수를 구해 이 값을 음수로 간주하는 방법을 사용합니다.\n\n2의 보수의 사전적 의미는 아래와 같습니다.\n\n> 어떤 수를 그보다 큰 $2^n$에서 뺀 값\n> \n\n즉, 2진수 11의 보수는 100에서 11을 뺀 01이 되는 것입니다.\n\n하지만, 쉽게 표현하자면\n\n> 모든 0과 1을 뒤집고, 거기에 1을 더한 값\n> \n\n이라 생각하면 됩니다.\n\n그렇다면, “-1011을 표현하기 위해 0101을 표현하는 것과, 5를 표현하기 위해 0101은 똑같이 생겼는데, 어떻게 구분하는가?”에 대해서는 플래그를 사용합니다.\n\n우선, 양수와 음수를 구분할 수 있도록 플래그가 있기에 CPU가 부호를 헷갈릴 일은 없다고 생각하고, 넘어가겠습니다.\n\n\n> 2의 보수표현의 한계\n>\n>만약 0을 음수로 표현하면 1도 되지만, 10, 100, 1000 … 과 같은 표현이 될 수 있으며\n>\n>1000을 음수로 표현하면 똑같이 1000으로 표현됩니다.\n>\n>첫번째 경우에서는 자리올림으로 인해 1을 버릴 수 있으며,\n>두번째 경우에선 n비트로 -2^n과 2^n을 동시에 표현할 수 없는 문제가 있습니다.\n{: .prompt-tip }\n\n## 십육진법\n\n16진법에 대해서도 넘어가겠습니다.\n\n```markdown\n16진법을 사용하는 이유는, 2진수를 간단하게 표현할 수 있기 때문입니다.\n\n예를 들어, 10진수 15는 2진수로 표현하면 1111이지만, 16진수로 표현하면 F 입니다.\n\n여기서, 1바이트를 2진수로 표현하면 1110 1111 이지만, 16진수로 표현하면 EF 입니다.\n\n이처럼 16진수를 이용하면 1바이트를 매우 간단하게 표현할 수 있기 때문에 사용합니다.\n\n단, 여기서 16진수를 구분하기 위해 0xF, 0xEF 와 같이 0x를 붙입니다.\n(2진수도 똑같이 0b를 사용하기도 함)\n```\n\n# 2-2 0과 1로 문자를 표현하는 방법\n\n키워드 : 문자 집합, 아스키 코드, EUC-KR, 유니코드\n\n---\n\n이번 절에서는 0과 1로 문자를 표현하는 방법에 대해 알아보겠습니다.\n\n## 문자 집합과 인코딩\n\n0과 1을 문자로 표현하는 방법을 알기 위해선, `문자 집합`, `인코딩`, `디코딩`에 대해 알아야 합니다.\n\n- 문자 집합 : 컴퓨터가 인식하고 표현할 수 있는 문자의 모음\n    \n    ex) 문자 집합이 {a, b, c, d, e}일 경우 이 5가지 문자는 이해할 수 있으나, f는 이해하지 못함.\n    \n\n- 문자 인코딩 : 문자를 숫자로 변환하는 과정\n    \n    문자 집합에 속한 문자가 있다고 그대로 이해할 수 있는건 아님. 문자를 0과 1로 변환해야 비로소 이해할 수 있게 됨.\n    \n\n- 문자 디코딩 : 숫자를 문자로 변환하는 과정\n    \n    반대로, 숫자를 문자로 변환하는 과정입니다.\n    \n\n## 아스키 코드(ASCII)\n\n(American Standard Code for Information Interchange)\n\n영어 알파벳과 아라비아 숫자, 그리고 일부 특수 문자를 포함하는 **문자 집합**입니다.\n\n아스키 문자는 7비트로 표현되는데, 즉 $2^7$개인 128개의 문자를 표현할 수 있습니다.\n\n\n> 실제로는 아스키 문자를 나타내기 위해 8비트(1바이트)를 사용합니다.\n> 7비트는 아스키 문자를 표현하며, 1비트는 패리티 비트(parity bit)라 불리는\n> 오류 검출을 위해 사용되는 비트가 있습니다.\n{: .prompt-info }\n\n### +) 기억해두면 좋을 아스키 코드표\n\n| 문자 | 십진수(코드 포인트) |\n| ---- | ------------------- |\n| 0    | 48                  |\n| A    | 65                  |\n| a    | 97                  |\n\n> 물론, 대소문자를 변경하는 상황에서 `ans = X - 'a' + 'A';` 와 같은 형태로 할 수 있겠지만,\n기본적으로 위 값들은 알아두는게 좋았던 것 같습니다.\n\n아스키코드는 매우 간단하게 인코딩되는 장점이 있지만, 한글을 표현할 수 없다는 단점이 있음.\n\n이후 1비트를 추가해 8비트의 **확장 아스키**가 등장했지만, 그럼에도 256 문자는 턱없이 부족했음.\n\n→ EUC-KR, 유니코드와 같은 인코딩 방식 등장\n\n## EUC-KR\n\n영어 인코딩과 달리, 한글은 초성, 중성, 종성의 조합으로 이루어져 있음.\n\n따라서, 한글 인코딩에는 두 가지 방식이 있음.\n\n1. 완성형(한글 완성형 인코딩 ex. ‘강’, ‘민’, ‘철’)\n2. 조합형(한글 조합형 인코딩 ex. ‘ㄱ’ + ‘ㅏ’ + ‘ㅇ’)\n\n**EUC-KR**은 대표적인 **완성형 인코딩 방식**입니다.\n\n즉, 초성, 중성, 종성이 모두 결합된 한글 단어에 2바이트 크기의 코드를 부여합니다.\n\n2바이트 → 16비트 → 네 자리 16진수로 표현할 수 있습니다.\n\nEUC-KR 인코딩 방식으로 총 2,350개 정도의 한글 단어를 표현할 수 있습니다.\n\n하지만, 그럼에도 ‘쀍’, ‘쀓’, ‘믜’와 같은 글자는 EUC-KR로 표현할 수 없습니다.\n\n이로 인해, EUC-KR 인코딩을 사용하는 웹사이트의 한글이 깨지거나, EUC-KR로는 표현할 수 없는 이름으로 인해 은행, 학교 등에서 피해를 받는 사람이 생기기도 했습니다.\n\n이를 조금이나마 해결하고자 등장한 것이 MS의 **CP949**(EUC-KR의 확장버전) 입니다.\n\n하지만, 그럼에도 불구하고 한글 전체를 표현할 수 없었습니다.\n\n## 유니코드와 UTF-8\n\nEUC-KR 인코딩 덕분에 한글을 표현할 수 있지만, 모든 한글을 표현할 수 없다는 문제가 있습니다.\n\n또한, 이렇게 언어별로 인코딩한다면 다국어를 지원하는 프로그램을 만들 때 어려움이 있습니다.\n\n모든 언어를 아우르는 문자 집합과 통일된 표준 인코딩 방식이 필요 → **유니코드**의 등장\n\n아스키 코드나 EUC-KR은 글자에 부여된 값을 그대로 인코딩 값으로 삼았습니다.\n\n하지만, 유니코드는 글자에 부여된 값 자체를 인코딩하지 않고, 다양한 방법으로 인코딩합니다.\n\n(UTF-8, UTF-16, UTF-32등, UTF = Unicode Transformation Format)\n\nUTF-8은 1~4바이트까지의 인코딩 결과를 만들어 냅니다.\n\n즉, 인코딩한 값의 결과는 1바이트가 될 수도, 2,3,4 바이트가 될 수도 있습니다.\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-10-31",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-2_chunk_0",
        "text": "[혼공컴운] 2장 데이터\n\n컴퓨터는 0과 1로 표현되는 것을 어떻게 다양한 숫자와 문자를 표현하는 지 학습\n\n# 2-1 0과 1로 숫자를 표현하는 방법\n\n키워드 : 비트, 바이트, 이진법, 2의 보수, 십육진법\n\n---\n\n컴퓨터는 0과 1로 모든 정보를 표현하고, 0과 1로 표현된 정보만을 이해할 수 있는데,\n\n어떻게 3과 4를 인식하고 3+4 = 7이라는 결과를 내놓을 수 있을까?\n\n## 정보 단위\n\n컴퓨터가 이해하는 가장 작은 정보 단위는 0과 1을 나타내는 비트!\n\n즉, 1비트는 2가지 상태를 나타낼 수 있다!\n\n> 2비트는 00, 01, 10, 11 총 4(2*2)가지,<br>\n>  3비트는 000, 001, … , 110, 111 총 8(2*2*2)가지\n{: .prompt-tip }\n\n\n즉, n개의 전구로 표현할 수 있는 상태는 $2^n$가지입니다.\n\n하지만, 우리는 어떤 파일의 용량을 얘기할 때 “이 동영상은 4.2GB 크기야.” 라고 말함.\n\n여기서 바이트는 8개의 비트를 묶은 단위로, 비트보다 한 단계 큰 단위입니다.\n\n1 byte = 8bits\n\n1 kB = 1000 bytes\n\n1 MB = 1000 kBytes\n\n…\n\n```markdown\n왜 1 byte = 8bits 인 가?에 대해서는 정확한 이유는 모르겠습니다.\n\n초기에는 1 byte의 정의가 다양했으나, 컴퓨터를 이용해서 문자를 표현할 때,\n\n아스키코드라는 체계를 이용했는데, 아스키코드가 7비트이며,\n\nIBM 360 시리즈는 8-bit byte로 개발되었고, 그 구조가 지금까지 전해진 것이라 생각합니다.\n```\n\n> 워드(word)<b",
        "index": 0
      },
      {
        "id": "2024-10-31-2_chunk_1",
        "text": "계를 이용했는데, 아스키코드가 7비트이며,\n\nIBM 360 시리즈는 8-bit byte로 개발되었고, 그 구조가 지금까지 전해진 것이라 생각합니다.\n```\n\n> 워드(word)<br>\n<br>\n워드란 CPU가 한 번에 처리할 수 있는 데이터 크기를 의미합니다.<br>\n만약 CPU가 한 번에 16비트를 처리할 수 있다면 1워드는 16비트가 되는 것입니다.<br>\n<br>\n현대 컴퓨터의 워드 크기는 대부분 32비트 혹은 64비트로,<br>\n인텔의 x86 CPU는 32비트 워드 CPU, x64 CPU는 64비트 워드 CPU입니다.<br>\n{: .prompt-tip }\n\n\n\n## 이진법\n\n이진법의 설명은 넘어가겠습니다.\n\n### 이진수의 음수 표현\n\n0과 1만으로 음수를 표현하기 위해, 2의 보수를 구해 이 값을 음수로 간주하는 방법을 사용합니다.\n\n2의 보수의 사전적 의미는 아래와 같습니다.\n\n> 어떤 수를 그보다 큰 $2^n$에서 뺀 값\n> \n\n즉, 2진수 11의 보수는 100에서 11을 뺀 01이 되는 것입니다.\n\n하지만, 쉽게 표현하자면\n\n> 모든 0과 1을 뒤집고, 거기에 1을 더한 값\n> \n\n이라 생각하면 됩니다.\n\n그렇다면, “-1011을 표현하기 위해 0101을 표현하는 것과, 5를 표현하기 위해 0101은 똑같이 생겼는데, 어떻게 구분하는가?”에 대해서는 플래그를 사용합니다.\n\n우선, 양수와 음수를 구분할 수 있도록 플래그가 있기에 CPU가 부호를 헷갈릴 일은 없다고 생각하고, 넘어가겠습니다.\n\n\n> 2의 보수표현의 한계\n>\n>만약 0을 음수로 표현하면 1도 되지만, 10, 100, 1000 … 과",
        "index": 1
      },
      {
        "id": "2024-10-31-2_chunk_2",
        "text": "있기에 CPU가 부호를 헷갈릴 일은 없다고 생각하고, 넘어가겠습니다.\n\n\n> 2의 보수표현의 한계\n>\n>만약 0을 음수로 표현하면 1도 되지만, 10, 100, 1000 … 과 같은 표현이 될 수 있으며\n>\n>1000을 음수로 표현하면 똑같이 1000으로 표현됩니다.\n>\n>첫번째 경우에서는 자리올림으로 인해 1을 버릴 수 있으며,\n>두번째 경우에선 n비트로 -2^n과 2^n을 동시에 표현할 수 없는 문제가 있습니다.\n{: .prompt-tip }\n\n## 십육진법\n\n16진법에 대해서도 넘어가겠습니다.\n\n```markdown\n16진법을 사용하는 이유는, 2진수를 간단하게 표현할 수 있기 때문입니다.\n\n예를 들어, 10진수 15는 2진수로 표현하면 1111이지만, 16진수로 표현하면 F 입니다.\n\n여기서, 1바이트를 2진수로 표현하면 1110 1111 이지만, 16진수로 표현하면 EF 입니다.\n\n이처럼 16진수를 이용하면 1바이트를 매우 간단하게 표현할 수 있기 때문에 사용합니다.\n\n단, 여기서 16진수를 구분하기 위해 0xF, 0xEF 와 같이 0x를 붙입니다.\n(2진수도 똑같이 0b를 사용하기도 함)\n```\n\n# 2-2 0과 1로 문자를 표현하는 방법\n\n키워드 : 문자 집합, 아스키 코드, EUC-KR, 유니코드\n\n---\n\n이번 절에서는 0과 1로 문자를 표현하는 방법에 대해 알아보겠습니다.\n\n## 문자 집합과 인코딩\n\n0과 1을 문자로 표현하는 방법을 알기 위해선, `문자 집합`, `인코딩`, `디코딩`에 대해 알아야 합니다.\n\n- 문자 집합 : 컴퓨터가 인식하고 표현할 수 있는 문자의 모음",
        "index": 2
      },
      {
        "id": "2024-10-31-2_chunk_3",
        "text": "자로 표현하는 방법을 알기 위해선, `문자 집합`, `인코딩`, `디코딩`에 대해 알아야 합니다.\n\n- 문자 집합 : 컴퓨터가 인식하고 표현할 수 있는 문자의 모음\n    \n    ex) 문자 집합이 {a, b, c, d, e}일 경우 이 5가지 문자는 이해할 수 있으나, f는 이해하지 못함.\n    \n\n- 문자 인코딩 : 문자를 숫자로 변환하는 과정\n    \n    문자 집합에 속한 문자가 있다고 그대로 이해할 수 있는건 아님.",
        "index": 3
      },
      {
        "id": "2024-10-31-2_chunk_4",
        "text": "해할 수 있으나, f는 이해하지 못함.\n    \n\n- 문자 인코딩 : 문자를 숫자로 변환하는 과정\n    \n    문자 집합에 속한 문자가 있다고 그대로 이해할 수 있는건 아님.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-0",
    "title": "[혼공컴운] 0장 혼자 공부하는 컴퓨터구조 운영체제",
    "path": "/2024/10/31/0장-혼자-공부하는-컴퓨터구조-운영체제/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "![pyoji](/assets/img/hongong/000pyoji.png){: .w-50}\n\n본 카테고리는 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\"를 읽고, 공부한 내용을 정리한 카테고리입니다.  \n교재의 중반부까지는 컴퓨터 구조에 대해 학습하고, 이후 운영체제에 대해 학습합니다.  \n\n> 제가 블로그에 작성한 내용은 **정말 간단하게 기억이 안날 때 리마인드를 하기 위한 수준**으로 정리했습니다.  \n> \n> 만약, 운영체제를 처음 공부하거나 익숙하지 않으시다면, **직접 교재를 구매하시길 권장**드립니다.  \n> 책에는 이해를 돕기 위한 **그림과 그래프**, 그리고 **친절한 예시**가 많이 있어 정말 도움이 많이 됩니다.  \n> 또한, 유튜브에 검색하면 강민철님의 강의 영상 또한 잘 활용하시길 추천드립니다.\n{: .prompt-info }\n",
    "date": "2024-10-31",
    "tags": [],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-0_chunk_0",
        "text": "[혼공컴운] 0장 혼자 공부하는 컴퓨터구조 운영체제\n\n![pyoji](/assets/img/hongong/000pyoji.png){: .w-50}\n\n본 카테고리는 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\"를 읽고, 공부한 내용을 정리한 카테고리입니다.  \n교재의 중반부까지는 컴퓨터 구조에 대해 학습하고, 이후 운영체제에 대해 학습합니다.  \n\n> 제가 블로그에 작성한 내용은 **정말 간단하게 기억이 안날 때 리마인드를 하기 위한 수준**으로 정리했습니다.  \n> \n> 만약, 운영체제를 처음 공부하거나 익숙하지 않으시다면, **직접 교재를 구매하시길 권장**드립니다.  \n> 책에는 이해를 돕기 위한 **그림과 그래프**, 그리고 **친절한 예시**가 많이 있어 정말 도움이 많이 됩니다.  \n> 또한, 유튜브에 검색하면 강민철님의 강의 영상 또한 잘 활용하시길 추천드립니다.\n{: .prompt-info }\n",
        "index": 0
      }
    ]
  },
  {
    "id": "2024-10-31-1",
    "title": "[혼공컴운] 1장 컴퓨터 구조 시작하기",
    "path": "/2024/10/31/1장-컴퓨터-구조-시작하기/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "# 1-1 컴퓨터 구조를 알아야 하는 이유\n\n키워드 : 문제 해결, 성능/용량/비용\n\n---\n\n컴퓨터 구조는 실력 있는 개발자가 되려면 반드시 알아야 할 기본 지식\n\n## 문제 해결\n\n코드가 제대로 작동하지 않을 때, 문제가 발생할 경우\n\n컴퓨터 구조를 이해하고 있다면 문제 상황을 빠르게 진단하고, 문제 해결 방안을 다양하게 찾을 수 있다.\n\n> 컴퓨터란 ‘미지의 대상’이 아닌 ‘분석의 대상’일 테니까요.\n> \n\n즉, 컴퓨터 구조 지식은 문법에 맞는 코드만 작성할 줄 아는 개발자를 넘어 문제를 스스로 해결할 줄 아는 개발자로 만들어준다!\n\n## 성능, 용량, 비용\n\n웹사이트를 개발하고 배포한다면, 서버 컴퓨터가 필요한데\n\n서버 컴퓨터 선택 시 CPU와 메모리와 그에 따른 서버 컴퓨터의 비용이 다양함\n\n무작정 싼걸 사거나, 비싼걸 사는게 최선의 선택은 아님!\n\n이는 온프레미스가 아닌 클라우드 서비스를 사용하더라도 고민해야 할 문제다.\n\n즉, 프로그래밍 언어의 문법만 안다고 성능,용량,비용 문제를 해결할 수는 없다.\n\n컴퓨터 구조를 이해하면 이를 고려해서 개발할 수 있다!\n\n<aside>\n💡 컴퓨터 구조를 이해하면 문제 해결 능력이 향상됩니다.\n\n컴퓨터 구조를 이해하면 문법만으로는 알기 어려운 성능/용량/비용을 고려하며 개발할 수 있습니다.\n\n</aside>\n\n# 1-2 컴퓨터 구조의 큰 그림\n\n키워드 : 데이터, 명령어, 메모리, CPU, 보조기억장치, 입출력장치, 시스템 버스\n\n---\n\n학습해 나갈 컴퓨터 구조의 큰 그림을 그려보기\n\n컴퓨터 구조란 크게 2가지.\n\n### 컴퓨터가 이해하는 정보\n\n1. 데이터\n    \n    데이터는 단순히 1,2,3… 혹은 jpg와 같은 이미지 파일들이 있음.\n    \n    즉, 컴퓨터가 이해하는 숫자, 문자, 이미지, 동영상과 같은 정적인 정보를 가리키는 말.\n    \n2. 명령어\n    \n    명령어는 데이터 `1`과 `2`가 있을 때,  `‘1’과 ‘2’를 더하라` \n    \n    혹은 `안녕` 이라는 데이터가 있을 때, `'안녕'을 화면에 출력하라` 와 같은 것이 명령어.\n    \n\n> 컴퓨터를 한마디로 정의해 보세요라고 묻는다면\n”컴퓨터는 명령어를 처리하는 기계입니다.”라고 답하겠습니다.\n> \n\n### 컴퓨터의 네 가지 핵심 부품\n\n1. CPU\n2. 주기억장치(RAM과 ROM이 있으나 RAM을 메모리라 지칭하며, 이 책에선 주기억장치=메모리)\n3. 보조기억장치\n4. 입출력장치\n\n### 메모리\n\n메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장하는 부품\n\n컴퓨터가 빠르게 작동하기 위해 저장된 명령어와 데이터의 위치는 정돈되어 있어야 함.\n\n이를 위해 `주소(address)`라는 개념이 사용된다.\n\n기억할 것\n\n- 프로그램이 실행되기 위해서는 반드시 메모리에 저장\n- 메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장\n- 메모리에 저장된 값의 위치는 주소로 알 수 있다\n\n### CPU\n\nCPU는 컴퓨터의 두뇌. 메모리에 저장된 명령어를 읽고, 해석하고, 실행하는 부품\n\nCPU의 내부 구성 요소는\n\n- 산술논리연산장치(ALU)\n    \n    계산기. 계산만을 위해 존재하는 부품\n    \n- 레지스터\n    \n    작은 임시 저장 장치. 프로그램 실행 중 필요한 값을 임시 저장함\n    \n- 제어장치(CU)\n    \n    전기 신호를 내보내고 명령어를 해석하는 장치.\n    \n    ex) 메모리 읽기 혹은 메모리 쓰기 제어 신호를 보낸다.\n    \n\n즉, 대략적인 흐름은\n\n1. 제어장치에서 메모리 읽기 신호를 보냄.\n2. 메모리는 초기위치에 저장된 명령어를 주고,\n이 명령어를 레지스터에 저장하며\n제어장치는 이를 해석한 뒤, 필요한 데이터가 있다면 읽기 신호를 보냄\n3. 명령어 실행 후, 레지스터에 값을 저장함\n4. 실행 후, 다음 명령어를 읽어 옴\n\n### 보조 기억 장치\n\n메모리는 전원이 꺼지면 저장된 내용을 잃기에, 메모리보다 크기가 크고 전원이 꺼져도 내용을 잃지 않는 저장 장치가 보조기억장치(HDD,SSD,USB …)\n\n즉, 메모리가 현재 ‘실행되는’ 프로그램을 저장한다면, 보조기억장치는 ‘보관할’ 프로그램을 저장함\n\n### 입출력장치\n\n입출력장치는 마이크, 스피커, 프린터, 마우스, 키보드처럼 컴퓨터 외부에 연결되어 컴퓨터 내부와 정보를 교환하는 장치를 의미한다.\n\n### 메인보드와 시스템 버스\n\n지금까지 설명한 컴퓨터의 핵심 부품들은 모두 메인보드(마더보드)라는 판에 연결됨.\n\n메인보드에 연결된 부품들은 내부에 있는 버스라는 통로를 이용해 서로 정보를 주고 받는다.\n\n다양한 종류의 버스(통로)가 있지만, 컴퓨터의 네 가지 핵심 부품을 연결하는 버스는 시스템 버스!\n\n> 시스템 버스는 주소 버스, 데이터 버스, 제어 버스로 구성!\n> \n\n즉, CPU가 메모리를 읽을 때, 단순히 제어 신호만 내보내는 것이 아니라,\n\n주소 버스와 제어 버스를 이용해 각각 주소와 신호를 보낸 후,\n\n메모리에서는 `1번지 + 읽기`를 확인하고 그 값을 데이터 버스를 통해 데이터를 CPU로 보냄.\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-10-31",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-1_chunk_0",
        "text": "[혼공컴운] 1장 컴퓨터 구조 시작하기\n\n# 1-1 컴퓨터 구조를 알아야 하는 이유\n\n키워드 : 문제 해결, 성능/용량/비용\n\n---\n\n컴퓨터 구조는 실력 있는 개발자가 되려면 반드시 알아야 할 기본 지식\n\n## 문제 해결\n\n코드가 제대로 작동하지 않을 때, 문제가 발생할 경우\n\n컴퓨터 구조를 이해하고 있다면 문제 상황을 빠르게 진단하고, 문제 해결 방안을 다양하게 찾을 수 있다.\n\n> 컴퓨터란 ‘미지의 대상’이 아닌 ‘분석의 대상’일 테니까요.\n> \n\n즉, 컴퓨터 구조 지식은 문법에 맞는 코드만 작성할 줄 아는 개발자를 넘어 문제를 스스로 해결할 줄 아는 개발자로 만들어준다!\n\n## 성능, 용량, 비용\n\n웹사이트를 개발하고 배포한다면, 서버 컴퓨터가 필요한데\n\n서버 컴퓨터 선택 시 CPU와 메모리와 그에 따른 서버 컴퓨터의 비용이 다양함\n\n무작정 싼걸 사거나, 비싼걸 사는게 최선의 선택은 아님!\n\n이는 온프레미스가 아닌 클라우드 서비스를 사용하더라도 고민해야 할 문제다.\n\n즉, 프로그래밍 언어의 문법만 안다고 성능,용량,비용 문제를 해결할 수는 없다.\n\n컴퓨터 구조를 이해하면 이를 고려해서 개발할 수 있다!\n\n<aside>\n💡 컴퓨터 구조를 이해하면 문제 해결 능력이 향상됩니다.\n\n컴퓨터 구조를 이해하면 문법만으로는 알기 어려운 성능/용량/비용을 고려하며 개발할 수 있습니다.\n\n</aside>\n\n# 1-2 컴퓨터 구조의 큰 그림\n\n키워드 : 데이터, 명령어, 메모리, CPU, 보조기억장치, 입출력장치, 시스템 버스\n\n---\n\n학습해 나갈 컴퓨터 구조의 큰 그림을 그려보기\n\n컴퓨터 구조란 크게 2가지.\n\n##",
        "index": 0
      },
      {
        "id": "2024-10-31-1_chunk_1",
        "text": "키워드 : 데이터, 명령어, 메모리, CPU, 보조기억장치, 입출력장치, 시스템 버스\n\n---\n\n학습해 나갈 컴퓨터 구조의 큰 그림을 그려보기\n\n컴퓨터 구조란 크게 2가지.\n\n### 컴퓨터가 이해하는 정보\n\n1. 데이터\n    \n    데이터는 단순히 1,2,3… 혹은 jpg와 같은 이미지 파일들이 있음.\n    \n    즉, 컴퓨터가 이해하는 숫자, 문자, 이미지, 동영상과 같은 정적인 정보를 가리키는 말.\n    \n2. 명령어\n    \n    명령어는 데이터 `1`과 `2`가 있을 때,  `‘1’과 ‘2’를 더하라` \n    \n    혹은 `안녕` 이라는 데이터가 있을 때, `'안녕'을 화면에 출력하라` 와 같은 것이 명령어.\n    \n\n> 컴퓨터를 한마디로 정의해 보세요라고 묻는다면\n”컴퓨터는 명령어를 처리하는 기계입니다.”라고 답하겠습니다.\n> \n\n### 컴퓨터의 네 가지 핵심 부품\n\n1. CPU\n2. 주기억장치(RAM과 ROM이 있으나 RAM을 메모리라 지칭하며, 이 책에선 주기억장치=메모리)\n3. 보조기억장치\n4. 입출력장치\n\n### 메모리\n\n메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장하는 부품\n\n컴퓨터가 빠르게 작동하기 위해 저장된 명령어와 데이터의 위치는 정돈되어 있어야 함.\n\n이를 위해 `주소(address)`라는 개념이 사용된다.\n\n기억할 것\n\n- 프로그램이 실행되기 위해서는 반드시 메모리에 저장\n- 메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장\n- 메모리에 저장된 값의 위치는 주소로 알 수 있다\n\n### CPU\n\nCPU는 컴퓨터의 두뇌.",
        "index": 1
      },
      {
        "id": "2024-10-31-1_chunk_2",
        "text": "반드시 메모리에 저장\n- 메모리는 현재 실행되는 프로그램의 명령어와 데이터를 저장\n- 메모리에 저장된 값의 위치는 주소로 알 수 있다\n\n### CPU\n\nCPU는 컴퓨터의 두뇌. 메모리에 저장된 명령어를 읽고, 해석하고, 실행하는 부품\n\nCPU의 내부 구성 요소는\n\n- 산술논리연산장치(ALU)\n    \n    계산기. 계산만을 위해 존재하는 부품\n    \n- 레지스터\n    \n    작은 임시 저장 장치. 프로그램 실행 중 필요한 값을 임시 저장함\n    \n- 제어장치(CU)\n    \n    전기 신호를 내보내고 명령어를 해석하는 장치.\n    \n    ex) 메모리 읽기 혹은 메모리 쓰기 제어 신호를 보낸다.\n    \n\n즉, 대략적인 흐름은\n\n1. 제어장치에서 메모리 읽기 신호를 보냄.\n2. 메모리는 초기위치에 저장된 명령어를 주고,\n이 명령어를 레지스터에 저장하며\n제어장치는 이를 해석한 뒤, 필요한 데이터가 있다면 읽기 신호를 보냄\n3. 명령어 실행 후, 레지스터에 값을 저장함\n4.",
        "index": 2
      },
      {
        "id": "2024-10-31-1_chunk_3",
        "text": "저장된 명령어를 주고,\n이 명령어를 레지스터에 저장하며\n제어장치는 이를 해석한 뒤, 필요한 데이터가 있다면 읽기 신호를 보냄\n3. 명령어 실행 후, 레지스터에 값을 저장함\n4. 실행 후, 다음 명령어를 읽어 옴\n\n### 보조 기억 장치\n\n메모리는 전원이 꺼지면 저장된 내용을 잃기에, 메모리보다 크기가 크고 전원이 꺼져도 내용을 잃지 않는 저장 장치가 보조기억장치(HDD,SSD,USB …)\n\n즉, 메모리가 현재 ‘실행되는’ 프로그램을 저장한다면, 보조기억장치는 ‘보관할’ 프로그램을 저장함\n\n### 입출력장치\n\n입출력장치는 마이크, 스피커, 프린터, 마우스, 키보드처럼 컴퓨터 외부에 연결되어 컴퓨터 내부와 정보를 교환하는 장치를 의미한다.\n\n### 메인보드와 시스템 버스\n\n지금까지 설명한 컴퓨터의 핵심 부품들은 모두 메인보드(마더보드)라는 판에 연결됨.\n\n메인보드에 연결된 부품들은 내부에 있는 버스라는 통로를 이용해 서로 정보를 주고 받는다.\n\n다양한 종류의 버스(통로)가 있지만, 컴퓨터의 네 가지 핵심 부품을 연결하는 버스는 시스템 버스!\n\n> 시스템 버스는 주소 버스, 데이터 버스, 제어 버스로 구성!\n> \n\n즉, CPU가 메모리를 읽을 때, 단순히 제어 신호만 내보내는 것이 아니라,\n\n주소 버스와 제어 버스를 이용해 각각 주소와 신호를 보낸 후,\n\n메모리에서는 `1번지 + 읽기`를 확인하고 그 값을 데이터 버스를 통해 데이터를 CPU로 보냄.\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }",
        "index": 3
      },
      {
        "id": "2024-10-31-1_chunk_4",
        "text": "터를 CPU로 보냄.\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-3",
    "title": "[혼공컴운] 3장 명령어",
    "path": "/2024/10/31/3장-명령어/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "명령어란 무엇이고, 어떻게 생겼으며, 컴퓨터를 어떻게 작동시키는지 알아봅니다.\n\n# 3-1 소스 코드와 명령어\n\n키워드 : 고급 언어, 저급 언어, 기계어, 어셈블리어, 컴파일 언어, 인터프리터 언어\n\n---\n\n개발자가 프로그래밍 언어로 작성한 소스 코드가 컴퓨터 내부에서 명령어가 되고 실행되는 과정에 대해 다룹니다.\n\n## 고급 언어와 저급 언어\n\n- 고급 언어(high-level programming language):\n    \n    우리가 프로그램을 만들 때 사용하는 프로그래밍 언어(C/C++, Java, Python)은 컴퓨터가 아닌 사람이 이해하고 작성하기 쉽게 만들어진 언어\n    \n\n- 저급 언어(low-level programming language):\n    \n    컴퓨터가 직접 이해하고 실행할 수 있는 언어.\n    \n    저급 언어는 명령어로 이루어져 있음.\n    \n\n고급 언어로 작성된 소스 코드가 실행되려면 저급 언어, 즉 명령어로 변환되어야 합니다.\n\n### 저급 언어\n\n저급 언어는 기계어와 어셈블리어, 두 종류가 있습니다.\n\n**기계어**란 0과 1 명령어 비트로 이루어진 언어입니다.\n\n(0과 1 혹은 16진수로 표현하기도 함)\n\n하지만, 이렇게 0과 1로 이루어진 기계어를 보면 어떻게 작동하는 지 알아보기 어렵습니다.\n\n그래서 등장한 저급 언어가 **어셈블리어** 입니다.\n\n즉 0과 1로 표현된 명령어(기계어)를 읽기 편한 형태로 번역한 언어가 어셈블리어\n\n| **기계어**  | **어셈블리어** |\n| ----------- | -------------- |\n| `0101 0101` | `push rbp`     |\n| `0101 1101` | `pop rbp`      |\n| `1100 0011` | `ret`          |\n\n하지만, 어셈블리어를 이용해 복잡한 프로그램을 만들기는 쉽지 않습니다.\n\n→ 고급 언어의 필요성!\n\n> “그렇다면, 저급 언어를 알아야 할 필요가 있나요? 고급 언어로 소스 코드를 작성하면 알아서 저급 언어로 변환되어 잘 실행되는데, 일부러 저급 언어로 개발할 일은 없지 않나요?”\n> \n\n개발자에 따라 다름.\n\n하드웨어와 밀접하게 맞닿아 있는 프로그램을 개발하는 임베디드 개발자, 게임 개발자, 정보 보안 분야 등의 개발자는 어셈블리어를 알아야하며, 이를 이용해 프로그램을 만드는 경우가 있음.\n\n> 즉, 어떤 개발자가 되냐에 따라 다르지만, 하드웨어와 밀접할 수록 저급 언어를 알아야 하며, 고급 언어와 저급 언어의 차이를 이해하는 것 자체가 매우 좋은 교양이기에 반드시 알아두는 것이 좋습니다.\n{: .prompt-tip}\n\n## 컴파일 언어와 인터프리터 언어\n\n그렇다면, 고급 언어는 어떻게 저급 언어로 변환될까요?\n\n크게 두 가지, **컴파일**방식과 **인터프리트**방식이 있습니다.\n\n### 컴파일 언어\n\n컴파일 언어는 **컴파일러**에 의해 소스 코드 **전체**가 저급 언어로 변환되어 실행되는 고급 언어!\n\n대표적으로는 C/C++\n\n고급 언어(소스 코드.c) → **컴파일(컴파일러)** → 저급 언어(목적 코드.o)\n\n### 인터프리터 언어\n\n인터프리터 언어는 **인터프리터**에 의해 소스 코드가 **한 줄씩** 실행되는 고급 언어!\n\n대표적으로는 Python\n\n즉, N번째 줄에 오류가 있는 상황에서 컴파일 언어는 컴파일에 실패하지만, 인터프리터 언어는 N-1번째 줄까지는 올바르게 수행되며 N번째 줄에서 오류가 발생함.\n\n> 컴파일 언어와 인터프리터 언어, 명확하게 구분될까?\n>\n> C,C++과 같이 명확하게 구분할 수 있는 언어도 있으나, 현대의 많은 언어들은 그 경계가 모호한 경우가 많음. 대표적인 인터프리터 언어인 Python도 컴파일을 하지 않는 것은 아니며, Java의 경우 저급 언어가 되는 과정에서 컴파일과 인터프리트를 동시에 수행함.\n>\n> 즉, 둘 중 하나의 방식으로만 작동되진 않으며, ‘고급 언어가 저급 언어로 변환되는 대표적인 방법에는 컴파일과 인터프리트가 있다’ 정도로만 이해하는 것이 좋음.\n{: .prompt-tip }\n\n### 목적 파일 vs 실행 파일\n\n이미지로 이루어진 파일 = 이미지 파일(.jpg)\n\n텍스트로 이루어진 파일 = 텍스트 파일(.txt)\n\n목적 코드로 이루어진 파일 = **목적 파일(.o)**\n\n실행 코드로 이루어진 파일 = **실행 파일(.exe)**\n\n목적 파일도 저급 언어로 이뤄져있지만, 목적 파일 ≠ 실행 파일\n\n목적 코드가 실행 파일이 되기 위해서는 **링킹**이라는 작업을 거쳐야 함.\n\n예를 들어, `helper.c` 와 `main.c` 라는 두 개의 소스 코드가 있음.\n\n1. `helper.c` 에는 `HELPER_더하기` 라는 기능이 구현되어 있음.\n2. `main.c` 에는 `helper.c`에 구현된 기능과 ‘화면 출력’이라는 기능이 있음.\n\n- `main.c`\n    \n    ```markdown\n    helper.c에 있는 HELPER_더하기\n    \n    화면_출력\n    ```\n    \n- `helper.c`\n    \n    ```markdown\n    HELPER_더하기\n    ```\n    \n\n이들을 컴파일하면 각각 목적 코드가 생길 것!(`main.o`, `helper.o`)\n\n하지만, `main.o`는 `HELPER_더하기`에 대해 모르기에, 바로 실행할 수 없음.\n\n즉, `main.o`에 없는 외부 기능들을 연결 짓는 작업이 필요한데 이게 **링킹!(linking)**\n\n# 3-2 명령어의 구조\n\n키워드 : 명령어, 연산 코드, 오퍼랜드, 주소 지정 방식\n\n---\n\n명령어의 구조와 주소 지정 방식을 학습하며 명령어의 생김새와 작동 원리 이해하기\n\n## 연산 코드와 오퍼랜드\n\n명령어는 연산 코드와 오퍼랜드로 구성되어 있음.\n\n| **작동(or 연산)** | **연산에 사용할 데이터(or 저장된 위치)** | **연산에 사용할 데이터(or 저장된 위치)** |\n| ----------------- | ---------------------------------------- | ---------------------------------------- |\n| 더해라            | 100과                                    | 120을                                    |\n| 빼라              | 메모리 32번지 안의 값과                  | 메모리 33번지 안의 값을                  |\n| 저장해라          | 10을                                     | 메모리 128번지에                         |\n\n연산 코드 = 연산자\n\n여기서 맨 왼쪽을 “연산 코드” 그리고 오른쪽을 “오퍼랜드”라고 합니다.\n\n오퍼랜드 = 피연산자\n\n어셈블리어 예시\n\n```nasm\npush rbp\nmov rbp, rsp\nmov DWORD PTR [rbp-4], 1\n...\n```\n\n여기서 왼쪽의 `push`, `mov`가 연산, 오른쪽이 오퍼랜드\n\n### 오퍼랜드\n\n오퍼랜드는 ‘연산에 사용할 데이터’ 혹은 ‘연산에 사용할 데이터가 저장된 위치’를 의미함.\n\n그래서 오퍼랜드 필드에는 숫자와 문자 등 데이터 값 혹은 메모리나 레지스터 주소가 올 수 있음.\n\n하지만, 보통 저장된 위치, 즉 메모리 주소나 레지스터 이름이 담기기에 오퍼랜드 필드 = 주소 필드\n\n\n> 여기서, 오퍼랜드가 하나도 없으면 0-주소 명령어, 오퍼랜드가 1개면 1-주소 명령어, …\n{: .prompt-info }\n\n### 연산코드\n\n연산 코드의 종류는 많지만, **기본적인** 연산 코드는 네 가지\n\n1. 데이터 전송\n2. 산술/논리 연산\n3. 제어 흐름 변경\n4. 입출력 제어\n\n## 주소 지정 방식\n\n오퍼랜드 필드에 직접적인 값이 아닌, 주소를 사용하는 이유는?\n\n**명령어의 길이 때문!**\n\n하나의 명령어가 n비트고, 그중 연산 코드 필드가 m비트라면\n\n→ n-m비트만큼 오퍼랜드 필드 사용 가능.(피연산자가 1개든 2개든 3개든)\n\n이로 인해, 오퍼랜드 필드에 표현할 수 있는 정보의 수는 매우 적어짐\n\n메모리 주소를 담는다면, 표현할 수 있는 데이터의 크기는 하나의 메모리 주소에 저장할 수 있는 공간만큼 커지기에, 데이터의 주소를 담는다!\n\n또한, 메모리 주소가 아닌 레지스터 이름을 명시할 때도 똑같음.\n\n연산 코드에 사용할 데이터가 저장된 위치, 즉 연산의 대상이 되는 데이터가 저장된 위치를 **“유효 주소”** 라고 한다!\n\n이처럼 오퍼랜드 필드에 데이터가 저장된 위치를 명시할 때 연산에 사용할 데이터 위치를 찾는 방법을 **주소 지정 방식(addressing mode)**이라고 함.\n\n### 즉시 주소 지정 방식\n\n오퍼랜드 필드에 연산에 사용할 **데이터**를 명시하는 방식!\n\n데이터의 크기가 작아지는 단점은 있지만, 데이터를 찾는 과정이 없기에 빠르다!\n\n### 직접 주소 지정 방식\n\n오퍼랜드 필드에 **유효 주소**를 명시하는 방식!\n\n데이터의 크기는 커졌지만, 여전히 유효 주소를 표현할 수 있는 칸이 연산 코드로 인해 제한됨\n\n### 간접 주소 지정 방식\n\n오퍼랜드 필드에 **유효 주소의 주소**를 명시하는 방식!\n\n직접 주소 지정 방식보다 표현할 수 있는 범위는 넓어졌지만, 두 번의 메모리 접근으로 인해 일반적으로 느린 방식!\n\n### 레지스터 주소 지정 방식\n\n오퍼랜드 필드에 데이터가 담긴 **레지스터 이름**을 명시하는 방식!\n\n직접 주소 지정 방식과 유사함. 메모리보다 레지스터에 접근하는 것이 더 빠르기에 더 빠르게 접근!\n\n하지만, 직접 주소 지정 방식과 동일한 문제를 갖고 있음.\n\n### 레지스터 간접 주소 지정 방식\n\n오퍼랜드 필드에 연산에 사용할 **데이터의 위치를 담은 레지스터를 명시**하는 방식!\n\n간접 주소 지정 방식과 유사함. 메모리에 접근하는 횟수가 한 번으로 줄어든다는 장점이 있음. 그리고 메모리보다는 레지스터 접근이 빠르기에 간접 주소 지정 방식보다 빠름\n\n## +) 스택과 큐\n\n스택은 LIFO(리포) Last In First Out\n\n큐는 FIFO(피포) First In First Out\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-10-31",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-3_chunk_0",
        "text": "[혼공컴운] 3장 명령어\n\n명령어란 무엇이고, 어떻게 생겼으며, 컴퓨터를 어떻게 작동시키는지 알아봅니다.\n\n# 3-1 소스 코드와 명령어\n\n키워드 : 고급 언어, 저급 언어, 기계어, 어셈블리어, 컴파일 언어, 인터프리터 언어\n\n---\n\n개발자가 프로그래밍 언어로 작성한 소스 코드가 컴퓨터 내부에서 명령어가 되고 실행되는 과정에 대해 다룹니다.\n\n## 고급 언어와 저급 언어\n\n- 고급 언어(high-level programming language):\n    \n    우리가 프로그램을 만들 때 사용하는 프로그래밍 언어(C/C++, Java, Python)은 컴퓨터가 아닌 사람이 이해하고 작성하기 쉽게 만들어진 언어\n    \n\n- 저급 언어(low-level programming language):\n    \n    컴퓨터가 직접 이해하고 실행할 수 있는 언어.\n    \n    저급 언어는 명령어로 이루어져 있음.\n    \n\n고급 언어로 작성된 소스 코드가 실행되려면 저급 언어, 즉 명령어로 변환되어야 합니다.\n\n### 저급 언어\n\n저급 언어는 기계어와 어셈블리어, 두 종류가 있습니다.\n\n**기계어**란 0과 1 명령어 비트로 이루어진 언어입니다.\n\n(0과 1 혹은 16진수로 표현하기도 함)\n\n하지만, 이렇게 0과 1로 이루어진 기계어를 보면 어떻게 작동하는 지 알아보기 어렵습니다.\n\n그래서 등장한 저급 언어가 **어셈블리어** 입니다.\n\n즉 0과 1로 표현된 명령어(기계어)를 읽기 편한 형태로 번역한 언어가 어셈블리어\n\n| **기계어**  | **어셈블리어** |\n| ----------- | -----------",
        "index": 0
      },
      {
        "id": "2024-10-31-3_chunk_1",
        "text": "즉 0과 1로 표현된 명령어(기계어)를 읽기 편한 형태로 번역한 언어가 어셈블리어\n\n| **기계어**  | **어셈블리어** |\n| ----------- | -------------- |\n| `0101 0101` | `push rbp`     |\n| `0101 1101` | `pop rbp`      |\n| `1100 0011` | `ret`          |\n\n하지만, 어셈블리어를 이용해 복잡한 프로그램을 만들기는 쉽지 않습니다.\n\n→ 고급 언어의 필요성!\n\n> “그렇다면, 저급 언어를 알아야 할 필요가 있나요?",
        "index": 1
      },
      {
        "id": "2024-10-31-3_chunk_2",
        "text": "|\n\n하지만, 어셈블리어를 이용해 복잡한 프로그램을 만들기는 쉽지 않습니다.\n\n→ 고급 언어의 필요성!\n\n> “그렇다면, 저급 언어를 알아야 할 필요가 있나요?",
        "index": 2
      },
      {
        "id": "2024-10-31-3_chunk_3",
        "text": "|\n\n하지만, 어셈블리어를 이용해 복잡한 프로그램을 만들기는 쉽지 않습니다.\n\n→ 고급 언어의 필요성!\n\n> “그렇다면, 저급 언어를 알아야 할 필요가 있나요?",
        "index": 3
      },
      {
        "id": "2024-10-31-3_chunk_4",
        "text": "|\n\n하지만, 어셈블리어를 이용해 복잡한 프로그램을 만들기는 쉽지 않습니다.\n\n→ 고급 언어의 필요성!\n\n> “그렇다면, 저급 언어를 알아야 할 필요가 있나요?",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-5--CPU",
    "title": "[혼공컴운] 5장 CPU 성능 향상 기법",
    "path": "/2024/10/31/5장-CPU-성능-향상-기법/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "클럭과 코어, 스레드라는 개념을 학습하고, 빠른 CPU를 만드는 설계 기법인 멀티코어와 멀티스레드에 대해 배웁니다\n\n# 5-1 빠른 CPU를 위한 설계 기법\n\n키워드 : 클럭, 코어, 멀티코어, 스레드, 멀티스레드\n\n---\n\n## 클럭\n\n1. 컴퓨터 부품들은 “클럭 신호”에 맞춰 동작합니다.\n2. CPU는 “명령어 사이클”이라는 정해진 흐름에 맞춰 명령어를 실행합니다.\n\n즉, 클럭 속도(Hz)가 높을 수록 CPU의 성능은 일반적으로 좋아진다.\n\n> 클럭 속도는 일정하지 않다!\n>\n> CPU는 기본 클럭 속도(Base)와 최대 클럭 속도(Max)로 나뉘어 있듯, 일정한 속도를 유지하기보단, 고성능을 요하는 순간에 순간적으로 속도를 높이고, 그렇지 않을 때는 유연하게 조정합니다.\n{: prompt-tip }\n\n## 코어와 멀티코어\n\n클럭 속도외에 CPU의 성능을 높이는 방법은 CPU의 코어와 스레드 수를 늘리는 방법이 있습니다.\n\n이전 CPU는 단일 코어로, 명령어를 실행하는 하나의 부품이였던 반면, 최근 멀티코어의 등장으로, CPU 내에 명령어를 실행하는 부품을 여러개 만들 수 있게 되었습니다.\n\n여기서 **코어**는 이전의 CPU의 정의였던 “명령어를 실행하는 부품”입니다.\n\n## 스레드와 멀티스레드\n\n스레드의 사전적 의미는 “실행 흐름의 단위” 입니다. \n\n**스레드 = 하드웨어적 스레드 + 소프트웨어적 스레드**\n\n### 하드웨어적 스레드(논리 프로세서)\n\n“하나의 코어가 동시에 처리하는 명령어 단위”를 의미합니다.\n\n지금까지 배운 CPU는 1코어 1스레드 CPU였습니다.\n\n하지만, 만약 여러 스레드를 지원하는 CPU는 하나의 코어로도 여러 개의 명령어를 동시에 실행할 수 있습니다.\n\nex) 2코어 4스레드 CPU라면, 한 번에 네 개의 명령어를 처리할 수 있습니다.\n\n이처럼 하나의 코어로 여러 명렁어를 동시에 처리하는 CPU를 **멀티 스레드 프로세서**라 합니다.\n\n### 소프트웨어적 스레드\n\n“하나의 프로그램에서 독립적으로 실행되는 단위”\n\n하나의 프로그램이 실행되는 과정에서 한 부분만 실행될 수도 있지만,\n\n프로그램의 여러 부분이 동시에 실행될 수도 있습니다.\n\nex) 워드 프로세서 프로그램을 개발한다면, \n\n1. 입력받은 내용을 화면에 보여 주는 기능\n2. 입력한 내용이 맞춤법에 맞는지 검사하는 기능\n3. 입력한 내용을 수시로 저장하는 기능\n\n### 멀티스레드 프로세서\n\n**멀티스레드 프로세서에서 가장 큰 핵심은 레지스터**\n\n하나의 코어로 여러 명령어를 동시에 처리하려면, 프로그램 카운터, 스택 포인터, 메모리 버퍼 레지스터, 메모리 주소 레지스터와 같이 하나의 명령어를 처리하기 위해 꼭 필요한 레지스터를 여러개 가지고 있어야 합니다.\n\n### 요약\n\n코어 : 명령어를 실행할 수 있는 “하드웨어 부품”\n\n스레드 : “명령어를 실행하는 단위”\n\n멀티코어 프로세서 : 명령어를 실행할 수 있는 하드웨어 부품이 CPU 안에 2개 이상 있는 CPU\n\n멀티스레드 포러세서 : 하나의 코어로 여러 개의 명령어를 동시에 실행할 수 있는 CPU\n\n# 5-2 명령어 병렬 처리 기법\n\n키워드 : 명령어 파이프라이닝, 슈퍼스칼라, 비순차적 명령어 처리 기법\n\n---\n\n명령어를 빠르고 효율적으로 처리하기 위해 CPU를 작동시키는 병렬 처리 기법에 대해 학습합니다.\n\n빠른 CPU를 만들기 위해 높은 클럭 속도, 멀티코어와 멀티스레드를 지원하는 것도 중요하지만, 쉬지 않고 작동하게 만드는 것도 중요합니다.\n\n→ **명령어 병렬 처리 기법(ILP; Instruction-Level Parallelism) !**\n\n→ **대표적인 방법 = 명령어 파이프라이닝 ,슈퍼스칼라, 비순차적 명령어 처리**\n\n## 명령어 파이프라이닝\n\n명령어 처리 과정을 클럭 단위로 나눠 보면\n\n1. 명령어 인출(Instruction Fetch)\n2. 명령어 해석(Instruction Decode)\n3. 명령어 실행(Execute Instruction)\n4. 결과 저장(Write Back)\n\n> 전공서에 따라 명령어 인출 → 명령어 실행으로 나누기도 하고,\n> \n> 인출 → 해석 → 실행 → 메모리 접근 → 결과 저장으로 나누기도 합니다.\n{: .prompt-info }\n\n중요한 점은 **같은 단계가 겹치지만 않는다면** CPU는 **각 단계를 동시에 실행할 수 있습니다.**\n\n모든 명령어를 순차적으로 처리하는 것보다, 명령어 파이프라이닝을 이용한다면 훨씬 효율적으로 작동합니다.\n\n![image.png](/assets/img/hongong/501.png)\n\n하지만, 특정 상황에서는 성능 향상에 실패하는 경우도 있습니다.\n\n- **파이프라인 위험(Pipeline Hazard)**\n\n→ 데이터 위험\n\n: 명령어 간 “데이터 의존성”에 의해 발생. 이전 명령의 데이터가 필요한 경우\n\n→ 제어 위험\n\n: 분기 등으로 인한 “프로그램 카운터의 갑작스러운 변화”에 의해 발생\n\n→ 구조적 위험(자원 위험)\n\n: 서로 다른 명령어가 동시에 ALU, 레지스터와 같은 부품을 사용하려 할 때\n\n## 슈퍼스칼라\n\n파이프라이닝은 단일 파이프라인으로도 구현 가능하지만, 오늘날 대부분의 CPU는 여러 개의 파이프라인을 이용합니다.\n\n이처럼 여러 개의 명령어 파이프라인을 포함한 구조를 “슈퍼스칼라”라 합니다.\n\n## 비순차적 명령어 처리(Out-of-order Execution)\n\n오늘날의 대부분의 CPU가 차용하는 기법\n\n비순차적으로 동작! “합법적인 새치기”\n\n파이프라이닝, 슈퍼스칼라 기법은 모두 명령어의 순차적인 처리를 상정한 방법.\n\n하지만, 이로 인해 pipeline hazard와 같은 상황에서 명령어가 곧바로 처리되지 않는 문제 발생 가능!\n\n- 예시\n\n![image.png](/assets/img/hongong/502.png)\n\n- OoOE 기법 적용 시\n\n![image.png](/assets/img/hongong/503.png)\n\n# 5-3 CICS와 RISC\n\n키워드 : ISA CISC RISC\n\nCPU의 언어인 ISA란 무엇인지, 현대 CPU의 설계 방식인 CICS와 RISC에 대해 학습\n\n---\n\n파이프라이닝과 슈퍼스칼라를 사용하기 위해선, 명령어가 파이프라이닝 하기 쉽게 생겨야 함\n\n→ 명령어가 어떻게 설계되어야 파이프라이닝 하기 쉬운 명령어인지 알기 위해 ISA를 배우고, CISC와 RISC에 관해 학습\n\n## 명령어 집합(Instruction Set) or ISA\n\n혹은 명령어 집합 구조(Instrunction Set Architecture : **ISA**)\n\nISA에는 x86, ARM등이 있으며, 이들은 서로 다른 설계를 갖기에 서로의 명령어를 이해할 수 없음.\n\n→ 명령어가 달라지면 어셈블리어도 다름 \n\n→ 똑같은 소스코드여도 컴파일 시 어셈블리어는 다름\n\n병렬적 명령어 처리 기법(명령어 파이프라이닝, 슈퍼 스칼라 등)을 적용하기 좋은 ISA란?\n\n## CISC (Complex Instruction Set Computer)\n\n→ x86, x86-64는 대표적인 CISC기반 ISA\n\nCISC는 다양하고 강력한 기능의 명령어 집합을 사용하기에, 명령어의 형태와 크기가 다양한\n\n**가변 길이 명령어**를 활용\n\n또한, 아주 특별한 상황에서만 사용되는 독특한 주소 지정 방식도 있음.\n\n- 장점 : ARM보다 적은 명령어로 같은 동작을 할 수 있기에, 메모리 절약에 좋음.\n- **단점 : 워낙 복잡하고 다양해 명령어의 크기와 실행되기까지의 시간이 일정하지 않음**\n\n→ 복잡한 명령어는 하나를 실행하는 데에 여러 클럭 주기를 필요로 함\n\n→ 명령어 파이프라인 구현에 큰 걸림돌\n\n<aside>\n💡\n\n요약\n\nCISC는 복잡하고 다양한 기능을 제공하기에 적은 수의 명령어로 프로그램 동작 가능!\n\n이로 인해 메모리 절약이 가능하지만, 명령어의 규격화가 어려워 파이프라이닝 Hard.\n\n그리고 대다수의 복잡한 명령어는 사용 빈도가 낮음.\n\n→ CISC 기반 CPU는 성장에 한계가 있음.\n\n</aside>\n\n## RISC (Reduced Insturction Set Computer)\n\n→ ARM은 대표적 RISC 기반 ISA\n\nCISC가 준 교훈 2가지\n\n1. 빠른 처리를 위해 명령어 파이프라인을 잘 활용해야 함. 이를 위해선 “명령어 길이와 수행 시간이 짧고 규격화”되어야 함.\n2. 어차피 자주 쓰이는 명령어만 사용함. 복잡한 기능을 지원하는 명령어보단 “자주 쓰이는 기본적인 명령어를 작고 빠르게 만들기”\n\n**→ RISC 등장!**\n\nCISC와 달리 짧고 규격화된 명령어, 되도록 1클럭 내외! 즉, **고정 길이 명령어**\n\n그리고, **메모리에 직접 접근하는 명령어를 Load, Store 두 개로 제한**할 만큼 메모리 접근을 단순화하고 최소화함!\n\n**대신, 레지스터를 적극 활용!**\n\n| CISC                               | RISC                               |\n| ---------------------------------- | ---------------------------------- |\n| 복잡하고 다양한 명령어             | 단순하고 적은 명령어               |\n| 가변 길이 명령어                   | 고정 길이 명령어                   |\n| 다양한 주소 지정 방식              | 적은 주소 지정 방식                |\n| 프로그램을 이루는 명령어 수가 적음 | 프로그램을 이루는 명령어 수가 많음 |\n| 여러 클럭에 걸쳐 명령어 수행       | 1클럭 내외로 명령어 수행           |\n| 파이프라이닝하기 어려움            | 파이프라이닝하기 쉬움              |\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-10-31",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-5--CPU_chunk_0",
        "text": "[혼공컴운] 5장 CPU 성능 향상 기법\n\n클럭과 코어, 스레드라는 개념을 학습하고, 빠른 CPU를 만드는 설계 기법인 멀티코어와 멀티스레드에 대해 배웁니다\n\n# 5-1 빠른 CPU를 위한 설계 기법\n\n키워드 : 클럭, 코어, 멀티코어, 스레드, 멀티스레드\n\n---\n\n## 클럭\n\n1. 컴퓨터 부품들은 “클럭 신호”에 맞춰 동작합니다.\n2. CPU는 “명령어 사이클”이라는 정해진 흐름에 맞춰 명령어를 실행합니다.\n\n즉, 클럭 속도(Hz)가 높을 수록 CPU의 성능은 일반적으로 좋아진다.\n\n> 클럭 속도는 일정하지 않다!\n>\n> CPU는 기본 클럭 속도(Base)와 최대 클럭 속도(Max)로 나뉘어 있듯, 일정한 속도를 유지하기보단, 고성능을 요하는 순간에 순간적으로 속도를 높이고, 그렇지 않을 때는 유연하게 조정합니다.\n{: prompt-tip }\n\n## 코어와 멀티코어\n\n클럭 속도외에 CPU의 성능을 높이는 방법은 CPU의 코어와 스레드 수를 늘리는 방법이 있습니다.\n\n이전 CPU는 단일 코어로, 명령어를 실행하는 하나의 부품이였던 반면, 최근 멀티코어의 등장으로, CPU 내에 명령어를 실행하는 부품을 여러개 만들 수 있게 되었습니다.\n\n여기서 **코어**는 이전의 CPU의 정의였던 “명령어를 실행하는 부품”입니다.\n\n## 스레드와 멀티스레드\n\n스레드의 사전적 의미는 “실행 흐름의 단위” 입니다.",
        "index": 0
      },
      {
        "id": "2024-10-31-5--CPU_chunk_1",
        "text": "되었습니다.\n\n여기서 **코어**는 이전의 CPU의 정의였던 “명령어를 실행하는 부품”입니다.\n\n## 스레드와 멀티스레드\n\n스레드의 사전적 의미는 “실행 흐름의 단위” 입니다. \n\n**스레드 = 하드웨어적 스레드 + 소프트웨어적 스레드**\n\n### 하드웨어적 스레드(논리 프로세서)\n\n“하나의 코어가 동시에 처리하는 명령어 단위”를 의미합니다.\n\n지금까지 배운 CPU는 1코어 1스레드 CPU였습니다.\n\n하지만, 만약 여러 스레드를 지원하는 CPU는 하나의 코어로도 여러 개의 명령어를 동시에 실행할 수 있습니다.\n\nex) 2코어 4스레드 CPU라면, 한 번에 네 개의 명령어를 처리할 수 있습니다.\n\n이처럼 하나의 코어로 여러 명렁어를 동시에 처리하는 CPU를 **멀티 스레드 프로세서**라 합니다.\n\n### 소프트웨어적 스레드\n\n“하나의 프로그램에서 독립적으로 실행되는 단위”\n\n하나의 프로그램이 실행되는 과정에서 한 부분만 실행될 수도 있지만,\n\n프로그램의 여러 부분이 동시에 실행될 수도 있습니다.\n\nex) 워드 프로세서 프로그램을 개발한다면, \n\n1. 입력받은 내용을 화면에 보여 주는 기능\n2. 입력한 내용이 맞춤법에 맞는지 검사하는 기능\n3.",
        "index": 1
      },
      {
        "id": "2024-10-31-5--CPU_chunk_2",
        "text": "시에 실행될 수도 있습니다.\n\nex) 워드 프로세서 프로그램을 개발한다면, \n\n1. 입력받은 내용을 화면에 보여 주는 기능\n2. 입력한 내용이 맞춤법에 맞는지 검사하는 기능\n3.",
        "index": 2
      },
      {
        "id": "2024-10-31-5--CPU_chunk_3",
        "text": "시에 실행될 수도 있습니다.\n\nex) 워드 프로세서 프로그램을 개발한다면, \n\n1. 입력받은 내용을 화면에 보여 주는 기능\n2. 입력한 내용이 맞춤법에 맞는지 검사하는 기능\n3.",
        "index": 3
      },
      {
        "id": "2024-10-31-5--CPU_chunk_4",
        "text": "시에 실행될 수도 있습니다.\n\nex) 워드 프로세서 프로그램을 개발한다면, \n\n1. 입력받은 내용을 화면에 보여 주는 기능\n2. 입력한 내용이 맞춤법에 맞는지 검사하는 기능\n3.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-4--CPU",
    "title": "[혼공컴운] 4장 CPU의 작동 원리",
    "path": "/2024/10/31/4장-CPU의-작동-원리/",
    "categories": [
      "Computer Science",
      "혼자 공부하는 컴퓨터구조+운영체제",
      "Computer_Science/hongong"
    ],
    "content": "CPU를 구성하는 부품들의 이름과 역할, 그리고 명령어를 실행하는 방식\n\n# 4-1 ALU와 제어장치\n\n키워드 : ALU, 플래그, 제어장치, 제어 신호\n\n---\n\nCPU는 메모리에 저장된 명령어를 읽고, 해석하고, 실행하는 장치\n\nCPU 내부에는\n\n- ALU : 산술/논리 계산 담당\n- 제어장치 :  명령어를 읽고 해석하는 장치\n- 레지스터 : 작은 임시 저장 장치\n\n## ALU\n\n**ALU가 받는 정보는?**\n\nALU는 레지스터를 통해 **피연산자**를 받아들이고, \n\n제어장치로부터 수행할 연산을 알려주는 **제어신호**를 받아들임.\n\n**ALU가 내보내는 정보는?**\n\n특정 숫자나 문자, 메모리 주소가 될 수 있음.(+플래그)\n\n결괏값은 바로 메모리에 저장되지 않고 일시적으로 레지스터에 저장!\n\n**플래그?**\n\n이진수만으로는 음수인지 양수인지 판단하기 어렵기에 추가적인 정보!\n\n| **플래그 종류**   | **의미**                           |\n| ----------------- | ---------------------------------- |\n| 부호 플래그       | 연산 결과의 부호                   |\n| 제로 플래그       | 연산 결과가 0인지                  |\n| 캐리 플래그       | 연산 결과 올림수나 빌림수가 있는지 |\n| 오버플로우 플래그 | 오버플로우 발생여부                |\n| 인터럽트 플래그   | 인터럽트가 가능한지                |\n| 슈퍼바이저 플래그 | 커널 OR 사용자모드 구분            |\n\n플래그들은 **플래그 레지스터**에 저장!\n\n## 제어장치\n\n제어 신호를 내보내고, 명령어를 해석하는 부품\n\n**제어 신호**는 컴퓨터 부품을 관리하고 작동시키기 위한 일종의 전기 신호\n\n### **제어장치가 받아들이는 신호는?**\n\n### 1. 클럭\n\n클럭(clock)이란 컴퓨터 연산의 시간 단위\n\n클럭에 맞춰 레지스터에서 다른 레지스터로 이동하거나, 연산을 수행하는 등\n\n### 2. 해석해야 할 명령어\n\nCPU가 해석해야 할 명령어는 **명령어 레지스터**라는 특별한 레지스터에 저장!\n\n제어장치는 이 명령어 레지스터로부터 해석할 명령어를 받아들이고 해석한 뒤,\n\n제어 신호를 발생시킴\n\n### 3. 플래그 레지스터 속 플래그 값\n\n### 4. 제어 버스(시스템 버스 中)로 전달된 제어 신호\n\n### 제어장치가 내보내는 신호는?\n\n### CPU 외부에 전달 or CPU 내부에 전달\n\n외부에 제어 신호를 전달한다는 것은 제어 버스로 제어 신호를 내보낸다는 것!\n\n크게 메모리에 전달 OR 입출력장치에 전달\n\n# 4-2 레지스터\n\n키워드 : 프로그램 카운터, 명령어 레지스터, 메모리 주소/버퍼 레지스터, 범용/플래그 레지스터, 스택 포인터, 베이스 레지스터\n\n---\n\n프로그램 속 명령어와 데이터는 실행 전후로 **반드시 레지스터에 저장**\n\n즉, 레지스터를 통해 프로그램 실행 시 cpu에서 어떻게 동작하는 지 알 수 있다!\n\n## 반드시 알아야 할 레지스터\n\n상용화된 cpu 속 레지스터들은 각자 다르다.\n\n하지만, 공통으로 포함하는 8개의 레지스터에 대해 학습!\n\n### 1. 프로그램 카운터(Program Counter)\n\n메모리에서 가져올 명령어의 주소, 즉, 메모리에서 읽어 들일 명령어의 주소를 저장!\n\n프로그램 카운터를 명령어 포인터(IP)라고 부르는 CPU도 있음.\n\n### 2. 명령어 레지스터(Instruction Register)\n\n해석할 명령어, 즉, 방금 메모리에서 읽어 들인 명령어를 저장!\n\n제어장치는 명령어 레지스터 속 명령어를 받아들이고 해석한 뒤 제어 신호를 보냄\n\n### 3. 메모리 주소 레지스터(MAR:Memory Address Register)\n\n메모리의 주소를 저장하는 레지스터\n\nCPU가 읽어 들이고자 하는 주소 값을 주소 버스로 보낼 때 메모리 주소 레지스터를 거쳐감.\n\n### 4. 메모리 버퍼 레지스터(Memory Buffer Register)\n\n메모리와 주고받을 값(데이터와 명령어)을 저장하는 레지스터\n\n즉, 메모리에 쓰고 싶은 값이나 메모리로부터 전달받은 값은 메모리 버퍼 레지스터를 거침\n\nCPU가 주소 버스로 내보낼 값이 3번 레지스터를 지난다면,\n\n데이터 버스로 주고 받을 값은 메모리 버퍼 레지스터를 거침\n\n### 예시!\n\n1. CPU로 실행할 프로그램이 1000~1500번지에 저장되어 있는 상황.\n2. 프로그램 실행을 위해 **프로그램 카운터**에 1000이 저장됨\n3. 프로그램 카운터의 1000값을 메모리 주소 레지스터에서 받아와 저장(주소를 저장)\n4. 제어 장치에서 ‘메모리 읽기’ 신호를 주소 버스를 통해 내보냄.\n5. 데이터 버스를 통해 1000번지에 있는 값 0xB1이 메모리 버퍼 레지스터로 전달\n+ 프로그램 카운터는 1 증가하여 1001로\n6. 메모리 버퍼 레지스터에 저장된 값은 명령어 레지스터로 이동(0xB1)\n7. 제어장치는 명령어 레지스터의 명령어를 해석하고 제어 신호 발생\n\n### 5. 범용 레지스터(general purpose register)\n\n다양하고 일반적인 상황에서 자유롭게 사용할 수 있는 레지스터\n\n범용 레지스터는 데이터와 주소 모두를 저장할 수 있음\n\n### 6. 플래그 레지스터(flag register)\n\nALU 연산 결과에 따른 플래그를 저장하는 레지스터\n\n연산 결과 또는 CPU 상태에 대한 부가적인 정보를 저장하는 레지스터\n\n## 특정 레지스터를 이용한 주소 지정 방식 : 스택 주소 지정\n\n**스택 주소 지정 방식**은 스택과 스택 포인터를 이용한 주소 지정 방식!\n\n스택은 가장 최근에 저장한 값부터 꺼내는데,\n\n여기서 스택의 꼭대기를 가리키는 **스택 포인터**라는 레지스터가 있음.\n\n즉, 스택 포인터는 스택에 마지막으로 저장된 값의 위치를 저장하는 레지스터\n\n\n> 그럼 스택은 어디에?\n>\n>메모리 영억에 스택처럼 사용할 영역이 정해져 있음.\n>→ 스택 영역!\n>\n>다른 주소 공간과는 다르게 암묵적으로 약속된 영억\n{: .prompt-tip }\n\n## 특정 레지스터를 이용한 주소 지정 방식 :  변위 주소 지정\n\n> 명령어 = 연산코드 + 오퍼랜드\n> 오퍼랜드 필드에는 메모리 주소가 담길 때도 있음\n{: .prompt-info }\n\n**변위 주소 지정 방식**이란 오퍼랜드 필드의 값(변위)과 특정 레지스터의 값을 더해\n\n유효 주소를 얻어내는 주소 지정 방식!\n\n오퍼랜드 필드의 주소와 어떤 레지스터를 더하는 지에 따라\n\n- 상대 주소 지정 방식\n- 베이스 레지스터 주소 지정 방식\n\n으로 나뉨.\n\n### 상대 주소 지정 방식\n\n오퍼랜드와 프로그램 카운터의 값을 더해 유효 주소를 얻는 방식\n\n만약 오퍼랜드가 -3이였다면, 프로그램 카운터에 -3을 한\n\n즉, 실행하기로 했던 주소에서 3번째 이전 번지로 가서!\n\n### 베이스 레지스터 주소 지정 방식\n\n오퍼랜드와 베이스 레지스터의 값을 더해 유효 주소를 얻는 방식\n\n여기서 베이스 레지스는 ‘기준 주소’, 오퍼랜드는 ‘기준 주소로부터 떨어진 거리’\n\n# 4-3 명령어 사이클과 인터럽트\n\n키워드 : 명령어 사이클, 인터럽트, 예외, 하드웨어 인터럽트, 인터럽트 서비스 루틴\n\n---\n\nCPU가 명령어를 처리하는 과정에는 정해진 흐름이 있고, 그 흐름을 반복하며 처리\n\n이렇게 하나의 명령어를 처리하는 정형화된 흐름을 **명령어 사이클** 이라 함\n\n간혹, 이 흐름을 끊어지는 상황이 있는데, 이것이 바로 **인터럽트**!\n\n## 명령어 사이클\n\n명령어 사이클 = 인출 사이클(데이터가져오기) + 실행 사이클(연산하고 제어신호보내기)\n\n하지만, 메모리에 접근이 필요할 경우 **간접 사이클**을 거쳐가기도 함\n\n## 인터럽트\n\nCPU가 수행 중인 작업을 방해해 잠시 중단하는 신호를 **인터럽트**라 한다!\n\n**인터럽트 = 동기 인터럽트 + 비동기 인터럽트**\n\n**동기 인터럽트**란 CPU에 의해 발생하는 인터럽트\n\nCPU가 명령어 수행 중, 오류와 같은 예외 상황을 마주쳤을 때 발생!\n\n(예외exception이라 부르기도 함)\n\n**비동기 인터럽트**는 주로 입출력장치에 의해 발생하는 인터럽트!\n\n세탁기 완료 알림, 전자레인지 조리 완료 알림과 같은 알림 역할을 함\n\n(하드웨어 인터럽트라 부르기도 함)\n\n**하드웨어 인터럽트**\n\n알림과 같은 인터럽트. 입출력 도중에도 효율적으로 명령어를 처리하기 위해 사용\n\n명령을 시켜놓고 주기적으로 확인할 필요 없기에, 효율적으로 명령어 처리 가능!\n\n**하드웨어 인터럽트 처리 순서**\n\n1. 입출력장치는 CPU에 인터럽트 요청 신호 보냄\n2. CPU는 실행 사이클이 끝나고 명령어 인출 전 항상 인터럽트 여부 확인\n3. CPU는 인터럽트 요청 확인하고 **인터럽트 플래그**를 통해 받을 수 있는지 확인\n4. 가능하다면 CPU는 지금까지의 작업을 백업\n5. CPU는 **인터럽트 벡터**를 참조하여 **인터럽트 서비스 루틴**을 실행\n6. 인터럽트 서비스 루인이 끝나면, 4에서 백업한 작업을 복구해 실행 재개\n\n# 추가(예외의 종류)\n\n---\n\n예외의 종류에는 폴트, 트랩, 중단, 소프트웨어 인터럽트가 있습니다.\n\n**인터럽트**\n\n1. **동기 인터럽트(예외)**\n    1. **폴트**\n    2. **트랩**\n    3. **중단** : 프로그램을 강제 중단시킬 수밖에 없는 심각한 오류!\n    4. **소프트웨어 인터럽트** : 시스템 콜 발생 시\n2. **비동기 인터럽트(하드웨어 인터럽트)**\n\n### 폴트 vs 트랩\n\n폴트 : 예외를 처리한 직후 **예외가 발생한 명령어**부터 실행을 재개하는 예외\n\n트랩 : 예외를 처리한 직후 예외가 발생한 명령어의 **다음 명령어부터** 실행을 재개\n\n---\n---\n---\n\n> 위 내용은 한빛미디어의 \"혼자 공부하는 컴퓨터 구조+운영체제\" 교재를 학습하고, 정리한 글입니다.\n{: .prompt-tip }\n",
    "date": "2024-10-31",
    "tags": [
      "컴퓨터구조",
      "운영체제"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-4--CPU_chunk_0",
        "text": "[혼공컴운] 4장 CPU의 작동 원리\n\nCPU를 구성하는 부품들의 이름과 역할, 그리고 명령어를 실행하는 방식\n\n# 4-1 ALU와 제어장치\n\n키워드 : ALU, 플래그, 제어장치, 제어 신호\n\n---\n\nCPU는 메모리에 저장된 명령어를 읽고, 해석하고, 실행하는 장치\n\nCPU 내부에는\n\n- ALU : 산술/논리 계산 담당\n- 제어장치 :  명령어를 읽고 해석하는 장치\n- 레지스터 : 작은 임시 저장 장치\n\n## ALU\n\n**ALU가 받는 정보는?**\n\nALU는 레지스터를 통해 **피연산자**를 받아들이고, \n\n제어장치로부터 수행할 연산을 알려주는 **제어신호**를 받아들임.\n\n**ALU가 내보내는 정보는?**\n\n특정 숫자나 문자, 메모리 주소가 될 수 있음.(+플래그)\n\n결괏값은 바로 메모리에 저장되지 않고 일시적으로 레지스터에 저장!\n\n**플래그?**\n\n이진수만으로는 음수인지 양수인지 판단하기 어렵기에 추가적인 정보!\n\n| **플래그 종류**   | **의미**                           |\n| ----------------- | ---------------------------------- |\n| 부호 플래그       | 연산 결과의 부호                   |\n| 제로 플래그       | 연산 결과가 0인지                  |\n| 캐리 플래그       | 연산 결과 올림수나 빌림수가 있는지 |\n| 오버플로우 플래그 | 오버플로우 발생여부                |\n| 인터럽트 플래그   | 인터럽트가 가능한지                |\n| 슈퍼",
        "index": 0
      },
      {
        "id": "2024-10-31-4--CPU_chunk_1",
        "text": "빌림수가 있는지 |\n| 오버플로우 플래그 | 오버플로우 발생여부                |\n| 인터럽트 플래그   | 인터럽트가 가능한지                |\n| 슈퍼바이저 플래그 | 커널 OR 사용자모드 구분            |\n\n플래그들은 **플래그 레지스터**에 저장!\n\n## 제어장치\n\n제어 신호를 내보내고, 명령어를 해석하는 부품\n\n**제어 신호**는 컴퓨터 부품을 관리하고 작동시키기 위한 일종의 전기 신호\n\n### **제어장치가 받아들이는 신호는?**\n\n### 1. 클럭\n\n클럭(clock)이란 컴퓨터 연산의 시간 단위\n\n클럭에 맞춰 레지스터에서 다른 레지스터로 이동하거나, 연산을 수행하는 등\n\n### 2. 해석해야 할 명령어\n\nCPU가 해석해야 할 명령어는 **명령어 레지스터**라는 특별한 레지스터에 저장!\n\n제어장치는 이 명령어 레지스터로부터 해석할 명령어를 받아들이고 해석한 뒤,\n\n제어 신호를 발생시킴\n\n### 3. 플래그 레지스터 속 플래그 값\n\n### 4.",
        "index": 1
      },
      {
        "id": "2024-10-31-4--CPU_chunk_2",
        "text": "레지스터에 저장!\n\n제어장치는 이 명령어 레지스터로부터 해석할 명령어를 받아들이고 해석한 뒤,\n\n제어 신호를 발생시킴\n\n### 3. 플래그 레지스터 속 플래그 값\n\n### 4. 제어 버스(시스템 버스 中)로 전달된 제어 신호\n\n### 제어장치가 내보내는 신호는?\n\n### CPU 외부에 전달 or CPU 내부에 전달\n\n외부에 제어 신호를 전달한다는 것은 제어 버스로 제어 신호를 내보낸다는 것!\n\n크게 메모리에 전달 OR 입출력장치에 전달\n\n# 4-2 레지스터\n\n키워드 : 프로그램 카운터, 명령어 레지스터, 메모리 주소/버퍼 레지스터, 범용/플래그 레지스터, 스택 포인터, 베이스 레지스터\n\n---\n\n프로그램 속 명령어와 데이터는 실행 전후로 **반드시 레지스터에 저장**\n\n즉, 레지스터를 통해 프로그램 실행 시 cpu에서 어떻게 동작하는 지 알 수 있다!\n\n## 반드시 알아야 할 레지스터\n\n상용화된 cpu 속 레지스터들은 각자 다르다.\n\n하지만, 공통으로 포함하는 8개의 레지스터에 대해 학습!\n\n### 1. 프로그램 카운터(Program Counter)\n\n메모리에서 가져올 명령어의 주소, 즉, 메모리에서 읽어 들일 명령어의 주소를 저장!\n\n프로그램 카운터를 명령어 포인터(IP)라고 부르는 CPU도 있음.\n\n### 2. 명령어 레지스터(Instruction Register)\n\n해석할 명령어, 즉, 방금 메모리에서 읽어 들인 명령어를 저장!\n\n제어장치는 명령어 레지스터 속 명령어를 받아들이고 해석한 뒤 제어 신호를 보냄\n\n### 3.",
        "index": 2
      },
      {
        "id": "2024-10-31-4--CPU_chunk_3",
        "text": "Register)\n\n해석할 명령어, 즉, 방금 메모리에서 읽어 들인 명령어를 저장!\n\n제어장치는 명령어 레지스터 속 명령어를 받아들이고 해석한 뒤 제어 신호를 보냄\n\n### 3. 메모리 주소 레지스터(MAR:Memory Address Register)\n\n메모리의 주소를 저장하는 레지스터\n\nCPU가 읽어 들이고자 하는 주소 값을 주소 버스로 보낼 때 메모리 주소 레지스터를 거쳐감.\n\n### 4. 메모리 버퍼 레지스터(Memory Buffer Register)\n\n메모리와 주고받을 값(데이터와 명령어)을 저장하는 레지스터\n\n즉, 메모리에 쓰고 싶은 값이나 메모리로부터 전달받은 값은 메모리 버퍼 레지스터를 거침\n\nCPU가 주소 버스로 내보낼 값이 3번 레지스터를 지난다면,\n\n데이터 버스로 주고 받을 값은 메모리 버퍼 레지스터를 거침\n\n### 예시!\n\n1. CPU로 실행할 프로그램이 1000~1500번지에 저장되어 있는 상황.\n2. 프로그램 실행을 위해 **프로그램 카운터**에 1000이 저장됨\n3. 프로그램 카운터의 1000값을 메모리 주소 레지스터에서 받아와 저장(주소를 저장)\n4. 제어 장치에서 ‘메모리 읽기’ 신호를 주소 버스를 통해 내보냄.\n5. 데이터 버스를 통해 1000번지에 있는 값 0xB1이 메모리 버퍼 레지스터로 전달\n+ 프로그램 카운터는 1 증가하여 1001로\n6. 메모리 버퍼 레지스터에 저장된 값은 명령어 레지스터로 이동(0xB1)\n7. 제어장치는 명령어 레지스터의 명령어를 해석하고 제어 신호 발생\n\n### 5.",
        "index": 3
      },
      {
        "id": "2024-10-31-4--CPU_chunk_4",
        "text": "증가하여 1001로\n6. 메모리 버퍼 레지스터에 저장된 값은 명령어 레지스터로 이동(0xB1)\n7. 제어장치는 명령어 레지스터의 명령어를 해석하고 제어 신호 발생\n\n### 5. 범용 레지스터(general purpose register)\n\n다양하고 일반적인 상황에서 자유롭게 사용할 수 있는 레지스터\n\n범용 레지스터는 데이터와 주소 모두를 저장할 수 있음\n\n### 6.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--PyTorch--State-dict",
    "title": "[PyTorch] State_dict란?",
    "path": "/2024/10/31/[PyTorch]-State_dict란/",
    "categories": [
      "AI & CV",
      "PyTorch"
    ],
    "content": "https://tutorials.pytorch.kr/recipes/recipes/what_is_state_dict.html<br>\n\n## STATE_DICT란?\n---\nPyTorch에서 `torch.nn.Module` 모델의 학습 가능한 매개변수(가중치와 편향)들은 모델의 배개변수에 포함되어 있습니다.\n(`model.parameters()`로 접근) `state_dict`는 간단히 말해 **각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체**입니다.\n\n### 개요\n`state_dict`는 PyTorch에서 모델을 <mark style=\"background: #ADCCFFA6;\">저장하거나 불러오는 데</mark> 필수적인 항목.\n`state_dict`객체는 Python dict이기에 쉽게 저장, 업데이트, 변경 및 복원할 수 있으며 이는 모델과 옵티마이저에 **모듈성**을 제공\n<mark style=\"background: #ADCCFFA6;\">학습가능한 매개변수를 갖는 계층</mark>(합성곱, 선형 레이어 등) 및 <mark style=\"background: #ADCCFFA6;\">버퍼</mark>들(batchnorm의 running_mean)만 모델의 `state_dict` 항목을 가짐\n\n옵티마이저 객체(`torch.optim`) 또한 상태 뿐만 아니라 사용된 하이퍼 파라미터 정보가 포함된 `state_dict`을 갖습니다.\n\n### 예시\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\n\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\n# 모델의 state_dict 출력\nprint(\"Model's state_dict:\")\nfor param_tensor in net.state_dict():\n    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n\nprint()\n\n# 옵티마이저의 state_dict 출력\nprint(\"Optimizer's state_dict:\")\nfor var_name in optimizer.state_dict():\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n```\n\n### 출력 결과\n```\nModel's state_dict:\nconv1.weight \t torch.Size([6, 3, 5, 5])\nconv1.bias \t torch.Size([6])\nconv2.weight \t torch.Size([16, 6, 5, 5])\nconv2.bias \t torch.Size([16])\nfc1.weight \t torch.Size([120, 400])\nfc1.bias \t torch.Size([120])\nfc2.weight \t torch.Size([84, 120])\nfc2.bias \t torch.Size([84])\nfc3.weight \t torch.Size([10, 84])\nfc3.bias \t torch.Size([10])\n\nOptimizer's state_dict:\nstate \t {}\nparam_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n```\n",
    "date": "2024-10-31",
    "tags": [
      "PyTorch"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--PyTorch--State-dict_chunk_0",
        "text": "[PyTorch] State_dict란?\n\nhttps://tutorials.pytorch.kr/recipes/recipes/what_is_state_dict.html<br>\n\n## STATE_DICT란?\n---\nPyTorch에서 `torch.nn.Module` 모델의 학습 가능한 매개변수(가중치와 편향)들은 모델의 배개변수에 포함되어 있습니다.\n(`model.parameters()`로 접근) `state_dict`는 간단히 말해 **각 계층을 매개변수 텐서로 매핑되는 Python 사전(dict) 객체**입니다.\n\n### 개요\n`state_dict`는 PyTorch에서 모델을 <mark style=\"background: #ADCCFFA6;\">저장하거나 불러오는 데</mark> 필수적인 항목.\n`state_dict`객체는 Python dict이기에 쉽게 저장, 업데이트, 변경 및 복원할 수 있으며 이는 모델과 옵티마이저에 **모듈성**을 제공\n<mark style=\"background: #ADCCFFA6;\">학습가능한 매개변수를 갖는 계층</mark>(합성곱, 선형 레이어 등) 및 <mark style=\"background: #ADCCFFA6;\">버퍼</mark>들(batchnorm의 running_mean)만 모델의 `state_dict` 항목을 가짐\n\n옵티마이저 객체(`torch.optim`) 또한 상태 뿐만 아니라 사용된 하이퍼 파라미터 정보가 포함된 `state_dict`을 갖습니다.\n\n### 예시\n```python\nimport torch\nimport torch.nn as nn\nimport torch.op",
        "index": 0
      },
      {
        "id": "2024-10-31--PyTorch--State-dict_chunk_1",
        "text": "라미터 정보가 포함된 `state_dict`을 갖습니다.\n\n### 예시\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\n\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\n# 모델의 state_dict 출력\nprint(\"",
        "index": 1
      },
      {
        "id": "2024-10-31--PyTorch--State-dict_chunk_2",
        "text": "Net()\n\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n\n# 모델의 state_dict 출력\nprint(\"Model's state_dict:\")\nfor param_tensor in net.state_dict():\n    print(param_tensor, \"\\t\", net.state_dict()[param_tensor].size())\n\nprint()\n\n# 옵티마이저의 state_dict 출력\nprint(\"Optimizer's state_dict:\")\nfor var_name in optimizer.state_dict():\n    print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n```\n\n### 출력 결과\n```\nModel's state_dict:\nconv1.weight \t torch.Size([6, 3, 5, 5])\nconv1.bias \t torch.Size([6])\nconv2.weight \t torch.Size([16, 6, 5, 5])\nconv2.bias \t torch.Size([16])\nfc1.weight \t torch.Size([120, 400])\nfc1.bias \t torch.Size([120])\nfc2.weight \t torch.Size([84, 120])\nfc2.bias \t torch.Size([84])\nfc3.weight \t torch.Size([10, 84])\nfc3.bias \t torch.Size([10])\n\nOptimizer's state_dict:\nstate \t {}",
        "index": 2
      },
      {
        "id": "2024-10-31--PyTorch--State-dict_chunk_3",
        "text": ")\nfc3.weight \t torch.Size([10, 84])\nfc3.bias \t torch.Size([10])\n\nOptimizer's state_dict:\nstate \t {}\nparam_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n```",
        "index": 3
      },
      {
        "id": "2024-10-31--PyTorch--State-dict_chunk_4",
        "text": "e': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]\n```",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--PyTorch",
    "title": "[PyTorch] 데이터 불러오기",
    "path": "/2024/10/31/[PyTorch]-데이터-불러오기/",
    "categories": [
      "AI & CV",
      "PyTorch"
    ],
    "content": "https://tutorials.pytorch.kr/recipes/recipes/loading_data_recipe.html<br>\nPyTorch는 인공신경망을 만드는데 필요한 다양한 기본 요소를 간단하고 직관적이며 안정적인 API로 제공합니다. PyTorch는 공용 데이터셋을 쉽게 사용할 수 있도록 도와주는 패키지를 포함.<br>\n\n### 개요\nPyTorch 데이터 불러오기 기능의 핵심은 `torch.utils.data.DataLoader` 클래스입니다.\n데이터를 파이썬 iterable로써 접근할 수 있게 해주는 클래스\n\n### 데이터에 접근하기\n`torchaudio` 의 YesNO 데이터셋은 오디오 클립 60개로 구성되어있음.\n오디오 클립 각각의 길이는 단어 8개\n`torchaudio.datasets.YESNO` 클래스를 사용해 YesNo 데이터셋 생성\n```python\ntorchaudio.datasets.YESNO(\n     root='./',\n     url='http://www.openslr.org/resources/1/waves_yesno.tar.gz',\n     folder_in_archive='waves_yesno',\n     download=True)\n```\n> 각각의 데이터 항목(item)은 튜플 형태(wafeform,sample_rate,labels)를 가짐\n\n```python\n# YesNo 안에 각각의 데이터 항목은 튜플 형태 (파형, 샘플 속도, 라벨)를 가지며,\n# 이때 labels는 0(no)과 1(yes)을 담은 리스트 형태로 되어 있습니다.\nyesno_data = torchaudio.datasets.YESNO('./', download=True)\n\n# 실제 데이터에 접근해서 yesno_data의 형태를 확인합니다. 세 번째 항목을 예시로 살펴봅니다.\nn = 3\nwaveform, sample_rate, labels = yesno_data[n]\nprint(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(waveform, sample_rate, labels))\n```\n\n### 데이터 불러오기\n데이터셋에 성공적으로 접근했으니, 이제 데이터셋을 `DataLoader`로 넘겨줍니다.\n`DataLoader`는 데이터셋을 sampler와 조합시켜 데이터셋을 순회할 수 있는 iterable을 만듦.\n```python\ndata_loader = torch.utils.data.DataLoader(yesno_data,\n\t\t\t\t\t\t\t\t\t\t batch_size=1,\n\t\t\t\t\t\t\t\t\t\t shuffle=True)\n```\n### 데이터 순회하기\n이제 `data_loader`를 이용 데이터를 순회할 수 있음. 모델을 학습하려면 순회 가능해야 함.\n아래 예시를 통해 data_loader 아넹 있는 각각의 데이터 항목이 텐서로 바뀌었음을 확인 가능.\n```python\nfor data in data_loader:\n\tprint(\"Data: \", data)\n\tprint(\"Waveform: {}\\nSample rate: {}\\nLabels: {}\".format(data[0], data[1], data[2]))\n\tbreak\n```\n\n",
    "date": "2024-10-31",
    "tags": [
      "PyTorch"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--PyTorch_chunk_0",
        "text": "[PyTorch] 데이터 불러오기\n\nhttps://tutorials.pytorch.kr/recipes/recipes/loading_data_recipe.html<br>\nPyTorch는 인공신경망을 만드는데 필요한 다양한 기본 요소를 간단하고 직관적이며 안정적인 API로 제공합니다.",
        "index": 0
      },
      {
        "id": "2024-10-31--PyTorch_chunk_1",
        "text": "ecipes/loading_data_recipe.html<br>\nPyTorch는 인공신경망을 만드는데 필요한 다양한 기본 요소를 간단하고 직관적이며 안정적인 API로 제공합니다.",
        "index": 1
      },
      {
        "id": "2024-10-31--PyTorch_chunk_2",
        "text": "ecipes/loading_data_recipe.html<br>\nPyTorch는 인공신경망을 만드는데 필요한 다양한 기본 요소를 간단하고 직관적이며 안정적인 API로 제공합니다.",
        "index": 2
      },
      {
        "id": "2024-10-31--PyTorch_chunk_3",
        "text": "ecipes/loading_data_recipe.html<br>\nPyTorch는 인공신경망을 만드는데 필요한 다양한 기본 요소를 간단하고 직관적이며 안정적인 API로 제공합니다.",
        "index": 3
      },
      {
        "id": "2024-10-31--PyTorch_chunk_4",
        "text": "ecipes/loading_data_recipe.html<br>\nPyTorch는 인공신경망을 만드는데 필요한 다양한 기본 요소를 간단하고 직관적이며 안정적인 API로 제공합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--PyTorch",
    "title": "[PyTorch] 컴퓨터 비전을 위한 전이학습",
    "path": "/2024/10/31/[PyTorch]-컴퓨터-비전을-위한-전이학습/",
    "categories": [
      "AI & CV",
      "PyTorch"
    ],
    "content": "https://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html<br>\n본 페이지에서는 전이학습을 이용하여 이미지 분류를 위한 CNN을 어떻게 학습시키는지 다룸<br>\n\n> CS231n 노트 인용\n> \n>실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에, (무작위 초기화를 통해) 맨 처음부터 합성곱 신경망(Convolutional Network) 전체를 학습하는 사람은 매우 적습니다. 대신, 매우 큰 데이터셋(예. 100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱 신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업 을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용합니다.\n{: .prompt-tip }\n\n전이학습 시나리오의 주요한 2가지<br>\n- **CNN의 미세조정**: 무작위 초기화 대신, 미리 학습한 신경망으로 초기화합니다.\n- **고정된 특징 추출기로써의 CNN**: 여기서는 마지막에 FC층을 제외한 모든 신경망의 가중치를 고정합니다. 이 마지막의 FC층은 새로운 가중치를 갖는 계층으로 대체돼 이 계층만 학습합니다.\n\n### 라이브러리 불러오기\n```python\n# License: BSD\n# Author: Sasank Chilamkurthy\n\nfrom __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n\ncudnn.benchmark = True\nplt.ion()   # 대화형 모드\n```\n### 데이터 불러오기\n데이터를 불러오기 위해 torchvision과 torch.utils.data 패키지 사용\n여기서는 **개미**와 **벌**을 **분류**하는 모델을 학습할 것.\n```python\n# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n# 검증을 위한 일반화\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_dir = 'data/hymenoptera_data'\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train', 'val']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train', 'val']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n```\n#### 일부 이미지 시각화하기(확인용)\n```python\ndef imshow(inp, title=None):\n    \"\"\"tensor를 입력받아 일반적인 이미지로 보여줍니다.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # 갱신이 될 때까지 잠시 기다립니다.\n\n\n# 학습 데이터의 배치를 얻습니다.\ninputs, classes = next(iter(dataloaders['train']))\n\n# 배치로부터 격자 형태의 이미지를 만듭니다.\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])\n```\n### 모델 학습하기\n이제 모델을 학습하기 위한 일반 함수를 작성.\n**학습률 관리와 최적의 모델 구하기**\n```python\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # 모델을 학습 모드로 설정\n            else:\n                model.eval()   # 모델을 평가 모드로 설정\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # 데이터를 반복\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # 매개변수 경사도를 0으로 설정\n                optimizer.zero_grad()\n\n                # 순전파\n                # 학습 시에만 연산 기록을 추적\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # 학습 단계인 경우 역전파 + 최적화\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # 통계\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            # 모델을 깊은 복사(deep copy)함\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best val Acc: {best_acc:4f}')\n\n    # 가장 나은 모델 가중치를 불러옴\n    model.load_state_dict(best_model_wts)\n    return model\n```\n",
    "date": "2024-10-31",
    "tags": [
      "PyTorch"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--PyTorch_chunk_0",
        "text": "[PyTorch] 컴퓨터 비전을 위한 전이학습\n\nhttps://tutorials.pytorch.kr/beginner/transfer_learning_tutorial.html<br>\n본 페이지에서는 전이학습을 이용하여 이미지 분류를 위한 CNN을 어떻게 학습시키는지 다룸<br>\n\n> CS231n 노트 인용\n> \n>실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에, (무작위 초기화를 통해) 맨 처음부터 합성곱 신경망(Convolutional Network) 전체를 학습하는 사람은 매우 적습니다. 대신, 매우 큰 데이터셋(예. 100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱 신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업 을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용합니다.\n{: .prompt-tip }\n\n전이학습 시나리오의 주요한 2가지<br>\n- **CNN의 미세조정**: 무작위 초기화 대신, 미리 학습한 신경망으로 초기화합니다.\n- **고정된 특징 추출기로써의 CNN**: 여기서는 마지막에 FC층을 제외한 모든 신경망의 가중치를 고정합니다.",
        "index": 0
      },
      {
        "id": "2024-10-31--PyTorch_chunk_1",
        "text": "*: 무작위 초기화 대신, 미리 학습한 신경망으로 초기화합니다.\n- **고정된 특징 추출기로써의 CNN**: 여기서는 마지막에 FC층을 제외한 모든 신경망의 가중치를 고정합니다.",
        "index": 1
      },
      {
        "id": "2024-10-31--PyTorch_chunk_2",
        "text": "*: 무작위 초기화 대신, 미리 학습한 신경망으로 초기화합니다.\n- **고정된 특징 추출기로써의 CNN**: 여기서는 마지막에 FC층을 제외한 모든 신경망의 가중치를 고정합니다.",
        "index": 2
      },
      {
        "id": "2024-10-31--PyTorch_chunk_3",
        "text": "*: 무작위 초기화 대신, 미리 학습한 신경망으로 초기화합니다.\n- **고정된 특징 추출기로써의 CNN**: 여기서는 마지막에 FC층을 제외한 모든 신경망의 가중치를 고정합니다.",
        "index": 3
      },
      {
        "id": "2024-10-31--PyTorch_chunk_4",
        "text": "*: 무작위 초기화 대신, 미리 학습한 신경망으로 초기화합니다.\n- **고정된 특징 추출기로써의 CNN**: 여기서는 마지막에 FC층을 제외한 모든 신경망의 가중치를 고정합니다.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--PyTorch--float----fuse----eval",
    "title": "[PyTorch] float(), fuse(), eval()",
    "path": "/2024/10/31/[PyTorch]-float(),-fuse(),-eval()/",
    "categories": [
      "AI & CV",
      "PyTorch"
    ],
    "content": "본 문서는 모델을 불러오는 과정에서 사용되는 `float()`, `fuse()`, `eval()`함수에 대해 다룹니다.\n\n## fuse()\n***\n`fuse()` 함수는 여러개의 PyTorch 모듈을 하나의 모듈로 합칠 때 사용됩니다. 이는 memory access time과 kernel launch time을 줄여 성능을 향상시킬 수 있습니다.<br>\n특히 elementwise addition, multiplication, and activation functions에서 유용합니다. 이러한 퓨전 프로세스는 연산들을 하나의 커널로 합치고, 메모리를 읽고 쓰는 횟수를 줄여줍니다.<br>\n아래는 `torch.jit.script`를 사용해 함수를 합치는 예시입니다.<br>\n```python\nimport torch\n\n@torch.jit.script\ndef fused_gelu(x):\n    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))\n\n# Usage\ninput_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\noutput_tensor = fused_gelu(input_tensor)\n```\n\n## eval()\n***\n`eval()` 함수는 PyTorch 모듈 혹은 모델을 평가 모드로 설정합니다. 평가 모드에선 배치 정규화 혹은 드롭아웃과 같은 모듈들이 학습 모드일때와 다르게 동작합니다.\n평가 모드에선 배치 정규화는 배치 통계 대신 전체 모집단의 통계를 사용합니다. 그리고 드롭아웃 레이어들은 비활성화됩니다.\n모델을 평가하거나 추론을 할 때 일정한 행동을 보장하려면 `eval()` 함수를 사용하는 것은 매우 중요합니다. 아래는 예시 입니다\n```python\nimport torch\n\nmodel = MyModel()\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()\n\ninput_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\noutput_tensor = model(input_tensor)\n```\n\n## float()\n***\n\n1. `float()`: The `float()` function is used to convert a PyTorch tensor to a float tensor. It returns a new tensor with the same data but with floating-point data type. This can be useful when you want to perform operations that require floating-point precision. Here's an example:\n\n```python\nimport torch\n\nint_tensor = torch.tensor([1, 2, 3])\nfloat_tensor = int_tensor.float()\n\nprint(float_tensor)\n# Output: tensor([1., 2., 3.])\n```\n\n\n\nhttps://coffeedjimmy.github.io/pytorch/2019/11/05/pytorch_nograd_vs_train_eval/\n",
    "date": "2024-10-31",
    "tags": [
      "PyTorch"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--PyTorch--float----fuse----eval_chunk_0",
        "text": "[PyTorch] float(), fuse(), eval()\n\n본 문서는 모델을 불러오는 과정에서 사용되는 `float()`, `fuse()`, `eval()`함수에 대해 다룹니다.\n\n## fuse()\n***\n`fuse()` 함수는 여러개의 PyTorch 모듈을 하나의 모듈로 합칠 때 사용됩니다. 이는 memory access time과 kernel launch time을 줄여 성능을 향상시킬 수 있습니다.<br>\n특히 elementwise addition, multiplication, and activation functions에서 유용합니다. 이러한 퓨전 프로세스는 연산들을 하나의 커널로 합치고, 메모리를 읽고 쓰는 횟수를 줄여줍니다.<br>\n아래는 `torch.jit.script`를 사용해 함수를 합치는 예시입니다.<br>\n```python\nimport torch\n\n@torch.jit.script\ndef fused_gelu(x):\n    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))\n\n# Usage\ninput_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\noutput_tensor = fused_gelu(input_tensor)\n```\n\n## eval()\n***\n`eval()` 함수는 PyTorch 모듈 혹은 모델을 평가 모드로 설정합니다. 평가 모드에선 배치 정규화 혹은 드롭아웃과 같은 모듈들이 학습 모드일때와 다르게 동작합니다.\n평가 모드에선 배치 정규화는 배치 통계 대신 전체 모집단의 통계를 사용합니다.",
        "index": 0
      },
      {
        "id": "2024-10-31--PyTorch--float----fuse----eval_chunk_1",
        "text": "니다. 평가 모드에선 배치 정규화 혹은 드롭아웃과 같은 모듈들이 학습 모드일때와 다르게 동작합니다.\n평가 모드에선 배치 정규화는 배치 통계 대신 전체 모집단의 통계를 사용합니다. 그리고 드롭아웃 레이어들은 비활성화됩니다.\n모델을 평가하거나 추론을 할 때 일정한 행동을 보장하려면 `eval()` 함수를 사용하는 것은 매우 중요합니다. 아래는 예시 입니다\n```python\nimport torch\n\nmodel = MyModel()\nmodel.load_state_dict(torch.load('model.pth'))\nmodel.eval()\n\ninput_tensor = torch.tensor([1, 2, 3], dtype=torch.float32)\noutput_tensor = model(input_tensor)\n```\n\n## float()\n***\n\n1. `float()`: The `float()` function is used to convert a PyTorch tensor to a float tensor. It returns a new tensor with the same data but with floating-point data type. This can be useful when you want to perform operations that require floating-point precision.",
        "index": 1
      },
      {
        "id": "2024-10-31--PyTorch--float----fuse----eval_chunk_2",
        "text": "type. This can be useful when you want to perform operations that require floating-point precision. Here's an example:\n\n```python\nimport torch\n\nint_tensor = torch.tensor([1, 2, 3])\nfloat_tensor = int_tensor.float()\n\nprint(float_tensor)\n# Output: tensor([1., 2., 3.])\n```\n\n\n\nhttps://coffeedjimmy.github.io/pytorch/2019/11/05/pytorch_nograd_vs_train_eval/",
        "index": 2
      },
      {
        "id": "2024-10-31--PyTorch--float----fuse----eval_chunk_3",
        "text": "1., 2., 3.])\n```\n\n\n\nhttps://coffeedjimmy.github.io/pytorch/2019/11/05/pytorch_nograd_vs_train_eval/",
        "index": 3
      },
      {
        "id": "2024-10-31--PyTorch--float----fuse----eval_chunk_4",
        "text": "1., 2., 3.])\n```\n\n\n\nhttps://coffeedjimmy.github.io/pytorch/2019/11/05/pytorch_nograd_vs_train_eval/",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--PyTorch",
    "title": "[PyTorch] 모델 저장 및 불러오기(추론)",
    "path": "/2024/10/31/[PyTorch]-모델-저장-및-불러오기(추론)/",
    "categories": [
      "AI & CV",
      "PyTorch"
    ],
    "content": "https://pytorch.org/tutorials/beginner/saving_loading_models<br>\nPyTorch에서 추론(inference)를 위해 모델을 저장하고 불러오는데 2가지 방법<br>\n첫번째는 `state_dict`를 저장하고 불러오는 것, 두번째는 전체 모델 저장하는 것.<br>\n\n### state_dict 저장\n`torch.save()`함수를 사용해 모델의 `state_dict`를 저장하면 이후에 모델을 불러올 때 유연함을 크게 살릴 수 있음. 학습된 모델의 매개변수만을 저장하면되므로 <mark style=\"background: #ADCCFFA6;\">모델 저장 시 권장하는 방법</mark>.\n```python\n# 모델 저장\ntorch.save(model.state_dict(), \"model_state_dict.pt\")\n\n# 모델 불러오기\nmodel = TheModelClass(*args, **kwargs) # 동일한 모델 구조 초기화\nmodel.load_state_dict(torch.load(\"model_state_dict.pt\"))\nmodel.eval()\n```\n> 이 방법의 장점은 매개변수만 저장하기에 모델의 구조가 코드에 명시적으로 존재하며 모델의 상태를 저장하고 불러올 때 유용함. 또한, 이 방법은 모델 체크포인트를 저장하고, 학습 중인 모델의 상태를 저장하고, 나중에 학습을 계속하거나 학습된 모델을 공유할 때 유용함.\n\n### 전체 모델 저장\n모델 전체를 저장하고 불러올 때에는 Python의 pickle 모듈을 사용해 전체 모듈 저장. \n모델 클래스의 구조와 함께 모델의 매개변수를 저장함.\n```python\n# 모델 저장\ntorch.save(model, \"model_full.pt\")\n\n# 모델 불러오기\nmodel = torch.load(\"model_full.pt\")\nmodel.eval()\n```\n> 이 방법의 장점은 모델의 코드를 완전히 직렬화하므로, 원본 Python 코드에 대한 접근 없이 모델을 불러올 수 있음. 하지만, 이로인해 디렉토리 등 종속성을 가지게 됨. -> 코드의 유지보수가 어렵고, 람다 함수나 사용자 정의 계층 등 일부 요소들은 올바르게 저장되지 않을 수 있음.\n\n### Summary\n일반적으로는 `state_dict`를 사용하여 모델을 저장하고 불러오는 것이 권장되며, 이는 코드의 유지보수성을 향상시키고, 모델을 불러올 때 더 많은 유연성을 제공함. 전체 모델 저장은 간단한 사용에서는 편리하나, 실제로는 `state_dict`를 사용하는 것이 더 안정적이고 확장 가능함.\n",
    "date": "2024-10-31",
    "tags": [
      "PyTorch"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--PyTorch_chunk_0",
        "text": "[PyTorch] 모델 저장 및 불러오기(추론)\n\nhttps://pytorch.org/tutorials/beginner/saving_loading_models<br>\nPyTorch에서 추론(inference)를 위해 모델을 저장하고 불러오는데 2가지 방법<br>\n첫번째는 `state_dict`를 저장하고 불러오는 것, 두번째는 전체 모델 저장하는 것.<br>\n\n### state_dict 저장\n`torch.save()`함수를 사용해 모델의 `state_dict`를 저장하면 이후에 모델을 불러올 때 유연함을 크게 살릴 수 있음. 학습된 모델의 매개변수만을 저장하면되므로 <mark style=\"background: #ADCCFFA6;\">모델 저장 시 권장하는 방법</mark>.\n```python\n# 모델 저장\ntorch.save(model.state_dict(), \"model_state_dict.pt\")\n\n# 모델 불러오기\nmodel = TheModelClass(*args, **kwargs) # 동일한 모델 구조 초기화\nmodel.load_state_dict(torch.load(\"model_state_dict.pt\"))\nmodel.eval()\n```\n> 이 방법의 장점은 매개변수만 저장하기에 모델의 구조가 코드에 명시적으로 존재하며 모델의 상태를 저장하고 불러올 때 유용함.",
        "index": 0
      },
      {
        "id": "2024-10-31--PyTorch_chunk_1",
        "text": "_dict.pt\"))\nmodel.eval()\n```\n> 이 방법의 장점은 매개변수만 저장하기에 모델의 구조가 코드에 명시적으로 존재하며 모델의 상태를 저장하고 불러올 때 유용함. 또한, 이 방법은 모델 체크포인트를 저장하고, 학습 중인 모델의 상태를 저장하고, 나중에 학습을 계속하거나 학습된 모델을 공유할 때 유용함.\n\n### 전체 모델 저장\n모델 전체를 저장하고 불러올 때에는 Python의 pickle 모듈을 사용해 전체 모듈 저장. \n모델 클래스의 구조와 함께 모델의 매개변수를 저장함.\n```python\n# 모델 저장\ntorch.save(model, \"model_full.pt\")\n\n# 모델 불러오기\nmodel = torch.load(\"model_full.pt\")\nmodel.eval()\n```\n> 이 방법의 장점은 모델의 코드를 완전히 직렬화하므로, 원본 Python 코드에 대한 접근 없이 모델을 불러올 수 있음. 하지만, 이로인해 디렉토리 등 종속성을 가지게 됨. -> 코드의 유지보수가 어렵고, 람다 함수나 사용자 정의 계층 등 일부 요소들은 올바르게 저장되지 않을 수 있음.\n\n### Summary\n일반적으로는 `state_dict`를 사용하여 모델을 저장하고 불러오는 것이 권장되며, 이는 코드의 유지보수성을 향상시키고, 모델을 불러올 때 더 많은 유연성을 제공함. 전체 모델 저장은 간단한 사용에서는 편리하나, 실제로는 `state_dict`를 사용하는 것이 더 안정적이고 확장 가능함.",
        "index": 1
      },
      {
        "id": "2024-10-31--PyTorch_chunk_2",
        "text": "상시키고, 모델을 불러올 때 더 많은 유연성을 제공함. 전체 모델 저장은 간단한 사용에서는 편리하나, 실제로는 `state_dict`를 사용하는 것이 더 안정적이고 확장 가능함.",
        "index": 2
      },
      {
        "id": "2024-10-31--PyTorch_chunk_3",
        "text": "상시키고, 모델을 불러올 때 더 많은 유연성을 제공함. 전체 모델 저장은 간단한 사용에서는 편리하나, 실제로는 `state_dict`를 사용하는 것이 더 안정적이고 확장 가능함.",
        "index": 3
      },
      {
        "id": "2024-10-31--PyTorch_chunk_4",
        "text": "상시키고, 모델을 불러올 때 더 많은 유연성을 제공함. 전체 모델 저장은 간단한 사용에서는 편리하나, 실제로는 `state_dict`를 사용하는 것이 더 안정적이고 확장 가능함.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31--PyTorch",
    "title": "[PyTorch] 모델 저장 및 불러오기(체크포인트)",
    "path": "/2024/10/31/[PyTorch]-모델-저장-및-불러오기(체크포인트)/",
    "categories": [
      "AI & CV",
      "PyTorch"
    ],
    "content": "**추론** 또는 **학습의 재개**를 위해 체크포인트 모델을 저장하고 불러오기.<br>\n\n체크포인트를 저장할 때는 기존의 `state_dict`에 <mark style=\"background: #ADCCFFA6;\">추가 정보</mark>가 필요함. 모델 학습 중 <mark style=\"background: #ADCCFFA6;\">갱신되는 버퍼</mark>와 <mark style=\"background: #ADCCFFA6;\">매개변수들을 포함하는 옵티마이저</mark>의 state_dict를 함께 저장하는 것이 중요함. 이 외에도 중단 시점의 <mark style=\"background: #ADCCFFA6;\">에폭</mark>, 마지막으로 기록된 <mark style=\"background: #ADCCFFA6;\">학습 오차</mark>, 외부 `torch.nn.Embedding` 계층 등, 알고리즘에 따라 저장하고 싶은 항목 추가\n\n### 체크포인트 저장하기\n```python\n# 추가 정보\nEPOCH = 5\nPATH = \"model.pt\"\nLOSS = 0.4\n\ntorch.save({\n            'epoch': EPOCH,\n            'model_state_dict': net.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': LOSS,\n            }, PATH)\n```\n\n### 체크포인트 불러오기\n```python\nmodel = Net()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\ncheckpoint = torch.load(PATH)\nmodel.load_state_dict(checkpoint['model_state_dict'])\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel.eval()\n# - 또는 -\nmodel.train()\n```\n",
    "date": "2024-10-31",
    "tags": [
      "PyTorch"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31--PyTorch_chunk_0",
        "text": "[PyTorch] 모델 저장 및 불러오기(체크포인트)\n\n**추론** 또는 **학습의 재개**를 위해 체크포인트 모델을 저장하고 불러오기.<br>\n\n체크포인트를 저장할 때는 기존의 `state_dict`에 <mark style=\"background: #ADCCFFA6;\">추가 정보</mark>가 필요함. 모델 학습 중 <mark style=\"background: #ADCCFFA6;\">갱신되는 버퍼</mark>와 <mark style=\"background: #ADCCFFA6;\">매개변수들을 포함하는 옵티마이저</mark>의 state_dict를 함께 저장하는 것이 중요함.",
        "index": 0
      },
      {
        "id": "2024-10-31--PyTorch_chunk_1",
        "text": "</mark>와 <mark style=\"background: #ADCCFFA6;\">매개변수들을 포함하는 옵티마이저</mark>의 state_dict를 함께 저장하는 것이 중요함.",
        "index": 1
      },
      {
        "id": "2024-10-31--PyTorch_chunk_2",
        "text": "</mark>와 <mark style=\"background: #ADCCFFA6;\">매개변수들을 포함하는 옵티마이저</mark>의 state_dict를 함께 저장하는 것이 중요함.",
        "index": 2
      },
      {
        "id": "2024-10-31--PyTorch_chunk_3",
        "text": "</mark>와 <mark style=\"background: #ADCCFFA6;\">매개변수들을 포함하는 옵티마이저</mark>의 state_dict를 함께 저장하는 것이 중요함.",
        "index": 3
      },
      {
        "id": "2024-10-31--PyTorch_chunk_4",
        "text": "</mark>와 <mark style=\"background: #ADCCFFA6;\">매개변수들을 포함하는 옵티마이저</mark>의 state_dict를 함께 저장하는 것이 중요함.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-Setup-Components-Kubeflow",
    "title": "Setup Components(Kubeflow)",
    "path": "/2024/10/31/Setup-Components(Kubeflow)/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Setup Components\n---\n## **Kubeflow v1.4.0**\n\n설치 파일 준비\n\n```bash\ngit clone -b v1.4.0 <https://github.com/kubeflow/manifests.git>\ncd manifests\n```\n\n### 각 구성 요소별 설치\n\ngit repo에 일괄 설치 커맨드가 있으나, **권장하지 않음.**\n\n```bash\nwhile ! kustomize build example | kubectl apply -f -; do echo \"Retrying to apply resources\"; sleep 10; done\n```\n\n> 23.11.21) 일괄 설치의 경우 mysql pod가 생성되지않고 pending 상태에 머물러 이로 인해 의존성이 걸려있는 pod들이 생성되지 못해 Kubeflow 설치가 정상적으로 되지 않았음.\n\n설치하며 발생할 수 있는 이슈를 확인하는 등 **구성 요소별 설치 권장**\n\n### **Cert-manager**\n\n```bash\n# cert-manager 설치\nkustomize build common/cert-manager/cert-manager/base | kubectl apply -f -\n\n# cert-manager namespace의 3개의 pod가 모두 Running이 될 때 까지 기다리기.\nkubectl get pod -n cert-manager -w\n```\n\n- 모두 Running이 되었다면 아래와 같은 결과가 출력됨\n\n```bash\nNAME                                       READY   STATUS    RESTARTS   AGE\ncert-manager-7dd5854bb4-7nmpd              1/1     Running   0          2m10s\ncert-manager-cainjector-64c949654c-2scxr   1/1     Running   0          2m10s\ncert-manager-webhook-6b57b9b886-7q6g2      1/1     Running   0          2m10s\n```\n\n```bash\n# kubeflow-issuer 설치\nkustomize build common/cert-manager/kubeflow-issuer/base | kubectl apply -f -\n```\n\n⚠️ cert-manager-webhook 이슈\n\ncert-manager-webhook deployment가 Running이 아닌 경우에 발생합니다.\n\ncert-manager의 pod **3개 모두 running**임을 확인한 후 다시 명령어 실행\n\n`kustomize build common/cert-manager/kubeflow-issuer/base | kubectl apply -f -`\n\n### **Istio**\n\n```bash\n# istio관련 Custom Resource Definition을 설치합니다.\nkustomize build common/istio-1-9/istio-crds/base | kubectl apply -f -\n\n# istio namespace를 설치합니다\nkustomize build common/istio-1-9/istio-namespace/base | kubectl apply -f -\n\n# istio를 설치합니다\nkustomize build common/istio-1-9/istio-install/base | kubectl apply -f -\n\n# istio-system namespace의 2개의 pod가 모두 Running이 될 때까지 기다리기\nkubectl get po -n istio-system -w\n```\n\n- 모두 Running이 되었다면 아래와 같은 결과가 출력됨\n\n```bash\nNAME                                   READY   STATUS    RESTARTS   AGE\nistio-ingressgateway-79b665c95-xm22l   1/1     Running   0          16s\nistiod-86457659bb-5h58w                1/1     Running   0          16s\n```\n\n### Dex\n\n```bash\n# Dex 설치\nkustomize build common/dex/overlays/istio | kubectl apply -f -\n\n# auth namespace의 1개의 pod가 모두 Running이 될 때까지 기다리기\nkubectl get po -n auth -w\n```\n\n- 모두 Running이 되었다면 아래와 같은 결과가 출력됨\n\n```bash\nNAME                   READY   STATUS    RESTARTS   AGE\ndex-5ddf47d88d-458cs   1/1     Running   1          12s\n```\n\n### OIDC AuthService\n\n```bash\n# OIDC AuthService를 설치합니다\nkustomize build common/oidc-authservice/base | kubectl apply -f -\n\n# istio-system namespace의 3개의 pod가 모두 Running이 될 때까지 기다리기\nkubectl get po -n istio-system -w\n```\n\n- 모두 Running이 되었다면 아래와 같은 결과가 출력됨\n\n```bash\nNAME                                   READY   STATUS    RESTARTS   AGE\nauthservice-0                          1/1     Running   0          14s\nistio-ingressgateway-79b665c95-xm22l   1/1     Running   0          2m37s\nistiod-86457659bb-5h58w                1/1     Running   0          2m37s\n```\n\n⚠️ 만약 authservice-0 pod가 Pending에서 5분 이상 머물러있다면, 아래 링크 참고\n\n[](https://velog.io/@moey920/Kubeflow-authservice-0-permission-denied-%EC%97%90%EB%9F%AC-%ED%95%B4%EA%B2%B0)[https://velog.io/@moey920/Kubeflow-authservice-0-permission-denied-에러-해결](https://velog.io/@moey920/Kubeflow-authservice-0-permission-denied-%EC%97%90%EB%9F%AC-%ED%95%B4%EA%B2%B0)\n\n### Kubeflow Namespace\n\n```bash\n# kubeflow namespace를 생성합니다\nkustomize build common/kubeflow-namespace/base | kubectl apply -f -\n\n# kubeflow namespace를 조회합니다.\nkubectl get ns kubeflow\n```\n\n- 정상적으로 생성되면 아래와 같은 결과가 출력됨\n\n```bash\nNAME       STATUS   AGE\nkubeflow   Active   8s\n```\n\n### Kubeflow Roles\n\n```bash\n# kubeflow-roles를 설치합니다\nkustomize build common/kubeflow-roles/base | kubectl apply -f -\n\n# 생성한 kubeflow-roles를 조회합니다. 6개의 cluster role이 출력되어야함.\nkubectl get clusterrole | grep kubeflow\n```\n\n### Kubeflow Istio Resources\n\n```bash\n# kubeflow-istio-resources를 설치합니다\nkustomize build common/istio-1-9/kubeflow-istio-resources/base | kubectl apply -f -\n\n# 생성한 kubeflow roles를 조회합니다. 3개의 cluster role이 출력되어야함.\nkubectl get clusterrole | grep kubeflow-istio\n```\n\nKubeflow namespace에 gateway가 정상적으로 설치되었는지 확인합니다.\n\n```bash\nkubectl get gateway -n kubeflow\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\nNAME               AGE\nkubeflow-gateway   31s\n```\n\n### Kubeflow Pipelines\n\n```bash\n# kubeflow pipelines를 설치합니다\nkustomize build apps/pipeline/upstream/env/platform-agnostic-multi-user | kubectl apply -f -\n```\n\n설치 순서의 의존성이 있는 리소스 존재. 아래와 같은 에러가 발생할 수 있음.\n\n```bash\n\"error: unable to recognize \"STDIN\": no matches for kind \"CompositeController\" in version \"metacontroller.k8s.io/v1alpha1\"\"\n```\n\n위 에러 발생 시 10초 기다린 후 다시 설치 명령 실행\n\n`kustomize build apps/pipeline/upstream/env/platform-agnostic-multi-user | kubectl apply -f -`\n\n정상적으로 설치되었는지 확인 16개의 pod가 모두 Running이 될 때까지 기다림\n\n```bash\nkubectl get po -n kubeflow -w\n```\n\n```bash\nNAME                                                     READY   STATUS    RESTARTS   AGE\ncache-deployer-deployment-79fdf9c5c9-bjnbg               2/2     Running   1          5m3s\ncache-server-5bdf4f4457-48gbp                            2/2     Running   0          5m3s\nkubeflow-pipelines-profile-controller-7b947f4748-8d26b   1/1     Running   0          5m3s\nmetacontroller-0                                         1/1     Running   0          5m3s\nmetadata-envoy-deployment-5b4856dd5-xtlkd                1/1     Running   0          5m3s\nmetadata-grpc-deployment-6b5685488-kwvv7                 2/2     Running   3          5m3s\nmetadata-writer-548bd879bb-zjkcn                         2/2     Running   1          5m3s\nminio-5b65df66c9-k5gzg                                   2/2     Running   0          5m3s\nml-pipeline-8c4b99589-85jw6                              2/2     Running   1          5m3s\nml-pipeline-persistenceagent-d6bdc77bd-ssxrv             2/2     Running   0          5m3s\nml-pipeline-scheduledworkflow-5db54d75c5-zk2cw           2/2     Running   0          5m2s\nml-pipeline-ui-5bd8d6dc84-j7wqr                          2/2     Running   0          5m2s\nml-pipeline-viewer-crd-68fb5f4d58-mbcbg                  2/2     Running   1          5m2s\nml-pipeline-visualizationserver-8476b5c645-wljfm         2/2     Running   0          5m2s\nmysql-f7b9b7dd4-xfnw4                                    2/2     Running   0          5m2s\nworkflow-controller-5cbbb49bd8-5zrwx                     2/2     Running   1          5m2s\n```\n\n- 추가로 ml-pipeline UI가 정상적으로 접속되는지 확인\n\n```bash\nkubectl port-forward svc/ml-pipeline-ui -n kubeflow 8888:80\n```\n\n[http://localhost:8888/#/pipelines/](http://localhost:8888/#/pipelines/) 경로에 접속합니다.\n\n![Untitled](/assets/img/kubeflow/kube001.png)\n\n### Katib\n\n```bash\n# Katib을 설치합니다.\nkustomize build apps/katib/upstream/installs/katib-with-kubeflow | kubectl apply -f -\n\n# 4개의 pod가 Running이 될 때까지 기다립니다.\nkubectl get po -n kubeflow | grep katib\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\nkatib-controller-68c47fbf8b-b985z                        1/1     Running   0          82s\nkatib-db-manager-6c948b6b76-2d9gr                        1/1     Running   0          82s\nkatib-mysql-7894994f88-scs62                             1/1     Running   0          82s\nkatib-ui-64bb96d5bf-d89kp                                1/1     Running   0          82s\n```\n\n- 추가로 katib UI가 정상적으로 접속되는지 확인\n\n```bash\nkubectl port-forward svc/katib-ui -n kubeflow 8081:80\n```\n\n[http://localhost:8081/katib/](http://localhost:8081/katib/) 경로에 접속합니다.\n\n![Untitled](/assets/img/kubeflow/kube002.png)\n\n### Central Dashboard\n\n```bash\n# Central Dashboard를 설치합니다\nkustomize build apps/centraldashboard/upstream/overlays/istio | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep centraldashboard\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\ncentraldashboard-8fc7d8cc-xl7ts                          1/1     Running   0          52s\n```\n\n- 추가로 Central Dashboard UI가 정상적으로 접속되는지 확인\n\n```bash\nkubectl port-forward svc/centraldashboard -n kubeflow 8082:80\n```\n\n[http://localhost:8082/](http://localhost:8082/) 경로에 접속합니다\n\n![Untitled](/assets/img/kubeflow/kube003.png)\n\n### Admission Webhook\n\n```bash\n# Admission Webhook을 설치합니다\nkustomize build apps/admission-webhook/upstream/overlays/cert-manager | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep admission-webhook\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\nadmission-webhook-deployment-667bd68d94-2hhrx            1/1     Running   0          11s\n```\n\n### Notebooks & Jupyter Web APP\n\n```bash\n# Notebook controller를 설치합니다\nkustomize build apps/jupyter/notebook-controller/upstream/overlays/kubeflow | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep notebook-controller\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\nnotebook-controller-deployment-75b4f7b578-w4d4l          1/1     Running   0          105s\n```\n\n```bash\n# Jupyter Web App를 설치합니다\nkustomize build apps/jupyter/jupyter-web-app/upstream/overlays/istio | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow | grep jupyter-web-app\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\njupyter-web-app-deployment-6f744fbc54-p27ts              1/1     Running   0          2m\n```\n\n### Profiles + KFAM\n\n```bash\n# Profile controller를 설치합니다\nkustomize build apps/profiles/upstream/overlays/kubeflow | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep profiles-deployment\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\nprofiles-deployment-89f7d88b-qsnrd                       2/2     Running   0          42s\n```\n\n### Volumes Web App\n\n```bash\n# Volumes Web APP를 설치합니다\nkustomize build apps/volumes-web-app/upstream/overlays/istio | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep volumes-web-app\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\nvolumes-web-app-deployment-8589d664cc-62svl              1/1     Running   0          27s\n```\n\n### Tensorboard & Tensorboard Web App\n\n```bash\n# Tensorboard Web App를 설치합니다\nkustomize build apps/tensorboard/tensorboards-web-app/upstream/overlays/istio | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow | grep tensorboards-web-app\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\ntensorboards-web-app-deployment-6ff79b7f44-qbzmw            1/1     Running             0          22s\n```\n\n```bash\n# Tensorboard Controller를 설치합니다\nkustomize build apps/tensorboard/tensorboard-controller/upstream/overlays/kubeflow | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep tensorboard-controller\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\ntensorboard-controller-controller-manager-954b7c544-vjpzj   3/3     Running   1          73s\n```\n\n### Training Operator\n\n```bash\n# Training Operator를 설치합니다\nkustomize build apps/training-operator/upstream/overlays/kubeflow | kubectl apply -f -\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get po -n kubeflow -w | grep training-operator\n```\n\n- 정상적으로 설치되었다면 아래와 같은 메세지가 출력됨\n\n```bash\ntraining-operator-7d98f9dd88-6887f                          1/1     Running   0          28s\n```\n\n### User Namespace\n\nKubeflow의 사용을 위해, 사용할 User의 Ubeflow Profile을 생성합니다.\n\n```bash\nkustomize build common/user-namespace/base | kubectl apply -f -\n```\n\n- 정상적으로 수행되면 아래와 같은 메세지가 출력됨\n\n```bash\nconfigmap/default-install-config-9h2h2b6hbk created\nprofile.kubeflow.org/kubeflow-user-example-com created\n```\n\n## 정상 설치 확인\n\n```bash\nkubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80\n```\n\n[http://localhost:8080/에](http://localhost:8080/%EC%97%90) 접속합니다.\n\n![Untitled](/assets/img/kubeflow/kube004.png)\n\nEmail Address : `user@example.com`\n\nPassword : `12341234`\n\n![Untitled](/assets/img/kubeflow/kube005.png)\n",
    "date": "2024-10-31",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Setup-Components-Kubeflow_chunk_0",
        "text": "Setup Components(Kubeflow)\n\n# Setup Components\n---\n## **Kubeflow v1.4.0**\n\n설치 파일 준비\n\n```bash\ngit clone -b v1.4.0 <https://github.com/kubeflow/manifests.git>\ncd manifests\n```\n\n### 각 구성 요소별 설치\n\ngit repo에 일괄 설치 커맨드가 있으나, **권장하지 않음.**\n\n```bash\nwhile !",
        "index": 0
      },
      {
        "id": "2024-10-31-Setup-Components-Kubeflow_chunk_1",
        "text": "sts.git>\ncd manifests\n```\n\n### 각 구성 요소별 설치\n\ngit repo에 일괄 설치 커맨드가 있으나, **권장하지 않음.**\n\n```bash\nwhile !",
        "index": 1
      },
      {
        "id": "2024-10-31-Setup-Components-Kubeflow_chunk_2",
        "text": "sts.git>\ncd manifests\n```\n\n### 각 구성 요소별 설치\n\ngit repo에 일괄 설치 커맨드가 있으나, **권장하지 않음.**\n\n```bash\nwhile !",
        "index": 2
      },
      {
        "id": "2024-10-31-Setup-Components-Kubeflow_chunk_3",
        "text": "sts.git>\ncd manifests\n```\n\n### 각 구성 요소별 설치\n\ngit repo에 일괄 설치 커맨드가 있으나, **권장하지 않음.**\n\n```bash\nwhile !",
        "index": 3
      },
      {
        "id": "2024-10-31-Setup-Components-Kubeflow_chunk_4",
        "text": "sts.git>\ncd manifests\n```\n\n### 각 구성 요소별 설치\n\ngit repo에 일괄 설치 커맨드가 있으나, **권장하지 않음.**\n\n```bash\nwhile !",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-Setup-Kubernetes",
    "title": "Setup Kubernetes",
    "path": "/2024/10/31/Setup-Kubernetes/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Setup Kubernetes\n---\n## Setup Kubernetes Cluster\n\n**k3s** : 쿠버네티스 클러스터를 쉽게 구축할 수 있음\n**kubeadm** : 프로덕션 레벨의 클러스터 구축. 공식적으로 지원하는 도구\n**minikube** : 다른 쿠버네티스를 add-on 형식으로 쉽게 설치할 수 있음\n\n## Install Prerequisite\n**apt 패키지 설치**\n클라이언트와 클러스터의 원활한 통신을 위해 포트포워딩 사용.\n\n```bash\nsudo apt-get update\nsudo apt-get install -y socat\n```\n\n**도커 설치**\n(본 문서에서는 다루지 않음)\n\n**Swap 메모리 끄기**\nkubelet의 정상 동작을 위해 클러스터 노드에서 swap을 꺼야함.\n\n```bash\nsudo sed -i '/ swap / s/^\\\\(.*\\\\)$/#\\\\1/g' /etc/fstab\nsudo swapoff -a\n```\n\n**Kubectl 설치(클라이언트 노드)**\nkubectl은 쿠버네티스 클러스터에 API를 요청할 때 사용하는 클라이언트 툴.\n\n```bash\n# kubectl v1.21.7 Download\ncurl -LO <https://dl.k8s.io/release/v1.21.7/bin/linux/amd64/kubectl>\n\n# kubectl 사용을 위해 권한과 위치 변경\nsudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl\n\n# 정상 설치 확인\nkubectl version --client\n\n# 아래와 같은 메시지가 보이면 정상 설치됨\nClient Version: version.Info{Major:\"1\", Minor:\"21\", GitVersion:\"v1.21.7\", GitCommit:\"1f86634ff08f37e54e8bfcd86bc90b61c98f84d4\", GitTreeState:\"clean\", BuildDate:\"2021-11-17T14:41:19Z\", GoVersion:\"go1.16.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n```\n\n## Minikube\n**Minikube 설치**\n```bash\n# 설치\nwget <https://github.com/kubernetes/minikube/releases/download/v1.24.0/minikube-linux-amd64>\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n\n# 정상 설치 확인\nminikube version\n\n# 아래와 같은 메시지가 보이면 정상 설치됨\nminikube version: v1.24.0\ncommit: 76b94fb3c4e8ac5062daf70d60cf03ddcc0a741b\n```\n\n### 쿠버네티스 클러스터 셋업\n\nMinikube를 활용해 클러스터 구축. GPU의 원활한 사용과 클러스터-클라이언트 간 통신을 편하게 수행하기 위해, `driver=none`\n`driver=none` 옵션은 root user로 실행해야 함.\n\n```bash\nsudo su\n\n# 클러스터 생성\nminikube start --driver=none \\\\\n  --kubernetes-version=v1.21.7 \\\\\n  --extra-config=apiserver.service-account-signing-key-file=/var/lib/minikube/certs/sa.key \\\\\n  --extra-config=apiserver.service-account-issuer=kubernetes.default.svc\n\n# 미사용 add-on 비활성화\nminikube addons disable storage-provisioner\nminikube addons disable default-storageclass\n```\n\n### 쿠버네티스 클라이언트 셋업\n**클라이언트**와 **클러스터** 노드가 분리되지 않은 경우 root user로 모든 작업을 진행해야 함.\n**클라이언트**와 **클러스터** 노드가 분리된 경우, k8s의 관리자 인증 정보를 **클라이언트**로 가져옵니다.\n\n```bash\n# 클러스터 노드\nminikube kubectl -- config view --flatten\n```\n\n- 출력 예시\n    \n    ```bash\n    apiVersion: v1\n    clusters:\n    - cluster:\n        certificate-authority-data: LS0...생략==\n        extensions:\n        - extension:\n            last-update: Tue, 21 Nov 2023 16:49:33 KST\n            provider: minikube.sigs.k8s.io\n            version: v1.24.0\n          name: cluster_info\n        server: <https://192.168.1.87:8443>\n      name: minikube\n    contexts:\n    - context:\n        cluster: minikube\n        extensions:\n        - extension:\n            last-update: Tue, 21 Nov 2023 16:49:33 KST\n            provider: minikube.sigs.k8s.io\n            version: v1.24.0\n          name: context_info\n        namespace: default\n        user: minikube\n      name: minikube\n    current-context: minikube\n    kind: Config\n    preferences: {}\n    users:\n    - name: minikube\n      user:\n        client-certificate-data: LS0...생략==\n        client-key-data: LS0t...생략==\n    ```\n    \n\n```bash\n# 클라이언트 노드\nmkdir -p /home/$USER/.kube\n\n# 클러스터 노드에서 출력한 정보 붙여넣기\nvi /home/$USER/.kube/config\n```\n\n**정상 설치 확인**\n\n```bash\nkubectl get nodes -o wide\n\n# 아래와 같은 출력이 보이면 정상 설치\nNAME        STATUS   ROLES                  AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME\ngyu         Ready    control-plane,master   18h   v1.21.7   192.168.1.87   <none>        Ubuntu 22.04.3 LTS   6.2.0-36-generic   docker://24.0.7\n```\n\n## Install Kubernetes Modules(클라이언트 노드)\n\n아래 모듈들은 모두 **클라이언트 노드**에서 진행\n\n### Helm\nHelm은 k8s 패키지와 관련된 자원을 한 번에 배포하고 관리할 수 있게 도와주는 패키지 매니징 도구\n\n```bash\n# 다운로드\nwget <https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz>\n\n# 설치\ntar -zxvf helm-v3.7.1-linux-amd64.tar.gz\nsudo mv linux-amd64/helm /usr/local/bin/helm\n\n# 정상 설치 확인\nhelm help\n```\n\n### Kustomize\nkustomize 또한 여러 k8s 리소스를 한 번에 배포하고 관리할 수 있게 도와주는 패키지 매니징 도구\n\n```bash\n# 다운로드(Linux amd64)\nwget <https://github.com/kubernetes-sigs/kustomize/releases/download/kustomize%2Fv3.10.0/kustomize_v3.10.0_linux_amd64.tar.gz>\n\n# 설치\ntar -zxvf kustomize_v3.10.0_linux_amd64.tar.gz\nsudo mv kustomize /usr/local/bin/kustomize\n\n# 정상 설치 확인\nkustomize help\n```\n\n### CSI Plugin : Local Path Provisioner\nCSI Plugin은 k8s 내의 스토리지를 담당하는 모듈.\n\n```bash\n# 설치\nkubectl apply -f <https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.20/deploy/local-path-storage.yaml>\n```\n\n```bash\n# pod이 Running인지 확인\nkubectl -n local-path-storage get pod\n\n# Running이 되었다면 default storage class로 변경\nkubectl patch storageclass local-path  -p '{\"metadata\": {\"annotations\":{\"storageclass.kubernetes.io/is-default-class\":\"true\"}}}'\n\n# default storage class로 설정되었는지 확인\nkubectl get sc\n```\n\n## Setup GPU\n\n쿠버네티스 및 Kubeflow 등 클러스터에서 GPU를 사용하기 위해\n\n**Nvidia Driver 설치**\n(본 문서에서는 다루지 않음)\n\n**Nvidia-Docker 설치**\n(본 문서에서는 다루지 않음)\n\n### **Nvidia-Docker를 Default Container Runtime으로 설정**\n`/etc/docker/daemon.json` 파일 수정\n\n```bash\nsudo vi /etc/docker/daemon.json\n```\n\n```json\n{\n  \"default-runtime\": \"nvidia\",\n  \"runtimes\": {\n      \"nvidia\": {\n          \"path\": \"nvidia-container-runtime\",\n          \"runtimeArgs\": []\n  }\n  }\n}\n```\n\n```bash\n# 파일 수정 후 Docker 재시작\nsudo systemctl daemon-reload\nsudo service docker start\n\n# 변경 사항 반영 확인\nsudo docker info |grep nvidia\n```\n\n### Nvidia-Device-Plugin\n\n```bash\n# nvidia-device-plugin daemonet을 생성합니다.\nkubectl create -f <https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.10.0/nvidia-device-plugin.yml>\n\n# pod이 Running 상태인지 확인\nkubectl get pod -n kube-system | grep nvidia\n\n# Running 상태가 되었다면 GPU가 사용가능하도록 설정되었는지 확인\nkubectl get nodes \"-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\\\\.com/gpu\"\n```\n\n정상적으로 설정 되었다면 아래와 같은 메시지가 출력됩니다.\n\n```bash\nNAME        GPU\ngyu         1\n```\n",
    "date": "2024-10-31",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Setup-Kubernetes_chunk_0",
        "text": "Setup Kubernetes\n\n# Setup Kubernetes\n---\n## Setup Kubernetes Cluster\n\n**k3s** : 쿠버네티스 클러스터를 쉽게 구축할 수 있음\n**kubeadm** : 프로덕션 레벨의 클러스터 구축.",
        "index": 0
      },
      {
        "id": "2024-10-31-Setup-Kubernetes_chunk_1",
        "text": "---\n## Setup Kubernetes Cluster\n\n**k3s** : 쿠버네티스 클러스터를 쉽게 구축할 수 있음\n**kubeadm** : 프로덕션 레벨의 클러스터 구축.",
        "index": 1
      },
      {
        "id": "2024-10-31-Setup-Kubernetes_chunk_2",
        "text": "---\n## Setup Kubernetes Cluster\n\n**k3s** : 쿠버네티스 클러스터를 쉽게 구축할 수 있음\n**kubeadm** : 프로덕션 레벨의 클러스터 구축.",
        "index": 2
      },
      {
        "id": "2024-10-31-Setup-Kubernetes_chunk_3",
        "text": "---\n## Setup Kubernetes Cluster\n\n**k3s** : 쿠버네티스 클러스터를 쉽게 구축할 수 있음\n**kubeadm** : 프로덕션 레벨의 클러스터 구축.",
        "index": 3
      },
      {
        "id": "2024-10-31-Setup-Kubernetes_chunk_4",
        "text": "---\n## Setup Kubernetes Cluster\n\n**k3s** : 쿠버네티스 클러스터를 쉽게 구축할 수 있음\n**kubeadm** : 프로덕션 레벨의 클러스터 구축.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-Setup-Components-Seldon-core",
    "title": "Setup Components(Seldon-core)",
    "path": "/2024/10/31/Setup-Components(Seldon-core)/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Setup Components\n---\nSeldon-Core는 쿠버네티스 환경에서 머신러닝 모델을 배포하고 관리할 수 있는 오픈소스 프레임워크\n\n## Install Seldon-Core\n\nSeldon-Core를 사용하기 위해서는 쿠버네티스의 인그레스(Ingress)를 담당하는 Ambassador혹은 Istio 모듈이 필요함.\n\n본 문서에서는 Ambassador를 사용해 Seldon-Core를 사용\n\n### Ambassador - Helm Repository 추가\n\n```bash\nhelm repo add datawire <https://www.getambassador.io>\n```\n\n- 출력\n\n```bash\n\"datawire\" has been added to your repositories\n```\n\n### Helm Repository 업데이트\n\n```bash\nhelm repo update\n```\n\n- 출력\n\n```bash\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete. ⎈Happy Helming!⎈\n```\n\n### Ambassador - Helm Install\n\n```bash\n# ambassador Chart 6.9.3 버전을 설치합니다\nhelm install ambassador datawire/ambassador \\\\\n  --namespace seldon-system \\\\\n  --create-namespace \\\\\n  --set image.repository=quay.io/datawire/ambassador \\\\\n  --set enableAES=false \\\\\n  --set crds.keep=false \\\\\n  --version 6.9.3\n\n# 4개의 pod가 Running이 될 때까지 기다림\nkubectl get pod -n seldon-system -w\n```\n\n- 다음과 같은 메세지가 출력되어야 합니다.\n\n```bash\n생략...\n\nW1206 17:01:36.026326   26635 warnings.go:70] rbac.authorization.k8s.io/v1beta1 Role is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 Role\nW1206 17:01:36.029764   26635 warnings.go:70] rbac.authorization.k8s.io/v1beta1 RoleBinding is deprecated in v1.17+, unavailable in v1.22+; use rbac.authorization.k8s.io/v1 RoleBinding\nNAME: ambassador\nLAST DEPLOYED: Mon Dec  6 17:01:34 2021\nNAMESPACE: seldon-system\nSTATUS: deployed\nREVISION: 1\nNOTES:\n-------------------------------------------------------------------------------\n  Congratulations! You've successfully installed Ambassador!\n\n-------------------------------------------------------------------------------\nTo get the IP address of Ambassador, run the following commands:\nNOTE: It may take a few minutes for the LoadBalancer IP to be available.\n     You can watch the status of by running 'kubectl get svc -w  --namespace seldon-system ambassador'\n\n  On GKE/Azure:\n  export SERVICE_IP=$(kubectl get svc --namespace seldon-system ambassador -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\n  On AWS:\n  export SERVICE_IP=$(kubectl get svc --namespace seldon-system ambassador -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')\n\n  echo http://$SERVICE_IP:\n\nFor help, visit our Slack at <http://a8r.io/Slack> or view the documentation online at <https://www.getambassador.io>.\n```\n\n```bash\nambassador-7f596c8b57-4s9xh                  1/1     Running   0          7m15s\nambassador-7f596c8b57-dt6lr                  1/1     Running   0          7m15s\nambassador-7f596c8b57-h5l6f                  1/1     Running   0          7m15s\nambassador-agent-77bccdfcd5-d5jxj            1/1     Running   0          7m15s\n```\n\n### Seldon-Core - Helm Install\n\n```bash\n# seldon-core operator chart 1.11.2버전을 설치합니다\nhelm install seldon-core seldon-core-operator \\\\\n    --repo <https://storage.googleapis.com/seldon-charts> \\\\\n    --namespace seldon-system \\\\\n    --set usageMetrics.enabled=true \\\\\n    --set ambassador.enabled=true \\\\\n    --version 1.11.2\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get pod -n seldon-system -w | grep seldon-controller\n```\n\n- 다음와 같은 메세지가 출력되어야 합니다\n\n```bash\n생략...\n\nW1206 17:05:38.336391   28181 warnings.go:70] admissionregistration.k8s.io/v1beta1 ValidatingWebhookConfiguration is deprecated in v1.16+, unavailable in v1.22+; use admissionregistration.k8s.io/v1 ValidatingWebhookConfiguration\nNAME: seldon-core\nLAST DEPLOYED: Mon Dec  6 17:05:34 2021\nNAMESPACE: seldon-system\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\n```\n\n```bash\nseldon-controller-manager-8457b8b5c7-r2frm   1/1     Running   0          2m22s\n```\n",
    "date": "2024-10-31",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Setup-Components-Seldon-core_chunk_0",
        "text": "Setup Components(Seldon-core)\n\n# Setup Components\n---\nSeldon-Core는 쿠버네티스 환경에서 머신러닝 모델을 배포하고 관리할 수 있는 오픈소스 프레임워크\n\n## Install Seldon-Core\n\nSeldon-Core를 사용하기 위해서는 쿠버네티스의 인그레스(Ingress)를 담당하는 Ambassador혹은 Istio 모듈이 필요함.\n\n본 문서에서는 Ambassador를 사용해 Seldon-Core를 사용\n\n### Ambassador - Helm Repository 추가\n\n```bash\nhelm repo add datawire <https://www.getambassador.io>\n```\n\n- 출력\n\n```bash\n\"datawire\" has been added to your repositories\n```\n\n### Helm Repository 업데이트\n\n```bash\nhelm repo update\n```\n\n- 출력\n\n```bash\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 0
      },
      {
        "id": "2024-10-31-Setup-Components-Seldon-core_chunk_1",
        "text": "repositories...\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 1
      },
      {
        "id": "2024-10-31-Setup-Components-Seldon-core_chunk_2",
        "text": "repositories...\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 2
      },
      {
        "id": "2024-10-31-Setup-Components-Seldon-core_chunk_3",
        "text": "repositories...\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 3
      },
      {
        "id": "2024-10-31-Setup-Components-Seldon-core_chunk_4",
        "text": "repositories...\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-Setup-Components-Prometheus---Grafana",
    "title": "Setup Components(Prometheus & Grafana)",
    "path": "/2024/10/31/Setup-Components(Prometheus-&-Grafana)/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Setup Components\n---\n프로메테우스는 다양한 대상으로부터 Metric을 수집하는 도구\n그라파나는 모인 데이터를 시각화하는 것을 도와주는 도구\n\n이번 페이지에서는 쿠버네티스 클러스터에 프로메테우스와 그라파나를 설치한 뒤, Seldon-Core로 생성한 SeldonDeployment로 API 요청을 보내 정상적으로 Metrics가 수집되는지 확인\n\n## Install Prometheus & Grafana\n\n### Helm Repository 추가\n\n```bash\nhelm repo add seldonio <https://storage.googleapis.com/seldon-charts>\n```\n\n- 출력\n\n```bash\n\"seldonio\" has been added to your repositories\n```\n\n### Helm Repository 업데이트\n\n```bash\nhelm repo update\n```\n\n- 출력\n\n```bash\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"seldonio\" chart repository\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete. ⎈Happy Helming!⎈\n```\n\n### Helm Install\n\n```bash\n# seldon-core-analytics Helm Chart 1.12.0버전을 설치합니다\nhelm install seldon-core-analytics seldonio/seldon-core-analytics \\\\\n  --namespace seldon-system \\\\\n  --version 1.12.0\n\n# 6개의 pod가 Running이 될 때까지 기다림\nkubectl get pod -n seldon-system -w | grep seldon-core-analytics\n```\n\n- 출력\n\n```bash\n생략...\nNAME: seldon-core-analytics\nLAST DEPLOYED: Tue Dec 14 18:29:38 2021\nNAMESPACE: seldon-system\nSTATUS: deployed\nREVISION: 1\n```\n\n```bash\nseldon-core-analytics-grafana-657c956c88-ng8wn                  2/2     Running   0          114s\nseldon-core-analytics-kube-state-metrics-94bb6cb9-svs82         1/1     Running   0          114s\nseldon-core-analytics-prometheus-alertmanager-64cf7b8f5-nxbl8   2/2     Running   0          114s\nseldon-core-analytics-prometheus-node-exporter-5rrj5            1/1     Running   0          114s\nseldon-core-analytics-prometheus-pushgateway-8476474cff-sr4n6   1/1     Running   0          114s\nseldon-core-analytics-prometheus-seldon-685c664894-7cr45        2/2     Running   0          114s\n```\n\n## 정상 설치 확인\n\n그라파나에 정상적으로 접속이 되는지 확인.\n\n```bash\n# 클라이언트 노드에서 접속하기 위해, 포트포워딩\nkubectl port-forward svc/seldon-core-analytics-grafana -n seldon-system 8090:80\n```\n\n[http://localhost:8090/](http://localhost:8090/) 접속\n\n![Untitled](/assets/img/kubeflow/kube201.png)\n\n- Email or Username : `admin`\n- Password : `password`\n\n![Untitled](/assets/img/kubeflow/kube202.png)\n\n- 좌측의 대시보드 아이콘 클릭 → `Manage` 버튼 클릭\n\n**Kubernetes cluster monitoring (via Prometheus) v2**\n\n![Untitled](/assets/img/kubeflow/kube203.png)\n\n**Prediction Analytics**\n\n![Untitled](/assets/img/kubeflow/kube204.png)\n",
    "date": "2024-10-31",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Setup-Components-Prometheus---Grafana_chunk_0",
        "text": "Setup Components(Prometheus & Grafana)\n\n# Setup Components\n---\n프로메테우스는 다양한 대상으로부터 Metric을 수집하는 도구\n그라파나는 모인 데이터를 시각화하는 것을 도와주는 도구\n\n이번 페이지에서는 쿠버네티스 클러스터에 프로메테우스와 그라파나를 설치한 뒤, Seldon-Core로 생성한 SeldonDeployment로 API 요청을 보내 정상적으로 Metrics가 수집되는지 확인\n\n## Install Prometheus & Grafana\n\n### Helm Repository 추가\n\n```bash\nhelm repo add seldonio <https://storage.googleapis.com/seldon-charts>\n```\n\n- 출력\n\n```bash\n\"seldonio\" has been added to your repositories\n```\n\n### Helm Repository 업데이트\n\n```bash\nhelm repo update\n```\n\n- 출력\n\n```bash\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"seldonio\" chart repository\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 0
      },
      {
        "id": "2024-10-31-Setup-Components-Prometheus---Grafana_chunk_1",
        "text": "hart repository\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 1
      },
      {
        "id": "2024-10-31-Setup-Components-Prometheus---Grafana_chunk_2",
        "text": "hart repository\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 2
      },
      {
        "id": "2024-10-31-Setup-Components-Prometheus---Grafana_chunk_3",
        "text": "hart repository\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 3
      },
      {
        "id": "2024-10-31-Setup-Components-Prometheus---Grafana_chunk_4",
        "text": "hart repository\n...Successfully got an update from the \"datawire\" chart repository\nUpdate Complete.",
        "index": 4
      }
    ]
  },
  {
    "id": "2024-10-31-Setup-Components-MLflow-Tracking-Server",
    "title": "Setup Components(MLflow Tracking Server)",
    "path": "/2024/10/31/Setup-Components(MLflow-Tracking-Server)/",
    "categories": [
      "AI & CV",
      "Kubeflow",
      "MLOps/Kubeflow"
    ],
    "content": "# Setup Components\n---\nMLflow는 오픈소스 ML 실험 관리 도구입니다. MLflow는 실험 관리 용도 외에도 ML Model 패키징, ML 모델 배포 관리, ML 모델 저장과 같은 기능도 제공함.\n\nMLflow를 실험 관리 용도로 사용할 것.\n\nMLflow에서 관리하는 데이터를 저장하고 UI를 제공하는 MLflow Tracking Server를 쿠버네티스 클러스터에 배포해 사용 예정\n\n## Before Install MLflow Tracking Server\n\n### PostgreSQL DB 설치\n\nMLflow Tracking Server가 Backend Store로 사용할 용도의 DB를 쿠버네티스 클러스터에 배포합니다.\n\n```bash\n# mlflow-system namespace 생성\nkubectl create ns mlflow-system\n\n# postgresql DB를 mlflow-system namespace에 생성\nkubectl -n mlflow-system apply -f <https://raw.githubusercontent.com/mlops-for-all/helm-charts/b94b5fe4133f769c04b25068b98ccfa7a505aa60/mlflow/manifests/postgres.yaml>\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get pod -n mlflow-system -w |grep postgresql\n```\n\n- 정상적으로 실행되면 아래와 같은 메세지가 출력됨\n\n```bash\npostgresql-mlflow-7b9bc8c79f-srkh7   1/1     Running   0          38s\n```\n\n### Minio 설정\n\nMLflow Tracking Server가 Artifacts Store로 사용할 용도의 MInio는 이전 Kubeflow 설치 시 설치된 Minio를 활용함. 단, kubeflow와 분리하기 위해, 전용 버킷을 생성\n\n```bash\n# minio에 접속해 버킷을 생성하기 위해 포트포워딩\nkubectl port-forward svc/minio-service -n kubeflow 9000:9000\n```\n\n[http://localhost:9000/](http://localhost:9000/) 에 접속합니다.\n\n![Untitled](/assets/img/kubeflow/kube101.png)\n\n- Username : `minio`\n- Password : `minio123`\n\n우측 하단의 `+` 버튼을 클릭 → `Create Bucket` 클릭\n\n`Bucket Name`에 `mlflow`를 입력하여 버킷을 생성합니다.\n\n![Untitled](/assets/img/kubeflow/kube102.png)\n\n## Install MLflow Tracking Server\n\n### Helm Repository 추가\n\n```bash\nhelm repo add mlops-for-all <https://mlops-for-all.github.io/helm-charts>\n```\n\n- 출력\n\n```bash\n\"mlops-for-all\" has been added to your repositories\n```\n\n### Helm Repository 업데이트\n\n```bash\nhelm repo update\n```\n\n- 출력\n\n```bash\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \"mlops-for-all\" chart repository\nUpdate Complete. ⎈Happy Helming!⎈\n```\n\n### Helm Install\n\n```bash\n# mlflow-server Helm Chart 0.2.0 버전을 설치합니다\nhelm install mlflow-server mlops-for-all/mlflow-server \\\\\n  --namespace mlflow-system \\\\\n  --version 0.2.0\n\n# 1개의 pod가 Running이 될 때까지 기다림\nkubectl get pod -n mlflow-system -w | grep mlflow-server\n```\n\n<aside> 💡 **주의:** 위의 helm chart는 MLflow의 backend store와 artifacts store의 접속 정보를 minio와 postgresql 정보를 default로 하여 설치합니다.\n\n별개로 생성한 DB 혹은 Object Storage를 활용하고 싶은 경우, 아래 링크를 참고해 helm install 시 value를 따로 설정해 설치합니다. [https://github.com/mlops-for-all/helm-charts/tree/main/mlflow/chart](https://github.com/mlops-for-all/helm-charts/tree/main/mlflow/chart)\n\n</aside>\n\n- 정상적으로 설치되었다면 아래와 같은 메세지 출력\n\n```bash\nmlflow-server-ffd66d858-6hm62        1/1     Running   0          74s\n```\n\n## 정상 설치 확인\n\nMLflow Server에 정상적으로 접속되는지 확인\n\n우선 클라이언트 노드에서 접속하기 위해, 포트포워딩을 수행\n\n```bash\nkubectl port-forward svc/mlflow-server-service -n mlflow-system 5000:5000\n```\n\n[http://localhost:5000/](http://localhost:5000/) 에 접속\n\n![Untitled](/assets/img/kubeflow/kube103.png)\n",
    "date": "2024-10-31",
    "tags": [
      "MLOps",
      "Kubeflow"
    ],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2024-10-31-Setup-Components-MLflow-Tracking-Server_chunk_0",
        "text": "Setup Components(MLflow Tracking Server)\n\n# Setup Components\n---\nMLflow는 오픈소스 ML 실험 관리 도구입니다.",
        "index": 0
      },
      {
        "id": "2024-10-31-Setup-Components-MLflow-Tracking-Server_chunk_1",
        "text": "",
        "index": 1
      },
      {
        "id": "2024-10-31-Setup-Components-MLflow-Tracking-Server_chunk_2",
        "text": "",
        "index": 2
      },
      {
        "id": "2024-10-31-Setup-Components-MLflow-Tracking-Server_chunk_3",
        "text": "",
        "index": 3
      },
      {
        "id": "2024-10-31-Setup-Components-MLflow-Tracking-Server_chunk_4",
        "text": "",
        "index": 4
      }
    ]
  },
  {
    "id": "2000-11-30-First-Posting",
    "title": "안녕하세요 !",
    "path": "/2000/11/30/First-Posting/",
    "categories": [],
    "content": "## 😀 Profile\n\n안녕하세요! 노규헌입니다.  \n`하드웨어`를 `소프트웨어`로 똑똑하게 만들어주는 개발자가 되기 위해 노력합니다!\n\n---\n\n## 🛠️ SKILLS\n\n#### Programming Languages\n#### ![C](https://img.shields.io/badge/-C-A8B9CC?style=flat-square&logo=c&logoColor=white)     ![C++](https://img.shields.io/badge/-C++-00599C?style=flat-square&logo=cplusplus&logoColor=white)     ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)\n\n#### Frameworks & Tools\n\n#### ![OpenCV](https://img.shields.io/badge/-OpenCV-5C3EE8?style=flat-square&logo=opencv&logoColor=white)     ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)     ![ROS](https://img.shields.io/badge/-ROS-22314E?style=flat-square&logo=ros&logoColor=white)\n#### ![Docker](https://img.shields.io/badge/-Docker-2496ED?style=flat-square&logo=docker&logoColor=white)     ![Kubeflow](https://img.shields.io/badge/-Kubeflow-326CE5?style=flat-square&logo=kubeflow&logoColor=white)     ![Kubernetes](https://img.shields.io/badge/-Kubernetes-326CE5?style=flat-square&logo=kubernetes&logoColor=white)\n#### ![GitHub](https://img.shields.io/badge/-GitHub-181717?style=flat-square&logo=github&logoColor=white)     ![Ubuntu](https://img.shields.io/badge/-Ubuntu-E95420?style=flat-square&logo=ubuntu&logoColor=white)\n\n\n---\n## 🧑‍💻 Experience\n\n> #### '18.03 - '24.02 서울과학기술대학교 \n> - 전공 : 기계시스템디자인공학과   \n> - 심화 프로그램 : 기계설계자동화공학\n{: .highlight}\n\n> #### '22.01 - '23.07 ICES Lab 학부연구생 \n> - 자율운항선박 프로젝트 및 기타 연구 업무 보조\n{: .highlight}\n\n> #### '23.08 - '23.12 (주) 스탠스 SW 인턴\n> - Object Detection 데이터셋 구축, 모델 학습 및 평가  \n{: .highlight}\n\n> #### '24.07 - Present 삼성 청년 SW아카데미(SSAFY)<sup>12th</sup> \n> - 1학기 임베디드 트랙 (성적 우수)  \n> - 웹, 알고리즘, 임베디드 총 800시간 교육 수강  \n{: .highlight}\n\n---\n\n## 📂 Projects\n\n> #### '22.06 초음파센서를 활용한 2D-SLAM 프로젝트 ![C#](https://img.shields.io/badge/-C%23-239120?style=flat-square&logo=csharp&logoColor=white)     ![Arduino](https://img.shields.io/badge/-Arduino-00979D?style=flat-square&logo=arduino&logoColor=white)\n> - 초음파센서를 서보모터에 장착해 각도별 거리 획득. 좌표 변환 후 데이터 시각화\n> - **참고 링크**: [블로그 글](https://knowgyu.github.io/posts/%EC%95%84%EB%91%90%EC%9D%B4%EB%85%B8-%EC%B4%88%EC%9D%8C%ED%8C%8C-SLAM/)\n{: .highlight}\n\n> #### '22.07 - '22.08 Mediapipe를 활용한 부정행위 감독 프로그램 ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![Mediapipe](https://img.shields.io/badge/-Mediapipe-4285F4?style=flat-square&logo=google&logoColor=white)\n> - Zoom 프로그램에서 참여자 영상 획득 후, Mediapipe를 활용해 얼굴의 랜드마크를 추출하고 정면 응시 여부를 확인  \n{: .highlight}\n\n> #### '22.09 - '22.12 축구공 자동 공기 주입기 ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![Arduino](https://img.shields.io/badge/-Arduino-00979D?style=flat-square&logo=arduino&logoColor=white)     ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)\n> - RGB 카메라와 DC 모터 2개를 이용해 축구공의 공기주입구를 목표 위치로 제어하고, 리니어모터를 활용해 공기 주입기를 장착하는 시스템  \n{: .highlight}\n\n> #### '22.11 - '22.12 당구공 경로 생성 프로젝트 ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)\n> - RGB 카메라로 획득한 영상에서 당구공을 검출한 후, 이동 경로 생성  \n> - **참고 링크**: [블로그 글](https://knowgyu.github.io/posts/%EB%8B%B9%EA%B5%AC%EA%B3%B5-%EA%B2%BD%EB%A1%9C-%EC%83%9D%EC%84%B1-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/)\n{: .highlight}\n\n> #### '22.07 - '23.06 자율운항선박 프로젝트 ![C++](https://img.shields.io/badge/-C++-00599C?style=flat-square&logo=cplusplus&logoColor=white)     ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![ROS](https://img.shields.io/badge/-ROS-22314E?style=flat-square&logo=ros&logoColor=white)\n> - IMO 레벨 3 수준의 자율운항 선박(무인 경비선) 개발   \n>   Jetson 보드와 ST 보드, 그리고 GNSS와 LiDAR 센서를 활용해 수동운항 및 자율운항 구현  \n>   Adaptive Clustering 알고리즘과 Artificial Potential Field 알고리즘을 활용해 장애물 인식 및 회피 알고리즘 구현\n{: .highlight}\n\n> #### '23.08 - '23.11 지능형 CCTV 딥러닝 모델 개발 ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![PyTorch](https://img.shields.io/badge/-PyTorch-EE4C2C?style=flat-square&logo=pytorch&logoColor=white)\n> - Object Detection 모델을 개발하여 지능형 CCTV 시스템에 적용  \n{: .highlight}\n\n> #### '23.12 Kubeflow 파이프라인 구축 ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![Kubeflow](https://img.shields.io/badge/-Kubeflow-326CE5?style=flat-square&logo=kubeflow&logoColor=white)     ![Kubernetes](https://img.shields.io/badge/-Kubernetes-326CE5?style=flat-square&logo=kubernetes&logoColor=white)\n> - Minikube를 활용하여 온프레미스 환경에서 YOLOv8 모델 학습 및 평가를 위한 Kubeflow 파이프라인 구축  \n> - **참고 링크**: [블로그 글](https://knowgyu.github.io/categories/kubeflow/)\n{: .highlight}\n\n> #### '24.11 ArUco 마커를 활용한 자율주행 RC카 ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![Raspberry Pi](https://img.shields.io/badge/-Raspberry%20Pi-A22846?style=flat-square&logo=raspberrypi&logoColor=white)     ![Renesas](https://img.shields.io/badge/-Renesas-0077C8?style=flat-square&logo=renesas&logoColor=white)\n> - 라즈베리파이로 영상 처리 후 ArUco 마커를 인식하여 제어 명령을 생성하고, 르네사스 보드에서 명령을 받아 모터를 제어하는 자율주행 RC카  \n> - **참고 링크**: [블로그 글](https://knowgyu.github.io/posts/Aruco-%EB%A7%88%EC%BB%A4%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%9C%A8%EC%A3%BC%ED%96%89-RC%EC%B9%B4/)\n{: .highlight}\n\n> #### '25.01 - '25.02 AI 실버케어 로봇 영웅이 ![C++](https://img.shields.io/badge/-C++-00599C?style=flat-square&logo=cplusplus&logoColor=white)     ![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)     ![ROS](https://img.shields.io/badge/-ROS-22314E?style=flat-square&logo=ros&logoColor=white)\n> - 독거노인을 위한 로봇으로 주요 특징으로는 4가지 모니터링 기능 제공.\n> - 정신 건강 모니터링, 활력 징후 모니터링, 실시간 활동 모니터링, 주거 환경 모니터링\n> - Hector SLAM + ROS Navigation Stack을 활용해 실내 자율주행 기능 구현\n> - **참고 링크**: [블로그 글](https://knowgyu.github.io/categories/ros/)\n{: .highlight}\n",
    "date": "2000-11-30",
    "tags": [],
    "author": "knowgyu",
    "chunks": [
      {
        "id": "2000-11-30-First-Posting_chunk_0",
        "text": "안녕하세요 !\n\n## 😀 Profile\n\n안녕하세요! 노규헌입니다.",
        "index": 0
      },
      {
        "id": "2000-11-30-First-Posting_chunk_1",
        "text": "",
        "index": 1
      },
      {
        "id": "2000-11-30-First-Posting_chunk_2",
        "text": "",
        "index": 2
      },
      {
        "id": "2000-11-30-First-Posting_chunk_3",
        "text": "",
        "index": 3
      },
      {
        "id": "2000-11-30-First-Posting_chunk_4",
        "text": "",
        "index": 4
      }
    ]
  }
]